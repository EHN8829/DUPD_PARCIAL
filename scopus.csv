"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Affiliations","Authors with affiliations","Abstract","Author Keywords","Index Keywords","Molecular Sequence Numbers","Chemicals/CAS","Tradenames","Manufacturers","Funding Details","Funding Texts","References","Correspondence Address","Editors","Publisher","Sponsors","Conference name","Conference date","Conference location","Conference code","ISSN","ISBN","CODEN","PubMed ID","Language of Original Document","Abbreviated Source Title","Document Type","Publication Stage","Open Access","Source","EID"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14449 LNCS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177829395&partnerID=40&md5=2c68efa2f1a85a474ed80ce2170e721e","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","03029743","978-981998066-6","","","English","Lect. Notes Comput. Sci.","Conference review","Final","","Scopus","2-s2.0-85177829395"
"Apostolopoulos I.D.; Papathanasiou N.D.; Papandrianos N.I.; Papageorgiou E.I.; Panayiotakis G.S.","Apostolopoulos, Ioannis D. (57195641603); Papathanasiou, Nikolaos D. (23995562200); Papandrianos, Nikolaos I. (24779749100); Papageorgiou, Elpiniki I. (56429800100); Panayiotakis, George S. (7006755481)","57195641603; 23995562200; 24779749100; 56429800100; 7006755481","Deep Learning Assessment for Mining Important Medical Image Features of Various Modalities","2022","Diagnostics","12","10","2333","","","","1","10.3390/diagnostics12102333","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140777302&doi=10.3390%2fdiagnostics12102333&partnerID=40&md5=a89512a0ce1f2fb4400dbafd50a79d7c","Department of Medical Physics, School of Medicine, University of Patras, Rio, 26504, Greece; Laboratory of Nuclear Medicine, University Hospital of Patras, Rio, 26504, Greece; Department of Energy Systems, University of Thessaly, Gaiopolis Campus, Larisa, 41500, Greece","Apostolopoulos I.D., Department of Medical Physics, School of Medicine, University of Patras, Rio, 26504, Greece; Papathanasiou N.D., Laboratory of Nuclear Medicine, University Hospital of Patras, Rio, 26504, Greece; Papandrianos N.I., Department of Energy Systems, University of Thessaly, Gaiopolis Campus, Larisa, 41500, Greece; Papageorgiou E.I., Department of Energy Systems, University of Thessaly, Gaiopolis Campus, Larisa, 41500, Greece; Panayiotakis G.S., Department of Medical Physics, School of Medicine, University of Patras, Rio, 26504, Greece","Deep learning (DL) is a well-established pipeline for feature extraction in medical and nonmedical imaging tasks, such as object detection, segmentation, and classification. However, DL faces the issue of explainability, which prohibits reliable utilisation in everyday clinical practice. This study evaluates DL methods for their efficiency in revealing and suggesting potential image biomarkers. Eleven biomedical image datasets of various modalities are utilised, including SPECT, CT, photographs, microscopy, and X-ray. Seven state-of-the-art CNNs are employed and tuned to perform image classification in tasks. The main conclusion of the research is that DL reveals potential biomarkers in several cases, especially when the models are trained from scratch in domains where low-level features such as shapes and edges are not enough to make decisions. Furthermore, in some cases, device acquisition variations slightly affect the performance of DL models. © 2022 by the authors.","biomarkers; deep learning; feature extraction; medical imaging","area under the curve; Article; classification algorithm; clinical article; computer assisted tomography; congenital skin disease; convolutional neural network; coronary artery disease; coronavirus disease 2019; data mining; deep learning; diagnostic accuracy; diagnostic imaging; diagnostic value; disease marker; feature extraction; gradient weighted class activation mapping; human; image processing; lung nodule; myocardial perfusion imaging; photography; positron emission tomography-computed tomography; prostate cancer; radiography; residual neural network; sensitivity and specificity; single photon emission computed tomography; skin cancer","","","Discovery iQ3 sl16, GE Healthcare; Hawkey-4, GE Healthcare; Infinia, GE Healthcare","GE Healthcare; GE Healthcare; GE Healthcare","Second Call for H.F.R.I., (3656); Hellenic Foundation for Research and Innovation, ΕΛ.ΙΔ.Ε.Κ","The research project was supported by the Hellenic Foundation for Research and Innovation (H.F.R.I.) under the “Second Call for H.F.R.I. Research Projects to support Faculty Members & Researchers” (Project Number: 3656).","Beykikhoshk A., Quinn T.P., Lee S.C., Tran T., Venkatesh S., Deep TRIAGE: Interpretable and individualised biomarker scores using attention mechanism for the classification of breast cancer sub-types, BMC Med. Genom, 13, (2020); Jain D., Singh V., Feature selection and classification systems for chronic disease prediction: A review, Egypt. Inform. J, 19, pp. 179-189, (2018); Traverso A., Wee L., Dekker A., Gillies R., Repeatability and Reproducibility of Radiomic Features: A Systematic Review, Int. J. Radiat. Oncol. Biol. Phys, 102, pp. 1143-1158, (2018); Lambin P., Leijenaar R.T.H., Deist T.M., Peerlings J., de Jong E.E.C., van Timmeren J., Sanduleanu S., Larue R.T.H.M., Even A.J.G., Jochems A., Et al., Radiomics: The bridge between medical imaging and personalized medicine, Nat. Rev. Clin. Oncol, 14, pp. 749-762, (2017); Cano-Espinosa C., Gonzalez G., Washko G.R., Cazorla M., Estepar R.S.J., Biomarker Localization From Deep Learning Regression Networks, IEEE Trans. Med. Imaging, 39, pp. 2121-2132, (2020); Cole J.H., Poudel R.P.K., Tsagkrasoulis D., Caan M.W.A., Steves C., Spector T.D., Montana G., Predicting brain age with deep learning from raw imaging data results in a reliable and heritable biomarker, NeuroImage, 163, pp. 115-124, (2017); Eaton-Rosen Z., Bragman F., Bisdas S., Ourselin S., Cardoso M.J., Towards Safe Deep Learning: Accurately Quantifying Biomarker Uncertainty in Neural Network Predictions, Medical Image Computing and Computer Assisted Intervention–MICCAI 2018, pp. 691-699, (2018); Okuda K., Watanabe N., Hashimoto M., Doai M., Kawai Y., Takahashi T., Arikawa T., Ooiso K., Sunatani Y., Iwabuchi K., Et al., Preliminary Quantitative Evaluation of Radiation-Induced DNA Damage in Peripheral Blood Lymphocytes after Cardiac Dual-Isotope Imaging, Appl. Radiat. Isot, 154, (2019); Putin E., Mamoshina P., Aliper A., Korzinkin M., Moskalev A., Kolosov A., Ostrovskiy A., Cantor C., Vijg J., Zhavoronkov A., Deep biomarkers of human aging: Application of deep neural networks to biomarker development, Aging, 8, pp. 1021-1033, (2016); Wang S., Liu Z., Rong Y., Zhou B., Bai Y., Wei W., Wei W., Wang M., Guo Y., Tian J., Deep learning provides a new computed tomography-based prognostic biomarker for recurrence prediction in high-grade serous ovarian cancer, Radiother. Oncol, 132, pp. 171-177, (2019); Akbari H., Rathore S., Bakas S., Nasrallah M.P., Shukla G., Mamourian E., Rozycki M., Bagley S.J., Rudie J.D., Flanders A.E., Et al., Histopathology-validated machine learning radiographic biomarker for noninvasive discrimination between true progression and pseudo-progression in glioblastoma, Cancer, 126, pp. 2625-2636, (2020); Courtiol P., Maussion C., Moarii M., Pronier E., Pilcer S., Sefta M., Manceron P., Toldo S., Zaslavskiy M., Le Stang N., Et al., Deep learning-based classification of mesothelioma improves prediction of patient outcome, Nat. Med, 25, pp. 1519-1525, (2019); Zhuang J., Dvornek N.C., Li X., Ventola P., Duncan J.S., Invertible Network for Classification and Biomarker Selection for ASD, Medical Image Computing and Computer Assisted Intervention–MICCAI 2019, pp. 700-708, (2019); Lei C., Li H., Hui W., Chen S., Yang L., Kang Y., Bo Q., Feng J., A deep learning-based framework for lung cancer survival analysis with biomarker interpretation, BMC Bioinform, 21, (2020); Waldstein S.M., Seebock P., Donner R., Sadeghipour A., Bogunovic H., Osborne A., Schmidt-Erfurth U., Unbiased identification of novel subclinical imaging biomarkers using unsupervised deep learning, Sci. Rep, 10, (2020); Razzak M.I., Naz S., Zaib A., Deep Learning for Medical Image Processing: Overview, Challenges and the Future, Classification in BioApps, 26, pp. 323-350, (2018); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, arXiv, (2015); Apostolopoulos I.D., Mpesiana T.A., COVID-19: Automatic detection from x-ray images utilizing transfer learning with convolutional neural networks, Phys. Eng. Sci. Med, 1, pp. 635-640, (2020); Apostolopoulos I.D., Apostolopoulos D.I., Spyridonidis T.I., Papathanasiou N.D., Panayiotakis G.S., Multi-input deep learning approach for Cardiovascular Disease diagnosis using Myocardial Perfusion Imaging and clinical data, Phys. Med, 84, pp. 168-177, (2021); Apostolopoulos I.D., Apostolopoulos D.J., Papathanasiou N.D., Deep Learning Methods to Reveal Important X-Ray Features in COVID-19 Detection: Investigation of Explainability and Feature Reproducibility, Reports, 5, (2022); Apostolopoulos I.D., Pintelas E.G., Livieris I.E., Apostolopoulos D.J., Papathanasiou N.D., Pintelas P.E., Panayiotakis G.S., Automatic classification of solitary pulmonary nodules in PET/CT imaging employing transfer learning techniques, Med. Biol. Eng. Comput, 59, pp. 1299-1310, (2021); Apostolopoulos I.D., Papathanasiou N.D., Panayiotakis G.S., Classification of Lung Nodule Malignancy in Computed Tomography Imaging Utilising Generative Adversarial Networks and Semi-Supervised Transfer Learning, Biocybern. Biomed. Eng, 41, pp. 1243-1257, (2021); Causey J.L., Zhang J., Ma S., Jiang B., Qualls J.A., Politte D.G., Prior F., Zhang S., Huang X., Highly accurate model for prediction of lung nodule malignancy with CT scans, Sci. Rep, 8, (2018); Ricciardi R., Mettivier G., Staffa M., Sarno A., Acampora G., Minelli S., Santoro A., Antignani E., Orientale A., Pilotti I.A.M., Et al., A deep learning classifier for digital breast tomosynthesis, Phys. Med, 83, pp. 184-193, (2021); Sheinfeld M., Levinson S., Orion I., Highly Accurate Prediction of Specific Activity Using Deep Learning, Appl. Radiat. Isot, 130, pp. 115-120, (2017); Zhao X., Liu L., Qi S., Teng Y., Li J., Qian W., Agile convolutional neural network for pulmonary nodule classification using CT images, Int. J. CARS, 13, pp. 585-595, (2018); Ali F., Khan S., Waseem Abbas A., Shah B., Hussain T., Song D., EI-Sappagh S., Singh J., A Two-Tier Framework Based on GoogLeNet and YOLOv3 Models for Tumor Detection in MRI, Comput. Mater. Contin, 72, pp. 73-92, (2022); Seide F., Agarwal A., CNTK: Microsoft’s Open-Source Deep-Learning Toolkit, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM; Armato S.G., McLennan G., Bidaut L., McNitt-Gray M.F., Meyer C.R., Reeves A.P., Zhao B., Aberle D.R., Henschke C.I., Hoffman E.A., Et al., The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI): A Completed Reference Database of Lung Nodules on CT Scans: The LIDC/IDRI thoracic CT database of lung nodules, Med. Phys, 38, pp. 915-931, (2011); Cohen J.P., COVID-19 Image Data Collection, (2020); Zhao J., Zhang Y., He X., Xie P., COVID-CT-Dataset: A CT Scan Dataset about COVID-19, arXiv, (2020); Matek C., Schwarz S., Marr C., Spiekermann K., A Single-Cell Morphological Dataset of Leukocytes from AML Patients and Non-Malignant Controls, (2019); (2019); Mourya S., Kant S., Kumar P., Gupta A., Gupta R., ALL Challenge Dataset of ISBI, (2019); Apostolopoulos I.D., Papathanasiou N.D., Spyridonidis T., Apostolopoulos D.J., Automatic characterization of myocardial perfusion imaging polar maps employing deep learning and data augmentation, Hell. J. Nucl. Med, 23, pp. 125-132, (2020); Grover V., Skin_Cancer_Large_Dataset, (2021); Tschandl P., Rosendahl C., Kittler H., The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions, Sci. Data, 5, (2018); Codella N., Rotemberg V., Tschandl P., Celebi M.E., Dusza S., Gutman D., Helba B., Kalloo A., Liopyris K., Marchetti M., Et al., Skin Lesion Analysis toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC), arXiv, (2019); Deng J., Dong W., Socher R., Li L.-J., Li K., Li F.F., Imagenet: A large-scale hierarchical image database, Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255; He K., Zhang X., Ren S., Sun J., Deep Residual Learning for Image Recognition, arXiv, (2015); Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., Rethinking the Inception Architecture for Computer Vision, arXiv, (2015); Chollet F., Xception: Deep learning with depthwise separable convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1251-1258; Huang G., Liu Z., Van Der Maaten L., Weinberger K.Q., Densely Connected Convolutional Networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4700-4708; Zoph B., Vasudevan V., Shlens J., Le Q.V., Learning Transferable Architectures for Scalable Image Recognition, arXiv, (2018); Howard A.G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, arXiv, (2017); Selvaraju R.R., Cogswell M., Das A., Vedantam R., Parikh D., Batra D., Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization, Int. J. Comput. Vis, 128, pp. 336-359, (2020); Yang H., Kim J.-Y., Kim H., Adhikari S.P., Guided Soft Attention Network for Classification of Breast Cancer Histopathology Images, IEEE Trans. Med. Imaging, 39, pp. 1306-1315, (2020); Choi H., Kim Y.K., Yoon E.J., Lee J.-Y., Lee D.S., Cognitive Signature of Brain FDG PET Based on Deep Learning: Domain Transfer from Alzheimer’s Disease to Parkinson’s Disease, Eur. J. Nucl. Med. Mol. Imaging, 47, pp. 403-412, (2020); Xie Y., Zhang J., Xia Y., Shen C., A Mutual Bootstrapping Model for Automated Skin Lesion Segmentation and Classification, IEEE Trans. Med. Imaging, 39, pp. 2482-2493, (2020); van der Velden B.H.M., Kuijf H.J., Gilhuijs K.G.A., Viergever M.A., Explainable Artificial Intelligence (XAI) in Deep Learning-Based Medical Image Analysis, Med. Image Anal, 79, (2022)","I.D. Apostolopoulos; Department of Medical Physics, School of Medicine, University of Patras, Rio, 26504, Greece; email: ece7216@upnet.gr","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","20754418","","","","English","Diagn.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85140777302"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Communications in Computer and Information Science","1965 CCIS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178596621&partnerID=40&md5=19f437f49d9e65ba67b8d9c5dfb5867d","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","18650929","978-981998144-1","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85178596621"
"Zidane M.; Makky A.; Bruhns M.; Rochwarger A.; Babaei S.; Claassen M.; Schürch C.M.","Zidane, Mohammed (58251599200); Makky, Ahmad (58076474600); Bruhns, Matthias (58534904300); Rochwarger, Alexander (58096322800); Babaei, Sepideh (57221709578); Claassen, Manfred (26640261400); Schürch, Christian M. (26642210200)","58251599200; 58076474600; 58534904300; 58096322800; 57221709578; 26640261400; 26642210200","Corrigendum: A review on deep learning applications in highly multiplexed tissue imaging data analysis (Front. Bioinform., (2023), 3, 1159381, 10.3389/fbinf.2023.1159381)","2023","Frontiers in Bioinformatics","3","","1287407","","","","0","10.3389/fbinf.2023.1287407","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174854913&doi=10.3389%2ffbinf.2023.1287407&partnerID=40&md5=0fd80dad07ad512a9fc94f4ad14f9ff2","Department of Pathology and Neuropathology, University Hospital and Comprehensive Cancer Center Tübingen, Tübingen, Germany; Department of Internal Medicine I, University Hospital Tübingen, Tübingen, Germany; Department of Computer Science, University of Tübingen, Tübingen, Germany","Zidane M., Department of Pathology and Neuropathology, University Hospital and Comprehensive Cancer Center Tübingen, Tübingen, Germany; Makky A., Department of Pathology and Neuropathology, University Hospital and Comprehensive Cancer Center Tübingen, Tübingen, Germany; Bruhns M., Department of Internal Medicine I, University Hospital Tübingen, Tübingen, Germany, Department of Computer Science, University of Tübingen, Tübingen, Germany; Rochwarger A., Department of Pathology and Neuropathology, University Hospital and Comprehensive Cancer Center Tübingen, Tübingen, Germany; Babaei S., Department of Internal Medicine I, University Hospital Tübingen, Tübingen, Germany; Claassen M., Department of Internal Medicine I, University Hospital Tübingen, Tübingen, Germany, Department of Computer Science, University of Tübingen, Tübingen, Germany; Schürch C.M., Department of Pathology and Neuropathology, University Hospital and Comprehensive Cancer Center Tübingen, Tübingen, Germany","In the published article, there was an error. “The abstract is duplicated.” A correction has been made to Abstract. This sentence previously stated: “Since its introduction into the field of oncology, deep learning (DL) has impacted clinical discoveries and biomarker predictions. DL-driven discoveries and predictions in oncology are based on a variety of biological data such as genomics, proteomics, and imaging data. DL-based computational frameworks can predict genetic variant effects on gene expression, as well as protein structures based on amino acid sequences. Furthermore, DL algorithms can capture valuable mechanistic biological information from several spatial “omics” technologies, such as spatial transcriptomics and spatial proteomics. Here, we review the impact that the combination of artificial intelligence (AI) with spatial omics technologies has had on oncology, focusing on DL and its applications in biomedical image analysis, encompassing cell segmentation, cell phenotype identification, cancer prognostication, and therapy prediction. We highlight the advantages of using highly multiplexed images (spatial proteomics data) compared to single-stained, conventional histopathological (“simple”) images, as the former can provide deep mechanistic insights that cannot be obtained by the latter, even with the aid of explainable AI. Furthermore, we provide the reader with the advantages/disadvantages of DL-based pipelines used in preprocessing highly multiplexed images (cell segmentation, cell type annotation). Therefore, this review also guides the reader to choose the DLbased pipeline that best fits their data. In conclusion, DL continues to be established as an essential tool in discovering novel biological mechanisms when combined with technologies such as highly multiplexed tissue imaging data. In balance with conventional medical data, its role in clinical routine will become more important, supporting diagnosis and prognosis in oncology, enhancing clinical decision-making, and improving the quality of care for patients. Since its introduction into the field of oncology, deep learning (DL) has impacted clinical discoveries and biomarker predictions. DL-driven discoveries and predictions in oncology are based on a variety of biological data such as genomics, proteomics, and imaging data. DL-based computational frameworks can predict genetic variant effects on gene expression, as well as protein structures based on amino acid sequences. Furthermore, DL algorithms can capture valuable mechanistic biological information from several spatial “omics” technologies, such as spatial transcriptomics and spatial proteomics. Here, we review the impact that the combination of artificial intelligence (AI) with spatial omics technologies has had on oncology, focusing on DL and its applications in biomedical image analysis, encompassing cell segmentation, cell phenotype identification, cancer prognostication, and therapy prediction. We highlight the advantages of using highly multiplexed images (spatial proteomics data) compared to single-stained, conventional histopathological (“simple”) images, as the former can provide deep mechanistic insights that cannot be obtained by the latter, even with the aid of explainable AI. Furthermore, we provide the reader with the advantages/ disadvantages of the DL-based pipelines used in preprocessing the highly multiplexed images (cell segmentation, cell type annotation). Therefore, this review also guides the reader to choose the DL-based pipeline that best fits their data. In conclusion, DL continues to be established as an essential tool in discovering novel biological mechanisms when combined with technologies such as highly multiplexed tissue imaging data. In balance with conventional medical data, its role in clinical routine will become more important, supporting diagnosis and prognosis in oncology, enhancing clinical decision-making, and improving the quality of care for patients.” The corrected sentence appears below: “Since its introduction into the field of oncology, deep learning (DL) has impacted clinical discoveries and biomarker predictions. DL-driven discoveries and predictions in oncology are based on a variety of biological data such as genomics, proteomics, and imaging data. DL-based computational frameworks can predict genetic variant effects on gene expression, as well as protein structures based on amino acid sequences. Furthermore, DL algorithms can capture valuable mechanistic biological information from several spatial “omics” technologies, such as spatial transcriptomics and spatial proteomics. Here, we review the impact that the combination of artificial intelligence (AI) with spatial omics technologies has had on oncology, focusing on DL and its applications in biomedical image analysis, encompassing cell segmentation, cell phenotype identification, cancer prognostication, and therapy prediction. We highlight the advantages of using highly multiplexed images (spatial proteomics data) compared to single-stained, conventional histopathological (“simple”) images, as the former can provide deep mechanistic insights that cannot be obtained by the latter, even with the aid of explainable AI. Furthermore, we provide the reader with the advantages/disadvantages of DL-based pipelines used in preprocessing highly multiplexed images (cell segmentation, cell type annotation). Therefore, this review also guides the reader to choose the DL-based pipeline that best fits their data. In conclusion, DL continues to be established as an essential tool in discovering novel biological mechanisms when combined with technologies such as highly multiplexed tissue imaging data. In balance with conventional medical data, its role in clinical routine will become more important, supporting diagnosis and prognosis in oncology, enhancing clinical decision-making, and improving the quality of care for patients.” In the published article, there was an error. “the word ‘recently’ is repeated.” A correction has been made to Applications in highly multiplexed images, [paragraph 3]. This sentence previously stated: “Recently, Graph Neural Networks (GNNs) (Scarselli et al., 2009) were recently used to model the TME.” The corrected sentence appears below: “Recently, Graph Neural Networks (GNNs) (Scarselli et al., 2009) were used to model the TME.” In the published article, there was an error. “the term ‘convolutional neural network’ is repeated”. A correction has been made to Applications in conventional medical (“simple”) images, [paragraph 5]. This sentence previously stated: “The DL-based framework consists of two neural networks: a convolutional neural network: a convolutional neural network CNN (pre-trained GoogleNet on ImageNet), which was trained on the CT scans to extract the important features from lesions of different organs, and a recurrent neural network RNN which learned the changes happening in these lesions across multiple time points.” The corrected sentence appears below: “The DL-based framework consists of two neural networks: a convolutional neural network CNN (pre-trained GoogleNet on ImageNet), which was trained on the CT scans to extract the important features from lesions of different organs, and a recurrent neural network RNN which learned the changes happening in these lesions across multiple time points.” In the published article, there was an error. “two references are not written as a hyperlink; it is just a number that you cannot click on”. A correction has been made to reference (148) in Table 1 is not a hyperlink and reference (171) in Table 3. Both references are written as numbers not as hyperlinks. This sentence previously stated: “Could be combined with TrackMate (148) for cell tracking in Table 1.” “Map snRNA-seq data to spatial data of different resolutions, ISH associated with histological and anatomical coordinates, midresolution Spatial Transcriptomics, and high-resolution STARmap (171) and MERFISH in Table 3.” The corrected sentence appears below: “They should be hyperlinks.” The authors apologize for these errors and state that this does not change the scientific conclusions of the article in any way. The original article has been updated. Copyright © 2023 Zidane, Makky, Bruhns, Rochwarger, Babaei, Claassen and Schürch.","artificial intelligence; biomarker; cancer; deep learning; highly multiplexed tissue imaging; prediction; review; spatial transcriptomics","","","","","","","","","C.M. Schürch; Department of Pathology and Neuropathology, University Hospital and Comprehensive Cancer Center Tübingen, Tübingen, Germany; email: christian.schuerch@med.uni-tuebingen.de","","Frontiers Media SA","","","","","","26737647","","","","English","Front. Bioinform.","Erratum","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85174854913"
"Woessner A.E.; Anjum U.; Salman H.; Lear J.; Turner J.T.; Campbell R.; Beaudry L.; Zhan J.; Cornett L.E.; Gauch S.; Quinn K.P.","Woessner, Alan E. (57202230415); Anjum, Usman (57367380200); Salman, Hadi (57526140800); Lear, Jacob (58848242400); Turner, Jeffrey T. (59233896100); Campbell, Ross (57204853222); Beaudry, Laura (59231463000); Zhan, Justin (59233555300); Cornett, Lawrence E. (7004305090); Gauch, Susan (6602196195); Quinn, Kyle P. (16647213500)","57202230415; 57367380200; 57526140800; 58848242400; 59233896100; 57204853222; 59231463000; 59233555300; 7004305090; 6602196195; 16647213500","Identifying and training deep learning neural networks on biomedical-related datasets","2024","Briefings in Bioinformatics","25","","bbae232","","","","0","10.1093/bib/bbae232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199492909&doi=10.1093%2fbib%2fbbae232&partnerID=40&md5=aaa77e45465e75e2c5cea912d90afc82","Arkansas Integrative Metabolic Research Center, University of Arkansas, Fayetteville, AR, United States; Department of Biomedical Engineering, University of Arkansas, Fayetteville, AR, United States; Department of Computer Science, University of Cincinnati, Cincinnati, OH, United States; Department of Computer Science and Computer Engineering, University of Arkansas, Fayetteville, AR, United States; Health Data and AI, Deloitte Consulting LLP, Arlington, VA, United States; Google Cloud, Reston, VA, United States; Department of Physiology and Cell Biology, University of Arkansas for Medical Sciences, Little Rock, AR, United States","Woessner A.E., Arkansas Integrative Metabolic Research Center, University of Arkansas, Fayetteville, AR, United States, Department of Biomedical Engineering, University of Arkansas, Fayetteville, AR, United States; Anjum U., Arkansas Integrative Metabolic Research Center, University of Arkansas, Fayetteville, AR, United States, Department of Computer Science, University of Cincinnati, Cincinnati, OH, United States, Department of Computer Science and Computer Engineering, University of Arkansas, Fayetteville, AR, United States; Salman H., Arkansas Integrative Metabolic Research Center, University of Arkansas, Fayetteville, AR, United States, Department of Computer Science and Computer Engineering, University of Arkansas, Fayetteville, AR, United States; Lear J., Department of Computer Science and Computer Engineering, University of Arkansas, Fayetteville, AR, United States; Turner J.T., Health Data and AI, Deloitte Consulting LLP, Arlington, VA, United States; Campbell R., Health Data and AI, Deloitte Consulting LLP, Arlington, VA, United States; Beaudry L., Google Cloud, Reston, VA, United States; Zhan J., Arkansas Integrative Metabolic Research Center, University of Arkansas, Fayetteville, AR, United States, Department of Computer Science, University of Cincinnati, Cincinnati, OH, United States, Department of Computer Science and Computer Engineering, University of Arkansas, Fayetteville, AR, United States; Cornett L.E., Department of Physiology and Cell Biology, University of Arkansas for Medical Sciences, Little Rock, AR, United States; Gauch S., Department of Computer Science and Computer Engineering, University of Arkansas, Fayetteville, AR, United States; Quinn K.P., Arkansas Integrative Metabolic Research Center, University of Arkansas, Fayetteville, AR, United States, Department of Biomedical Engineering, University of Arkansas, Fayetteville, AR, United States","This manuscript describes the development of a resources module that is part of a learning platform named ‘NIGMS Sandbox for Cloud-based Learning’ https://github.com/NIGMS/NIGMS-Sandbox. The overall genesis of the Sandbox is described in the editorial NIGMS Sandbox at the beginning of this Supplement. This module delivers learning materials on implementing deep learning algorithms for biomedical image data in an interactive format that uses appropriate cloud resources for data access and analyses. Biomedical-related datasets are widely used in both research and clinical settings, but the ability for professionally trained clinicians and researchers to interpret datasets becomes difficult as the size and breadth of these datasets increases. Artificial intelligence, and specifically deep learning neural networks, have recently become an important tool in novel biomedical research. However, use is limited due to their computational requirements and confusion regarding different neural network architectures. The goal of this learning module is to introduce types of deep learning neural networks and cover practices that are commonly used in biomedical research. This module is subdivided into four submodules that cover classification, augmentation, segmentation and regression. Each complementary submodule was written on the Google Cloud Platform and contains detailed code and explanations, as well as quizzes and challenges to facilitate user training. Overall, the goal of this learning module is to enable users to identify and integrate the correct type of neural network with their data while highlighting the ease-of-use of cloud computing for implementing neural networks. This manuscript describes the development of a resource module that is part of a learning platform named “NIGMS Sandbox for Cloud-based Learning” https://github.com/NIGMS/NIGMS-Sandbox. The overall genesis of the Sandbox is described in the editorial NIGMS Sandbox [1] at the beginning of this Supplement. This module delivers learning materials on the analysis of bulk and single-cell ATACseq data in an interactive format that uses appropriate cloud resources for data access and analyses. © The Author(s) 2024. Published by Oxford University Press.","artificial intelligence; biomedical research; cloud-based computing; deep learning; engineering education","Algorithms; Biomedical Research; Cloud Computing; Deep Learning; Humans; Neural Networks, Computer; algorithm; artificial neural network; cloud computing; deep learning; human; medical research","","","","","National Institute of General Medical Sciences, NIGMS, (3P20GM103429-21S2); National Institute of General Medical Sciences, NIGMS; Arkansas Integrative Metabolic Research Center, (P20GM139768); National Institutes of Health, NIH, (R01AG056560, R01EB031032); National Institutes of Health, NIH","This research was funded by National Institutes of General Medical Sciences (NIGMS) supplement to the Arkansas IDeA Network of Biomedical Research Excellence (Arkansas INBRE; 3P20GM103429-21S2), the Arkansas Integrative Metabolic Research Center (NIH P20GM139768), as well as National Institutes of Health (NIH) grant numbers R01AG056560, R01EB031032. ","Lei M, Matukumalli LK, Arora K, Et al., NIGMS Sandbox: A Learning Platform toward Democratizing Cloud Computing for Biomedical Research; Russ JC., The Image Processing Handbook, (2011); Gore JC., Artificial intelligence in medical imaging, Magn Reson Imaging, 68, pp. A1-A4, (2020); Min S, Lee B, Yoon S., Deep learning in bioinformatics, Brief Bioinform, 18, pp. 851-869, (2017); Tran KA, Kondrashova O, Bradley A, Et al., Deep learning in cancer diagnosis, prognosis and treatment selection, Genome Med, 13, (2021); Kather JN, Krisam J, Charoentong P, Et al., Predicting survival from colorectal cancer histology slides using deep learning: a retrospective multicenter study, PLoS Med, 16, (2019); Alzubaidi L, Zhang J, Humaidi AJ, Et al., Review of deep learning: concepts, CNN architectures, challenges, applications, future directions, J Big Data, 8, (2021); LeCun Y, Bengio Y, Hinton G., Deep learning, Nature, 521, pp. 436-444, (2015); Jones JD, Rodriguez MR, Quinn KP., Automated extraction of skin wound healing biomarkers from In vivo label-free multiphoton microscopy using convolutional neural networks, Lasers Surg Med, 53, pp. 1086-1095, (2021); Woessner AE, Quinn KP., Improved segmentation of collagen second harmonic generation images with a deep learning convolutional neural network, J Biophotonics, 15, (2022); Newby JM, Schaefer AM, Lee PT, Et al., Convolutional neural networks automate detection for tracking of submicron-scale particles in 2D and 3D, Proc Natl Acad Sci U S A, 115, pp. 9026-9031, (2018); Lee JH, Kim KG., Applying deep learning in medical images: the case of bone age estimation, Healthc Inform Res, 24, pp. 86-92, (2018); He K, Zhang X, Ren S, Et al., Deep residual learning for image recognition, (2015); Krizhevsky A, Sutskever I, Hinton GE., ImageNet classification with deep convolutional neural networks, Commun ACM, 60, pp. 84-90, (2017); Simonyan K, Zisserman A., Very deep convolutional networks for large-scale image recognition, (2014); Deng J, Dong W, Socher R, Et al., ImageNet: A large-scale hierarchical image database, 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255, (2009); Shin H-C, Roth HR, Gao M, Et al., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning, IEEE Trans Med Imaging, 35, pp. 1285-1298, (2016); Yang J, Shi R, Wei D, Et al., MedMNIST v2—a large-scale lightweight benchmark for 2D and 3D biomedical image classification, Sci Data, 10, (2023); Zhang Z, Sabuncu MR., Generalized cross entropy loss for training deep neural networks with noisy labels, (2018); Perez L, Wang J., The effectiveness of data augmentation in image classification using deep learning, (2017); Wang X, Peng Y, Lu L, Et al., ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3462-3471, (2017); Al-Dhabyani W, Gomaa M, Khaled H, Et al., Dataset of breast ultrasound images, Data Brief, 28, (2020); Ciresan D, Giusti A, Gambardella L, Et al., Deep neural networks segment neuronal membranes in electron microscopy images, Neural Information Processing Systems (NIPS), pp. 2843-2851, (2012); Ronneberger O, Fischer P, Brox T., U-net: convolutional networks for biomedical image segmentation, (2015); Wang C-Y, Yeh I-H, Liao H-YM., You only learn one representation: unified network for multiple tasks, (2021); Kirillov A, Mintun E, Ravi N, Et al., Segment anything; Klein A, Wallkotter S, Silvester S, Et al., imageio/imageio: v2.31.1, (2023); Jones JD, Quinn KP., Automated quantitative analysis of wound histology using deep-learning neural networks, J Investig Dermatol, 141, pp. 1367-1370, (2021); Kingma DP, Ba J., Adam: a method for stochastic optimization, (2014); Street WN, Wolberg WH, Mangasarian OL., Nuclear feature extraction for breast tumor diagnosis, Proc. SPIE 1905, Biomedical Image Processing and Biomedical Visualization, pp. 861-870, (1993); William Wolberg OM., Breast cancer Wisconsin (diagnostic), (1993); Pedregosa F, Varoquaux G, Gramfort A, Et al., Scikit-learn: machine learning in python, (2012)","K.P. Quinn; Department of Biomedical Engineering, University of Arkansas, Fayetteville, 123 John A. White Jr. Engineering Hall, 72701, United States; email: kyle@quinnlab.org","","Oxford University Press","","","","","","14675463","","","39041915","English","Brief. Bioinform.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85199492909"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Communications in Computer and Information Science","1967 CCIS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180334873&partnerID=40&md5=16d85a38e9dcfbace5d1b62acb39bd6e","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","18650929","978-981998177-9","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85180334873"
"Valanarasu J.M.J.; Sindagi V.A.; Hacihaliloglu I.; Patel V.M.","Valanarasu, Jeya Maria Jose (57219450328); Sindagi, Vishwanath A. (56829595000); Hacihaliloglu, Ilker (24467768400); Patel, Vishal M. (56660008900)","57219450328; 56829595000; 24467768400; 56660008900","KiU-Net: Overcomplete Convolutional Architectures for Biomedical Image and Volumetric Segmentation","2022","IEEE Transactions on Medical Imaging","41","4","","965","976","11","118","10.1109/TMI.2021.3130469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120042907&doi=10.1109%2fTMI.2021.3130469&partnerID=40&md5=eefa38c45acc8d157806cf40dddf3b17","Whiting School of Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States; Department of Biomedical Engineering, Rutgers, State University of New Jersey, New Brunswick, 08901, NJ, United States","Valanarasu J.M.J., Whiting School of Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States; Sindagi V.A., Whiting School of Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States; Hacihaliloglu I., Department of Biomedical Engineering, Rutgers, State University of New Jersey, New Brunswick, 08901, NJ, United States; Patel V.M., Whiting School of Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States","Most methods for medical image segmentation use U-Net or its variants as they have been successful in most of the applications. After a detailed analysis of these 'traditional' encoder-decoder based approaches, we observed that they perform poorly in detecting smaller structures and are unable to segment boundary regions precisely. This issue can be attributed to the increase in receptive field size as we go deeper into the encoder. The extra focus on learning high level features causes U-Net based approaches to learn less information about low-level features which are crucial for detecting small structures. To overcome this issue, we propose using an overcomplete convolutional architecture where we project the input image into a higher dimension such that we constrain the receptive field from increasing in the deep layers of the network. We design a new architecture for im- age segmentation- KiU-Net which has two branches: (1) an overcomplete convolutional network Kite-Net which learns to capture fine details and accurate edges of the input, and (2) U-Net which learns high level features. Furthermore, we also propose KiU-Net 3D which is a 3D convolutional architecture for volumetric segmentation. We perform a detailed study of KiU-Net by performing experiments on five different datasets covering various image modalities. We achieve a good performance with an additional benefit of fewer parameters and faster convergence. We also demonstrate that the extensions of KiU-Net based on residual blocks and dense blocks result in further performance improvements. Code: https://github.com/jeya-maria-jose/KiU-Net-pytorch © 1982-2012 IEEE.","deep learning; Medical image segmentation; overcomplete representations","Image Processing, Computer-Assisted; Neural Networks, Computer; Computer architecture; Convolution; Deep learning; Diagnosis; Image segmentation; Medical imaging; Network architecture; Network layers; Signal encoding; Three dimensional displays; Deep learning; Features extraction; Images segmentations; Learn+; Medical diagnostic imaging; Medical image segmentation; Over-complete; Over-complete representations; Three-dimensional display; Volumetric segmentations; Article; clinical article; convolutional neural network; deep learning; echoencephalography; feature extraction; glioblastoma; glioma; human; image processing; image segmentation; liver tumor; neuroanatomy; newborn; nuclear magnetic resonance imaging; qualitative analysis; quantitative analysis; receptive field; segmentation algorithm; image processing; procedures; Feature extraction","","","","","","","Badrinarayanan V., Kendall A., Cipolla R., SegNet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell, 39, 12, pp. 2481-2495, (2017); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 234-241, (2015); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., UNet++: A nested U-Net architecture for medical image segmentation, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 3-11, (2018); Zhou Z., Et al., UNet++: Redesigning skip connections to exploit multiscale features in image segmentation, IEEE Trans. Med. Imag, 39, 6, pp. 1856-1867, (2019); Huang H., Et al., UNet 3+: A full-scale connected UNet for medical image segmentation, Proc IEEE Int. Conf. Acoust., Speech Signal Process. ICASSP, pp. 1055-1059, (2020); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-Net: Learning dense volumetric segmentation from sparse annotation, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 424-432, (2016); Milletari F., Navab N., Ahmadi S.-A., V-Net: Fully convolutional neural networks for volumetric medical image segmentation, Proc. 4th Int. Conf. 3D Vis. 3DV, pp. 565-571, (2016); Xiao X., Lian S., Luo Z., Li S., Weighted Res-UNet for highquality retina vessel segmentation, Proc. 9th Int. Conf. Inf. Technol. Med. Educ. (ITME, pp. 327-331, (2018); Li X., Chen H., Qi X., Dou Q., Fu C.-W., Heng P.-A., H-DenseUNet: Hybrid densely connected UNet for liver and tumor segmentation from CT volumes, IEEE Trans. Med. Imag, 37, 12, pp. 2663-2674, (2018); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proc IEEE Conf. Comput. Vis. Pattern Recognit. CVPR, pp. 770-778, (2016); Huang G., Liu Z., Maaten Der L.Van, Weinberger K.Q., Densely connected convolutional networks, Proc IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR, pp. 4700-4708, (2017); Valanarasu J.M.J., Sindagi V.A., Hacihaliloglu I., Patel V.M., KiU-Net: Towards accurate segmentation of biomedical images using over-complete representations, Medical Image Computing and Computer Assisted Intervention, pp. 363-373, (2020); Qu H., Yan Z., Riedlinger G.M., De S., Metaxas D.N., Improving nuclei/gland instance segmentation in histopathology images by full resolution neural network and spatial constrained loss, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 378-386, (2019); Wang G., Et al., DeepIGeoS: A deep interactive geodesic framework for medical image segmentation, IEEE Trans. Pattern Anal. Mach. Intell, 41, 7, pp. 1559-1572, (2019); Lewicki M.S., Sejnowski T.J., Learning overcomplete representations, Neural Comput, 12, 2, pp. 337-365, (2000); Vincent P., Larochelle H., Bengio Y., Manzagol P.-A., Extracting and composing robust features with denoising autoencoders, Proc. 25th Int. Conf. Mach. Learn ICML, pp. 1096-1103, (2008); Martin M., Sciolla B., Sdika M., Wang X., Quetin P., Delachartre P., Automatic segmentation of the cerebral ventricle in neonates using deep learning with 3D reconstructed freehand ultrasound imaging, Proc IEEE Int. Ultrason. Symp. (IUS, pp. 1-4, (2018); Wang P., Cuccolo N.G., Tyagi R., Hacihaliloglu I., Patel V.M., Automatic real-Time CNN-based neonatal brain ventricles segmentation, Proc IEEE 15th Int. Symp. Biomed. Imag. (ISBI), pp. 716-719, (2018); Valanarasu J.M.J., Yasarla R., Wang P., Hacihaliloglu I., Patel V.M., Learning to segment brain anatomy from 2D ultrasound with less data, IEEE J. Sel. Topics Signal Process, 14, 6, pp. 1221-1234, (2020); Chen H., Qi X., Yu L., Dou Q., Qin J., Heng P.-A., DCAN: Deep contour-Aware networks for object instance segmentation from histology images, Med. Image Anal, 36, pp. 135-146, (2017); Bentaieb A., Hamarneh G., Topology aware fully convolutional networks for histology gland segmentation, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 460-468, (2016); Jiang Y., Zhang H., Tan N., Chen L., Automatic retinal blood vessel segmentation based on fully convolutional neural networks, Symmetry, 11, 9, (2019); Feng Z., Yang J., Yao L., Patch-based fully convolutional neural network with skip connections for retinal blood vessel segmentation, Proc IEEE Int. Conf. Image Process. ICIP, pp. 1742-1746, (2017); Samuel P.M., Veeramalai T., Multilevel and multiscale deep neural network for retinal blood vessel segmentation, Symmetry, 11, 7, (2019); Weng Y.-T., Chan H.-W., Huang T.-Y., Automatic segmentation of brain tumor from 3D MR images using SegNet, U-Net, and PSP-Net, Proc. Int. MICCAI Brainlesion Workshop, pp. 226-233, (2019); Fang L., He H., Three pathways U-Net for brain tumor segmentation, Proc. Pre-Conf. 7th Med. Image Comput. Comput.-Assist. Intervent. (MICCAI) BraTS Challenge, pp. 119-126, (2018); Fridman N., Brain tumor detection and segmentation using deep learning U-Net on multi modal MRI, Proc. Pre-Conf. 7th MICCAI BraTS Challenge, pp. 135-143, (2018); Kermi A., Mahmoudi I., Khadir M.T., Deep convolutional neural networks using U-Net for automatic brain tumor segmentation in multimodal MRI volumes, Proc. Int. MICCAI Brainlesion Workshop, pp. 37-48, (2018); Bansal A., Chen X., Russell B., Gupta A., Ramanan D., PixelNet: Representation of the Pixels, by the Pixels, and for the Pixels, (2017); Zhao H., Shi J., Qi X., Wang X., Jia J., Pyramid scene parsing network, Proc IEEE Conf. Comput. Vis. Pattern Recognit. CVPR, pp. 2881-2890, (2017); Islam M., Jose V.J.M., Ren H., Glioma prognosis: Segmentation of the tumor and survival prediction using shape, geometric and clinical information, Proc. Int. MICCAI Brainlesion Workshop, pp. 142-153, (2018); Myronenko A., 3D MRI brain tumor segmentation using autoencoder regularization, Proc. Int. MICCAI Brainlesion Workshop, pp. 311-320, (2018); Chen W., Liu B., Peng S., Sun J., Qiao X., S3D-UNet: Separable 3D U-Net for brain tumor segmentation, Proc. Int. MICCAI Brainlesion Workshop, pp. 358-368, (2018); Isensee F., Kickingereder P., Wick W., Bendszus M., Maier-Hein K.H., No New-Net Proc. Int. MICCAI Brainlesion Workshop, pp. 234-244, (2018); Zhang J., Xie Y., Zhang P., Chen H., Xia Y., Shen C., Lightweight hybrid convolutional network for liver tumor segmentation, Proc. 28th Int. Joint Conf. Artif. Intell, pp. 4271-4277, (2019); Valanarasu J.M.J., Sindagi V.A., Hacihaliloglu I., Patel V.M., KiU-Net: Towards accurate segmentation of biomedical images using over-complete representations, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 363-373, (2020); Roy A.G., Navab N., Wachinger C., Recalibrating fully convolutional networks with spatial and channel squeeze and excitation blocks, IEEE Trans. Med. Imag, 38, 2, pp. 540-549, (2019); Feng S., Et al., CPFNet: Context pyramid fusion network for medical image segmentation, IEEE Trans. Med. Imag, 39, 10, pp. 3008-3018, (2020); Sirinukunwattana K., Et al., Gland segmentation in colon histology images: The GlaS challenge contest, Med. Image Anal, 35, pp. 489-502, (2017); Staal J., Abramoff M.D., Niemeijer M., Viergever M.A., Van Ginneken B., Ridge-based vessel segmentation in color images of the retina, IEEE Trans. Med. Imag, 23, 4, pp. 501-509, (2004); Hu Q., Abramoff M.D., Garvin M.K., Automated separation of binary overlapping trees in low-contrast color retinal images, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 436-443, (2013); Menze B.H., Et al., The multimodal brain tumor image segmentation benchmark (BRATS), IEEE Trans. Med. Imag, 34, 10, pp. 1993-2024, (2015); Bakas S., Et al., Advancing the Cancer Genome atlas glioma MRI collections with expert segmentation labels and radiomic features, Sci. Data, 4, (2017); Bakas S., Et al., Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge, (2018); Bilic P., Et al., The Liver Tumor Segmentation Benchmark (LiTS), (2019); Bhalerao M., Thakur S., Brain tumor segmentation based on 3D residual U-Net, Proc. Int. MICCAI Brainlesion Workshop, pp. 218-225, (2019); Jesson A., Arbel T., Brain tumor segmentation using a 3D FCN with multi-scale loss, Proc. Int. MICCAI Brainlesion Workshop, pp. 392-402, (2017); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs, IEEE Trans. Pattern Anal. Mach. Intell, 40, 4, pp. 834-848, (2017); Yushkevich P.A., Et al., User-guided 3D active contour segmentation of anatomical structures: Significantly improved efficiency and reliability, NeuroImage, 31, 3, pp. 1116-1128, (2006)","J.M.J. Valanarasu; Whiting School of Engineering, Johns Hopkins University, Baltimore, 21218, United States; email: jvalana1@jhu.edu","","Institute of Electrical and Electronics Engineers Inc.","","","","","","02780062","","ITMID","34813472","English","IEEE Trans. Med. Imaging","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85120042907"
"Khan R.U.; Almakdi S.; Alshehri M.; Haq A.U.; Ullah A.; Kumar R.","Khan, Riaz Ullah (57202445169); Almakdi, Sultan (57211498975); Alshehri, Mohammed (57210193521); Haq, Amin Ul (59157731200); Ullah, Aman (57208471108); Kumar, Rajesh (58488212700)","57202445169; 57211498975; 57210193521; 59157731200; 57208471108; 58488212700","An intelligent neural network model to detect red blood cells for various blood structure classification in microscopic medical images","2024","Heliyon","10","4","e26149","","","","0","10.1016/j.heliyon.2024.e26149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187303011&doi=10.1016%2fj.heliyon.2024.e26149&partnerID=40&md5=adad2207a4666da4c8a5340283f9cd09","Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou, 313001, China; Department of Computer Science, College of Computer Science and Information systems, Najran University, Najran, 55461, Saudi Arabia; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, 611731, China","Khan R.U., Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou, 313001, China; Almakdi S., Department of Computer Science, College of Computer Science and Information systems, Najran University, Najran, 55461, Saudi Arabia; Alshehri M., Department of Computer Science, College of Computer Science and Information systems, Najran University, Najran, 55461, Saudi Arabia; Haq A.U., School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, 611731, China; Ullah A., Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou, 313001, China; Kumar R., Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou, 313001, China","Biomedical image analysis plays a crucial role in enabling high-performing imaging and various clinical applications. For the proper diagnosis of blood diseases related to red blood cells, red blood cells must be accurately identified and categorized. Manual analysis is time-consuming and prone to mistakes. Analyzing multi-label samples, which contain clusters of cells, is challenging due to difficulties in separating individual cells, such as touching or overlapping cells. High-performance biomedical imaging and several medical applications are made possible by advanced biosensors. We develop an intelligent neural network model that can automatically identify and categorize red blood cells from microscopic medical images using region-based convolutional neural networks (RCNN) and cutting-edge biosensors. Our model successfully navigates obstacles like touching or overlapping cells and accurately recognizes various blood structures. Additionally, we utilized data augmentation as a pre-processing method on microscopic images to enhance the model's computational efficiency and expand the sample size. To refine the data and eliminate noise from the dataset, we utilized the Radial Gradient Index filtering algorithm for imaging data equalization. We exhibit improved detection accuracy and a reduced model loss rate when using medical imagery datasets to apply our proposed model in comparison to existing ResNet and GoogleNet models. Our model precisely detected red blood cells in a collection of medical images with 99% training accuracy and 91.21% testing accuracy. Our proposed model outperformed earlier models like ResNet-50 and GoogleNet by 10-15%. Our results demonstrated that Artificial intelligence (AI)-assisted automated red blood cell detection has the potential to revolutionize and speed up blood cell analysis, minimizing human error and enabling early illness diagnosis. © 2024 The Author(s)","Deep learning; Image processing; Object detection; RBC detection","","","","","","University of Electronic Science and Technology of China, UESTC, (U03210068); University of Electronic Science and Technology of China, UESTC; Deanship of Scientific Research, University of Jordan, DSR, (NU/RG/SERC/12/3); Deanship of Scientific Research, University of Jordan, DSR","This project was supported by the Deanship of Scientific Research at Najran University (Grant No: NU/RG/SERC/12/3 ) and research funding from the Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China (Grant No. U03210068 ).","Navya K.T., Prasad K., Singh B.M.K., Analysis of red blood cells from peripheral blood smear images for anemia detection: a methodological review, Med. Biol. Eng. Comput., 60, 9, pp. 2445-2462, (2022); Nurcin F.V., Imanov E., Selective hole filling of red blood cells for improved marker-controlled watershed segmentation, Scanning, 2021, 1, pp. 1-9, (2021); Savkare S., Narote S., Automatic system for classification of erythrocytes infected with malaria and identification of parasite's life stage, Proc. Technol., 6, pp. 405-410, (2012); Khalid D., Al-Saedi A., Savas S., Classification of skin cancer with deep transfer learning method, J. Comput. Sci., IDAP-2022, pp. 202-210, (2022); Ali R., Alhatemi J., Savas S., Transfer learning-based classification comparison of stroke, J. Comput. Sci., pp. 192-201, (2022); Kabat G.C., Kim M.Y., Manson J.E., Lessin L., Lin J., Wassertheil-Smoller S., Rohan T.E., White blood cell count and total and cause-specific mortality in the women's health initiative, Am. J. Epidemiol., 186, 1, pp. 63-72, (2017); Malik Mohamed O., Normal reference value of blood cell count, red, white and..., Al Neelain Med. J., 3, 8, pp. 100-109, (2013); Savas S., Topaloglu N., Kazci O., Kosar P.N., Performance Comparison of Carotid Artery Intima Media Thickness Classification by Deep Learning Methods, HORA2019 - International Congress on Human-Computer Interaction, Optimization and Robotic Applications, 4, pp. 125-131, (2019); Khan R.U., Almakdi S., Alshehri M., Kumar R., Ali I., Hussain S.M., Haq A.U., Khan I., Ullah A., Uddin M.I., Probabilistic approach to COVID-19 data analysis and forecasting future outbreaks using a multi-layer perceptron neural network, Diagnostics, 12, 12, (2022); Gangadhar A., Sari-Sarraf H., Vanapalli S.A., Deep learning assisted holography microscopy for in-flow enumeration of tumor cells in blood, RSC Adv., 13, 7, pp. 4222-4235, (2023); Sharma S., Gupta S., Gupta D., Juneja S., Gupta P., Dhiman G., Kautish S., Deep learning model for the automatic classification of white blood cells, Comput. Intell. Neurosci., 2022, 1, pp. 1-13, (2022); Raillon C., Che J., Thill S., Duchamp M., Desbiolles B.X., Millet A., Sollier E., Renaud P., Toward microfluidic label-free isolation and enumeration of circulating tumor cells from blood samples, Cytometry, Part A, 95, 10, pp. 1085-1095, (2019); Yoon J., Jang W.S., Nam J., Mihn D.C., Lim C.S., An automated microscopic malaria parasite detection system using digital image analysis, Diagnostics, 11, 3, (2021); Cruz D., Jennifer Valiente C., Castor L.C., Mendoza C.M.T., Jay B.A., Jane L.S.C., Brian P.T.B., Determination of blood components (WBCs, RBCs, and Platelets) count in microscopic images using image processing and analysis, HNICEM 2017 - 9th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management, vol. 2018-Janua, pp. 1-7, (2017); Fatonah N.S., Tjandrasa H., Fatichah C., Automatic leukemia cell counting using iterative distance transform for convex sets, Int. J. Electr. Comput. Eng., 8, 3, pp. 1731-1740, (2018); Chen T.C., Chung K.L., An efficient randomized algorithm for detecting circles, Comput. Vis. Image Underst., 83, 2, pp. 172-191, (2001); Maitra M., Kumar Gupta R., Mukherjee M., Maitra M., Kumar Gupta R., Mukherjee M., Detection and counting of red blood cells in blood cell images using Hough transform, Int. J. Comput. Appl., 53, 16, pp. 13-17, (2012); Mahmood N.H., Lim P., Mazalan S., Abdul Razak M., Blood cells extraction using color based segmentation technique, Int. J. Life Sci. Biotechnol. Pharma Res., 2, 2, pp. 233-240, (2013); Mahmood N.H., Mansor M.A., Red blood cells estimation using Hough transform technique, Signal Image Process., 3, 2, (2012); Venkatalakshmi B., Thilagavathi K., Automatic red blood cell counting using Hough transform, IEEE Conference on Information and Communication Technologies, ICT 2013, pp. 267-271, (2013); Chen D.R., Chang R.F., Wu W.J., Moon W.K., Wu W.L., 3-D breast ultrasound segmentation using active contour model, Ultrasound Med. Biol., 29, 7, pp. 1017-1026, (2003); Shan J., Cheng H.D., Wang Y., Completely automated segmentation approach for breast ultrasound images using multiple-domain features, Ultrasound Med. Biol., 38, 2, pp. 262-275, (2012); Diaz-Pernil D., Berciano A., Pena-Cantillana F., Gutierrez-Naranjo M.A., Bio-inspired parallel computing of representative geometrical objects of holes of binary 2D-images, Int. J. Bio-Inspir. Comput., 9, 2, pp. 77-92, (2017)","R.U. Khan; Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou, 313001, China; email: rerukhan@gmail.com","","Elsevier Ltd","","","","","","24058440","","","","English","Heliyon","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85187303011"
"Shchetinin E.Y.; Glushkova A.G.; Blinkov Y.A.","Shchetinin, Eugene Yu. (16408533100); Glushkova, Anastasia G. (57485591900); Blinkov, Yury A. (6701893186)","16408533100; 57485591900; 6701893186","On Effectiveness of the Adversarial Attacks on the Computer Systems of Biomedical Images Classification","2023","Communications in Computer and Information Science","1748 CCIS","","","91","103","12","1","10.1007/978-3-031-30648-8_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161391475&doi=10.1007%2f978-3-031-30648-8_8&partnerID=40&md5=1be7cdf52aeacb41c838831351b7b3da","Financial University Under the Government of the Russian Federation, Moscow, Russian Federation; Oxford University, Oxford, United Kingdom; Peoples Friendship University of Russia (RUDN), Moscow, Russian Federation; Saratov State University, Saratov, Russian Federation","Shchetinin E.Y., Financial University Under the Government of the Russian Federation, Moscow, Russian Federation; Glushkova A.G., Oxford University, Oxford, United Kingdom; Blinkov Y.A., Peoples Friendship University of Russia (RUDN), Moscow, Russian Federation, Saratov State University, Saratov, Russian Federation","The problems of vulnerability of the computer systems of biomedical images classification to adversarial attacks on are investigated. The aim of the work is to study the effectiveness of the impact of various models of adversarial attacks on biomedical images and the values of control parameters of algorithms for generating their attacking versions. The effectiveness of attacks prepared using the projected gradient descent algorithm (PGD), Deep Fool (DF) algorithm and Carlini-Wagner algorithm (CW) is investigated. Experimental studies were carried out on the example of solving typical problems of medical images classification using deep neural networks VGG16, EfficientNetB2, DenseNet121, Xception, ResNet50 as well as data containing chest X-rays images and brain MRI-scan images. Our findings in this work are as follows. Deep models were very susceptible to adversarial attacks, which led to decrease of the accuracy classification of the models for all datasets. Prior to the use of adversarial methods, we achieved a classification accuracy of 93.6% for brain MRI and 99.1% for chest X-rays. During the DF attack the accuracy of the VGG16 model showed a maximum absolute decrease of 49.8% for MRI-scans, and 57.3% for chest X-rays images. The gradient descent (PGD) algorithm with the same values of malicious image disturbances is less effective than the DF and the CW adversarial attacks. VGG16 deep model is more effective in accuracy classification on considered datasets and most vulnerable to adversarial attacks among other deep models. We hope that these results would be useful to design more robust and secure medical deep learning systems. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","adversarial attacks; black-box attack; brain tumor MRI-scans; chest X-ray images; deep learning; white-box attacks","Bioinformatics; Deep neural networks; Gradient methods; Image classification; Learning systems; Magnetic resonance imaging; Medical imaging; Medical problems; Adversarial attack; Black boxes; Black-box attack; Brain tumor MRI-scan; Brain tumors; Chest X-ray image; Deep learning; MRI scan; White box; White-box attack; Classification (of information)","","","","","RUDN University","Y. Blinkov—This paper has been supported by the RUDN University Strategic Academic Leadership Program.","Cognitive Power Electronics 4.0-So knnten leistungselektronische Schaltungen entschei-den, All-Electronics.De-Entwicklung, Ferti-Gung, Automatisierung, 29.03.2019. [Online]; Towards evaluating the robustness of neural networks, 2017 IEEE Symposium on Security and Privacy (SP), pp. 39-57, (2017); Adversarial Attacks and Defences: A Survey, (2018); Analysis of classifiers’ robustness to adversarial perturbations, Mach. Learn., 107, 3, pp. 481-508, (2017); Adversarial attacks on medical machine learning, Science, 363, 6433, pp. 1287-1289, (2019); Adversarial examples are not bugs, they are features, Advances in Neural Information Processing Systems, 32, (2019); A deep learning approach to detect Covid-19 coronavirus with X-ray images, Biocybern. Biomed. Eng., 40, 4, pp. 1391-1405, (2020); Cognitive Power Electronics 4.0-So knnten leistungselektronische Schaltungen entschei-den, All-Electronics.De-Entwicklung, Ferti-Gung, Automatisierung, 29.03.2019. [Online]; A survey on deep learning in medical image analysis, Med. Image Anal., 42, pp. 60-88, (2017); Towards Deep Learning Models Resistant to Adversarial Attacks, (2017); DeepFool: A simple and accurate method to fool deep neural networks, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2574-2582, (2016); Adversarial attacks and defenses against deep neural networks: A survey, Procedia Comput. Sci., 140, pp. 152-161, (2018); Cognitive Power Electronics 4.0-So knnten leistungselektronische Schaltungen entschei-den, All-Electronics.De-Entwicklung, Ferti-Gung, Automatisierung, 29.03.2019. [Online]; Transferability in machine learning: From phenomena to black-box attacks using adversarial samples, Corr Abs/1605, (2016); On transfer learning methods in biomedical image classification tasks, Informatika I Ee Primeneniya, 15, 4, pp. 59-64, (2021); Automated detection of Covid-19 coronavirus infection based on analysis of chest X-ray images by deep learning methods. Tomsk State Univ, J. Control Comput. Sci., 58, pp. 98-105, (2022); Curls & Whey: Boosting black-box adversarial attacks, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6512-6520, (2019); Brain tumor detection using deep neural network and machine learning algorithm, 2019 9Th International Conference on Computer and Knowledge Engineering (ICCKE), pp. 363-368, (2019); A direct approach to robust deep learning using adversarial networks, Corr Abs/1905, (2019); PICA: A pixel correlation-based attentional black-box adversarial attack, Corr Abs/2101, (2021); Learning black-box attackers with transferable priors and query feedback, Proceedings of the 34Th International Conference on Neural Information Processing Systems, NIPS 2020, Vol. 33, pp. 12288-12299, (2020); Cognitive Power Electronics 4.0-So knnten leistungselektronische Schaltungen entschei-den, All-Electronics.De-Entwicklung, Ferti-Gung, Automatisierung, 29.03.2019. [Online]","Y.A. Blinkov; Saratov State University, Saratov, Russian Federation; email: BlinkovUA@sgu.ru","Vishnevskiy V.M.; Samouylov K.E.; Kozyrev D.V.; Kozyrev D.V.","Springer Science and Business Media Deutschland GmbH","","25th International Conference on Distributed Computer and Communication Networks, DCCN 2022","26 September 2022 through 29 September 2022","Moscow","294039","18650929","978-303130647-1","","","English","Commun. Comput. Info. Sci.","Conference paper","Final","","Scopus","2-s2.0-85161391475"
"Mishra A.K.; Gupta I.K.; Diwan T.D.; Srivastava S.","Mishra, Awanish Kumar (57222248739); Gupta, Indresh Kumar (57188752252); Diwan, Tarun Dhar (57195319554); Srivastava, Swati (57198632001)","57222248739; 57188752252; 57195319554; 57198632001","Cervical precancerous lesion classification using quantum invasive weed optimization with deep learning on biomedical pap smear images","2024","Expert Systems","41","7","e13308","","","","4","10.1111/exsy.13308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158055678&doi=10.1111%2fexsy.13308&partnerID=40&md5=07f0811a97227eda45c6eebe7a88a959","Computer Science & Engineering, Pranveer Singh Institute of Technology, Kanpur, India; Computer Science & Engineering, Harcourt Butler Technical University, Kanpur, India; Information Technology, Government E. R. R. Post Graduate Science College, Bilaspur, India; Computer Engineering and Applications, GLA University, Mathura, India","Mishra A.K., Computer Science & Engineering, Pranveer Singh Institute of Technology, Kanpur, India; Gupta I.K., Computer Science & Engineering, Harcourt Butler Technical University, Kanpur, India; Diwan T.D., Information Technology, Government E. R. R. Post Graduate Science College, Bilaspur, India; Srivastava S., Computer Engineering and Applications, GLA University, Mathura, India","Biomedical imaging devices, in general, have been made and used a lot lately to examine the insides of the body during diagnostic and analytic procedures. Biomedical imaging gives accurate information about metabolites, which can be used to find and classify diseases because it is not invasive. For the study of cervical cancer (CC), the pap smear is a crucial type of biological imaging. CC is a crucial reason to enhance the rate of women's mortalities. Proper screening of pap smear images is critical for assisting in the early detection and analysis of CC. Computer-aided systems for cancerous cell recognition need well established artificial intelligence (AI) methods. In this study, we introduce an automated Cervical Precancerous Lesion Classification using Quantum Invasive Weed Optimization with Deep Learning (CPLC-QIWODL) on biomedical pap smear images. The presented CPLC-QIWODL technique examines the pap smear images for cervical cancer classification. To do so, the presented CPLC-QIWODL technique pre-processes the biomedical images using a Gabor filtering (GF) approach. Moreover, the CPLC-QIWODL technique uses a deep convolutional neural network-based SqueezeNet system for feature extraction. Furthermore, the hyperparameter tuning of the SqueezeNet methodology takes place using the QIWO technique, showing the novelty of the work. Finally, to classify CC, the deep variational autoencoder (DVAE) model is applied. The experimental result analysis of the CPLC-QIWODL technique is tested using a benchmark medical image database. Extensive comparative results demonstrated the enhanced outcomes of the CPLC-QIWODL technique over other existing algorithms, with a maximum accuracy of 99.07%. © 2023 John Wiley & Sons Ltd.","artificial intelligence; biomedical imaging; cervical cancer; metaheuristics; pap smear images","Classification (of information); Computer aided analysis; Computer aided diagnosis; Deep neural networks; Diseases; Image analysis; Image classification; Learning systems; Medical imaging; Metabolites; Biological imaging; Biomedical imaging; Cervical cancers; Imaging device; Invasive weed optimization; Learning techniques; Lesion classification; Metaheuristic; Pap smear; Pap smear images; Invasive weed optimization","","","","","","","Alanazi A.A., Khayyat M.M., Khayyat M.M., Elamin Elnaim B.M., Abdel-Khalek S., Intelligent deep learning enabled oral squamous cell carcinoma detection and classification using biomedical images, Computational Intelligence and Neuroscience, 2022, pp. 1-11, (2022); Buiu C., Danaila V.R., Raduta C.N., MobileNetV2 ensemble for cervical precancerous lesions classification, Processes, 8, 5, (2020); Dong Y., Wan J., Wang X., Xue J.H., Zou J., He H., Li P., Hou A., Ma H., A polarization-imaging-based machine learning framework for quantitative pathological diagnosis of cervical precancerous lesions, IEEE Transactions on Medical Imaging, 40, 12, pp. 3728-3738, (2021); Fang S., Yang J., Wang M., Liu C., Liu S., An improved image classification method for cervical precancerous lesions based on ShuffleNet, Computational Intelligence and Neuroscience, 2022, pp. 1-8, (2022); Gonzalez-Muniz A., Diaz I., Cuadrado A.A., Garcia-Perez D., Perez D., Two-step residual-error based approach for cancer detection in engineering systems using variational autoencoders, Computers and Electrical Engineering, 101, (2022); Guo P., Xue Z., Mtema Z., Yeates K., Ginsburg O., Demarco M., Long L.R., Schiffman M., Antani S., Ensemble deep learning for cervix image selection toward improving reliability in automated cervical precancer screening, Diagnostics, 10, 7, (2020); Hu L., Horning M.P., Banik D., Ajenifuja O.K., Adepiti C.A., Yeates K., Mtema Z., Wilson B., Mehanian C., Deep learning-based image evaluation for cervical precancer screening with a smartphone targeting low resource settings–engineering approach, 2020 42nd annual international conference of the IEEE engineering in Medicine & Biology Society (EMBC), pp. 1944-1949, (2020); Kundu R., Chattopadhyay S., Deep features selection through genetic algorithm for cervical pre-cancerous cell classification, Multimedia Tools and Applications, 82, pp. 1-22, (2022); Li S., Yan L., Yang J., Shen X., Guo Y., Ren P., Multi-source data fusion for recognition of cervical precancerous lesions, In 2020 Chinese Automation Congress (CAC), pp. 3597-3601, (2020); Liu J., Sun X., Li R., Peng Y., Recognition of cervical precancerous lesions based on probability distribution feature guidance, Current Medical Imaging, 18, 11, pp. 1204-1213, (2022); Luo Y.M., Zhang T., Li P., Liu P.Z., Sun P., Dong B., Ruan G., MDFI: Multi-CNN decision feature integration for diagnosis of cervical precancerous lesions, IEEE Access, 8, pp. 29616-29626, (2020); Movassagh A.A., Alzubi J.A., Gheisari M., Rahimi M., Mohan S., Abbasi A.A., Nabipour N., Artificial neural networks training algorithm integrating invasive weed optimization with differential evolutionary model, Journal of Ambient Intelligence and Humanized Computing, 6, pp. 1-9, (2021); Peng G., Dong H., Liang T., Li L., Liu J., Diagnosis of cervical precancerous lesions based on multimodal feature changes, Computers in Biology and Medicine, 130, (2021); Song H., Yan L., Yang J., Shen X., Guo Y., Ren P., Multi-model data fusion for cervical precancerous lesions detection, 2020 Chinese Automation Congress (CAC), pp. 4462-4467, (2020); Tyassari W., Jusman Y., Riyadi S., Sulaiman S.N., Classification of cervical precancerous cell of ThinPrep images based on deep learning model AlexNet and InceptionV3, In 2022 IEEE 11th international conference on communication systems and network technologies (CSNT), pp. 276-281, (2022); Ullah A., Elahi H., Sun Z., Khatoon A., Ahmad I., Comparative analysis of AlexNet, ResNet18 and SqueezeNet with diverse modification and arduous implementation, Arabian Journal for Science and Engineering, 47, 2, pp. 2397-2417, (2022); Waly M.I., Sikkandar M.Y., Aboamer M.A., Kadry S., Thinnukool O., Optimal deep convolution neural network for cervical cancer diagnosis model, Computers, Materials and Continua, 70, 2, pp. 3297-3309, (2022); Yan L., Li S., Guo Y., Ren P., Song H., Yang J., Shen X., Multi-state colposcopy image fusion for cervical precancerous lesion diagnosis using BF-CNN, Biomedical Signal Processing and Control, 68, (2021); Zhang B., Zhang Q., Zhou H., Xia C., Wang J., Automated prediction of cervical Precancer based on deep learning, Chinese intelligent systems conference, pp. 485-494, (2020); Zhang T., Luo Y.M., Li P., Liu P.Z., Du Y.Z., Sun P., Dong B., Xue H., Cervical precancerous lesions classification using pre-trained densely connected convolutional networks with colposcopy images, Biomedical Signal Processing and Control, 55, (2020); Zhang Y., Li L., Gu J., Wen T., Xu Q., Cervical precancerous lesion detection based on deep learning of colposcopy images, Journal of Medical Imaging and Health Informatics, 10, 5, pp. 1234-1241, (2020); Zhang Y., Zall Y., Nissim R., Zimmermann R., Evaluation of a new dataset for visual detection of cervical precancerous lesions, Expert Systems with Applications, 190, (2022)","A.K. Mishra; Computer Science & Engineering, Pranveer Singh Institute of Technology, Kanpur, India; email: mishra.awanish@gmail.com","","John Wiley and Sons Inc","","","","","","02664720","","EXSYE","","English","Expert Syst","Article","Final","","Scopus","2-s2.0-85158055678"
"Naeem A.; Anees T.; Fiza M.; Naqvi R.A.; Lee S.-W.","Naeem, Ahmad (57215772535); Anees, Tayyaba (50461069100); Fiza, Makhmoor (57853673900); Naqvi, Rizwan Ali (55975847900); Lee, Seung-Won (57223118056)","57215772535; 50461069100; 57853673900; 55975847900; 57223118056","SCDNet: A Deep Learning-Based Framework for the Multiclassification of Skin Cancer Using Dermoscopy Images","2022","Sensors","22","15","5652","","","","37","10.3390/s22155652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136341545&doi=10.3390%2fs22155652&partnerID=40&md5=e88839a56ed44629475b2fc55ce2fb19","Department of Computer Science, University of Management and Technology, Lahore, 54000, Pakistan; Department of Software Engineering, University of Management and Technology, Lahore, 54000, Pakistan; Department of Management Sciences and Technology, Begum Nusrat Bhutto Women University, Sukkur, 65200, Pakistan; Department of Unmanned Vehicle Engineering, Sejong University, Seoul, 05006, South Korea; Department of Data Science, College of Software Convergence, Sejong University, Seoul, 05006, South Korea; School of Medicine, Sungkyunkwan University, Suwon, 16419, South Korea","Naeem A., Department of Computer Science, University of Management and Technology, Lahore, 54000, Pakistan; Anees T., Department of Software Engineering, University of Management and Technology, Lahore, 54000, Pakistan; Fiza M., Department of Management Sciences and Technology, Begum Nusrat Bhutto Women University, Sukkur, 65200, Pakistan; Naqvi R.A., Department of Unmanned Vehicle Engineering, Sejong University, Seoul, 05006, South Korea; Lee S.-W., Department of Data Science, College of Software Convergence, Sejong University, Seoul, 05006, South Korea, School of Medicine, Sungkyunkwan University, Suwon, 16419, South Korea","Skin cancer is a deadly disease, and its early diagnosis enhances the chances of survival. Deep learning algorithms for skin cancer detection have become popular in recent years. A novel framework based on deep learning is proposed in this study for the multiclassification of skin cancer types such as Melanoma, Melanocytic Nevi, Basal Cell Carcinoma and Benign Keratosis. The proposed model is named as SCDNet which combines Vgg16 with convolutional neural networks (CNN) for the classification of different types of skin cancer. Moreover, the accuracy of the proposed method is also compared with the four state-of-the-art pre-trained classifiers in the medical domain named Resnet 50, Inception v3, AlexNet and Vgg19. The performance of the proposed SCDNet classifier, as well as the four state-of-the-art classifiers, is evaluated using the ISIC 2019 dataset. The accuracy rate of the proposed SDCNet is 96.91% for the multiclassification of skin cancer whereas, the accuracy rates for Resnet 50, Alexnet, Vgg19 and Inception-v3 are 95.21%, 93.14%, 94.25% and 92.54%, respectively. The results showed that the proposed SCDNet performed better than the competing classifiers. © 2022 by the authors.","automated/computer aided diagnosis; biomedical image; melanoma; skin cancer; transfer learning","Deep Learning; Dermoscopy; Humans; Melanoma; Neural Networks, Computer; Skin Neoplasms; Classification (of information); Convolutional neural networks; Deep learning; Dermatology; Diseases; Learning algorithms; Oncology; Transfer learning; Accuracy rate; Automated/computer aided diagnose; Biomedical images; Dermoscopy images; Early diagnosis; Melanoma; Multi-classification; Skin cancers; State of the art; Transfer learning; diagnostic imaging; epiluminescence microscopy; human; melanoma; pathology; procedures; skin tumor; Computer aided diagnosis","","","","","Ministry of Science, ICT and Future Planning, MSIP, (NRF2021R1I1A2059735, NRF2022R1G1A101022611); National Research Foundation of Korea, NRF","This work was supported by a national research foundation (NRF) grant funded by the Ministry of Science and ICT (MSIT), South Korea through the Development Research Program (NRF2022R1G1A101022611) and (NRF2021R1I1A2059735).","Basal and Squamous Cell Skin Cancer Causes Risk Factors, and Prevention; Gandhi S.A., Kampp J., Skin cancer epidemiology, detection, and management, Med. Clin, 99, pp. 1323-1335, (2015); Harrison S.C., Bergfeld W.F., Ultraviolet light and skin cancer in athletes, Sports Health, 1, pp. 335-340, (2009); Skin Cancers; Kittler H., Pehamberger H., Wolff K., Binder M., Diagnostic accuracy of dermoscopy, Lancet Oncol, 3, pp. 159-165, (2002); Yelamos O., Braun R.P., Liopyris K., Wolner Z.J., Kerl K., Gerami P., Marghoob A.A., Usefulness of dermoscopy to improve the clinical and histopathologic diagnosis of skin cancers, J. Am. Acad. Dermatol, 80, pp. 365-377, (2019); Fee J.A., McGrady F.P., Rosendahl C., Hart N.D., Training primary care physicians in dermoscopy for skin cancer detection: A scoping review, J. Cancer Educ, 35, pp. 643-650, (2020); Marra E., van Rijsingen M.C.J., Alkemade J.A.C., Groenewoud J.M.M., Hueskes K.F., Bijvank C.H.M.N., van de Laar F.A., Lubeek S.F.K., The effect of a dermato-oncological training programme on the diagnostic skills and quality of referrals for suspicious skin lesions by general practitioners, Br. J. Dermatol, 184, pp. 538-544, (2021); Oliveira R.B., Papa J.P., Pereira A.S., Tavares J.M.R.S., Computational methods for pigmented skin lesion classification in images: Review and future trends, Neural Comput. Appl, 29, pp. 613-636, (2018); Saba T., Khan M.A., Rehman A., Marie-Sainte S.L., Region extraction and classification of skin cancer: A heterogeneous framework of deep CNN features fusion and reduction, J. Med. Syst, 43, (2019); Emanuelli M., Sartini D., Molinelli E., Campagna R., Pozzi V., Salvolini E., Simonetti O., Campanati A., Offidani A., The double-edged sword of oxidative stress in skin damage and melanoma: From physiopathology to therapeutical approaches, Antioxidants, 11, (2022); Nasir M., Khan M.A., Sharif M., Lali I.U., Saba T., Iqbal T., An improved strategy for skin lesion detection and classification using uniform segmentation and feature selection-based approach, Microsc. Res. Tech, 81, pp. 528-543, (2018); Tronnier M., Melanotic spots and melanocytic nevi, Braun-Falco´s Dermatology, pp. 1-18, (2020); Ferlay J., Colombet M., Soerjomataram I., Parkin D.M., Pineros M., Znaor A., Bray F., Cancer statistics for the year 2020: An overview, Int. J. Cancer, 149, pp. 778-789, (2021); Rogers H.W., Weinstock M.A., Feldman S.R., Coldiron B.M., Incidence estimate of nonmelanoma skin cancer (keratinocyte carcinomas) in the US population, 2012, JAMA Dermatol, 151, pp. 1081-1086, (2015); Facts and Figures, (2021); Cancer Facts and Figures, (2022); Arbyn M., Weiderpass E., Bruni L., de Sanjose S., Saraiya M., Ferlay J., Bray F., Estimates of incidence and mortality of cervical cancer in 2018: A worldwide analysis, Lancet Glob. Health, 8, pp. e191-e203, (2020); Melanoma of the Skin Statistics; Sung H., Ferlay J., Siegel R.L., Laversanne M., Soerjomataram I., Jemal A., Bray F., Global cancer statistics 2020: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries, CA Cancer J. Clin, 71, pp. 209-249, (2021); Silverberg E., Boring C.C., Squires T.S., Cancer statistics, 1990, CA Cancer J. Clin, 40, pp. 9-26, (1990); Zhang B., Zhou X., Luo Y., Zhang H., Yang H., Ma J., Ma L., Opportunities and challenges: Classification of skin disease based on deep learning, Chin. J. Mech. Eng, 34, (2021); Thanh D.N.H., Prasath V.B., Hieu L.M., Hien N.N., Melanoma skin cancer detection method based on adaptive principal curvature, colour normalisation and feature extraction with the ABCD rule, J. Digit. Imaging, 33, pp. 574-585, (2020); Ali A.-R.H., Li J., Yang G., Automating the ABCD rule for melanoma detection: A survey, IEEE Access, 8, pp. 83333-83346, (2020); Murugan A., Nair S.A.H., Kumar K.P., Detection of skin cancer using SVM, random forest and kNN classifiers, J. Med. Syst, 43, (2019); Zawish M., Siyal A.A., Shahani S.H., Junejo A.Z., Khalil A., Brain tumor segmentation through region-based, supervised and unsupervised learning methods: A literature survey, J. Biomed. Eng. Med. Imaging, 6, pp. 8-26, (2019); Abdar M., Samami M., Mahmoodabad S.D., Doan T., Mazoure B., Hashemifesharaki R., Liu L., Khosravi A., Acharya U.R., Makarenkov V., Et al., Uncertainty quantification in skin cancer classification using three-way decision-based Bayesian deep learning, Comput. Biol. Med, 135, (2021); Hosny K.M., Kassem M.A., Foaud M.M., Classification of skin lesions using transfer learning and augmentation with Alex-net, PLoS ONE, 14, (2019); Khamparia A., Singh P.K., Rani P., Samanta D., Khanna A., Bhushan B., An internet of health things-driven deep learning framework for detection and classification of skin cancer using transfer learning, Trans. Emerg. Telecommun. Technol, 32, (2021); Nahata H., Singh S.P., Deep learning solutions for skin cancer detection and diagnosis, Machine Learning with Health Care Perspective, pp. 159-182, (2020); Demir A., Yilmaz F., Kose O., Early detection of skin cancer using deep learning architectures: Resnet-101 and inception-v3, Proceedings of the 2019 Medical Technologies Congress (TIPTEKNO), pp. 1-4; Cassidy B., Kendrick C., Brodzicki A., Jaworek-Korjakowska J., Yap M.H., Analysis of the ISIC image datasets: Usage, benchmarks and recommendations, Med. Image Anal, 75, (2022); Abbas Q., Ramzan F., Ghani M.U., Acral melanoma detection using dermoscopic images and convolutional neural networks, Vis. Comput. Ind. Biomed. Art, 4, (2021); Sayed G.I., Soliman M.M., Hassanien A.E., A novel melanoma prediction model for imbalanced data using optimized SqueezeNet by bald eagle search optimization, Comput. Biol. Med, 136, (2021); Mijwil M.M., Skin cancer disease images classification using deep learning solutions, Multimed. Tools Appl, 80, pp. 26255-26271, (2021); Nawaz M., Mehmood Z., Nazir T., Naqvi R.A., Rehman A., Iqbal M., Saba T., Skin cancer detection from dermoscopic images using deep learning and fuzzy k-means clustering, Microsc. Res. Tech, 85, pp. 339-351, (2022); Dorj U., Lee Ke Choi J., Lee M., The skin cancer classification using deep convolutional neural network, Multimed. Tools Appl, 77, pp. 9909-9924, (2018); Afza F., Sharif M., Mittal M., Khan M.A., Jude Hemanth D., A hierarchical three-step superpixels and deep learning framework for skin lesion classification, Methods, 202, pp. 88-102, (2022); Hameed N., Shabut A.M., Ghosh M.K., Hossain M., Multi-class multi-level classification algorithm for skin lesions classification using machine learning techniques, Expert Syst. Appl, 141, (2020); Singh L., Janghel R.R., Sahu S.P., TrCSVM: A novel approach for the classification of melanoma skin cancer using transfer learning, Data Technol. Appl, 55, pp. 64-81, (2021); Arshad M., Khan M.A., Tariq U., Armghan A., Alenezi F., Javed M.Y., Aslam S.M., Kadry S., A computer-aided diagnosis system using deep learning for multiclass skin lesion classification, Comput. Intell. Neurosci, 2021, (2021); Khan M.A., Akram T., Zhang Y.-D., Sharif M., Attributes based skin lesion detection and recognition: A mask RCNN and transfer learning-based deep learning framework, Pattern Recognit. Lett, 143, pp. 58-66, (2021); Abunadi I., Senan E.M., Deep learning and machine learning techniques of diagnosis dermoscopy images for early detection of skin diseases, Electronics, 10, (2021); Naeem A., Farooq M.S., Khelifi A., Abid A., Malignant melanoma classification using deep learning: Datasets, performance measurements, challenges and opportunities, IEEE Access, 8, pp. 110575-110597, (2020); Malik H., Anees T., BDCNet: Multi-classification convolutional neural network model for classification of COVID-19, pneumonia, and lung cancer from chest radiographs, Multimed. Syst, 28, pp. 815-829, (2022); Naeem A., Anees T., Naqvi R.A., Loh W.-K., A comprehensive analysis of recent deep and federated-learning-based methodologies for brain tumor diagnosis, J. Pers. Med, 12, (2022); Deeba F., Kun S., Dharejo F.A., Zhou Y., Sparse representation based computed tomography images reconstruction by coupled dictionary learning algorithm, IET Image Process, 14, pp. 2365-2375, (2020); Zawish M., Siyal A.A., Ahmed K., Khalil A., Memon S., Brain tumor segmentation in MRI images using Chan-Vese technique in MATLAB, Proceedings of the 2018 International Conference on Computing, Electronic and Electrical Engineering (ICE Cube), pp. 1-6; Eraslan G., Avsec Z., Gagneur J., Theis F.J., Deep learning: New computational modelling techniques for genomics, Nat. Rev. Genet, 20, pp. 389-403, (2019); Khan M.A., Muhammad K., Sharif M., Akram T., Kadry S., Intelligent fusion-assisted skin lesion localization and classification for smart healthcare, Neural Comput. Appl, pp. 1-16, (2021); Chaturvedi S.S., Tembhurne J.V., Diwan T., A multi-class skin cancer classification using deep convolutional neural networks, Multimed. Tools Appl, 79, pp. 28477-28498, (2020); Deeba F., Kun S., Dharejo F.A., Zhou Y., Wavelet-based enhanced medical image super resolution, IEEE Access, 8, pp. 37035-37044, (2020); Dharejo F.A., Deeba F., Zhou Y., Das B., Jatoi M.A., Zawish M., Du Y., Wang X., TWIST-GAN: Towards wavelet transform and transferred GAN for spatio-temporal single image super resolution, ACM Trans. Intell. Syst. Technol. (TIST), 12, pp. 1-20, (2021); Jeny A.A., Sakib A.N.M., Junayed M.S., Lima K.A., Ahmed I., Islam B., SkNet: A convolutional neural networks based classification approach for skin cancer classes, Proceedings of the 2020 23rd International Conference on Computer and Information Technology (ICCIT), pp. 1-6; AAli S., Miah S., Haque J., Rahman M., Islam K., An enhanced technique of skin cancer classification using deep convolutional neural network with transfer learning models, Mach. Learn. Appl, 5, (2021); You Y., Zhang Z., Hsieh C., Demmel J., Keutzer K., Imagenet training in minutes, Proceedings of the 47th International Conference on Parallel Processing, pp. 1-10; Quang N.H., Automatic skin lesion analysis towards melanoma detection, Proceedings of the 2017 21st Asia Pacific Symposium on Intelligent and Evolutionary Systems (IES), pp. 106-111; Amin J., Sharif A., Gul N., Anjum M.A., Nisar M.W., Azam F., Bukhari S.A.C., Integrated design of deep features fusion for localization and classification of skin cancer, Pattern Recognit. Lett, 131, pp. 63-70, (2020); Aburaed N., Panthakkan A., Al-Saad M., Amin S.A., Mansoor W., Deep convolutional neural network (DCNN) for skin cancer classification, Proceedings of the 2020 27th IEEE International Conference on Electronics, Circuits and Systems (ICECS), pp. 1-4; Zhang J., Xie Y., Xia Y., Shen C., Attention residual learning for skin lesion classification, IEEE Trans. Med. Imaging, 38, pp. 2092-2103, (2019); Liu L., Mou L., Zhu X.X., Mandal M., Automatic skin lesion classification based on mid-level feature learning, Comput. Med. Imaging Graph, 84, (2020); Hohn J., Hekler A., Krieghoff-Henning E., Kather J.N., Utikal J.S., Meier F., Gellrich F.F., Hauschild A., French L., Schlager J.G., Et al., Integrating patient data into skin cancer classification using convolutional neural networks: Systematic review, J. Med. Internet Res, 23, (2021); Esteva A., Kuprel B., Novoa R.A., Ko J., Swetter S.M., Blau H.M., Thrun S., Dermatologist-level classification of skin cancer with deep neural networks, Nature, 542, pp. 115-118, (2017); Maron R.C., Weichenthal M., Utikal J.S., Hekler A., Berking C., Hauschild A., Enk A.H., Haferkamp S., Klode J., Schadendorf D., Et al., Systematic outperformance of 112 dermatologists in multiclass skin cancer image classification by convolutional neural networks, Eur. J. Cancer, 119, pp. 57-65, (2019); Hosny K.M., Kassem M.A., Fouad M.M., Classification of skin lesions into seven classes using transfer learning with AlexNet, J. Digit. Imaging, 33, pp. 1325-1334, (2020)","R.A. Naqvi; Department of Unmanned Vehicle Engineering, Sejong University, Seoul, 05006, South Korea; email: rizwanali@sejong.ac.kr; S.-W. Lee; Department of Data Science, College of Software Convergence, Sejong University, Seoul, 05006, South Korea; email: swlsejong@sejong.ac.kr","","MDPI","","","","","","14248220","","","35957209","English","Sensors","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85136341545"
"de Freitas Barbosa V.A.; Félix da Silva A.; de Santana M.A.; Rabelo de Azevedo R.; Fernandes de Lima R.D.C.; dos Santos W.P.","de Freitas Barbosa, Valter Augusto (57201760368); Félix da Silva, Anderson (57894860500); de Santana, Maíra Araújo (57211919598); Rabelo de Azevedo, Rian (57894860600); Fernandes de Lima, Rita de Cássia (8986453100); dos Santos, Wellington Pinheiro (57193746428)","57201760368; 57894860500; 57211919598; 57894860600; 8986453100; 57193746428","Deep-Wavelets and convolutional neural networks to support breast cancer diagnosis on thermography images","2023","Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization","11","3","","895","913","18","1","10.1080/21681163.2022.2118174","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138268240&doi=10.1080%2f21681163.2022.2118174&partnerID=40&md5=84c3cf6717c0528b6b0a3920a75acd50","Departamento de Engenharia Mecânica, Universidade Federal de Pernambuco, Pernambuco, Recife, Brazil; Unidade Acadêmica de Serra Talhada, Pernambuco, Serra Talhada, Brazil; Departamento de Engenharia Biomédica, Universidade Federal de Pernambuco, Pernambuco, Recife, Brazil; Escola Politécnica da Universidade de Pernambuco, Pernambuco, Recife, Brazil","de Freitas Barbosa V.A., Departamento de Engenharia Mecânica, Universidade Federal de Pernambuco, Pernambuco, Recife, Brazil, Unidade Acadêmica de Serra Talhada, Pernambuco, Serra Talhada, Brazil; Félix da Silva A., Departamento de Engenharia Biomédica, Universidade Federal de Pernambuco, Pernambuco, Recife, Brazil; de Santana M.A., Escola Politécnica da Universidade de Pernambuco, Pernambuco, Recife, Brazil; Rabelo de Azevedo R., Departamento de Engenharia Biomédica, Universidade Federal de Pernambuco, Pernambuco, Recife, Brazil; Fernandes de Lima R.D.C., Departamento de Engenharia Mecânica, Universidade Federal de Pernambuco, Pernambuco, Recife, Brazil; dos Santos W.P., Departamento de Engenharia Biomédica, Universidade Federal de Pernambuco, Pernambuco, Recife, Brazil","Breast cancer is the most dangerous type of cancer and one of the most lethal for women, both in underdeveloped and central countries. Breast thermography is an emerging imaging technique that can be applied as a complementary procedure for screening breast lesions. However, the low knowledge about the interpretation of these images by mastologists makes it difficult to adopt them in clinical practice. Computer-aided detection (CAD) systems can assist medical professionals in this task. Deep learning techniques have contributed to obtaining good results in the classification of biomedical images in general. In this work, we propose Deep-Wavelet Neural Networks (DWNN), convolutional architectures based on the general theory of Wavelets to extract features from images. For classification of thermographic images, we propose hybrid architectures based on deep network for feature extraction, Random Forests for selection of the most statistically relevant features and linear kernel support vector machines for final layer classification. We compare DWNN with next-gen deep networks. Our dataset consists of 336 thermographic images, classified into healthy (no lesion), cyst, benign lesion and malignant lesion. Experimental results show that the 6-layer DWNN achieved accuracy, sensitivity, specificity, kappa and precision above 98%. These results show that DWNN are competitive deep architectures that can be used to optimise thermographic image analysis and clinical adoption. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","breast cancer diagnosis; convolutional neural networks; Deep-Wavelet Neural Networks; Hybrid deep architectures; image diagnosis","Computer aided diagnosis; Computer aided instruction; Convolution; Decision trees; Deep neural networks; Diseases; Feature extraction; Image classification; Learning systems; Medical imaging; Network architecture; Support vector machines; Thermography (imaging); Architecture-based; Breast Cancer; Breast cancer diagnosis; Breast lesion; Convolutional neural network; Deep architectures; Deep-wavelet neural network; Hybrid deep architecture; Image diagnosis; Neural-networks; Article; breast cancer; cancer diagnosis; classifier; clinical decision making; clinical practice; computer assisted tomography; controlled study; convolutional neural network; cross validation; deep learning; deep neural network; diagnostic test accuracy study; feature extraction; female; high throughput sequencing; human; image segmentation; inception v3; learning algorithm; machine learning; mathematical analysis; measurement accuracy; mobilenet neural network; neighborhood; random forest; residual neural network; sensitivity and specificity; support vector machine; thermography; very deep convolutional network; wavelet analysis; xception nerual network; Convolutional neural networks","","","","","CAPES-PPGEC-UPE-2020; CNPq-DT2-2021; Ci?ncia e Tecnologia do Estado de Pernambuco, (IBPG-PPGEC-UPE-2020); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior, CAPES; Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq; Fundação de Amparo à Ciência e Tecnologia do Estado de Pernambuco, FACEPE; Universidade de Pernambuco, UPE, (PPGEC-UPE-2020); Universidade de Pernambuco, UPE","Funding text 1: The authors are grateful to the Brazilian research agencies FACEPE, CAPES and CNPq, for the partial financial support of this research. ; Funding text 2: The work was supported by the CAPES [CAPES-PPGEC-UPE-2020]; CNPQ [CNPq-DT2-2021]; Funda??o de Amparo ? Ci?ncia e Tecnologia do Estado de Pernambuco [IBPG-PPGEC-UPE-2020]; Universidade de Pernambuco [PPGEC-UPE-2020]. The authors are grateful to the Brazilian research agencies FACEPE, CAPES and CNPq, for the partial financial support of this research.","Albawi S., Mohammed T.A., Al-Zawi S., Understanding of a convolutional neural network, 2017 International Conference on Engineering and Technology (ICET), pp. 1-6, (2017); Araujo M.C., Lima R.C., De Souza R.M., Interval symbolic feature extraction for thermography breast cancer detection, Expert Syst Appl, 41, 15, pp. 6728-6737, (2014); Arora N., Martins D., Ruggerio D., Tousimis E., Swistel A.J., Osborne M.P., Simmons R.M., Effectiveness of a noninvasive digital infrared thermal imaging system in the detection of breast cancer, Am J Surg, 196, 4, pp. 523-526, (2008); Azevedo W.W., Lima S.M., Fernandes I.M., Rocha A.D., Cordeiro F.R., Da Silva-Filho A.G., Dos Santos W.P., Fuzzy Morphological Extreme Learning Machines to detect and classify masses in mammograms, IEEE International Conference on Fuzzy Systems, (2015); Barbosa V.A.D.F., de Santana M.A., Andrade M.K.S., de Lima R.D.C.F., dos Santos W.P., Deep-Wavelet neural networks for breast cancer early diagnosis using mammary termographies, Deep Learning for Data Analytics: foundations, Biomedical Applications, and Challenges, pp. 99-124, (2020); Bezerra L., Oliveira M., Rolim T., Conci A., Santos F., Lyra P., Lima R.C., Estimation of breast tumor thermal properties using infrared images, Sig Proc, 93, 10, pp. 2851-2863, (2013); Blagus R., Lusa L., Smote for high-dimensional class-imbalanced data, BMC Bioinform, 14, 1, (2013); Borchartt T.B., Conci A., Lima R.C., Resmini R., Sanchez A., Breast thermography from an image processing viewpoint: a survey, Sig Proc, 93, 10, pp. 2785-2803, (2013); Bouckaert R.R., Frank E., Hall M., Kirkby R., Reutemann P., Seewald A., Scuse D., Weka manual for version 3-8-1, (2016); Chaves E., Goncalves C.B., Albertini M.K., Lee S., Jeon G., Fernandes H.C., Evaluation of transfer learning of pre-trained CNNs applied to breast cancer detection on infrared images, Appl Opt, 59, 17, pp. E23-E28, (2020); Chawla N.V., Bowyer K.W., Hall L.O., Kegelmeyer W.P., Smote: synthetic minority over-sampling technique, J Artif Intell Res, 16, pp. 321-357, (2002); Cherepenin V., Karpov A., Korjenevsky A., Kornienko V., Mazaletskaya A., Mazourov D., Meister D., A 3D electrical impedance tomography (EIT) system for breast cancer detection, Physiol Meas, 22, 1, (2001); Chollet F., Keras, (2015); Chollet F., Xception: deep learning with depthwise separable convolutions, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1251-1258, (2017); de Freitas Oliveira Baffa M., Grassano Lattari L., Convolutional neural networks for static and dynamic breast infrared imaging classification, 2018 31st SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI), pp. 174-181, (2018); Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L., ImageNet: a large-scale hierarchical image database, 2009 IEEE conference on computer vision and pattern recognition, pp. 248-255, (2009); Ekici S., Jawzal H., Breast cancer diagnosis using thermography and convolutional neural networks, Med Hypotheses, 137, (2020); Etehadtavakol M., Ng E.Y., Breast thermography as a potential non-contact method in the early detection of cancer: a review, J Mech Med Biol, 13, 2, (2013); Gautherie M., Gros C.M., Breast thermography and cancer risk prediction, Cancer, 45, 1, pp. 51-56, (1980); Gogoi U.R., Bhowmik M.K., Bhattacharjee D., Ghosh A.K., Singular value based characterization and analysis of thermal patches for early breast abnormality detection, Australas Phys Eng Sci Med, 41, 4, pp. 861-879, (2018); Hall M., Frank E., Holmes G., Pfahringer B., Reutemann P., Witten I.H., The weka data mining software: an update, ACM SIGKDD Explorations Newsletter, 11, 1, pp. 10-18, (2009); Haykin S., He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (1998); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Hinton G., Vinyals O., Dean J., Distilling the knowledge in a neural network, (2015); Howard A.G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., Mobilenets: efficient convolutional neural networks for mobile vision applications, CoRr, (2017); Estatísticas de câncer, (2021); Karim C.N., Mohamed O., Ryad T., A new approach for breast abnormality detection based on thermography, Med Technol J, 2, 3, pp. 245-254, (2018); Karpathy A., Toderici G., Shetty S., Leung T., Sukthankar R., Fei-Fei L., Large-Scale video classification with convolutional neural networks, Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pp. 1725-1732, (2014); Keras, Keras applications; Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Adv Neural Inf Process Syst, 25, pp. 1097-1105, (2012); Liang H., Lin X., Zhang Q., Kang X., Recognition of spoofed voice using convolutional neural networks, 2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP), pp. 293-297, (2017); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3431-3440, (2015); Mallat S.G., Multifrequency channel decompositions of images and wavelet models, IEEE Trans Acoustics, Speech, and Sig Proc, 37, 12, pp. 2091-2110, (1989); Mambou S.J., Maresova P., Krejcar O., Selamat A., Kuca K., Breast cancer detection using infrared thermal imaging and a deep learning model, Sensors, 18, 9, (2018); Meira L.F., Krueger E., Neves E.B., Nohama P., de Souza M.A., Termografia na área biomédica, Pan Am J Med Thermol, 1, 1, pp. 31-41, (2014); Mishra S., Prakash A., Roy S.K., Sharan P., Mathur N., Breast cancer detection using thermal images and deep learning, 2020 7th International Conference on Computing for Sustainable Global Development (INDIACom), pp. 211-216, (2020); Moghbel M., Mashohor S., A review of computer assisted detection/diagnosis (CAD) in breast thermography for breast cancer detection, Artif Intell Rev, 39, 4, pp. 305-313, (2013); Morales-Cervantes A., Kolosovas-Machuca E.S., Guevara E., Reducindo M.M., Hernandez A.B.B., Garcia M.R., Gonzalez F.J., An automated method for the evaluation of breast cancer using infrared thermography, EXCLI Journal, 17, (2018); Neumann L., Nowak R.M., Okuniewski R., Oleszkiewicz W., Cichosz P., Jagodzinski D., Matysiewicz M., Preprocessing for classification of thermograms in breast cancer detection, Photonics Applications in Astronomy, Communications, Industry, and High-Energy Physics Experiments 2016, 10031, (2016); Oleszkiewicz W., Cichosz P., Jagodzinski D., Matysiewicz M., Neumann L., Nowak R.M., Okuniewski R., Application of SVM classifier in thermographic image classification for early detection of breast cancer, Photonics Applications in Astronomy, Communications, Industry, and High-Energy Physics Experiments 2016, 10031, (2016); Oliveira M.M.D., Desenvolvimento de protocolo e construção de um aparato mecânico para padronização da aquisição de imagens termográficas de mama, (2012); O'Shea K., Nash R., An introduction to convolutional neural networks, (2015); Parsian A., Ramezani M., Ghadimi N., A hybrid neural network-gray wolf optimization algorithm for melanoma detection, Biomed Res, 28, 8, pp. 3408-3411, (2017); Razmjooy N., Sheykhahmad F.R., Ghadimi N., A hybrid neural network–world cup optimization algorithm for melanoma detection, Open Med, 13, 1, pp. 9-16, (2018); Rodrigues A.L., de Santana M.A., Azevedo W.W., Bezerra R.S., Barbosa V.A., de Lima R.C., dos Santos W.P., Identification of mammary lesions in thermographic images: feature selection study using genetic algorithms and particle swarm optimization, J Biomed Eng Res, 35, 3, pp. 213-222, (2019); Ronneberger O., Fischer P., Brox T., U-Net: convolutional networks for biomedical image segmentation, International Conference on Medical image computing and computer-assisted intervention, pp. 234-241, (2015); Roslidar R., Saddami K., Arnia F., Syukri M., Munadi K., A study of fine-tuning cnn models based on thermal imaging for breast cancer classification, 2019 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom), pp. 77-81, (2019); Sanchez-Ruiz D., Olmos-Pineda I., Olvera-Lopez J.A., Automatic region of interest segmentation for breast thermogram image classification, Pattern Recognit Lett, 135, pp. 72-81, (2020); Santana M.A.D., Pereira J.M.S., Silva F.L.D., Lima N.M.D., Sousa F.N.D., Arruda G.M.S.D., Lima R.D.C.F.D., Silva W.W.A.D., Santos W.P.D., Breast cancer diagnosis based on mammary thermography and extreme learning machines, J Biomed Eng Res, 34, 1, pp. 45-53, (2018); Schaefer G., Nakashima T., Zavisek M., Analysis of breast thermograms based on statistical image features and hybrid fuzzy classification, International Symposium on Visual Computing, pp. 753-762, (2008); Silva L., Saade D., Sequeiros G., Silva A., Paiva A., Bravo R., Conci A., A new database for breast research with infrared image, J Med Imaging Health Infor, 4, 1, pp. 92-100, (2014); Silva L.F., Santos A.A.S., Bravo R.S., Silva A.C., Muchaluat-Saade D.C., Conci A., Hybrid analysis for indicating patients with breast cancer using temperature time series, Comput Methods Programs Biomed, 130, pp. 142-153, (2016); Silva L., Seixas F., Fontes C., Muchaluat-Saade D., Conci A., A computational method for breast abnormality detection using thermographs, 2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS), pp. 469-474, (2020); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, CoRr, (2015); Singh D., Singh A.K., Role of image thermography in early breast cancer detection- past, present and future, Comput Methods Programs Biomed, 183, (2020); Szegedy C., Ioffe S., Vanhoucke V., Alemi A., Inception-V4, inception-resnet and the impact of residual connections on learning, Proceedings of the AAAI Conference on Artificial Intelligence, 31, (2017); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (2015); Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., Rethinking the inception architecture for computer vision, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2818-2826, (2016); Tello-Mijares S., Woo F., Flores F., Breast cancer identification via thermography image segmentation with a gradient vector flow and a convolutional neural network, J Healthc Eng, 2019, (2019); Tran D., Wang H., Torresani L., Feiszli M., Video classification with channel-separated convolutional networks, Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 5552-5561, (2019); Walker D., Kaczor T., Breast thermography: history, theory, and use. Is this screening tool adequate for standalone use?, Nat Med J, 4, 7, (2012); Breast cancer, (2019); Xu Z., Sheykhahmad F.R., Ghadimi N., Razmjooy N., Computer-Aided diagnosis of skin cancer based on soft computing techniques, Open Med, 15, 1, pp. 860-871, (2020); Yang F., Sun Q., Jin H., Zhou Z., Superpixel segmentation with fully convolutional networks, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 13964-13973, (2020); Zhou R., Liu F., Gravelle C.W., Deep learning for modulation recognition: a survey with a demonstration, IEEE Access, 8, pp. 67366-67376, (2020)","W.P. dos Santos; Departamento de Engenharia Biomédica, Universidade Federal de Pernambuco, Recife, Pernambuco, Brazil; email: wellington.santos@ufpe.br","","Taylor and Francis Ltd.","","","","","","21681163","","","","English","Comput. Methods Biomech. Biomed. Eng. Imaging and Visualization","Article","Final","","Scopus","2-s2.0-85138268240"
"Pradhan A.K.; Das K.; Mishra D.; Chithaluru P.","Pradhan, Ashwini Kumar (57223054673); Das, Kaberi (57210528390); Mishra, Debahuti (35070028500); Chithaluru, Premkumar (57201708482)","57223054673; 57210528390; 35070028500; 57201708482","Optimizing CNN-LSTM hybrid classifier using HCA for biomedical image classification","2023","Expert Systems","40","5","e13235","","","","15","10.1111/exsy.13235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147220372&doi=10.1111%2fexsy.13235&partnerID=40&md5=1adc130c8bfea14dd807c881a0b1023a","Department of Computer Science and Engineering, Siksha O Anusandhan (Deemed to Be University), Bhubaneswar, India; Department of Computer Science and Engineering, Chaitanya Bharathi Institute of Technology, Hyderabad, India","Pradhan A.K., Department of Computer Science and Engineering, Siksha O Anusandhan (Deemed to Be University), Bhubaneswar, India; Das K., Department of Computer Science and Engineering, Siksha O Anusandhan (Deemed to Be University), Bhubaneswar, India; Mishra D., Department of Computer Science and Engineering, Siksha O Anusandhan (Deemed to Be University), Bhubaneswar, India; Chithaluru P., Department of Computer Science and Engineering, Chaitanya Bharathi Institute of Technology, Hyderabad, India","In medical science, imaging is the most effective diagnostic and therapeutic tool. Almost all modalities have transitioned to direct digital capture devices, which have emerged as a major future healthcare option. Three diseases such as Alzheimer's (AD), Haemorrhage (HD), and COVID-19 have been used in this manuscript for binary classification purposes. Three datasets (AD, HD, and COVID-19) were used in this research out of which the first two, that is, AD and HD belong to brain Magnetic Resonance Imaging (MRI) and the last one, that is, COVID-19 belongs to Chest X-Ray (CXR) All of the diseases listed above cannot be eliminated, but they can be slowed down with early detection and effective medical treatment. This paper proposes an intelligent method for classifying brain (MRI) and CXR images into normal and abnormal classes for the early detection of AD, HD, and COVID-19 based on an ensemble deep neural network (DNN). In the proposed method, the convolutional neural network (CNN) is used for automatic feature extraction from images and long-short term memory (LSTM) is used for final classification. Moreover, the Hill-Climbing Algorithm (HCA) is implemented for finding the best possible value for hyper parameters of CNN and LSTM, such as the filter size of CNN and the number of units of LSTM while fixing the other parameters. The data-set is pre-processed (resized, cropped, and noise removed) before feeding the train images to the proposed models for accurate and fast learning. Forty-five MR images of AD, Sixty MR images of HD, and 600 CXR images of COVID-19 were used for testing the proposed model ‘CNN-LSTM-HCA’. The performance of the proposed model is evaluated using six types of statistical assessment metrics such as; Accuracy, Sensitivity, Specificity, F-measure, ROC, and AUC. The proposed model compared with the other three types of hybrid models such as CNN-LSTM-PSO, CNN-LSTM-Jaya, and CNN-LSTM-GWO and also with state-of-art techniques. The overall accuracy of the proposed model received was 98.87%, 85.75%, and 99.1% for COVID-19, Haemorrhage, and Alzheimer's data sets, respectively. © 2023 John Wiley & Sons Ltd.","Alzheimer disease; CNN; COVID-19; CXR; deep learning; Haemorrhage disease; LSTM","Biomedical signal processing; Convolutional neural networks; Deep neural networks; Diagnosis; Digital devices; Image classification; Long short-term memory; Magnetic resonance imaging; Medical imaging; Neurodegenerative diseases; Optimization; Alzheimer; Alzheimers disease; Chest X-ray; Chest X-ray image; Convolutional neural network; Data set; Deep learning; Haemorrage; Hemorrhage disease; Hill-Climbing algorithm; COVID-19","","","","","","","Abraham M.K., Chang W.T.W., Subarachnoid hemorrhage, Emergency Medicine Clinics, 34, 4, pp. 901-916, (2016); Addeh A., Khormali A., Golilarz N.A., Control chart pattern recognition using rbf neural network with new training algorithm and practical features, ISA Transactions, 79, pp. 202-216, (2018); Addeh J., Ebrahimzadeh A., Breast cancer recognition using a novel hybrid intelligent method, Journal of Medical Signals and Sensors, 2, 2, pp. 95-102, (2012); Aditi M.K., Poovammal E., Image classification using a hybrid lstm-cnn deep neural network, The International Journal of Engineering and Advanced Technology (IJEAT), 8, 6, pp. 1342-1348, (2019); Ai T., Yang Z., Hou H., Han C., Chen C., Lv W., Tao Q., Sun Z., Xia L., Correlation of chest CT and RT-PCR testing in coronavirus disease 2019 (COVID-19) in China: A report of 1014 cases, Radiology, 2, (2020); Apostolopoulos I.D., Mpesiana T.A., COVID-19: Automatic detection from x-ray images utilizing transfer learning with convolutional neural networks, Physical and Engineering Sciences in Medicine, 43, 2, pp. 635-640, (2020); Appel L.-M., Franke V., Bruno M., Grishkovskaya I., Kasiliauskaite A., Kaufmann T., Schoeberl U.E., Puchinger M.G., Kostrhon S., Ebenwaldner C., Sebesta M., PHF3 regulates neuronal gene expression through the Pol II CTD reader domain SPOC, Nature Communications, 12, 1, pp. 1-24, (2021); Ashiquzzaman A., Tushar A.K., Islam M.R., Shon D., Im K., Park J.-H., Kim J., Reduction of overfitting in diabetes prediction using deep learning neural network, It convergence and security 2017, pp. 35-43, (2018); Attallah O., Ragab D.A., Sharkas M., Multi-deep: A novel cad system for coronavirus (COVID-19) diagnosis from CT images using multiple convolution neural networks, PeerJ, 8, (2020); Ayon S.I., Islam M.M., Hossain M.R., Coronary artery heart disease prediction: A comparative study of computational intelligence techniques, IETE Journal of Research, 68, 4, pp. 1-20, (2020); Baltruschat I., Nickisch H., Grass M., Comparison of deep learning approaches for multi-label chest x-ray classification, Scientific Reports, 9, (2019); Bandyopadhyay S.K., Dutta S., Machine learning approach for confirmation of COVID-19 cases: Positive, negative, death and release, Iberoamerican Journal of Medicine, 2, 3, pp. 172-177, (2020); Bardenet R., Brendel M., Kegl B., Sebag M., Collaborative hyperparameter tuning. In International conference on machine learning (pp. 199–207), (2013); Barman A., Lopez-Rivera V., Lee S., Vahidy F.S., Fan J.Z., Savitz S.I., Giancardo L., Combining symmetric and standard deep convolutional representations for detecting brain hemorrhage, Medical imaging 2020: Computer-aided diagnosis, 11314, (2020); Basaia S., Agosta F., Wagner L., Canu E., Magnani G., Santangelo R., Filippi M., Automated classification of alzheimer's disease and mild cognitive impairment using a single mri and deep neural networks, NeuroImage: Clinical, 21, (2019); Bergstra J., Bengio Y., Random search for hyper-parameter optimization, Journal of Machine Learning Research, 13, 2, pp. 281-305, (2012); Burduja M., Ionescu R.T., Verga N., Accurate and efficient intracranial hemorrhage detection and subtype classification in 3d CT scans with convolutional and long short-term memory neural networks, Sensors, 20, 19, (2020); Bwire G.M., Paulo L.S., Coronavirus disease-2019: Is fever an adequate screening for the returning travelers?, Tropical Medicine and Health, 48, 1, pp. 1-3, (2020); Chang P.D., Kuoy E., Grinband J., Weinberg B.D., Thompson M., Homo R., Chen J., Abcede H., Shafie M., Sugrue L., Filippi C.G., Hybrid 3d/2d convolutional neural network for hemorrhage evaluation on head ct, American Journal of Neuroradiology, 39, 9, pp. 1609-1616, (2018); Chithaluru P., Al-Turjman F., Stephan T., Kumar M., Mostarda L., Energy-efficient blockchain implementation for cognitive wireless communication networks (CWCNS), Energy Reports, 7, pp. 8277-8286, (2021); Chithaluru P., Fadi A.-T., Kumar M., Stephan T., MTCEE-LLN: Multi-layer threshold cluster-based energy efficient low power and lossy networks for industrial internet of things, IEEE Internet of Things Journal, 9, pp. 4940-4948, (2021); Chithaluru P., Tiwari R., Kumar K., Areor–adap tive ranking based energy efficient opportunistic routing scheme in wireless sensor network, Computer Networks, 162, (2019); Chitradevi D., Prabha S., Analysis of brain sub regions using optimization techniques and deep learning method in Alzheimer disease, Applied Soft Computing, 86, (2020); Dawud A.M., Yurtkan K., Oztoprak H., Application of deep learning in neuroradiology: Brain haemorrhage classification using transfer learning, Computational Intelligence and Neuroscience, 2019, pp. 1-12, (2019); Dhamodharavadhani S., Rathipriya R., Chatterjee J.M., COVID-19 mortality rate prediction for India using statistical neural network models, Frontiers in Public Health, 8, (2020); Dua M., Makhija D., Manasa P., Mishra P., A CNN–RNN–LSTM based amalgamation for alzheimer's disease detection, Journal of Medical and Biological Engineering, 40, 5, pp. 688-706, (2020); El-Bana S., Al-Kabbany A., Sharkas M., A multi-task pipeline with specialized streams for classification and segmentation of infection manifestations in COVID-19 scans, PeerJ Computer Science, 6, (2020); Fallenius M., Skrifvars M.B., Reinikainen M., Bendel S., Curtze S., Sibolt G., Martinez-Majander N., Raj R., Spontaneous intracerebral hemorrhage: Factors predicting long-term mortality after intensive care, Stroke, 50, 9, pp. 2336-2343, (2019); Fielding B., Zhang L., Evolving image classification architectures with enhanced particle swarm optimisation, IEEE Access, 6, pp. 68560-68575, (2018); Gao B., Yang Y., Gouk H., Hospedales T.M., Deep clusteringwith concrete k-means. In ICASSP 2020-2020 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 4252–4256), (2020); Ghoshal B., Tucker A., Estimating uncertainty and interpretability in deep learning for coronavirus (COVID-19) detection, arXiv Preprint, (2020); Haque I.R.I., Neubert J., Deep learning approaches to biomedical image segmentation, Informatics in Medicine Unlocked, 18, (2020); Haque M.R., Islam M.M., Iqbal H., Reza M.S., Hasan M.K., Performance evaluation of random forests and artificial neural networks for the classification of liver disorder. In 2018 international conference on computer, communication, chemical, material and electronic engineering (IC4ME2) (pp. 1–5), (2018); Hasan M.K., Islam M.M., Hashem M., Mathematical model development to detect breast cancer using multigene genetic programming. In 2016 5th international conference on informatics, electronics and vision (ICIEV) (pp. 574–579), (2016); Hashemi M., Enlarging smaller images before inputting into convolutional neural network: Zero-padding vs. interpolation, Journal of Big Data, 6, 1, pp. 1-13, (2019); Hemdan E.E.D., Shouman M.A., Karar M.E., Covidx-net: A framework of deep learning classifiers to diagnose COVID-19 in x-ray images, arXiv Preprint, (2020); Horry M.J., Chakraborty S., Paul M., Ulhaq A., Pradhan B., Saha M., Shukla N., X-ray image based COVID-19 detection using pre-trained deep learning models., (2020); Hsu Y.-C., Lv Z., Schlosser J., Odom P., Kira Z., Multi-class classification without multi-class labels, arXiv Preprint, (2019); Huang C., Wang Y., Li X., Ren L., Zhao J., Hu Y., Zhang L., Fan G., Xu J., Gu X., Cheng Z., Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China, The Lancet, 395, 10223, pp. 497-506, (2020); Hussain A., Tahir A., Hussain Z., Sheikh Z., Gogate M., Dashtipour K., Ali A., Sheikh A., Artificial intesslligence-enabled analysis of UK and US public attitudes on facebook and twitter towards COVID-19 vaccinations, medRxiv, 23, 4, (2020); Islam M.M., Rahaman A., Islam M.R., Development of smart healthcare monitoring system in iot environment, SN Computer Science, 1, pp. 1-11, (2020); Islam M.Z., Islam M.M., Asraf A., A combined deep CNN-LSTM network for the detection of novel coronavirus (COVID-19) using x-ray images, Informatics in Medicine Unlocked, 20, (2020); Iwendi C., Bashir A.K., Peshkar A., Sujatha R., Chatterjee J.M., Pasupuleti S., Mishra R., Jo O., COVID-19 patient health prediction using boosted random forest algorithm, Frontiers in Public Health, 8, (2020); Jiang X., Feature extraction for image recognition and computer vision. In 2009 2nd IEEE international conference on computer science and information technology (pp. 1–15), (2009); Jibril M.L., Islam M.M., Sharif U.S., Ayon S.I., Predictive data mining models for novel coronavirus (COVID-19) infected patients' recovery, SN Computer Science, 1, 4, (2020); Johnson M., How the statistical revolution changes (computational) linguistics. In Proceedings of the EACL 2009 workshop on the interaction between linguistics and computational linguistics: Virtuous, vicious or vacuous? (pp. 3–11), (2009); Kapoor S., Zeya I., Singhal C., Nanda S.J., A grey wolf optimizer based automatic clustering algorithm for satellite image segmentation, Procedia Computer Science, 115, pp. 415-422, (2017); Khan A.I., Shah J.L., Bhat M.M., Coronet: A deep neural network for detection and diagnosis of COVID-19 from chest x-ray images, Computer Methods and Programs in Biomedicine, 196, (2020); Khan Z.Y., Niu Z., Cnn with depthwise separable convolutions and combined kernels for rating prediction, Expert Systems with Applications, 170, (2021); Khormali A., Addeh J., A novel approach for recognition of control chart patterns: Type-2 fuzzy clustering optimized support vector machine, ISA Transactions, 63, pp. 256-264, (2016); Kim J., Thayabaranathan T., Donnan G.A., Howard G., Howard V.J., Rothwell P.M., Feigin V., Norrving B., Owolabi M., Pandian J., Liu L., Global stroke statistics 2019, International Journal of Stroke, 15, 8, pp. 819-838, (2020); Kim J.K., Park J.M., Song K.S., Park H.W., Adaptive mammographic image enhancement using first derivative and local statistics, IEEE Transactions on Medical Imaging, 16, 5, pp. 495-502, (1997); Kinghorn P., Zhang L., Shao L., A region-based image caption generator with refined descriptions, Neurocomputing, 272, pp. 416-424, (2018); Lauer S.A., Grantz K.H., Bi Q., Jones F.K., Zheng Q., Meredith H.R., Azman A.S., Reich N.G., Lessler J., The incubation period of coronavirus disease 2019 (COVID-19) from publicly reported confirmed cases: Estimation and application, Annals of Internal Medicine, 172, 9, pp. 577-582, (2020); Long X., Chen L., Jiang C., Zhang L., Initiative A.D.N., Prediction and classification of Alzheimer disease based on quantification of mri deformation, PLoS One, 12, 3, (2017); Lv N., Liang X., Chen C., Zhou Y., Li J., Wei H., Wang H., A long short-term memory cyclic model with mutual information for hydrology forecasting: A case study in the xixian basin, Advances in Water Resources, 141, (2020); Ma X., Cheng Y., Garcia R., Haorah J., Hemorrhage associated mechanisms of neuroinflammation in experimental traumatic brain injury, Journal of Neuroimmune Pharmacology, 15, 2, pp. 181-195, (2020); Mehmood A., Yang S., Feng Z., Wang M., Ahmad A.S., Khan R., Maqsood M., Yaqub M., A transfer learning approach for early diagnosis of Alzheimer's disease on MRI images, Neuroscience, 460, pp. 43-52, (2021); Melin P., Sanchez D., Monica J.C., Castillo O., Optimization using the firefly algorithm of ensemble neural networks with type-2 fuzzy integration for COVID-19 time series prediction, Soft Computing, 2021, pp. 1-38, (2021); Memon M.H., Golilarz N.A., Li J., Yazdi M., Addeh A., Early detection of COVID-19 disease using computed tomography images and optimized cnn-lstm. In 2020 17th international computer conference on wavelet active media technology and information processing (ICCWAMTIP) (pp. 161–165), (2020); Memon M.H., Li J.P., Haq A.U., Memon M.H., Zhou W., Breast cancer detection in the iot health environment using modified recursive feature selection, Wireless Communications and Mobile Computing, 2019, pp. 1-19, (2019); Mushtaq M.F., Shahroz M., Aseere A.M., Shah H., Majeed R., Shehzad D., Samad A., Bhcnet: Neural network-based brain hemorrhage classification using head CT scan, IEEE Access, 9, pp. 113901-113916, (2021); Narin A., Kaya C., Pamuk Z., Automatic detection of coronavirus disease (COVID-19) using x-ray images and deep convolutional neural networks, Pattern Analysis and Applications, 24, pp. 1-14, (2021); Otterskog M., Petrovic N., Risman P.O., A multi-layered head phantom for microwave investigations of brain hemorrhages. In 2016 IEEE conference on antenna measurements & applications (CAMA) (pp. 1–3), (2016); Panwar H., Gupta P., Siddiqui M.K., Morales-Menendez R., Singh V., Application of deep learning for fast detection of COVID-19 in x-rays using nCOVnet, Chaos, Solitons & Fractals, 138, (2020); Patel A., Van De Leemput S.C., Prokop M., Van Ginneken B., Manniesing R., Image level training and prediction: Intracranial hemorrhage identification in 3D non-contrast CT, IEEE Access, 7, pp. 92355-92364, (2019); Pradhan A., Mishra D., Das K., Panda G., Kumar S., Zymbler M., On the classification of mr images using “ELM-SSA” coated hybrid model, Mathematics, 9, 17, (2021); Pradhan A.K., Das K., Mishra D., Mishra S., Exploration of hyperparameter in extreme learning machine for brain MRI datasets, Intelligent and cloud computing, pp. 449-457, (2021); Ragab D.A., Attallah O., Fusi-cad: Coronavirus (COVID-19) diagnosis based on the fusion of CNNS and handcrafted features, PeerJ Computer Science, 6, (2020); Rahaman A., Islam M.M., Islam M.R., Sadi M.S., Nooruddin S., Developing IOT based smart health monitoring systems: A review, Revue d'Intelligence Artificielle, 33, 6, pp. 435-440, (2019); Rai H.M., Chatterjee K., Detection of brain abnormality by a novel LU-net deep neural CNN model from MR images, Machine Learning with Applications, 2, (2020); Rai H.M., Chatterjee K., Dashkevich S., Automatic and accurate abnormality detection from brain MR images using a novel hybrid UnetResNext-50 deep CNN model, Biomedical Signal Processing and Control, 66, (2021); Rai H.M., Chatterjee K., Gupta A., Dubey A., A novel deep CNN model for classification of brain tumor from MR images. In 2020 IEEE 1st international conference for convergence in engineering (ICCE) (pp. 134–138), (2020); Rai H.M., Chatterjee K., Gupta D., Srivastava P., Tumor detection from brain magnetic resonance images using MRDWTA-RBFNNC. In Proceedings of the second international conference on information management and machine intelligence (pp. 267–278), (2021); Rao R.V., Saroj A., A self-adaptive multi-population based Jaya algorithm for engineering optimization, Swarm and Evolutionary Computation, 37, pp. 1-26, (2017); Sethy P.K., Behera S.K., Detection of coronavirus disease (COVID-19) based on deep features, (2020); Sherstinsky A., Fundamentals of recurrent neural network (RNN) and long short-term memory (LSTM) network, Physica D: Nonlinear Phenomena, 404, (2020); Shinde G.R., Kalamkar A.B., Mahalle P.N., Dey N., Chaki J., Hassanien A.E., Forecasting models for coronavirus disease (COVID-19): A survey of the state-of-the-art, SN Computer Science, 1, 4, pp. 1-15, (2020); Sierra M.R., Coello Coello C.A., Improving PSO-based multi-objective optimization using crowding, mutation and -dominance. In International conference on evolutionary multi-criterion optimization (pp. 505–519), (2005); Singh M., Bansal S., Ahuja S., Dubey R.K., Panigrahi B.K., Dey N., Transfer learning-based ensemble support vector machine model for automated COVID-19 detection using lung computerized tomography scan data, Medical & Biological Engineering & Computing, 59, 4, pp. 825-839, (2021); Sorbello M., El-Boghdadly K., Di Giacinto I., Cataldo R., Esposito C., Falcetta S., Merli G., Cortese G., Corso R.M., Bressan F., Pintaudi S., The Italian coronavirus disease 2019 outbreak: Recommendations from clinical practice, Anaesthesia, 75, 6, pp. 724-732, (2020); Stephen O., Sain M., Maduh U.J., Jeong D.-U., An efficient deep learning approach to pneumonia classification in healthcare, Journal of Healthcare Engineering, 2019, pp. 1-7, (2019); Tan T.Y., Zhang L., Lim C.P., Adaptive melanoma diagnosis using evolving clustering, ensemble and deep neural networks, Knowledge-Based Systems, 187, (2020); Taylor C.A., Bell J.M., Breiding M.J., Xu L., Traumatic brain injury-related emergency department visits, hospitalizations, and deaths—United States, 2007 and 2013, MMWR Surveillance Summaries, 66, 9, pp. 1-16, (2017); Thevenot J., Lopez M.B., Hadid A., A survey on computer vision for assistive medical diagnosis from faces, IEEE Journal of Biomedical and Health Informatics, 22, 5, pp. 1497-1511, (2017); Ugwuanyi D.C., Sibeudu T.F., Irole C.P., Ogolodom M.P., Nwagbara C.T., Ibekwe A.M., Mbaba A.N., Evaluation of common findings in brain computerized tomography (CT) scan: A single center study, AIMS Neuroscience, 7, 3, pp. 311-318, (2020); Vrbancic G., Zorman M., Podgorelec V., Transfer learning tuning utilizing grey wolf optimizer for identification of brain hemorrhage from head ct images. In Stucosrec: Proceedings of the 2019 6th student computer science research conference (pp. 61–66), (2019); Wang Y., Wu Q., Dey N., Fong S., Ashour A.S., Deep back propagation–long short-term memory network based upper-limb semg signal classification for automated rehabilitation, Biocybernetics and Biomedical Engineering, 40, 3, pp. 987-1001, (2020); Wen T.-H., Gasic M., Mrksic N., Su P.-H., Vandyke D., Young S., Semantically conditioned lstm-based natural language generation for spoken dialogue systems, arXiv Preprint, pp. 1711-1721, (2015); Wijdicks E.F., The first ct scan of the brain: Entering the neurologic information age, Neurocritical Care, 28, 3, pp. 273-275, (2018); Wu Z., Wang X., Jiang Y.-G., Ye H., Xue X., Modeling spatial-temporal clues in a hybrid deep learning framework for video classification. In Proceedings of the 23rd ACM international conference on multimedia (pp. 461–470), (2015); Xu F., Pan Z., Xia R., E-commerce product review sentiment classification based on a naïve bayes continuous learning framework, Information Processing & Management, 57, 5, (2020); Yadav S.S., Jadhav S.M., Deep convolutional neural network based medical image classification for disease diagnosis, Journal of Big Data, 6, 1, pp. 1-18, (2019); Yang C., Wang Y., Wang X., Geng L., A stride-based convolution decomposition method to stretch CNN acceleration algorithms for efficient and flexible hardware implementation, IEEE Transactions on Circuits and Systems I: Regular Papers, 67, 9, pp. 3007-3020, (2020); Zhang X., Yao L., Wang X., Monaghan J., Mcalpine D., Zhang Y., A survey on deep learning-based non-invasive brain signals: Recent advances and new frontiers, Journal of Neural Engineering, 18, 3, (2021)","A.K. Pradhan; Department of Computer Science and Engineering, Siksha O Anusandhan (Deemed to Be University), Bhubaneswar, India; email: ashwini.10.pradhan@gmail.com","","John Wiley and Sons Inc","","","","","","02664720","","EXSYE","","English","Expert Syst","Article","Final","","Scopus","2-s2.0-85147220372"
"Obayya M.; Haj Hassine S.B.; Alazwari S.; K. Nour M.; Mohamed A.; Motwakel A.; Yaseen I.; Sarwar Zamani A.; Abdelmageed A.A.; Mohammed G.P.","Obayya, Marwa (6505869929); Haj Hassine, Siwar Ben (57556207300); Alazwari, Sana (57867288800); K. Nour, Mohamed (57885708800); Mohamed, Abdullah (57213606201); Motwakel, Abdelwahed (57103616300); Yaseen, Ishfaq (57410292800); Sarwar Zamani, Abu (57295189700); Abdelmageed, Amgad Atta (57876641300); Mohammed, Gouse Pasha (57886165200)","6505869929; 57556207300; 57867288800; 57885708800; 57213606201; 57103616300; 57410292800; 57295189700; 57876641300; 57886165200","Aquila Optimizer with Bayesian Neural Network for Breast Cancer Detection on Ultrasound Images","2022","Applied Sciences (Switzerland)","12","17","8679","","","","5","10.3390/app12178679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137843061&doi=10.3390%2fapp12178679&partnerID=40&md5=b463627ced7ee2bfa675a2a3c4b892a5","Department of Biomedical Engineering, College of Engineering, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Information Systems, College of Science Art at Mahayil, King Khalid University, Abha, 62529, Saudi Arabia; Department of Information Technology, College of Computers and Information Technology, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia; Department of Computer Sciences, College of Computing and Information System, Umm Al-Qura University, Makkah, 24382, Saudi Arabia; Research Centre, Future University in Egypt, New Cairo, 11845, Egypt; Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, 16278, Saudi Arabia","Obayya M., Department of Biomedical Engineering, College of Engineering, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Haj Hassine S.B., Department of Information Systems, College of Science Art at Mahayil, King Khalid University, Abha, 62529, Saudi Arabia; Alazwari S., Department of Information Technology, College of Computers and Information Technology, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia; K. Nour M., Department of Computer Sciences, College of Computing and Information System, Umm Al-Qura University, Makkah, 24382, Saudi Arabia; Mohamed A., Research Centre, Future University in Egypt, New Cairo, 11845, Egypt; Motwakel A., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, 16278, Saudi Arabia; Yaseen I., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, 16278, Saudi Arabia; Sarwar Zamani A., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, 16278, Saudi Arabia; Abdelmageed A.A., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, 16278, Saudi Arabia; Mohammed G.P., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, 16278, Saudi Arabia","Breast cancer is the second most dominant kind of cancer among women. Breast Ultrasound images (BUI) are commonly employed for the detection and classification of abnormalities that exist in the breast. The ultrasound images are necessary to develop artificial intelligence (AI) enabled diagnostic support technologies. For improving the detection performance, Computer Aided Diagnosis (CAD) models are useful for breast cancer detection and classification. The current advancement of the deep learning (DL) model enables the detection and classification of breast cancer with the use of biomedical images. With this motivation, this article presents an Aquila Optimizer with Bayesian Neural Network for Breast Cancer Detection (AOBNN-BDNN) model on BUI. The presented AOBNN-BDNN model follows a series of processes to detect and classify breast cancer on BUI. To accomplish this, the AOBNN-BDNN model initially employs Wiener filtering (WF) related noise removal and U-Net segmentation as a pre-processing step. Besides, the SqueezeNet model derives a collection of feature vectors from the pre-processed image. Next, the BNN algorithm will be utilized to allocate appropriate class labels to the input images. Finally, the AO technique was exploited to fine-tune the parameters related to the BNN method so that the classification performance is improved. To validate the enhanced performance of the AOBNN-BDNN method, a wide experimental study is executed on benchmark datasets. A wide-ranging experimental analysis specified the enhancements of the AOBNN-BDNN method in recent techniques. © 2022 by the authors.","Aquila Optimizer; Bayesian Neural Network; breast cancer; medical images; ultrasound images","","","","","","Abdulrahman University, (PNURSP2022R203); Deanship of Scientific Research at Umm Al-Qura University, (22UQU4310373DSR31); Princess Nourah Bint Abdulrahman University, PNU; Deanship of Scientific Research, King Faisal University, DSR, KFU, (25/43)","The authors extend their appreciation to the Deanship of Scientific Research at King Khalid University for funding this work through the Large Groups Project under grant number (25/43). Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2022R203), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia. The authors would like to thank the Deanship of Scientific Research at Umm Al-Qura University for supporting this work by Grant Code: 22UQU4310373DSR31.","Muhammad M., Zeebaree D., Brifcani A.M.A., Saeed J., Zebari D.A., Region of interest segmentation based on clustering techniques for breast cancer ultrasound images: A review, J. Appl. Sci. Technol. Trends, 1, pp. 78-91, (2020); Sun Q., Lin X., Zhao Y., Li L., Yan K., Liang D., Sun D., Li Z.C., Deep learning vs. radiomics for predicting axillary lymph node metastasis of breast cancer using ultrasound images: Don’t forget the peritumoral region, Front. Oncol, 10, (2020); Ayana G., Dese K., Choe S.W., Transfer learning in breast cancer diagnoses via ultrasound imaging, Cancers, 13, (2021); Qian X., Pei J., Zheng H., Xie X., Yan L., Zhang H., Han C., Gao X., Zhang H., Zheng W., Et al., Prospective assessment of breast cancer risk from multimodal multiview ultrasound images via clinically applicable deep learning, Nat. Biomed. Eng, 5, pp. 522-532, (2021); Zhang X., Li H., Wang C., Cheng W., Zhu Y., Li D., Jing H., Li S., Hou J., Li J., Et al., Evaluating the accuracy of breast cancer and molecular subtype diagnosis by ultrasound image deep learning model, Front. Oncol, 11, (2021); Khairalseed M., Javed K., Jashkaran G., Kim J.W., Parker K.J., Hoyt K., Monitoring Early Breast Cancer Response to Neoadjuvant Therapy Using H-Scan Ultrasound Imaging: Preliminary Preclinical Results, J. Ultrasound Med, 38, pp. 1259-1268, (2019); Zhang T., Jiang Z., Xve T., Sun S., Li J., Ren W., Wu A., Huang P., One-pot synthesis of hollow PDA@ DOX nanoparticles for ultrasound imaging and chemo-thermal therapy in breast cancer, Nanoscale, 11, pp. 21759-21766, (2019); Wang Y., Choi E.J., Choi Y., Zhang H., Jin G.Y., Ko S.B., Breast cancer classification in automated breast ultrasound using multiview convolutional neural network with transfer learning, Ultrasound Med. Biol, 46, pp. 1119-1132, (2020); Yan Y., Liu Y., Wu Y., Zhang H., Zhang Y., Meng L., Accurate segmentation of breast tumors using AE U-net with HDC model in ultrasound images, Biomed. Signal Process. Control, 72, (2022); Zhang G., Zhao K., Hong Y., Qiu X., Zhang K., Wei B., SHA-MTL: Soft and hard attention multi-task learning for automated breast cancer ultrasound image segmentation and classification, Int. J. Comput. Assist. Radiol. Surg, 16, pp. 1719-1725, (2021); Hijab A., Rushdi M.A., Gomaa M.M., Eldeib A., Breast cancer classification in ultrasound images using transfer learning, Proceedings of the 2019 Fifth International Conference on Advances in Biomedical Engineering (ICABME), pp. 1-4; Kalafi E.Y., Jodeiri A., Setarehdan S.K., Lin N.W., Rahmat K., Taib N.A., Ganggayah M.D., Dhillon S.K., Classification of breast cancer lesions in ultrasound images by using attention layer and loss ensemble in deep convolutional neural networks, Diagnostics, 11, (2021); Lee H., Park J., Hwang J.Y., Channel attention module with multiscale grid average pooling for breast cancer segmentation in an ultrasound image, IEEE Trans. Ultrason. Ferroelectr. Freq. Control, 67, pp. 1344-1353, (2020); Xie X.Z., Niu J.W., Liu X.F., Li Q.F., Wang Y., Han J., Tang S., DG-CNN: Introducing Margin Information into Convolutional Neural Networks for Breast Cancer Diagnosis in Ultrasound Images, J. Comput. Sci. Technol, 37, pp. 277-294, (2022); Zhu Y.C., AlZoubi A., Jassim S., Jiang Q., Zhang Y., Wang Y.B., Ye X.D., Hongbo D.U., A generic deep learning framework to classify thyroid and breast lesions in ultrasound images, Ultrasonics, 110, (2021); Zhuang Z., Li N., Joseph Raj A.N., Mahesh V.G., Qiu S., An RDAU-NET model for lesion segmentation in breast ultrasound images, PLoS ONE, 14, (2019); Lahmiri S., An iterative denoising system based on Wiener filtering with application to biomedical images, Opt. Laser Technol, 90, pp. 128-132, (2017); Saood A., Hatem I., COVID-19 lung CT image segmentation using deep learning methods: U-Net versus SegNet, BMC Med. Imaging, 21, (2021); Iandola F.N., Han S., Moskewicz M.W., Ashraf K., Dally W.J., Keutzer K., SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5 MB model size, arXiv, (2016); Koonce B., SqueezeNet, Convolutional Neural Networks with Swift for Tensorflow, pp. 73-85, (2021); Ullah A., Elahi H., Sun Z., Khatoon A., Ahmad I., Comparative analysis of AlexNet, ResNet18 and SqueezeNet with diverse modification and arduous implementation, Arab. J. Sci. Eng, 47, pp. 2397-2417, (2022); Wu A., Nowozin S., Meeds E., Turner R.E., Hernandez-Lobato J.M., Gaunt A.L., Deterministic variational inference for robust bayesian neural networks, arXiv, (2018); Meng X., Babaee H., Karniadakis G.E., Multi-fidelity Bayesian neural networks: Algorithms and applications, J. Comput. Phys, 438, (2021); Abualigah L., Yousri D., Abd Elaziz M., Ewees A.A., Al-Qaness M.A., Gandomi A.H., Aquila optimizer: A novel meta-heuristic optimization algorithm, Comput. Ind. Eng, 157, (2021); AlRassas A.M., Al-qaness M.A., Ewees A.A., Ren S., Abd Elaziz M., Damasevicius R., Krilavicius T., Optimized ANFIS model using Aquila Optimizer for oil production forecasting, Processes, 9, (2021); Al-Dhabyani W., Gomaa M., Khaled H., Fahmy A., Dataset of breast ultrasound images, Data Brief, 28, (2020)","A. Motwakel; Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, 16278, Saudi Arabia; email: a.ismaeil@psau.edu.sa","","MDPI","","","","","","20763417","","","","English","Appl. Sci.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137843061"
"Bose S.; Sur Chowdhury R.; Das R.; Maulik U.","Bose, Shirsha (57639719800); Sur Chowdhury, Ritesh (57230114200); Das, Rangan (57215627205); Maulik, Ujjwal (6603607810)","57639719800; 57230114200; 57215627205; 6603607810","Dense Dilated Deep Multiscale Supervised U-Network for biomedical image segmentation","2022","Computers in Biology and Medicine","143","","105274","","","","13","10.1016/j.compbiomed.2022.105274","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123837775&doi=10.1016%2fj.compbiomed.2022.105274&partnerID=40&md5=3b7826f5186811ab8949e135692c0509","Department of Electronics and Telecommunication Engineering, Jadavpur University, 188, Raja S.C. Mallick Rd, Kolkata, 700032, West Bengal, India; Department of Computer Science Engineering, Jadavpur University, 188, Raja S.C. Mallick Rd, Kolkata, 700032, West Bengal, India","Bose S., Department of Electronics and Telecommunication Engineering, Jadavpur University, 188, Raja S.C. Mallick Rd, Kolkata, 700032, West Bengal, India; Sur Chowdhury R., Department of Electronics and Telecommunication Engineering, Jadavpur University, 188, Raja S.C. Mallick Rd, Kolkata, 700032, West Bengal, India; Das R., Department of Computer Science Engineering, Jadavpur University, 188, Raja S.C. Mallick Rd, Kolkata, 700032, West Bengal, India; Maulik U., Department of Computer Science Engineering, Jadavpur University, 188, Raja S.C. Mallick Rd, Kolkata, 700032, West Bengal, India","Biomedical image segmentation is essential for computerized medical image analysis. Deep learning algorithms allow us to design state-of-the-art models for solving segmentation problems. The U-Net and its variants have provided positive results across various datasets. However, the existing networks have the same receptive field at each level and the models are supervised only at the shallow level. Considering these two ideas, we have proposed the D3MSU-Net where the field of view in each level is varied depending upon the depth of the resolution layer and the model is supervised at each resolution level. We have evaluated our network in eight benchmark datasets such as Electron Microscopy, Lung segmentation, Montgomery Chest X-ray, Covid-Radiopaedia, Wound, Medetec, Brain MRI, and Covid-19 lung CT dataset. Additionally, we have provided the performance for various ablations. The experimental results show the superiority of the proposed network. The proposed D3MSU-Net and ablation models are available at www.github.com/shirshabose/D3MSUNET. © 2022 Elsevier Ltd","Biomedical image segmentation; Deep learning; Deep multiscale supervision; Dense dilated convolution","Biological organs; Computerized tomography; Deep learning; Image segmentation; Learning algorithms; Magnetic resonance imaging; Medical imaging; ART model; Biomedical image segmentation; Deep learning; Deep multiscale supervision; Dense dilated convolution; Design state; Medical image analysis; Receptive fields; Shallow levels; State of the art; Article; brain; computer assisted tomography; controlled study; convolutional neural network; coronavirus disease 2019; deep learning; diagnostic imaging; electron microscopy; human; image segmentation; intermethod comparison; medical photography; nuclear magnetic resonance imaging; supervised machine learning; thorax radiography; three-dimensional imaging; Ablation","","","","","","","Li K., Fang Y., Li W., Pan C., Qin P., Zhong Y., Liu X., Huang M., Liao Y., Li S., Ct image visual quantitative evaluation and clinical classification of coronavirus disease (covid-19), Eur. Radiol., 30, 8, pp. 4407-4416, (2020); Zeng N., Han L., Peng Y., A new deep belief network-based multi-task learning for diagnosis of alzheimer's disease, Neural Comput. Appl., pp. 1-12, (2021); Li J.P., Haq A.U., Din S.U., Khan J., Khan A., Saboor A., Heart disease identification method using machine learning classification in e-healthcare, IEEE Access, 8, pp. 107562-107582, (2020); Lameire N.H., Levin A., Kellum J.A., Cheung M., Jadoul M., Winkelmayer W.C., Stevens P.E., Caskey F.J., Farmer C.K., Fuentes A.F., Et al., Harmonizing acute and chronic kidney disease definition and classification: report of a kidney disease: improving global outcomes (kdigo) consensus conference, Kidney Int., 100, 3, pp. 516-526, (2021); Wu P., Han L., Zeng N., Li F., Fmd-yolo: an efficient face mask detection method for covid-19 prevention and control in public, Image Vis Comput., (2021); Zhao H., Qi X., Shen X., Shi J., Jia J., Icnet for real-time semantic segmentation on high-resolution images, Proceedings of the European Conference on Computer Vision (ECCV), pp. 405-420, (2018); Jiang J., Hu Y.-C., Liu C.-J., Halpenny D., Hellmann M.D., O Deasy J., Mageras G., Veeraraghavan H., Multiple resolution residually connected feature streams for automatic lung tumor segmentation from ct images, IEEE Trans. Med. Imag., 38, 1, pp. 134-144, (2018); Fang Y., Chen C., Yuan Y., Tong K.-Y., Selective feature aggregation network with area-boundary constraints for polyp segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 302-310, (2019); Long J., Shelhamer E., Trevor Darrell, Fully convolutional networks for semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, (2015); Wang C., Anisuzzaman D.M., Williamson V., Dhar M.K., Rostami B., Niezgoda J., Gopalakrishnan S., Yu Z., Fully automatic wound segmentation with deep convolutional neural networks, Sci. Rep., 10, 1, pp. 1-9, (2020); Fauzi M.F.A., Khansa I., Catignani K., Gordillo G., Sen C.K., Gurcan M.N., Computerized segmentation and measurement of chronic wound images, Comput. Biol. Med., 60, pp. 74-85, (2015); Cirillo M.D., Mirdell R., Sjoberg F., Pham T.D., Tensor decomposition for colour image segmentation of burn wounds, Sci. Rep., 9, 1, pp. 1-13, (2019); Menze B.H., Jakab A., Bauer S., Kalpathy-Cramer J., Farahani K., Kirby J., Burren Y., Porz N., Johannes Slotboom, Roland W., Et al., The multimodal brain tumor image segmentation benchmark (brats), IEEE Trans. Med. Imag., 34, 10, pp. 1993-2024, (2014); Mendrik A.M., Vincken K.L., Kuijf H.J., Breeuwer M., Bouvy W.H., De Bresser J., Alansary A., De Bruijne M., Carass A., El-Baz A., Et al., Mrbrains challenge: online evaluation framework for brain image segmentation in 3t mri scans, Comput. Intell. Neurosci., 2015, (2015); Zhou Z., Rahman Siddiquee M.M., Tajbakhsh N., Liang J., Unet++: redesigning skip connections to exploit multiscale features in image segmentation, IEEE Trans. Med. Imag., 39, 6, pp. 1856-1867, (2019); Zhao X., Zhang P., Fan S., Fan G., Sun Y., Wang Y., Tian Z., Zhang L., Zhang G., D2a u-net: automatic segmentation of covid-19 ct slices based on dual attention and hybrid dilated convolution, Comput. Biol. Med., (2021); Fan D.-P., Zhou T., Ji G.-P., Zhou Y., Chen G., Fu H., Shen J., Shao L., Inf-net: automatic covid-19 lung infection segmentation from ct images, IEEE Trans. Med. Imag., 39, 8, pp. 2626-2637, (2020); Aquino A., Gegundez-Arias M.E., Marin D., Detecting the optic disc boundary in digital fundus images using morphological, edge detection, and feature extraction techniques, IEEE Trans. Med. Imag., 29, 11, pp. 1860-1869, (2010); Zhu X., Rangayyan R.M., Detection of the optic disc in images of the retina using the hough transform, 2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pp. 3546-3549, (2008); Lee Y., Hara T., Fujita H., Itoh S., Takeo Ishigaki, Automated detection of pulmonary nodules in helical ct images based on an improved template-matching technique, IEEE Trans. Med. Imag., 20, 7, pp. 595-604, (2001); Mihaylova A., Georgieva V., Spleen segmentation in mri sequence images using template matching and active contours, Procedia Comput. Sci., 131, 15-22, (2018); Chen W., Smith R., Ji S.-Y., Ward K.R., Najarian K., Automated ventricular systems segmentation in brain ct images by combining low-level segmentation and high-level template matching, BMC Med. Inf. Decis. Making, 9, 1, pp. 1-14, (2009); Tsai A., Anthony Y., Wells W., Clare T., Tucker D., Fan A., Grimson W.E., Willsky A., A shape-based approach to the segmentation of medical imagery using level sets, IEEE Trans. Med. Imag., 22, 2, pp. 137-154, (2003); Khalifa F., Gimel'farb G., El-Ghar M.A., Guela Sokhadze, Manning S., McClure P., Ouseph R., El-Baz A., A new deformable model-based segmentation approach for accurate extraction of the kidney from abdominal ct images, 2011 18th IEEE International Conference on Image Processing, pp. 3393-3396, (2011); Aganj I., Harisinghani M.G., Weissleder R., Fischl B., Unsupervised medical image segmentation based on the local center of mass, Sci. Rep., 8, 1, pp. 1-8, (2018); Kanimozhi M., Bindu C.H., Brain mr image segmentation using self organizing map, Brain, 2, 10, pp. 261-274, (2013); Noh H., Hong S., Han B., Learning deconvolution network for semantic segmentation, Proceedings of the IEEE International Conference on Computer Vision, pp. 1520-1528, (2015); Badrinarayanan V., Kendall A., Cipolla R., Segnet: a deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, 12, pp. 2481-2495, (2017); Ronneberger O., Fischer P., Brox T., U-net: convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Chen S., Zou Y., Liu P.X., Iba-u-net: attentive bconvlstm u-net with redesigned inception for medical image segmentation, Comput. Biol. Med., (2021); Christ P.F., Ettlinger F., Grun F., Elshaera M.E.A., Jana L., Schlecht S., Ahmaddy F., Tatavarty S., Bickel M., Bilic P., Et al., Automatic Liver and Tumor Segmentation of Ct and Mri Volumes Using Cascaded Fully Convolutional Neural Networks, (2017); Zhou X.-Y., Shen M., Riga C., Yang G.-Z., Lee S.-L., Focal Fcn: towards Small Object Segmentation with Limited Training Data, (2017); Zeng G., Zheng G., Multi-stream 3d fcn with multi-scale deep supervision for multi-modality isointense infant brain mr image segmentation, 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018), pp. 136-140, (2018); Cicek O., Ahmed A., Lienkamp S.S., Brox T., Ronneberger O., 3d u-net: learning dense volumetric segmentation from sparse annotation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 424-432, (2016); Milletari F., Navab N., Seyed-Ahmad A., V-net: fully convolutional neural networks for volumetric medical image segmentation, 2016 Fourth International Conference on 3D Vision (3DV), pp. 565-571, (2016); Gu Z., Cheng J., Fu H., Zhou K., Hao H., Zhao Y., Zhang T., Gao S., Jiang L., Ce-net: context encoder network for 2d medical image segmentation, IEEE Trans. Med. Imag., 38, 10, pp. 2281-2292, (2019); Wei Y., Xiao H., Shi H., Zequn J., Feng J., Huang T.S., Revisiting dilated convolution: a simple approach for weakly-and semi-supervised semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7268-7277, (2018); Mahmud T., Rahman M.A., Fattah S.A., Covxnet: a multi-dilation convolutional neural network for automatic covid-19 and other pneumonia detection from chest x-ray images with transferable multi-receptive feature optimization, Comput. Biol. Med., 122, (2020); Fisher Y., Koltun V., Multi-scale Context Aggregation by Dilated Convolutions, (2015); Lee C.-Y., Xie S., Gallagher P., Zhang Z., Tu Z., Deeply-supervised nets, Artificial Intelligence and Statistics, pp. 562-570, (2015); Szegedy C., Liu W., Jia Y., Sermanet P., Scott R., Anguelov D., Erhan D., Vincent V., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Cardona A., Saalfeld S., Preibisch S., Schmid B., Cheng A., Jim Pulokas, Tomancak P., Hartenstein V., An integrated micro-and macroarchitectural analysis of the drosophila brain by computer-assisted serial section electron microscopy, PLoS Biol., 8, 10, (2010); Jaeger S., Candemir S., Antani S., Yi-Xiang J.W., Lu P.-X., George T., Two public chest x-ray datasets for computer-aided screening of pulmonary diseases, Quant. Imag. Med. Surg., 4, 6, (2014); Buda M., Saha A., Mazurowski M.A., Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm, Comput. Biol. Med., 109, pp. 218-225, (2019); Saood A., Hatem I., Covid-19 lung ct image segmentation using deep learning methods: U-net versus segnet, BMC Med. Imag., 21, 1, pp. 1-10, (2021); He K., Gkioxari G., Dollar P., Girshick R., Mask r-cnn, Proceedings of the IEEE International Conference on Computer Vision, pp. 2961-2969, (2017); Sandler M., Howard A., Zhu M., Zhmoginov A., Chen L.-C., Mobilenetv2: inverted residuals and linear bottlenecks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4510-4520, (2018)","U. Maulik; Department of Computer Science Engineering, Jadavpur University, Kolkata, 188, Raja S.C. Mallick Rd, 700032, India; email: ujjwal.maulik@jadavpuruniversity.in","","Elsevier Ltd","","","","","","00104825","","CBMDA","35123135","English","Comput. Biol. Med.","Article","Final","","Scopus","2-s2.0-85123837775"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Communications in Computer and Information Science","1964 CCIS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178598232&partnerID=40&md5=efc2e5f9beece0459200cd1145901a6d","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","18650929","978-981998140-3","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85178598232"
"Asif S.; Qurrat-ul-Ain; Awais M.; Khan S.U.R.","Asif, Sohaib (57221248320); Qurrat-ul-Ain (58179973500); Awais, Muhammad (59276254700); Khan, Saif Ur Rehman (58836834300)","57221248320; 58179973500; 59276254700; 58836834300","IR-CNN: Inception residual network for detecting kidney abnormalities from CT images","2023","Network Modeling Analysis in Health Informatics and Bioinformatics","12","1","35","","","","2","10.1007/s13721-023-00431-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171877377&doi=10.1007%2fs13721-023-00431-4&partnerID=40&md5=e700067af39abaad0cb7f9c0215ae2a6","School of Computer Science and Engineering, Central South University, Hunan, Changsha, China; School of Public Health, Central South University, Hunan, Changsha, China; School of Minerals Processing and BioEngineering, Central South University, Hunan, Changsha, China","Asif S., School of Computer Science and Engineering, Central South University, Hunan, Changsha, China; Qurrat-ul-Ain, School of Public Health, Central South University, Hunan, Changsha, China; Awais M., School of Minerals Processing and BioEngineering, Central South University, Hunan, Changsha, China; Khan S.U.R., School of Computer Science and Engineering, Central South University, Hunan, Changsha, China","Kidney abnormalities are a public health problem and a common disease with adverse effects such as kidney damage. Due to the shortage of nephrologists worldwide, detecting these abnormalities are expensive and time consuming. Thus, deep learning (DL) techniques can help clinicians to automate the diagnosis of kidney diseases. However, achieving better performance is still a challenge in kidney disease detection. In this study, we propose an efficient architecture “IR-CNN” based on the Inception residual network for the detection of three major kidney diseases, tumor, kidney stone and cyst, using CT images. We customized the top layer of InceptionResNetV2 and further added global average pooling (GAP), batch normalization (BN), dropout and dense layers with swish activation functions to extract robust features, avoid vanishing gradient problems and achieve better accuracy in detecting kidney disease. The proposed IR-CNN model was trained and tested on a publicly available kidney CT dataset with 4000 images using different optimizers (Adam, SGD, and RMSprop). Experimental results show that IR-CNN achieves 99.38%, 94.63%, 97.38% using Adam, SGD and RMSprop optimizers, respectively. In addition, IR-CNN with Adam optimizer achieved better performance with only 5 misclassifications out of 800 test images and performed better than existing methods in diagnosing kidney disease. The superior results of our IR-CNN architecture can help urologists diagnose kidney disease, thereby reducing human error. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.","Biomedical image analysis; Deep learning; Inception residual network; Kidney abnormalities; Kidney disease detection","Computerized tomography; Deep learning; Network architecture; Biomedical image analysis; CT Image; Deep learning; Disease detection; Inception residual network; Kidney abnormality; Kidney disease; Kidney disease detection; Optimizers; Performance; accuracy; Article; augmentation index; classification algorithm; computer assisted tomography; convolutional neural network; cyst; deep learning; feature extraction; global average pooling; human; image analysis; image segmentation; kidney disease; kidney injury; kidney malformation; learning; learning algorithm; machine learning; medical research; nephrolithiasis; network analysis; patient dropout; receiver operating characteristic; residual network; sensitivity and specificity; spatial discrimination; training; validation process; Diagnosis","","","","","","","Asif S., Yi W., Ain Q.U., Hou J., Yi T., Si J., Improving effectiveness of different deep transfer learning-based models for detecting brain tumors from MR images, IEEE Access, 10, pp. 34716-34730, (2022); Asif S., Wenhui Y., Amjad K., Jin H., Tao Y., Jinhai S., Detection of COVID‐19 from chest X‐ray images: Boosting the performance with convolutional neural network and transfer learning, Expert Systems; De Perrot T., Hofmeister J., Burgermeister S., Martin S.P., Feutry G., Klein J., Et al., Differentiating kidney stones from phleboliths in unenhanced low-dose computed tomography using radiomics and machine learning, Europ Radiol, 29, 9, pp. 4776-4782, (2019); Eggers P.W., Has the incidence of end-stage renal disease in the USA and other countries stabilized, Curr Opinion Nephrol Hyper, 20, 3, pp. 241-245, (2011); ElKarami B., Alkhateeb A., Qattous H., Alshomali L., Shahrrava B., Multi-omics data integration model based on UMAP embedding and convolutional neural network, Cancer Inform, 21, (2022); Foreman K.J., Marquez N., Dolgert A., Fukutaki K., Fullman N., McGaughey M., Et al., Forecasting life expectancy, years of life lost, and all-cause and cause-specific mortality for 250 causes of death: reference and alternative scenarios for 2016–40 for 195 countries and territories, The Lancet, 392, pp. 2052-2090, (2018); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Islam M.N., Hasan M., Hossain M., Alam M., Rabiul G., Uddin M.Z., Et al., Vision transformer and explainable transfer learning models for auto detection of kidney cyst, stone and tumor from CT-radiography, Sci Rep, 12, 1, pp. 1-14, (2022); Kingma D.P., Ba J.A., A method for stochastic optimization, Arxiv Preprint Arxiv:14126980, (2014); Langkvist M., Jendeberg J., Thunberg P., Loutfi A., Liden M., Computer aided detection of ureteral stones in thin slice computed tomography volumes using convolutional neural networks, Comput Biol Med., 97, pp. 153-160, (2018); Lin M., Chen Q., Yan S., Network in network, Arxiv Preprint Arxiv:13124400, (2013); M B., Mohan N., K S.; New F., Somani B.K., A complete world literature review of quality of life (QOL) in patients with kidney stone disease (KSD), Current Urol Rep, 17, 12, pp. 1-6, (2016); Parakh A., Lee H., Lee J.H., Eisner B.H., Sahani D.V., Do S., Urinary stone detection on CT images using deep convolutional neural networks: Evaluation of model performance and generalization, Radiology Artificial Intelligence, 1, 4, (2019); Ramachandran P., Zoph B., Le Q.V., Searching for activation functions, Arxiv Preprint Arxiv:171005941, (2017); Ruder S., An overview of gradient descent optimization algorithms, Arxiv Preprint Arxiv:160904747, (2016); Selvaraju R.R., Cogswell M., Das A., Vedantam R., Parikh D., Batra D., Grad-cam: Visual explanations from deep networks via gradient-based localization, Proceedings of the IEEE International Conference on Computer Vision, pp. 618-626, (2017); Shlipak M.G., Fried L.F., Cushman M., Manolio T.A., Peterson D., Stehman-Breen C., Et al., Cardiovascular mortality risk in chronic kidney disease: comparison of traditional and novel risk factors, JAMA, 293, 14, pp. 1737-1745, (2005); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, Arxiv Preprint Arxiv:14091556, (2014); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Et al., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Szegedy C., Ioffe S., Vanhoucke V., Alemi A.A., Inception-v4, inception-resnet and the impact of residual connections on learning, Thirty-First AAAI Conference on Artificial Intelligence2017; Tangri N., Stevens L.A., Griffith J., Tighiouart H., Djurdjev O., Naimark D., Et al., A predictive model for progression of chronic kidney disease to kidney failure, JAMA, 305, 15, pp. 1553-1559, (2011); Wu Y., Yi Z., Automated detection of kidney abnormalities using multi-feature fusion convolutional neural networks, Knowl-Based Syst, 200, (2020); Yan K., Wang X., Lu L., Summers R.M., DeepLesion: automated mining of large-scale lesion annotations and universal lesion detection with deep learning, J Med Imag, 5, 3, (2018); Yildirim K., Bozdag P.G., Talo M., Yildirim O., Karabatak M., Acharya U.R., Deep learning model for automated kidney stone detection using coronal CT images, Comput Biol Med, 135, (2021); Zhang H., Chen Y., Song Y., Xiong Z., Yang Y., Wu Q.J., Automatic kidney lesion detection for CT images using morphological cascade convolutional neural networks, IEEE Access, 7, pp. 83001-83011, (2019); Zheng Q., Furth S.L., Tasian G.E., Fan Y., Computer-aided diagnosis of congenital abnormalities of the kidney and urinary tract in children based on ultrasound imaging data by integrating texture image features and deep transfer learning image features, J Ped Urol, 15, 1, (2019); Zhou L., Rueda M., Alkhateeb A., Classification of Breast Cancer Nottingham Prognostic Index Using High-Dimensional Embedding and Residual Neural Network, Cancers (Basel), (2022)","S. Asif; School of Computer Science and Engineering, Central South University, Changsha, Hunan, China; email: punjabians1592@gmail.com","","Springer","","","","","","21926662","","","","English","Netw. Model. Anal. Health Informatics Bioinformatics","Article","Final","","Scopus","2-s2.0-85171877377"
"Agarwal R.; Sarma P.; Dev N.; Mazumder P.P.","Agarwal, Rashi (59031244600); Sarma, Parismita (57195313986); Dev, Nabamita (58852199200); Mazumder, Partha Pratim (57405259600)","59031244600; 57195313986; 58852199200; 57405259600","Detection of Brain Tumor from MRI Samples Using Deep Learning Algorithms","2023","2023 1st International Conference on Advances in Electrical, Electronics and Computational Intelligence, ICAEECI 2023","","","","","","","0","10.1109/ICAEECI58247.2023.10370777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183550578&doi=10.1109%2fICAEECI58247.2023.10370777&partnerID=40&md5=f8a40d1c63e296105317ac6f6a7b69f1","Gauhati University, Department of Information Technology, Guwahati, India","Agarwal R., Gauhati University, Department of Information Technology, Guwahati, India; Sarma P., Gauhati University, Department of Information Technology, Guwahati, India; Dev N., Gauhati University, Department of Information Technology, Guwahati, India; Mazumder P.P., Gauhati University, Department of Information Technology, Guwahati, India","Biomedical image processing is a rapidly expanding and challenging discipline. Brain tumor segmentation technique is critical in the detection and treatment of MRI brain cancers. It aids clinicians in the detection and measurement of cancers, as well as the development of treatment and rehabilitation methods. MRI brain tumor segmentation approaches based on U-Net architecture have gained popularity because they significantly enhance segmentation accuracy by combining high-level and low-level feature information using skip connections. This project, shows comparison of the performance of deep learning models such as ResNet50, VGG16 (via transfer learning), and CNN models in detecting brain tumor, demonstrating that ResNet50 outperforms VGG16 and CNN models by achieving the highest classification accuracy of 98 percent. © 2023 IEEE.","Brain tumor; CNN; MRI scan; ResNet-50; VGG-16","Brain; Convolutional neural networks; Deep learning; Diseases; Learning algorithms; Learning systems; Medical imaging; Tumors; Brain cancer; Brain tumor segmentation; Brain tumors; CNN models; Learning models; Measurements of; MRI scan; Resnet-50; Segmentation techniques; VGG-16; Magnetic resonance imaging","","","","","","","Fallica K.M., Sustaining Feminist Film Cultures: An Institutional History of Women Make Movies, (2013); Imm J.L., Exploring the Epigenome of Neurons and Glia in Vitro to Determine Their Utility As a Model for Alzheimer's Disease, (2020); Mostafa F.A., Et al., A Survey on AI Techniques for Thoracic Diseases Diagnosis Using Medical Images, Diagnostics, 12, 12, (2022); Mehrotra R., A transfer learning approach for AI-based classification of brain tumors, Machine Learning with Applications, 2, (2020); Amin J., Et al., A New Model for Brain Tumor Detection Using Ensemble Transfer Learning and Quantum Variational Classifier, Computational Intelligence and Neuroscience: Cin, 2022, (2022); Arif M., Et al., Application of Genetic Algorithm and U-Net in Brain Tumor Segmentation and Classification: A Deep Learning Approach, Computational Intelligence and Neuroscience : Cin, 2022, (2022); Brindha P.G., Et al., Brain tumor detection from MRI images using deep learning techniques, Iop Conference Series.Materials Science and Engineering, 1055, 1, (2021)","P. Sarma; Gauhati University, Department of Information Technology, Guwahati, India; email: pari@gauhati.ac.in","","Institute of Electrical and Electronics Engineers Inc.","","1st International Conference on Advances in Electrical, Electronics and Computational Intelligence, ICAEECI 2023","19 October 2023 through 20 October 2023","Tiruchengode","196103","","979-835034279-6","","","English","Int. Conf. Adv. Electr., Electron. Comput. Intell., ICAEECI","Conference paper","Final","","Scopus","2-s2.0-85183550578"
"Smolders A.; Lomax A.; Weber D.C.; Albertini F.","Smolders, A. (57212110146); Lomax, A. (35596133400); Weber, D.C. (7402029492); Albertini, F. (36008103200)","57212110146; 35596133400; 7402029492; 36008103200","Patient-specific neural networks for contour propagation in online adaptive radiotherapy","2023","Physics in Medicine and Biology","68","9","095010","","","","7","10.1088/1361-6560/accaca","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153803344&doi=10.1088%2f1361-6560%2faccaca&partnerID=40&md5=6649d44df63088c0c377db717aa2ea4a","Paul Scherrer Institute, Center for Proton Therapy, Switzerland; Department of Physics, ETH Zurich, Switzerland; Department of Radiation Oncology, University Hospital Zurich, Switzerland; Department of Radiation Oncology, Inselspital, Bern University Hospital, University of Bern, Switzerland","Smolders A., Paul Scherrer Institute, Center for Proton Therapy, Switzerland, Department of Physics, ETH Zurich, Switzerland; Lomax A., Paul Scherrer Institute, Center for Proton Therapy, Switzerland, Department of Physics, ETH Zurich, Switzerland; Weber D.C., Paul Scherrer Institute, Center for Proton Therapy, Switzerland, Department of Radiation Oncology, University Hospital Zurich, Switzerland, Department of Radiation Oncology, Inselspital, Bern University Hospital, University of Bern, Switzerland; Albertini F., Paul Scherrer Institute, Center for Proton Therapy, Switzerland","Objective. fast and accurate contouring of daily 3D images is a prerequisite for online adaptive radiotherapy. Current automatic techniques rely either on contour propagation with registration or deep learning (DL) based segmentation with convolutional neural networks (CNNs). Registration lacks general knowledge about the appearance of organs and traditional methods are slow. CNNs lack patient-specific details and do not leverage the known contours on the planning computed tomography (CT). This works aims to incorporate patient-specific information into CNNs to improve their segmentation accuracy. Approach. patient-specific information is incorporated into CNNs by retraining them solely on the planning CT. The resulting patient-specific CNNs are compared to general CNNs and rigid and deformable registration for contouring of organs-at-risk and target volumes in the thorax and head-and-neck regions. Results. patient-specific fine-tuning of CNNs significantly improves contour accuracy compared to standard CNNs. The method further outperforms rigid registration and a commercial DL segmentation software and yields similar contour quality as deformable registration (DIR). It is additionally 7-10 times faster than DIR. Significance. patient-specific CNNs are a fast and accurate contouring technique, enhancing the benefits of adaptive radiotherapy. © 2023 The Author(s). Published on behalf of Institute of Physics and Engineering in Medicine by IOP Publishing Ltd.","adaptive radiotherapy; biomedical image segmentation; contour propagation; deep learning","Algorithms; Cone-Beam Computed Tomography; Head and Neck Neoplasms; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Radiotherapy Planning, Computer-Assisted; Backpropagation; Convolutional neural networks; Deep learning; E-learning; Image segmentation; Radiotherapy; Adaptive radiotherapy; Biomedical image segmentation; Contour propagation; Contouring; Convolutional neural network; Deep learning; Online adaptive radiotherapies; Patient specific; Rigid registration; Specific information; algorithm; artificial neural network; cone beam computed tomography; head and neck tumor; human; image processing; procedures; Computerized tomography","","","","","Barbara Bachtiary; European Union’s Horizon 2020 Marie Skłodowska-Curie Actions, (955956); Reinhardt Krcek","Funding text 1: This project has received funding from the European Union’s Horizon 2020 Marie Skłodowska-Curie Actions under Grant Agreement No. 955956. The authors would like to thank Barbara Bachtiary, Reinhardt Krcek, Enrique Amaya and Marc Walser for contouring of daily CTs. We would further like to acknowledge Limbus AI for providing a trial version of Limbus Contour. Finally, we would like to thank Chiara Paganelli for the insightful discussions. ; Funding text 2: This project has received funding from the European Union’s Horizon 2020 Marie Skłodowska-Curie Actions under Grant Agreement No. 955956. The authors would like to thank Barbara Bachtiary, Reinhardt Krcek, Enrique Amaya and Marc Walser for contouring of daily CTs. We would further like to acknowledge Limbus AI for providing a trial version of Limbus Contour. Finally, we would like to thank Chiara Paganelli for the insightful discussions.","Albertini F, Hug E B, Lomax A J, Is it necessary to plan with safety margins for actively scanned proton therapy?, Phys. Med. Biol, 56, pp. 4399-44134399, (2011); Albertini F, Online daily adaptive proton therapy, Br. J. Radiol, 93, (2020); Amstutz F, An approach for estimating dosimetric uncertainties in deformable dose accumulation in pencil beam scanning proton therapy for lung cancer, Phys. Med. Biol, 66, (2021); Bortfeld T, IMRT: a review and preview, Phys. Med. Biol, 51, (2006); Brock K K, Use of image registration and fusion algorithms and techniques in radiotherapy: report of the AAPM Radiation Therapy Committee Task Group No. 132, Report Med. Phys, 44, pp. e43-e76e43, (2017); Brouwer C L, 3D Variation in delineation of head and neck organs at risk, Radiat. Oncol, 7, (2012); Caelles S, One-shot video object segmentation, Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), (2017); Chen W, A comparative study of auto-contouring softwares in delineation of organs at risk in lung cancer and rectal cancer, Sci. Rep, 11, (2021); Chun J, Intentional deep overfit learning (IDOL): a novel deep learning strategy for adaptive radiation therapy, Medical Physics, 49, (2022); Costea M, Comparison of atlas-based and deep learning methods for organs at risk delineation on head-and-neck CT images using an automated treatment planning system, Radiother. Oncol, 177, pp. 61-70, (2022); D'Aviero A, Clinical validation of a deep-learning segmentation software in head and neck: an early analysis in a developing radiation oncology center, Int. J. Environ. Res. Public Health, 19, (2022); Deeley M A, Comparison of manual and automatic segmentation methods for brain structures in the presence of space-occupying lesions: a multi-expert study, Phys. Med. Biol, 56, pp. 4557-45774557, (2011); Elmahdy M S, Robust contour propagation using deep learning and image registration for online adaptive proton therapy of prostate cancer, Med. Phys, 46, pp. 3329-33433329, (2019); Elmahdy M S, Patient-specific finetuning of deep learning models for adaptive radiotherapy in prostate CT, Proc.— Int. Symp. on Biomedical Imaging 2020-April, 577 580, pp. 577-580, (2020); Fransson S, Tilly D, Strand R, Patient specific deep learning based segmentation for magnetic resonance guided prostate radiotherapy, Phys. Imaging Radiat. Oncol, 23, (2022); Fu Y, Deep learning in medical image registration: a review, Phys. Med. Biol, 65, (2020); Gu X, Implementation and evaluation of various demons deformable image registration algorithms on a GPU, Phys. Med. Biol, 55, pp. 207-219207, (2010); Haskins G, Kruger U, Yan P, Deep learning in medical image registration: a survey, Mach. Vis. Appl, 31, (2020); Isensee F, batchgenerators—a python framework for data augmentation, (2020); Jansen M J A, Patient-specific fine-tuning of convolutional neural networks for follow-up lesion quantification, J. Med. Imaging, 7, (2020); Josipovic M, Geometric uncertainties in voluntary deep inspiration breath hold radiotherapy for locally advanced lung cancer, Radiother. Oncol, 118, pp. 510-514510, (2016); Klein A, Evaluation of 14 nonlinear deformation algorithms applied to human brain MRI registration, NeuroImage, 46, pp. 786-802786, (2009); Klein S, A toolbox for intensity-based medical image registration, IEEE Trans. Med. Imaging, 29, pp. 196-205196, (2010); Kosmin M, Rapid advances in auto-segmentation of organs at risk and target volumes in head and neck cancer, Radiother. Oncol, 135, pp. 130-140130, (2019); Kumar S, Variability of gross tumour volume delineation: MRI and CT based tumour and lymph node delineation for lung radiotherapy, Radiother. Oncol, 167, pp. 292-299292, (2022); Kumarasiri A, Deformable image registration based automatic CT-to- CT contour propagation for head and neck adaptive radiotherapy in the routine clinical setting, Med. Phys, 41, (2014); Lim-Reinders S, Online adaptive radiation therapy, Int. J. Radiat. Oncol.*Biol.*Phys, 99, pp. 994-1003994, (2017); Liu W, Robust optimization of intensity modulated proton therapy, Med. Phys, 39, pp. 1079-10911079, (2012); Liu X, Review of deep learning based automatic segmentation for lung cancer radiotherapy, Front. Oncol, 11, (2021); Lomax A, Intensity modulation methods for proton radiotherapy, Phys. Med. Biol, 44, pp. 185-205185, (1999); Lomax A J, Intensity modulated proton therapy and its sensitivity to treatment uncertainties: II. The potential effects of inter-fraction and inter-field motions, Phys. Med. Biol, 53, pp. 1043-10561043, (2008); Mattiucci G C, Automatic delineation for replanning in nasopharynx radiotherapy: what is the agreement among experts to be considered as benchmark?, Acta Oncol, 52, pp. 1417-14221417, (2013); Moreno A C, Intensity modulated proton therapy (IMPT)—the future of IMRT for head and neck cancer, Oral Oncol, 88, (2019); Nenoff L, Deformable image registration uncertainty for inter-fractional dose accumulation of lung cancer proton therapy, Radiother. Oncol, 147, pp. 178-185178, (2020); Nenoff L, Dosimetric influence of deformable image registration uncertainties on propagated structures for online daily adaptive proton therapy of lung cancer patients, Radiother. Oncol, 159, pp. 136-143136, (2021); Nikolov S, Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy, Journal of Medical Imaging Research, 23, (2021); Oh S, Kim S, Deformable image registration in radiation therapy, Radiat Oncol J, 35, pp. 101-111101, (2017); Otto K, Volumetric modulated arc therapy: IMRT in a single gantry arc, Med. Phys, 35, pp. 310-317310, (2008); Paganetti H, Adaptive proton therapy, Phys. Med. Biol, 66, (2021); Shaban A, One-shot learning for semantic segmentation, (2017); Shaheen E, A novel deep learning system for multi-class tooth segmentation and classification on cone beam computed tomography. A validation study, J. Dentistry, 115, (2021); Sharp G C, Plastimatch: an open source software suite for radiotherapy image processing, Proc. of the 16th Int. Conf. on the use of Computers in Radiotherapy (ICCR), (2010); Tao C J, Multi-subject atlas-based auto-segmentation reduces interobserver variation and improves dosimetric parameter consistency for organs at risk in nasopharyngeal carcinoma: a multi-institution clinical study, Radiother. Oncol, 115, pp. 407-411407, (2015); Thor M, Deformable image registration for contour propagation from CT to cone-beam CT scans in radiotherapy of prostate cancer, Acta Oncol, 50, pp. 918-925918, (2011); Tran A, Treatment planning comparison of IMPT, VMAT and 4p radiotherapy for prostate cases, Radiat. Oncol, 12, (2017); Unkelbach J, Robust radiotherapy planning, Phys. Med. Biol, 63, (2018); van der Veen J, Benefits of deep learning for delineation of organs at risk in head and neck cancer, Radiother. Oncol, 138, pp. 68-7468, (2019); van der Veen J, Interobserver variability in organ at risk delineation in head and neck cancer, Radiat. Oncol, 16, (2021); Verhaart R F, CT-based patient modeling for head and neck hyperthermia treatment planning: Manual versus automatic normal-tissuesegmentation, Radiother. Oncol, 111, pp. 158-163158, (2014); Weiss K, Khoshgoftaar T M, Wang D, A survey of transfer learning, J. Big Data, 3, (2016); Weistrand O, Svensson S, The ANACONDA algorithm for deformable image registration in radiotherapy, Med. Phys, 42, pp. 40-5340, (2015); Wong J, Comparing deep learning-based auto-segmentation of organs at risk and clinical target volumes to expert inter-observer variability in radiotherapy planning, Radiother. Oncol, 144, pp. 152-158152, (2020); Xiao H, Ren G, Cai J, A review on 3D deformable image registration and its application in dose warping, Radiat. Med. Prot, 1, pp. 171-178171, (2020); Yan D, Adaptive radiation therapy, Phys. Med. Biol, 42, pp. 123-132123, (1997); Yang J, Autosegmentation for thoracic radiation treatment planning: a grand challenge at AAPM 2017, Med. Phys, 45, (2018); Zhang H, Huang W, Reduction of inter-observer variability using mri and ct fusion in delineating of primary tumor for radiotherapy in lung cancer with atelectasis, Int. J. Radiat. Oncol.*Biol.*Phys, 114, (2022); Zhang M, Westerly D C, Mackie T R, Introducing an on-line adaptive procedure for prostate image guided intensity modulate proton therapy, Phys. Med. Biol, 56, pp. 4947-49654947, (2011)","A. Smolders; Paul Scherrer Institute, Center for Proton Therapy, Switzerland; email: andreas.smolders@psi.ch","","Institute of Physics","","","","","","00319155","","PHMBA","37019120","English","Phys. Med. Biol.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85153803344"
"Pattichis M.S.; Acton S.T.; Pattichis C.S.; Panayides A.S.","Pattichis, Marios S. (7004755649); Acton, Scott T. (7006577888); Pattichis, Constantinos S. (35495139000); Panayides, Andreas S. (16646871500)","7004755649; 7006577888; 35495139000; 16646871500","Guest Editorial Large-Scale Medical Image and Video Analytics for Clinical Decision Support","2023","IEEE Journal of Biomedical and Health Informatics","27","1","","4","6","2","0","10.1109/JBHI.2022.3227126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147148092&doi=10.1109%2fJBHI.2022.3227126&partnerID=40&md5=f37653dd0c112f20cea70bc2f5f37358","University of New Mexico, Albuquerque, 87131, NM, United States; University of Virginia, Charlottesville, 22903, VA, United States; University of Cyprus & HealthXR Group Leader, Cyens Centre of Excellence, Department of Computer Science, Biomedical Engineering Research Centre, Nicosia, 1016, Cyprus; Cyens Centre of Excellence, Videomics Group Leader, Nicosia, 1016, Cyprus","Pattichis M.S., University of New Mexico, Albuquerque, 87131, NM, United States; Acton S.T., University of Virginia, Charlottesville, 22903, VA, United States; Pattichis C.S., University of Cyprus & HealthXR Group Leader, Cyens Centre of Excellence, Department of Computer Science, Biomedical Engineering Research Centre, Nicosia, 1016, Cyprus; Panayides A.S., Cyens Centre of Excellence, Videomics Group Leader, Nicosia, 1016, Cyprus","[No abstract available]","","accuracy; adenocarcinoma; artificial intelligence; artificial neural network; biomedical image classification method; brain tissue segmentation; Bruch membrane; conceptual framework; data base; decision support system; deep learning; degenerative disease; dual attention deep manifold harmonic discrimination; Editorial; endobronchial ultrasonography; endoscopy; ensemble learning; gastritis atrophy; geometry; glioma; human; image classification; intestinal metaplasia; large scale production; learning algorithm; light imaging; meta learning; microscopy; multiinstance learning; multilabel classification; nerve cell network; neurilemoma; optical coherence tomography; partial image phase correlation; performance; personalized medicine; polyculture; radiography; radiologist; rheumatoid arthritis; small cell carcinoma; squamous cell carcinoma; training; ultrasound; validation study; video analytics; videorecording; visual feature","","","","","","","Yang J., Et al., A benchmark dataset of endoscopic images and novel deep learning method to detect intestinal metaplasia and gastritis atrophy, IEEE J. Biomed. Health Inform., 27, 1, pp. 7-16, (2023); Jiang H., Gao M., Li H., Jin R., Miao H., Liu J., Multi-learner based deep meta-learning for fewshot medical image classification, IEEE J. Biomed. Health Inform., 27, 1, pp. 17-28, (2023); Xu M., Et al., Automatic representative frame selection and intrathoracic lymph node diagnosis with endobronchial ultrasound elastography videos, IEEE J. Biomed. Health Inform., 27, 1, pp. 29-40, (2023); Fazekas B., Lachinov D., Aresta G., Mai J., Schmidt-Erfurth U., Bogunovic H., Segmentation of Bruch's Membrane in retinal OCT with AMD using anatomical priors and uncertainty quantification, IEEE J. Biomed. Health Inform., 27, 1, pp. 41-52, (2023); Ou Y., Et al., A sub-pixel accurate quantification of joint space narrowing progression in rheumatoid arthritis, IEEE J. Biomed. Health Inform., 27, 1, pp. 53-64, (2023); Chakraborty G., Wang W., Chakraborty B., Tai S.-K., Lo Y.-S., Grading of HCC biopsy images using nucleus and texture features, IEEE J. Biomed. Health Inform., 27, 1, pp. 65-74, (2023); Zhuang Y., Liu H., Song E., Hung C.-C., A 3D cross-modality feature interaction network with volumetric feature alignment for brain tumor and tissue segmentation, IEEE J. Biomed. Health Inform., 27, 1, pp. 75-86, (2023); Xu C., Et al., BMAnet: Boundary mining with adversarial learning for semi-supervised 2Dmyocardial infarction segmentation, IEEE J. Biomed. Health Inform., 27, 1, pp. 87-96, (2023); Shi J., Gong T., Wang C., Li C., Semi-supervised pixel contrastive learning framework for tissue segmentation in histopathological image, IEEE J. Biomed. Health Inform., 27, 1, pp. 97-108, (2023); Fu Y., Xue P., Xiao T., Zhang Z., Zhang Y., Dong E., Semi-supervised adversarial learning for improving the diagnosis of pulmonary nodules, IEEE J. Biomed. Health Inform., 27, 1, pp. 109-120, (2023); Borowa A., Rymarczyk D., Ochonska D., Sroka-Oleksiak A., Brzychczy-Woch M., Zielinski B., Identifying bacteria species on microscopic polyculture images using deep learning, IEEE J. Biomed. Health Inform., 27, 1, pp. 121-130, (2023); Sheng X., Chen J., Liu Y., Hu B., Cai H., Deep manifold harmonic network with dual attention for brain disorder classification, IEEE J. Biomed. Health Inform., 27, 1, pp. 131-142, (2023)","","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21682194","","ITIBF","","English","IEEE J. Biomedical Health Informat.","Editorial","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85147148092"
"Keshta I.; Deshpande P.S.; Shabaz M.; Soni M.; Bhadla M.; Muhammed Y.","Keshta, Ismail (56444410400); Deshpande, Pallavi Sagar (56591984200); Shabaz, Mohammad (57202955007); Soni, Mukesh (57202986134); Bhadla, Mohit kumar (57666121300); Muhammed, Yasser (57705952100)","56444410400; 56591984200; 57202955007; 57202986134; 57666121300; 57705952100","Multi-stage biomedical feature selection extraction algorithm for cancer detection","2023","SN Applied Sciences","5","5","131","","","","5","10.1007/s42452-023-05339-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152771079&doi=10.1007%2fs42452-023-05339-2&partnerID=40&md5=87f215eb76631e8895e4ba4ef5c6135d","Computer Science and Information Systems Department, College of Applied Sciences, AlMaarefa University, Riyadh, Saudi Arabia; Bharati Vidyapeeth (Deemed to Be University) College of Engineering, Pune, India; Arba Minch University, Arba Minch, Ethiopia; Department of CSE, University Centre for Research & Development Chandigarh University, Punjab, Mohali, 140413, India; Department of Information Technology, Ahmedabad Institute of Technology, Ahmedabad, India; College of Technical Engineering, Al-Farahidi University, Baghdad, Iraq","Keshta I., Computer Science and Information Systems Department, College of Applied Sciences, AlMaarefa University, Riyadh, Saudi Arabia; Deshpande P.S., Bharati Vidyapeeth (Deemed to Be University) College of Engineering, Pune, India; Shabaz M., Arba Minch University, Arba Minch, Ethiopia; Soni M., Department of CSE, University Centre for Research & Development Chandigarh University, Punjab, Mohali, 140413, India; Bhadla M., Department of Information Technology, Ahmedabad Institute of Technology, Ahmedabad, India; Muhammed Y., College of Technical Engineering, Al-Farahidi University, Baghdad, Iraq","Cancer is a significant cause of death worldwide. Early cancer detection is greatly aided by machine learning and artificial intelligence (AI) to gene microarray data sets (microarray data). Despite this, there is a significant discrepancy between the number of gene features in the microarray data set and the number of samples. Because of this, it is crucial to identify markers for gene array data. Existing feature selection algorithms, however, generally use long-standing, are limited to single-condition feature selection and rarely take feature extraction into account. This work proposes a Multi-stage algorithm for Biomedical Deep Feature Selection (MBDFS) to address this issue. In the first, three feature selection techniques are combined for thorough feature selection, and feature subsets are obtained; in the second, an unsupervised neural network is used to create the best representation of the feature subset to enhance final classification accuracy. Using a variety of metrics, including a comparison of classification results before and after feature selection and the performance of alternative feature selection methods, we evaluate MBDFS's efficacy. The experiments demonstrate that although MBDFS uses fewer features, classification accuracy is either unchanged or enhanced. © 2023, The Author(s).","Artificial intelligence; Artificial Intelligence; Biomedical Image; Cancer Detection; Deep Feature Selection; Feature Selection; Machine Learning","Bioinformatics; Classification (of information); Deep learning; Diseases; Extraction; Genes; Learning systems; Biomedical images; Cancer detection; Deep feature selection; Feature subset; Features selection; Machine-learning; Microarray dataset; Multi-stages; STAGE algorithm; Feature Selection","","","","","","","Zhang D., Zou L., Zhou X., He F., Integrating Feature Selection and Feature Extraction Methods With Deep Learning to Predict Clinical Outcome of Breast Cancer, IEEE Access, 6, pp. 28936-28944, (2018); Sevakula R.K., Singh V., Verma N.K., Kumar C., Cui Y., Transfer Learning for Molecular Cancer Classification Using Deep Neural Networks,, IEEE/ACM Transactions on Computational Biology and Bioinformatics, Vol., 16, 6, pp. 2089-2100, (2019); Mulenga M., Et al., Feature Extension of Gut Microbiome Data for Deep Neural Network-Based Colorectal Cancer Classification, IEEE Access, 9, pp. 23565-23578, (2021); Fadel M.M., Elseddeq N.G., Arnous R., Ali Z.H., Eldesouky A.I., A Fast Accurate Deep Learning Framework for Prediction of All Cancer Types, IEEE Access, 10, pp. 122586-122600, (2022); Raj R.J.S., Shobana S.J., Pustokhina I.V., Pustokhin D.A., Gupta D., Shankar K., Optimal Feature Selection-Based Medical Image Classification Using Deep Learning Model in Internet of Medical Things, IEEE Access, 8, pp. 58006-58017, (2020); Ali I., Muzammil M., Haq I.U., Khaliq A.A., Abdullah S., Deep Feature Selection and Decision Level Fusion for Lungs Nodule Classification, IEEE Access, 9, pp. 18962-18973, (2021); Batbaatar E., Et al., Class-Incremental Learning With Deep Generative Feature Replay for DNA Methylation-Based Cancer Classification, IEEE Access, 8, pp. 210800-210815, (2020); Muzammil M., Ali I., Haq I.U., Khaliq A.A., Abdullah S., Pulmonary Nodule Classification Using Feature and Ensemble Learning-Based Fusion Techniques, IEEE Access, 9, pp. 113415-113427, (2021); Qi Q., Et al., Label-Efficient Breast Cancer Histopathological Image Classification, IEEE J Biomed Health Inform, 23, 5, pp. 2108-2116, (2019); Senthilkumar G., Et al., Incorporating Artificial Fish Swarm in Ensemble Classification Framework for Recurrence Prediction of Cervical Cancer, IEEE Access, 9, pp. 83876-83886, (2021); Elseddeq N.G., Elghamrawy S.M., Salem M.M., Eldesouky A.I., A Selected Deep Learning Cancer Prediction Framework, IEEE Access, 9, pp. 151476-151492, (2021); BamunuMudiyanselage T.K., Xiao X., Zhang Y., Pan Y., Deep Fuzzy Neural Networks for Biomarker Selection for Accurate Cancer Detection, IEEE Trans Fuzzy Syst, 28, 12, pp. 3219-3228, (2020); Ning Z., Et al., Pattern Classification for Gastrointestinal Stromal Tumors by Integration of Radiomics and Deep Convolutional Features, IEEE J Biomed Health Inform, 23, 3, pp. 1181-1191, (2019); Mulenga M., Kareem S.A., Sabri A.Q.M., Seera M., Stacking and Chaining of Normalization Methods in Deep Learning-Based Classification of Colorectal Cancer Using Gut Microbiome Data, IEEE Access, 9, pp. 97296-97319, (2021); Khan M.A., Et al., Computer-Aided Gastrointestinal Diseases Analysis From Wireless Capsule Endoscopy: A Framework of Best Features Selection, IEEE Access, 8, pp. 132850-132859, (2020); Lee S.-A., Cho H.C., Cho H.-C., A Novel Approach for Increased Convolutional Neural Network Performance in Gastric-Cancer Classification Using Endoscopic Images, IEEE Access, 9, pp. 51847-51854, (2021); Zeimarani B., Costa M.G.F., Nurani N.Z., Bianco S.R., de Albuquerque Pereira W.C., Filho C.F.F.C., Breast Lesion Classification in Ultrasound Images Using Deep Convolutional Neural Network,, IEEE Access, 8, pp. 133349-133359, (2020); Zhang B., Et al., Ensemble Learners of Multiple Deep CNNs for Pulmonary Nodules Classification Using CT Images, IEEE Access, 7, pp. 110358-110371, (2019); Ferreira J., Domingues I., Sousa O., Sampaio I.L., Santos J.A.M., Classification of oesophagic early-stage cancers: Deep learning versus traditional learning approaches, IEEE 20Th International Conference on Bioinformatics and Bioengineering (BIBE), 2020, pp. 746-751, (2020); Mamun A.A., Duan W., Mondal A.M., Pan-cancer Feature Selection and Classification Reveals Important Long Non-coding RNAs, IEEE International Conference on Bioinformatics and Biomedicine (BIBM), 2020, pp. 2417-2424, (2020); Zemouri R., Zerhouni N., Racoceanu D., Deep learning in the biomedical applications: recent and future status, Appl Sci, 9, pp. 1526-1566, (2019); Sheikhpour R., Sarram M.A., Sheikhpour R., Particle swarm optimization for bandwidth determination and feature selection of kernel density estimation-based classifiers in diagnosis of breast cancer, Appl Soft Comput, 40, pp. 113-131, (2016); Shen R., Yang Y., Shao F., Intelligent Breast Cancer Prediction Model Using Data Mining Techniques, In 2014 Sixth Int. Conf. Intelligent Human-Machine Systems and Cybernetics, August 26–27, pp. 384-387, (2014); Pawar P.S., Patil D.R., Breast Cancer Detection Using Neural Network Models, In 2013 Int. Conf. Communication Systems and Network Technologies, April 6–8, pp. 568-572, (2013); Javaid A., Sadiq M., Akram F., Skin Cancer Classification Using Image Processing and Machine Learning, International Bhurban Conference on Applied Sciences and Technologies (IBCAST), 2021, pp. 439-444, (2021); Al Mamun A., Sobhan M., Tanvir R.B., Dimitroff C.J., Mondal A.M., Deep Learning to Discover Cancer Glycome Genes Signifying the Origins of Cancer, ,"" 2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM, pp. 2425-2431, (2020); Sol Dussaut J., Javier Vidal P., Ponzoni I., Carolina Olivera A., Comparing Multiobjective Evolutionary Algorithms for Cancer Data Microarray Feature Selection, 2018 IEEE Congress on Evolutionary Computation (CEC), pp. 1-8, (2018); Khanna P., Sahu M., Kumar Singh B., Improving the classification performance of breast ultrasound image using deep learning and optimization algorithm, IEEE International Conference on Technology, Research, and Innovation for Betterment of Society (TRIBES), pp. 1-6, (2021); Mathews C., Mohamed A., Deep Classification of Glioma Grade using 3D Wavelet Features, International Conference for Advancement in Technology (ICONAT), 2022, pp. 1-5, (2022); Daoud M.I., Abdel-Rahman S., Alazrai R., Breast Ultrasound Image Classification Using a Pre-Trained Convolutional Neural Network, ,"" 2019 15Th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS, pp. 167-171, (2019); Xu B., Look, Investigate, and Classify: A Deep Hybrid Attention Method for Breast Cancer Classification, 2019 IEEE 16Th International Symposium on Biomedical Imaging (ISBI 2019, pp. 914-918, (2019)","M. Shabaz; Arba Minch University, Arba Minch, Ethiopia; email: mohammad.shabaz@amu.edu.et","","Springer Nature","","","","","","25233971","","","","English","SN Appl. Sci.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85152771079"
"Altun S.; Alkan A.; Altun I.","Altun, Sinan (57482139300); Alkan, Ahmet (56261391700); Altun, İdiris (55975679200)","57482139300; 56261391700; 55975679200","LSS-VGG16: Diagnosis of Lumbar Spinal Stenosis with Deep Learning","2023","Clinical Spine Surgery","36","5","","E180","E190","10","3","10.1097/BSD.0000000000001418","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160969409&doi=10.1097%2fBSD.0000000000001418&partnerID=40&md5=ad05ba3d2030aa119b22766cd58a0911","Department of Electrical and Electronics Engineering, Turkey; Department of Neurosurgery, Kahramanmaras Sutcu Imam Universirty, Kahramanmaras, Turkey","Altun S., Department of Electrical and Electronics Engineering, Turkey; Alkan A., Department of Electrical and Electronics Engineering, Turkey; Altun I., Department of Neurosurgery, Kahramanmaras Sutcu Imam Universirty, Kahramanmaras, Turkey","Study Design: This was a retrospective study. Objection: Lumbar Spinal Stenosis (LSS) is a disease that causes chronic low back pain and can often be confused with herniated disk. In this study, a deep learning-based classification model is proposed to make LSS diagnosis quickly and automatically with an objective tool. Summary of Background Data: LSS is a disease that causes negative consequences such as low back pain, foot numbness, and pain. Diagnosis of this disease is difficult because it is confused with herniated disk and requires serious expertise. The shape and amount of this stenosis are very important in deciding the surgery and the surgical technique to be applied in these patients. When the spinal canal narrows, as a result of compression on these nerves and/or pressure on the vessels feeding the nerves, poor nutrition of the nerves causes loss of function and structure. Image processing techniques are applied in biomedical images such as MR and CT and high classification success is achieved. In this way, computer-aided diagnosis systems can be realized to help the specialist in the diagnosis of different diseases. Methods: To demonstrate the success of the proposed model, different deep learning methods and traditional machine learning techniques have been studied. Results: The highest classification success was obtained in the VGG16 method, with 87.70%. Conclusions: The proposed LSS-VGG16 model reveals that a computer-aided diagnosis system can be created for the diagnosis of spinal canal stenosis. In addition, it was observed that higher classification success was achieved compared with similar studies in the literature. This shows that the proposed LSS-VGG16 model will be an important resource for scientists who will work in this field. © 2023 Lippincott Williams and Wilkins. All rights reserved.","deep learning; image processing; lumbar spinal stenosis; VGG16","Constriction, Pathologic; Deep Learning; Humans; Intervertebral Disc Displacement; Low Back Pain; Lumbar Vertebrae; Retrospective Studies; Spinal Stenosis; accuracy; adult; aged; algorithm; area under the curve; Article; artificial intelligence; artificial neural network; backache; cerebrospinal fluid; cervical spine; classification algorithm; compression; controlled study; decision tree; decompression surgery; deep learning; diagnostic test accuracy study; feeding; female; histogram; human; image processing; image quality; image reconstruction; intervertebral disk degeneration; intervertebral disk hernia; knee; learning algorithm; loss of function mutation; low back pain; lumbar spinal stenosis; machine learning; major clinical study; male; natural language processing; nerve; nuclear magnetic resonance imaging; operation duration; random forest; receiver operating characteristic; retrospective study; sensitivity and specificity; spine surgery; structure activity relation; support vector machine; surgical technique; three-dimensional imaging; vertebral canal; VGG16; complication; diagnostic imaging; intervertebral disk hernia; low back pain; lumbar vertebra; stenosis, occlusion and obstruction; surgery; vertebral canal stenosis","","","","","Türkiye Bilimsel ve Teknolojik Araştırma Kurumu, TÜBİTAK, (122E042)","This work is supported by the Scientific and Technological Research Council of Turkey (TÜBİTAK), 1002-Fast Support Program, with the number 122E042. ","Kilicaslan M.F., Nabi V., Yardibi F., Research tendency in lumbar spinal stenosis over the past decade: A bibliometric analysis, World Neurosurg, 149, pp. e71-e84, (2021); Secen A.E., Yigitkanli K., Lumbar Narrow Canal; Pathophysiology and Natural Course [Lumber Narrow Canal; Pathophysiology and Natural Course]., Türk Nöroşirürji Dergsi, 28, pp. 216-220, (2018); Natalia F., Meidia H., Afriliana N., Development of Ground Truth Data for Automatic Lumbar Spine MRI Image Segmentation, 2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City, (2018); Altun I., Yuksel K.Z., Histopathological Analysis of Ligamentum Flavum in Lumbar Spinal Stenosis and Disc Herniation, Asian Spine J, 11, pp. 71-74, (2017); Siccoli A., Wispelaere M.P., Schroder M.L., Machine learning-based preoperative predictive analytics for lumbar spinal stenosis, Neurosurg Focus, 46, (2019); Mbarki W., Bouchouicha M., Frizzi S., Lumbar spine discs classification based on deep convolutional neural networks using axial view MRI, Interdiscip Neurosurg, 22, (2020); Lee S., Lee H., Spinal stenosis grading in magnetic resonance imaging using deep convolutional neural networks, Spine J, 20, (2020); Hallinan J., Zhu L., Yang K., Deep learning model for automated detection and classification of central canal, lateral recess, and neural foraminal stenosis at lumbar spine MRI, Radiology, 300, pp. 130-138, (2021); Kim K., Kim H., Park J., Development of a machine-learning model of short-term prognostic prediction for spinal stenosis surgery in Korean Patients, Brain Sci, 10, (2020); Al-Kafri A.S., Sudirman S., Hussain A., Boundary Delineation of MRI Images for Lumbar Spinal Stenosis Detection Through Semantic Segmentation Using Deep Neural Networks, IEEE Access, 7, pp. 43487-43501, (2019); Sriphirom P., Siramanakul C., Chaipanha P., Clinical Outcomes of Interlaminar Percutaneous Endoscopic Decompression for Degenerative Lumbar Spondylolisthesis with Spinal Stenosis, Brain Sci, 11, (2021); Guo J., Hua C., Xiong X., Feature extraction of workpiece circular contour based on Sobel operator, 2018 IEEE 4th Information Technology and Mechatronics Engineering Conference (ITOEC), (2018); Sharifrazi D., Alizadehsani R., Roshanzamir M., Fusion of convolution neural network, support vector machine and Sobel filter for accurate detection of COVID-19 patients using X-ray images, Biomed Signal Process Control, 68, (2021); Munawar H., Aggarwal R., Qadir Z., A gabor filter-based protocol for automated image-based building detection, Buildings, 11, (2021); Tadic V., Loncar-Turukalo T., Odry A., A note on advantages of the Fuzzy Gabor Filter in object and text detection, Symmetry, 13, (2021); Liberda D., Kosowska K., Koziol P., Spatial sampling effect on data structure and random forest classification of tissue types in High Definition and Standard Definition FT-IR imaging, Chemometr Intell Lab Syst, 217, (2021); Mohana Priya R., Venkatesan P., An efficient image segmentation and classification of lung lesions in pet and CT image fusion using DTWT incorporated SVM, Microprocess Microsyst, 82, (2021); Li Z., Hu A., Wang X., Learning to capture dependencies between global features of different convolution layers, J Vis Commun Image Represent, 81, (2021); Jian J., Xia W., Zhang R., Multiple instance convolutional neural network with modality-based attention and contextual multi-instance learning pooling layer for effective differentiation between borderline and malignant epithelial ovarian tumors, Artif Intell Med, 121, (2021); Ghosh S., Chaki A., Santosh K., Improved U-Net architecture with VGG-16 for brain tumor segmentation, Phys Eng Sci Med, 44, pp. 703-712, (2021); Dong N., Zhao L., Wu C., Inception v3 based cervical cell classification combined with artificially extracted features, Appl Soft Comput, 93, (2020); Zhang Z., Wu C., Coleman S., DENSE-INception U-net for medical image segmentation, Comput Methods and Programs Biomed, 192, (2020); Shehab L.H., Fahmy O.M., Gasser S.M., An efficient brain tumor image segmentation based on deep residual networks (ResNets), J King Saud Univ Eng Sci, 33, pp. 404-412, (2021); Lu S., Wang S.H., Zhang Y.D., Detecting pathological brain via ResNet and randomized neural networks, Heliyon, 6, (2020); Nan Y., Ju J., Hua Q., A-MobileNet: An approach of facial expression recognition, Alex Eng J, 61, pp. 4435-4444, (2021)","S. Altun; Kahramanmaras Sutcu Imam University, Imam University, Kahramanmaraş, Avsar Campus: Kahramanmaras Sutcu, Turkey; email: s.altun@yaani.com","","Lippincott Williams and Wilkins","","","","","","23800186","","","36727890","English","Clin. Spine Surg.","Article","Final","","Scopus","2-s2.0-85160969409"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Communications in Computer and Information Science","1968 CCIS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178625415&partnerID=40&md5=bb0a33ddf85aef908ebced83f2ea0b55","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","18650929","978-981998180-9","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85178625415"
"Chen R.; Wang Q.; Huang X.","Chen, Rongcan (58508148800); Wang, Qinglian (57212104509); Huang, Xiaoyuan (58543221500)","58508148800; 57212104509; 58543221500","Intelligent deep learning supports biomedical image detection and classification of oral cancer","2024","Technology and Health Care","32","","","S465","S475","10","0","10.3233/THC-248041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195530501&doi=10.3233%2fTHC-248041&partnerID=40&md5=7a182e955099d55de2fab4ff1623b77f","School of Informatics, Xiamen University, Fujian, Xiamen, China; Department of Stomatology, Zhongshan Hospital (Xiamen), Fudan University, Fujian, Xiamen, China; Department of Stomatology, Zhongshan Hospital, Xiamen University, Xiamen, China","Chen R., School of Informatics, Xiamen University, Fujian, Xiamen, China; Wang Q., School of Informatics, Xiamen University, Fujian, Xiamen, China, Department of Stomatology, Zhongshan Hospital (Xiamen), Fudan University, Fujian, Xiamen, China; Huang X., Department of Stomatology, Zhongshan Hospital, Xiamen University, Xiamen, China","BACKGROUND: Oral cancer is a malignant tumor that usually occurs within the tissues of the mouth. This type of cancer mainly includes tumors in the lining of the mouth, tongue, lips, buccal mucosa and gums. Oral cancer is on the rise globally, especially in some specific risk groups. The early stage of oral cancer is usually asymptomatic, while the late stage may present with ulcers, lumps, bleeding, etc. OBJECTIVE: The objective of this paper is to propose an effective and accurate method for the identification and classification of oral cancer. METHODS: We applied two deep learning methods, CNN and Transformers. First, we propose a new CANet classification model for oral cancer, which uses attention mechanisms combined with neglected location information to explore the complex combination of attention mechanisms and deep networks, and fully tap the potential of attention mechanisms. Secondly, we design a classification model based on Swim transform. The image is segmented into a series of two-dimensional image blocks, which are then processed by multiple layers of conversion blocks. RESULTS: The proposed classification model was trained and predicted on Kaggle Oral Cancer Images Dataset, and satisfactory results were obtained. The average accuracy, sensitivity, specificity and F1-Socre of Swin transformer architecture are 94.95%, 95.37%, 95.52% and 94.66%, respectively. The average accuracy, sensitivity, specificity and F1-Score of CANet model were 97.00%, 97.82%, 97.82% and 96.61%, respectively. CONCLUSIONS: We studied different deep learning algorithms for oral cancer classification, including convolutional neural networks, converters, etc. Our Attention module in CANet leverages the benefits of channel attention to model the relationships between channels while encoding precise location information that captures the long-term dependencies of the network. The model achieves a high classification effect with an accuracy of 97.00%, which can be used in the automatic recognition and classification of oral cancer.  © 2024 - The authors. Published by IOS Press.","attention mechanism; Oral cancer classification; transformer","Deep Learning; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Mouth Neoplasms; Neural Networks, Computer; Sensitivity and Specificity; Article; cancer classification; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; human; image analysis; image segmentation; learning algorithm; major clinical study; mouth cancer; sensitivity and specificity; artificial neural network; classification; computer assisted diagnosis; diagnosis; diagnostic imaging; image processing; mouth tumor; pathology; procedures","","","","","National Natural Science Foundation of China, NSFC, (62002304); National Natural Science Foundation of China, NSFC; Fundamental Research Funds for the Central Universities, (20720210053); Fundamental Research Funds for the Central Universities","This work was supported by the National Natural Science Foundation of China (Grant no. 62002304) and the China Fundamental Research Funds for the Central Universities (Grant no. 20720210053).","Singh A., Sahu A., Verma S., Computer intelligence in detection of malignant or premalignant oral lesions: the story so far, Computational Intelligence in Oncology: Applications in Diagnosis. Prognosis and Therapeutics of Cancers, pp. 187-200, (2022); Siddiqui S.Y., Haider A., Ghazal T.M., Et al., IoMT cloud-based intelligent prediction of breast cancer stages empowered with deep learning, IEEE Access, 9, pp. 146478-146491, (2021); Mansour R.F., Alfar N.M., Abdel-Khalek S., Et al., Optimal deep learning based fusion model for biomedical image classification, Expert Systems, 39, 3, (2022); Azimi S., Ghorbani Z., Tennant M., Et al., Population survey of knowledge about oral cancer and related factors in the capital of Iran, Journal of Cancer Education, 34, pp. 116-123, (2019); Figueroa K.C., Song B., Sunny S., Et al., Interpretable deep learning approach for oral cancer classification using guided attention inference network, Journal of Biomedical Optics, 27, 1, (2022); Lim J.H., Tan C.S., Chan C.S., Et al., D'OraCa: deep learning-based classification of oral lesions with mouth landmark guidance for early detection of oral cancer, Medical Image Understanding and Analysis: 25th Annual Conference, MIUA 2021, pp. 408-422, (2021); Shamim M.Z.M., Syed S., Shiblee M., Et al., Automated detection of oral pre-cancerous tongue lesions using deep learning for early diagnosis of oral cavity cancer, The Computer Journal, 65, 1, pp. 91-104, (2022); Chan C.H., Huang T.T., Chen C.Y., Et al., Texture-map-based branch-collaborative network for oral cancer detection, IEEE Transactions on Biomedical Circuits and Systems, 13, 4, pp. 766-780, (2019); Han K., Wang Y., Chen H., Et al., A survey on vision transformer, IEEE Transactions on Pattern Analysis and Machine Intelligence, 45, 1, pp. 87-110, (2022); Xu Y., Wei H., Lin M., Et al., Transformers in computational visual media: A survey, Computational Visual Media, 8, pp. 33-62, (2022); Bhandari B., Alsadoon A., Prasad P.W.C., Et al., Deep learning neural network for texture feature extraction in oral cancer: Enhanced loss function, Multimedia Tools and Applications, 79, pp. 27867-27890, (2020); Lu J., Sladoje N., Runow Stark C., Et al., A deep learning based pipeline for efficient oral cancer screening on whole slide images, International Conference on Image Analysis and Recognition, pp. 249-261, (2020); Song B., Sunny S., Uthoff R.D., Et al., Automatic classification of dual-modalilty, smartphone-based oral dysplasia and malignancy images using deep learning, Biomedical Optics Express, 9, 11, pp. 5318-5329, (2018); Vaswani A., Shazeer N., Parmar N., Et al., Attention is all you need, Advances in Neural Information Processing Systems, (2017); Gheflati B., Rivaz H., Vision transformers for classification of breast ultrasound images, 2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC), pp. 480-483, (2022); Buslaev A., Iglovikov V.I., Khvedchenya E., Et al., Albumentations: fast and flexible image augmentations, Information, 11, 2, (2020); Touvron H., Cord M., Douze M., Et al., Training data-efficient image transformers & distillation through attention, International conference on machine learning, pp. 10347-10357, (2021); Yuan L., Chen Y., Wang T., Et al., Tokens-to-token vit: Training vision transformers from scratch on imagenet, Proceedings of the IEEE/CVF international conference on computer vision, pp. 558-567, (2021); Wang W., Xie E., Li X., Et al., Pyramid vision transformer: A versatile backbone for dense prediction without convolutions, Proceedings of the IEEE/CVF international conference on computer vision, pp. 568-578, (2021); Liu Z., Lin Y., Cao Y., Et al., Swin transformer: Hierarchical vision transformer using shifted windows, Proceedings of the IEEE/CVF international conference on computer vision, pp. 10012-10022, (2021); Hou Q., Zhou D., Feng J., Coordinate attention for efficient mobile network design, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 13713-13722, (2021); Zhou B., Khosla A., Lapedriza A., Et al., Learning deep features for discriminative localization, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2921-2929, (2016); Dosovitskiy A., Beyer L., Kolesnikov A., Et al., An image is worth 16 16 words: Transformers for image recognition at scale, (2020); Alabdan R., Alruban A., Hilal A.M., Et al., Artificial-Intelligence-Based Decision Making for Oral Potentially Malignant Disorder Diagnosis in Internet of Medical Things Environment, Healthcare. MDPI, 11, 1, (2022); Alanazi A.A., Khayyat M.M., Khayyat M.M., Et al., Intelligent deep learning enabled oral squamous cell carcinoma detection and classification using biomedical images, Computational Intelligence and Neuroscience, (2022)","X. Huang; Department of Stomatology, Zhongshan Hospital, Xiamen University, Xiamen, China; email: huangxiaoyuan6531@163.com","","IOS Press BV","","","","","","09287329","","THCAE","38759069","English","Technol. Health Care","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85195530501"
"Fu W.; Xue B.; Zhang M.; Schindler J.","Fu, Wenlong (36801652400); Xue, Bing (55329093700); Zhang, Mengjie (8729040400); Schindler, Jan (57219929281)","36801652400; 55329093700; 8729040400; 57219929281","Evolving U-Nets Using Genetic Programming for Tree Crown Segmentation","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13836 LNCS","","","188","201","13","0","10.1007/978-3-031-25825-1_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147987723&doi=10.1007%2f978-3-031-25825-1_14&partnerID=40&md5=221f096403c5b621c4c069c1e08632d0","Victoria University of Wellington, PO Box 600, Wellington, 6140, New Zealand; Manaaki Whenua-Landcare Research, Wellington, 6011, New Zealand","Fu W., Victoria University of Wellington, PO Box 600, Wellington, 6140, New Zealand; Xue B., Victoria University of Wellington, PO Box 600, Wellington, 6140, New Zealand; Zhang M., Victoria University of Wellington, PO Box 600, Wellington, 6140, New Zealand; Schindler J., Manaaki Whenua-Landcare Research, Wellington, 6011, New Zealand","The U-Net deep learning algorithm and its variants have been developed for biomedical image segmentation, and due to their success gained popularity in other science domains including remote sensing. So far no U-Net structure has been specifically designed to segment complex tree canopies from aerial imagery. In this paper, a handcrafted convolutional block is introduced to replace the raw convolutional block used in the standard U-Net structure. Furthermore, we proposed a Genetic Programming (GP) approach to evolving convolutional blocks used in the U-Net structure. The experimental results on a tree crown dataset show that both the handcrafted block and the GP evolved blocks have better segmentation results than the standard U-Net. Additionally, the U-Net using the proposed handcrafted blocks has fewer numbers of the learning parameters than the standard U-Net. Also, the proposed GP approach can evolve convolutional blocks used in U-Nets that perform better than the handcrafted U-Net and the standard U-Net, and can also achieve automation. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Convolutional neural network; Genetic programming; Image segmentation; U-Net","Aerial photography; Antennas; Bioinformatics; Convolution; Deep learning; Genetic algorithms; Genetic programming; Learning algorithms; Remote sensing; Aerial imagery; Biomedical image segmentation; Convolutional neural network; Images segmentations; Net structures; Remote-sensing; Segmentation results; Tree canopy; Tree crowns; U-net; Image segmentation","","","","","Ministry of Business, Innovation and Employment, MBIE, (C09X1923); Ministry of Business, Innovation and Employment, MBIE","Funded by the New Zealand Ministry of Business, Innovation and Employment under contract C09X1923 (Catalyst: Strategic Fund).","Agarap A.F., Deep learning using rectified linear units (ReLU), (2018); Alzubaidi L., Et al., Review of deep learning: concepts, CNN architectures, challenges, applications, future directions, J. Big Data, 8, (2021); Deng S., Sun Y., Galvan E., Neural architecture search using genetic algorithm for facial expression recognition, GECCO 2022: Genetic and Evolutionary Computation Conference, Companion Volume, Boston, Massachusetts, USA, 9–13 July 2022, pp. 423-426; Fernandez J.G., Mehrkanoon S., Broad-UNet: multi-scale feature learning for nowcasting tasks, Neural Netw, 144, pp. 419-427, (2021); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, (2015); He K., Zhang X., Ren S., Sun J., Delving deep into rectifiers: surpassing human-level performance on ImageNet classification, 2015 IEEE International Conference on Computer Vision (ICCV), pp. 1026-1034, (2015); Huang G., Liu Z., Van Der Maaten L., Weinberger K.Q., Densely connected convolutional networks, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269, (2017); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Proceedings of the 25th International Conference on Neural Information Processing Systems, NIPS 2012, 1, pp. 1097-1105, (2012); Li Z., Liu F., Yang W., Peng S., Zhou J., A survey of convolutional neural networks: analysis, applications, and prospects, IEEE Trans. Neural Netw. Learn. Syst, 33, 12, pp. 6999-7019, (2022); Liu Y., Sun Y., Xue B., Zhang M., Yen G., Tan K., A survey on evolutionary neural architecture search, IEEE Trans. Neural Netw. Learn. Syst, (2021); Minaee S., Boykov Y., Porikli F., Plaza A., Kehtarnavaz N., Terzopoulos D., Image segmentation using deep learning: a survey, IEEE Trans. Pattern Anal. Mach. Intell, 44, 7, pp. 3523-3542, (2022); Mo Y., Wu Y., Yang X., Liu F., Liao Y., Review the state-of-the-art technologies of semantic segmentation based on deep learning, Neurocomputing, 493, pp. 626-646, (2022); Oktay O., Et al., Attention U-Net: learning where to look for the pancreas, Medical Imaging with Deep Learning, (2018); Ren P., Et al., A comprehensive survey of neural architecture search: challenges and solutions, ACM Comput. Surv, 54, 4, pp. 1-34, (2021); Ronneberger O., Fischer P., Brox T., U-Net: convolutional networks for biomedical image segmentation, MICCAI 2015. LNCS, 9351, pp. 234-241, (2015); Suganuma M., Shirakawa S., Nagao T., A genetic programming approach to designing convolutional neural network architectures, Proceedings of the Genetic and Evolutionary Computation Conference, pp. 497-504, (2017); Wang B., Xue B., Zhang M., Particle swarm optimisation for evolving deep neural networks for image classification by evolving and stacking transferable blocks, 2020 IEEE Congress on Evolutionary Computation (CEC), pp. 1-8, (2020); Yu F., Wang D., Shelhamer E., Darrell T., Deep layer aggregation, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2403-2412, (2018); Zhan Z.H., Li J.Y., Zhang J., Evolutionary deep learning: a survey, Neurocomputing, 483, pp. 42-58, (2022); Zhou X., Qin A.K., Gong M., Tan K.C., A survey on evolutionary construction of deep neural networks, IEEE Trans. Evol. Comput, 25, 5, pp. 894-912, (2021); Zhou Z., Rahman Siddiquee M.M., Tajbakhsh N., Liang J., UNet++: a nested U-Net architecture for medical image segmentation, DLMIA/ML-CDS-2018. LNCS, 11045, pp. 3-11, (2018)","W. Fu; Victoria University of Wellington, Wellington, PO Box 600, 6140, New Zealand; email: wenlong.fu@gmail.com","Yan W.Q.; Nguyen M.; Stommel M.","Springer Science and Business Media Deutschland GmbH","","37th International Conference on Image and Vision Computing New Zealand, IVCNZ 2022","24 November 2022 through 25 November 2022","Auckland","290019","03029743","978-303125824-4","","","English","Lect. Notes Comput. Sci.","Conference paper","Final","","Scopus","2-s2.0-85147987723"
"Elmoufidi A.; Ammoun H.","Elmoufidi, Abdelali (56252362600); Ammoun, Hind (57226315963)","56252362600; 57226315963","Diabetic Retinopathy Prevention Using EfficientNetB3 Architecture and Fundus Photography","2023","SN Computer Science","4","1","78","","","","8","10.1007/s42979-022-01482-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143389752&doi=10.1007%2fs42979-022-01482-6&partnerID=40&md5=dbb921421744e589793bc923c4c9aeb5","Data4Earth Laboratory, Sultan Moulay Slimane University, BP 523, Beni Mellal, 23000, Morocco; Mathematics and Interactions Team, Sultan Moulay Slimane University, BP 523, Beni Mellal, 23000, Morocco","Elmoufidi A., Data4Earth Laboratory, Sultan Moulay Slimane University, BP 523, Beni Mellal, 23000, Morocco; Ammoun H., Mathematics and Interactions Team, Sultan Moulay Slimane University, BP 523, Beni Mellal, 23000, Morocco","Classification of stages of diabetic retinopathy (DR) is considered a key step in the assessment and management of diabetic retinopathy. Due to damage caused by high blood sugar in the retinal blood vessels, different microscopic structures can be occupied in the retinal area, such as micro-aneurysms, hard exudate, and neovascularization. The convolutional neural network (CNN) based on deep learning has become a promising method for the analysis of biomedical images. In this work, representative images of diabetic retinopathy (DR) are divided into five categories according to the professional knowledge of ophthalmologists. This article focuses on the use of convolutional neural networks to classify background images of DR according to disease severity and on the application of pooling, Softmax activation to achieve greater accuracy. The aptos2019-blindness-detection database makes it possible to verify the performance of the proposed algorithm. © 2022, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.","Convolutional neural networks; Deep learning; Diabetic retinopathy; EfficientNet; Fundus photography","","","","","","","","Alex K., Ilya S., Geoffrey E.H., Imagenet classification with deep convolutional neural networks, Adv Neural Inf Process Syst, 25, pp. 1097-1105, (2012); Hajeb Mohammad Alipour S., Rabbani H., Akhlaghi M.R., Diabetic retinopathy grading by digital curvelet transform, Comput Math Methods Med, 2012, (2012); Darshit D., Aniket S., Deep S., Prachi G., Diabetic retinopathy detection using deep convolutional neural networks, In: 2016 International Conference on Computing, Analytics and Security Trends, pp. 261-266, (2016); Dang N.H.T., Nguyen H.H., Prayag T., Surya Prasath V.B., Et al., Skin lesion segmentation method for dermoscopic images with convolutional neural networks and semantic segmentation, Comput Opt, 45, 1, pp. 122-129, (2021); Kashan Z., Syed O.G., Asim W., Ali A., Mohsin J., Muhammad N.K., Amer S.K., Skin lesion segmentation from dermoscopic images using convolutional neural network, Sensors, 20, 6, (2020); Neha Y., Md Alfayeed S.K., Aditya K., Babita P., Dang N.H.T., Sagar P., hsv model-based segmentation driven facial acne detection using deep learning, Expert Syst, 39, (2021); Aditya K., Subrato B., Prajoy P., Deepak G., Ashish K., Thai K.P., Dang N.H.T., Diagnosis of breast cancer based on modern mammography using hybrid transfer learning, Multidimens Syst Signal Process, 32, 2, pp. 747-765, (2021); Kumar V., Mishra B.K., Mazzara M., Thanh D.N., Verma A., Prediction of malignant and benign breast cancer: a data mining approach in healthcare applications, Advances in data science and management, pp. 435-442, (2020); Elmoufidi A., El Fahssi K., Jai-Andaloussi S., Sekkaki A., Gwenole Q., Lamard M., anomaly classification in digital mammography based on multiple-instance learning, IET Image Process, 12, 3, pp. 320-328, (2018); Elmoufidi A., El Fahssi K., Jai-Andaloussi S., Madrane N., Sekkaki A., Detection of regions of interest’s in mammograms by using local binary pattern, dynamic k-means algorithm and gray level co-occurrence matrix, 2014 International Conference on Next Generation Networks and Services (NGNS), pp. 118-123, (2014); Pre-processing algorithms on digital x-ray mammograms, . In: 2019 IEEE International Smart Cities Conference (ISC2, pp. 87-92; Elmoufidi A., Deep Multiple Instance Learning for Automatic Breast Cancer Assessment Using Digital Mammography, IEEE transactions on instrumentation and measurement, 71, pp. 1-13; Elmoufidi A., Skouta A., Jai-Andaloussi S., Ouchetto O., CNN with multiple inputs for automatic glaucoma assessment using fundus images, Int J Image Graph, (2022); Elmoufidi A., Skouta A., Jai-Andaloussi S., Et al., Deep multiple instance learning for automatic glaucoma prevention and auto-annotation using color fundus photography, Prog Artif Intell, 11, pp. 397-409, (2022); Thanh D.N.H., Sergey D., Surya Prasath V.B., Hai N.H., Blood vessels segmentation method for retinal fundus images based on adaptive principal curvature and image derivative operators, Int Arch Photogramm Remote Sens Spatial Inf Sci, 42, pp. 211-218, (2019); Skouta A., Elmoufidi A., Jai-Andaloussi S., Ochetto O., Automated binary classification of diabetic retinopathy by convolutional neural networks, Advances on smart and soft computing, pp. 177-187, (2021); El Hossi A., Skouta A., Elmoufidi A., Nachaoui M., Applied CNN for automatic diabetic retinopathy assessment using fundus images, International conference on business intelligence, pp. 425-433, (2021); Skouta A., Elmoufidi A., Jai-Andaloussi S., Ouchetto O., Hemorrhage semantic segmentation in fundus images for the diagnosis of diabetic retinopathy by using a convolutional neural network, J Big Data, 9, 1, pp. 1-24, (2022); Skouta A., Elmoufidi A., Jai-Andaloussi S., Ouchetto O., Semantic segmentation of retinal blood vessels from fundus images by using CNN and the random forest algorithm, In: SENSORNETS, pp. 163-170, (2022); Sabuncu M.R., Yeo B.T., Van Leemput K., Fischl B., Golland P., A generative model for image segmentation based on label fusion, IEEE Trans Med Imaging, 29, 10, pp. 1714-1729, (2010); Sinthanayothin C., Kongbunkiat V., Phoojaruenchanachai S., Singalavanija A., Automated screening system for diabetic retinopathy, Int Symp Image Signal Process Anal, 2, pp. 915-920, (2003); Lee S.C., Lee E.T., Wang Y., Klein R., Kingsley R.M., Warn A., Computer classification of nonproliferative diabetic retinopathy, Arch Ophthalmol, 123, 6, pp. 759-764, (2005); Larsen N., Godt J., Grunkin M., Lund-Andersen H., Larsen M., Automated detection of diabetic retinopathy in a fundus photographic screening population, Investig Ophthalmol Vis Sci, 44, 2, pp. 767-771, (2003); Agurto C., Murray V., Barriga E., Murillo S., Pattichis M., Davis H., Russell S., Abramoff M., Soliz P., Multiscale AM–FM methods for diabetic retinopathy lesion detection, IEEE Trans Med Imaging, 29, 2, pp. 502-512, (2010); Noronha K., Acharya U.R., Nayak K.P., Kamath S., Bhandary S.V., Decision support system for diabetic retinopathy using discrete wavelet transform, Proc Inst Mech Eng Part H, 227, 3, pp. 251-261, (2013); Jelinek H.J., Cree M.J., Worsley D., Luckie A., Nixon P., An automated microaneurysm detector as a tool for identification of diabetic retinopathy in rural optometric practice, Clin Exp Optom, 89, 5, pp. 299-305, (2006); Spencer T., Olson J.A., McHardy K.C., Sharp P.F., Forrester J.V., An image-processing strategy for the segmentation and quantification of microaneurysms in fluorescein angiograms of the ocular fundus, Comput Biomed Res, 29, 4, pp. 284-302, (1996); Abramoff M.D., Reinhardt J.M., Russell S.R., Folk J.C., Mahajan V.B., Niemeijer M., Quellec G., Automated early detection of diabetic retinopathy, Ophthalmology, 117, 6, pp. 1147-1154, (2010); Dupas B., Walter T., Erginay A., Ordonez R., Deb-Joardar N., Gain P., Klein J.C., Massin P., Evaluation of automated fundus photograph analysis algorithms for detecting microaneurysms, haemorrhages and exudates, and of a computer-assisted diagnostic system for grading diabetic retinopathy, Diabetes Metab, 36, 3, pp. 213-220, (2010); Acharya U.R., Chua C.K., Ng E.Y., Yu W., Chee C., Application of higher order spectra for the identification of diabetes retinopathy stages, J Med Syst, 32, 6, pp. 481-488, (2008); Roychowdhury S., Koozekanani D.D., Parhi K.K., Dream: diabetic retinopathy analysis using machine learning, IEEE J Biomed Health Inf, 18, 5, pp. 1717-1728, (2013); Your Home for Data Science., (2019); Harry P., Frans C., Deborah M.B., Simon P.H., Yalin Z., Convolutional neural networks for diabetic retinopathy, Proced Comput Sci, 90, pp. 200-205, (2016); Saket S.C., Kajol G., Vaishali N., Prakash SP. Automated diabetic retinopathy grading using deep convolutional neural network, 2020. Arxiv Preprint Arxiv, (2004); Lisa T., Jude S., Transfer learning, Handbook of research on machine learning applications and trends: algorithms, methods, and techniques, pp. 242-264, (2010); Zhiguang W., Jianbo Y., Diabetic retinopathy detection via deep convolutional networks for discriminative localization and visual explanation, Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence, (2018); Yang Y., Li T., Li W., Wu H., Fan W., Zhang W., Lesion detection and grading of diabetic retinopathy via two-stages deep convolutional neural networks, International conference on medical image computing and computer-assisted intervention, pp. 533-540, (2017); Schmidt-Erfurth U., Sadeghipour A., Gerendas B.S., Waldstein S.M., Hrvoje B., Artificial intelligence in retina, Prog Retinal Eye Res, 67, pp. 1-29, (2018); Qingyong H., Bo Y., Linhai X., Stefano R., Yulan G., Zhihua W., Niki T., Andrew M., Randla-net: Efficient semantic segmentation of large-scale point clouds, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 11108-11117, (2020); Kassani S.H., Kassani P.H., Khazaeinezhad R., Wesolowski M.J., Schneider K.A., Deters R., Diabetic retinopathy classification using a modified xception architecture, . In: 2019 IEEE International Symposium on Signal Processing and Information Technology, pp. 1-6, (2019); Wejdan L.A., Maysoon F.A., Wafaa M.S., Diabetic retinopathy fundus image classification and lesions localization system using deep learning, Sensors, 21, 11, (2021); Sikder N., Chowdhury M.S., Arif A.S., Nahid A.A., Early Blindness Detection Based on Retinal Images Using Ensemble Learning. In: 2019 22Nd International Conference on Computer and Information Technology, pp. 1-6, (2019); Lucy W., Amelie S., Diagnosing Diabetic Retinopathy from Images of the Eye Fundus; Sikder N., Masud M., Bairagi A.K., Arif A.S., Nahid A.A., Alhumyani H.A., Severity classification of diabetic retinopathy using an ensemble learning algorithm through analyzing retinal images, Symmetry, 13, 4, (2021); Sarah S., Uvais Q., Smartphone-based diabetic retinopathy severity classification using convolution neural networks, Proceedings of SAI intelligent systems conference, pp. 469-481, (2020); Pak A., Ziyaden A., Tukeshev K., Jaxylykova A., Abdullina D., Comparative analysis of deep learning methods of detection of diabetic retinopathy, Cogent Eng, 7, 1, (2020)","A. Elmoufidi; Data4Earth Laboratory, Sultan Moulay Slimane University, Beni Mellal, BP 523, 23000, Morocco; email: a.elmoufidi@usms.ma","","Springer","","","","","","2662995X","","","","English","SN COMPUT. SCI.","Article","Final","","Scopus","2-s2.0-85143389752"
"Rasal T.; Veerakumar T.; Subudhi B.N.; Esakkirajan S.","Rasal, Tushar (57223182545); Veerakumar, T. (24172086600); Subudhi, Badri Narayan (26423349500); Esakkirajan, S. (16051889700)","57223182545; 24172086600; 26423349500; 16051889700","Segmentation and counting of multiple myeloma cells using IEMD based deep neural network","2022","Leukemia Research","122","","106950","","","","2","10.1016/j.leukres.2022.106950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138503251&doi=10.1016%2fj.leukres.2022.106950&partnerID=40&md5=6f178b05928840036344b9bd2bff01ef","Department of Electronics and Communication Engineering, National Institute of Technology, Goa, 403401, India; Department of Electrical Engineering, Indian Institute of Technology Jammu, Jammu, 181121, India; Department of Instrumentation and Control Systems Engineering, PSG College of Technology, Coimbatore, 641004, India","Rasal T., Department of Electronics and Communication Engineering, National Institute of Technology, Goa, 403401, India; Veerakumar T., Department of Electronics and Communication Engineering, National Institute of Technology, Goa, 403401, India; Subudhi B.N., Department of Electrical Engineering, Indian Institute of Technology Jammu, Jammu, 181121, India; Esakkirajan S., Department of Instrumentation and Control Systems Engineering, PSG College of Technology, Coimbatore, 641004, India","In biomedical image analysis, segmentation of cell nuclei from microscopic images is a highly challenging research problem. In the computer-assisted health care system, the segmented microscopic cells have been used by many biological researchers for the early prediction of various diseases. Multiple myeloma is one type of disease which is also term as a plasma cell cancer. The segmentation of the nucleus and cell is a very critical step for multiple myeloma detection. Here, In this work, we have designed two modules. One is for recognizing the nucleus of myeloma cells with a deep IEMD neural network, and the other is for differentiating the cell i.e cytoplasm. The different IMFs provides detailed frequency component of an image which are used for feature extraction. This will significantly improves the performance. We proposed a new counting algorithm for counting the myeloma-affected plasma cells in this paper. An algorithm for counting overgrowth plasma cells within the myeloid tissue has been developed using the Python TensorFlow framework. Experimental outcomes on SegPC datasets substantiate that, the proposed deep learning approach outperforms other competitive methods in myeloma recognition and detection. The result of this research indicates that, the proposed image segmentation mechanism can recognize multiple myeloma with superiority. Early detection of multiple myeloma at the initial stage increases the chances to cure patients. © 2022 Elsevier Ltd","Deep learning; Fluorescence microscopy; Image segmentation; Multiple myeloma","Algorithms; Cell Nucleus; Humans; Image Processing, Computer-Assisted; Multiple Myeloma; Neural Networks, Computer; accuracy; algorithm; Article; cell membrane; cell nucleus; controlled study; convolutional neural network; cytoplasm; deep learning; deep neural network; Fourier analysis; health care system; human; human cell; image analysis; image processing; image quality; image segmentation; learning algorithm; leukocyte; mathematical model; mathematical phenomena; multiple myeloma; myeloma cell; prediction; recall; scoring system; training; validation process; vision; diagnostic imaging; procedures","","","","","","","Furukawa Y., Kikuchi J., Molecular basis of clonal evolution in multiple myeloma, Int. J. Hematol., 111, 4, pp. 496-511, (2020); Roex G., Timmers M., Wouters K., Campillo-Davo D., Flumens D., Schroyens W., Anguille S., Safety and clinical efficacy of BCMA CAR-T-cell therapy in multiple myeloma, J. Hematol. Oncol., 13, 1, pp. 1-14, (2020); Kumar D., Jain N., Khurana A., Mittal S., Satapathy S.C., Senkerik R., Hemanth J.D., Automatic detection of white blood cancer from bone marrow microscopic images using convolutional neural networks, IEEE Access, 8, pp. 142521-142531, (2020); Wei X.Y., Yang Z.Q., Zhang X.L., Liao G., Sheng A.L., Zhou S.K., Wu Y., Du L., Deep collocative learning for immunofixation electrophoresis image analysis, IEEE Trans. Med. Imaging, 40, 7, pp. 1898-1910, (2021); Xia C.Q., Han K., Qi Y., Zhang Y., Yu D.J., A self-training subspace clustering algorithm under low-rank representation for cancer classification on gene expression data, IEEE/ACM Trans. Comput. Biol. Bioinform., 15, 4, pp. 1315-1324, (2017); Oulas A., Reczko M., Poirazi P., MicroRNAs and cancer: the search begins, IEEE Trans. Inf. Technol. Biomed., 13, 1, pp. 67-77, (2009); Gehlot S., Gupta A., Gupta R., A CNN-based unified framework utilizing projection loss in unison with label noise handling for multiple Myeloma cancer diagnosis, Med. Image Anal., 72, (2021); Vyshnav M.T., Sowmya V., Gopalakrishnan E.A., Menon V.K., Deep learning based approach for multiple myeloma detection, (2020); Lopez-Perez R., Garcia-Sanz R., Gonzalez D., Balanzategui A., Chillon M.C., Alaejos I., Mateos M.V., Caballero M.D., Corral M., Orfao A., Gonzalez M., Gene scanning of VDJH-amplified segments is a clinically relevant technique to detect contaminating tumor cells in the apheresis products of multiple myeloma patients undergoing autologous peripheral blood stem cell transplantation, Bone Marrow Transplant., 28, 7, pp. 665-672, (2001); Almeida S.D., Santinha J., Oliveira F.P., Ip J., Lisitskaya M., Lourenco J., Uysal A., Matos C., Joao C., Papanikolaou N., Quantification of tumor burden in multiple myeloma by atlas-based semi-automatic segmentation of WB-DWI, Cancer Imaging, 20, 1, pp. 1-10, (2020); Tehsin S., Zameer S., Saif S., Myeloma cell detection in bonemarrow aspiration using microscopic images, (2019); Cai Z., Vasconcelos N., Cascade R-CNN: high quality object detection and instance segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 43, 5, pp. 1483-1498, (2019); ZirakchianZadeh M., Ayubcha C., Raynor W.Y., Werner T.J., Alavi A., A review of different methods used for quantification and assessment of FDG-PET/CT in multiple myeloma, Nucl. Med. Commun., 43, 4, pp. 378-391, (2022); Kamma S.P., Chilukuri G.S.S., Tholeti G.S.R., Nayak R.K., Maradani T., Multiple myeloma prediction from bone-marrow blood cell images using machine learning, 2021 Emerg. Trends Ind., pp. 1-6, (2021); Ho P.J., Campbell L.J., Gibson J., Brown R., Joshua D., The biology and cytogenetics of multiple myeloma, Rev. Clin. Exp. Hematol., 6, 3, pp. 276-300, (2002); Iqbal A., Ahmed M.F., Suvon M.N.I., Shuvho S.D., Fahmin A., Towards efficient segmentation and classification of white blood cell cancer using deep learning, (2021); Rasal T., Veerakumar T., Subudhi B.N., Esakkirajan S., Mixed Poisson Gaussian noise reduction in fluorescence microscopy images using modified structure of wavelet transform, IET Image Process., 15, 7, pp. 1383-1398, (2021); Rasal T., Veerakumar T., Subudhi B.N., Esakkirajan S., Fluorescence microscopy image noise reduction using IEMD-based adaptive thresholding approach, Signal Image Video Process., pp. 1-9, (2022); He K., Gkioxari G., Dollar P., Girshick R., (2017); Chen K., Pang J., Wang J., Xiong Y., Li X., Sun S., Feng W., Liu Z., Shi J., Ouyang W., Et al., (2019); Vu T., Haeyong K., Yoo C.D., Scnet: training inference sampleconsistency for instance segmentation, (2021); Dates I., (2021); Rasal T., Veerakumar T., Subudhi B.N., Esakkirajan S., A new approach forreduction of the noise from microscopy images using Fourier decomposition, Biocybern. Biomed. Eng., (2022)","T. Rasal; Department of Electronics and Communication Engineering, National Institute of Technology, Goa, 403401, India; email: tusharoptimus@gmail.com","","Elsevier Ltd","","","","","","01452126","","LERED","36152502","English","Leuk. Res.","Article","Final","","Scopus","2-s2.0-85138503251"
"Yuan S.; Chen Y.; Ye C.; Bhatt M.W.; Saradeshmukh M.; Hossain M.S.","Yuan, Shuping (57224940153); Chen, Yang (57846517500); Ye, Chengqiong (57223099696); Bhatt, Mohammed Wasim (57222961220); Saradeshmukh, Mhalasakant (55898294500); Hossain, Md Shamim (57210989648)","57224940153; 57846517500; 57223099696; 57222961220; 55898294500; 57210989648","Cross-modal multi-label image classification modeling and recognition based on nonlinear","2023","Nonlinear Engineering","12","1","20220194","","","","2","10.1515/nleng-2022-0194","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146732047&doi=10.1515%2fnleng-2022-0194&partnerID=40&md5=c7a5b25aa71d42f0773d681a8b420685","The Academy of Big Data and Artificial Intelligence, Anhui Xinhua University, Anhui, Hefei, 230088, China; Department of Computer Science and Engineering, National Institute of Technology, Srinagar, India; Department of Electronics and Telecommunication Engineering, JSPM Narhe Technical Campus, Maharashtra, Pune, India; Department of Marketing, Hajee Mohammad Danesh Science and Technology University, Dinajpur, Bangladesh","Yuan S., The Academy of Big Data and Artificial Intelligence, Anhui Xinhua University, Anhui, Hefei, 230088, China; Chen Y., The Academy of Big Data and Artificial Intelligence, Anhui Xinhua University, Anhui, Hefei, 230088, China; Ye C., The Academy of Big Data and Artificial Intelligence, Anhui Xinhua University, Anhui, Hefei, 230088, China; Bhatt M.W., Department of Computer Science and Engineering, National Institute of Technology, Srinagar, India; Saradeshmukh M., Department of Electronics and Telecommunication Engineering, JSPM Narhe Technical Campus, Maharashtra, Pune, India; Hossain M.S., Department of Marketing, Hajee Mohammad Danesh Science and Technology University, Dinajpur, Bangladesh","Recently, it has become a popular strategy in multi-label image recognition to predict those labels that co-occur in a picture. Previous work has concentrated on capturing label correlation but has neglected to correctly fuse picture features and label embeddings, which has a substantial influence on the model's convergence efficiency and restricts future multi-label image recognition accuracy improvement. In order to better classify labeled training samples of corresponding categories in the field of image classification, a cross-modal multi-label image classification modeling and recognition method based on nonlinear is proposed. Multi-label classification models based on deep convolutional neural networks are constructed respectively. The visual classification model uses natural images and simple biomedical images with single labels to achieve heterogeneous transfer learning and homogeneous transfer learning, capturing the general features of the general field and the proprietary features of the biomedical field, while the text classification model uses the description text of simple biomedical images to achieve homogeneous transfer learning. The experimental results show that the multi-label classification model combining the two modes can obtain a hamming loss similar to the best performance of the evaluation task, and the macro average F1 value increases from 0.20 to 0.488, which is about 52.5% higher. The cross-modal multi-label image classification algorithm can better alleviate the problem of overfitting in most classes and has better cross-modal retrieval performance. In addition, the effectiveness and rationality of the two cross-modal mapping techniques are verified.  © 2023 the author(s), published by De Gruyter.","cross-mode retrieval; deep learning; multiple label points","Classification (of information); Convolutional neural networks; Deep neural networks; Image enhancement; Image recognition; Text processing; Transfer learning; Classification models; Cross-modal; Cross-mode retrieval; Deep learning; Images classification; Label images; Label points; Multi-labels; Multiple label point; Multiple labels; Image classification","","","","","","","Xiao X., Yang J., Ning X., Research on multimodal emotion analysis algorithm based on deep learning, J Phys Conf ser, 1802, 3, (2021); Chen Z., Cong B., Hua Z., Cengiz K., Shabaz M., Application of clustering algorithm in complex landscape farmland synthetic aperture radar image segmentation, J Intell Syst, 30, 1, pp. 1014-1025, (2021); Chaudhury S., Shelke N., Sau K., Prasanalakshmi B., Shabaz M., A novel approach to classifying breast cancer histopathology biopsy images using bilateral knowledge distillation and label smoothing regularization, Comput Math Methods Med, 2021, (2021); Wang D., Mao K., Task-generic semantic convolutional neural network for web text-aided image classification, Neurocomputing, 329, pp. 103-115, (2019); Liu Y., Xie Y., Yang J., Zuo X., Zhou B., Target classification and recognition for high-resolution remote sensing images: Using the parallel cross-modal neural cognitive computing algorithm, IEEE Geosci Remote Sens Mag, 8, 3, pp. 50-62, (2020); Jagota V., Luthra M., Bhola J., Sharma A., Shabaz M., A secure energy-aware game theory (SEGaT) mechanism for coordination in WSANs, Int J Swarm Intell Res, 13, 2, pp. 1-16, (2022); Tang S., Shabaz M., A new face image recognition algorithm based on cerebellum-basal ganglia mechanism, J Healthc Eng, 2021, (2021); Wang Y., Xie Y., Liu Y., Zhou K., Li X., Fast graph convolution network based multi-label image recognition via cross-modal fusion, Proceedings of the 29th ACM International Conference on Information & Knowledge Management, pp. 1575-1584, (2020); Duan Y., Chen N., Zhang P., Kumar N., Chang L., Wen W., MS2GAH: Multi-label semantic supervised graph attention hashing for robust cross-modal retrieval, Pattern Recognit, 128, (2022); Sharma A., Ansari M.D., Kumar R., A comparative study of edge detectors in digital image processing, 2017 4th International Conference on Signal Processing, Computing and Control (ISPCC), pp. 246-250, (2018); Bhola J., Soni S., Harvey D., Kar H., Verma S., Bhadauria V., Advances in VLSI, Communication, and Signal Processing. Lecture Notes in Electrical Engineering, 683, (2021); Gu J., Liu B., Li X., Wang P., Wang B., Cross-modal representations in early visual and auditory cortices revealed by multi-voxel pattern analysis, Brain Imaging Behav, 14, 5, pp. 1908-1920, (2020); Liu L., Zhang H., Zhou D., Clothing generation by multi-modal embedding: A compatibility matrix-regularized gan model, Image Vis Comput, 107, 8, (2021); Wang L., Sharma A., Analysis of sports video using image recognition of sportsmen, Int J Syst Assur Eng Manag, 13, pp. 1-7, (2022); Zhang S., Srividya K., Kakaravada I., Karras D.A., Jagota V., Hasan I., A Global Optimization Algorithm for Intelligent Electromechanical Control System with Improved Filling Function, Sci Program, 2022, (2022); Bhola J., Soni S., Cheema G.K., Recent trends for security applications in wireless sensor networks - A technical review, 2019 6th International Conference on Computing for Sustainable Global Development (INDIACom), pp. 707-712, (2020); Chen J., Chen L., Shabaz M., Singh D., Image Fusion Algorithm at Pixel Level Based on Edge Detection, J Healthc Eng, 2021, pp. 1-10, (2021); Zhang X., Li S., Jing X.Y., Ma F., Zhu C., Unsupervised domain adaption for image-to-video person re-identification, Multimed Tools Appl, 79, 45, pp. 33793-33810, (2020); Huddar M.G., Sannakki S.S., Rajpurohit V.S., Multi-level context extraction and attention-based contextual inter-modal fusion for multimodal sentiment analysis and emotion classification, Int J Multimed Inf Retr, 9, 2, pp. 103-112, (2020); Xu X., Li L., Sharma A., Controlling messy errors in virtual reconstruction of random sports image capture points for complex systems, Int J Syst Assur Eng Manag, pp. 1-8, (2021); Gala R., Budzillo A., Baftizadeh F., Miller J., Sumbul U., Consistent cross-modal identification of cortical neurons with coupled autoencoders, Nat Comput Sci, 1, 2, pp. 120-127, (2021); Li D., Wei X., Hong X., Gong Y., Infrared-visible cross-modal person re-identification with an X modality, Proceedings of the AAAI Conference on Artifficial Intelligence, pp. 4610-4617, (2020); Chuanxu C., Sharma A., Improved CNN license plate image recognition based on shark odor optimization algorithm, Int J Syst Assur Eng Manag, pp. 1-8, (2021); Classen D., Siedt M., Nguyen K.T., Ackermann J., Schaeffer A., Formation, classification and identification of non-extractable residues of <sup>14</sup>C-labelled ionic compounds in soil, Chemosphere, 232, pp. 164-170, (2019)","M.W. Bhatt; Department of Computer Science and Engineering, National Institute of Technology, Srinagar, India; email: wasimmohammad71@gmail.com","","De Gruyter Open Ltd","","","","","","21928010","","","","English","Nonlenier Eng.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85146732047"
"Jose A.; Roy R.; Stegmaier J.","Jose, Abin (57221473187); Roy, Rĳo (58080719100); Stegmaier, Johannes (55584699900)","57221473187; 58080719100; 55584699900","Weakly-supervised Temporal Segmentation of Cell-cycle Stages with Center-cell Focus using Recurrent Neural Networks","2023","Informatik aktuell","","","","212","219","7","0","10.1007/978-3-658-41657-7_47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164964949&doi=10.1007%2f978-3-658-41657-7_47&partnerID=40&md5=9f3ab6bb9ca126f7607ba63067803d77","Institute of Imaging and Computer Vision, RWTH Aachen University, Germany","Jose A., Institute of Imaging and Computer Vision, RWTH Aachen University, Germany; Roy R., Institute of Imaging and Computer Vision, RWTH Aachen University, Germany; Stegmaier J., Institute of Imaging and Computer Vision, RWTH Aachen University, Germany","Training deep-learning models for biomedical images has always been a problem due to the lack of annotated data. Here we propose using a model and a training approach for the weakly-supervised temporal classification of cell-cycle stages during mitosis. Instead of using annotated data, by using an ordered set of classes called transcript, our proposed approach classifies the cell-cycle stages of cell video sequences. The network design helps to propagate information in time using Recurrent Neural Network and helps to focus the features on the center-cell. The algorithm is evaluated on four datasets from Moreno-Andrés et al. [1] and has a performance close to the supervised approaches, which is impressive, considering that annotated data is not used in training. © 2023 Der/die Autor(en), exklusiv lizenziert an Springer Fachmedien Wiesbaden GmbH, ein Teil von Springer Nature.","","Cells; Cytology; Biomedical images; Cell cycle; Learning models; Network design; Ordered set; Performance; Temporal classification; Temporal segmentations; Video sequences; Recurrent neural networks","","","","","","","Moreno-Andres D., Bhattacharyya A., Scheufen A., Stegmaier J., LiveCellMiner: A new tool to analyze mitotic progression, Plos One, 17, 7, (2022); Araujo A.R., Gelens L., Sheriff R.S., Santos S.D., Positive feedback keeps duration of mitosis temporally insulated from upstream cell-cycle events, Mol Cell, 64, 2, pp. 362-375, (2016); Zhong Q., Busetto A.G., Fededa J.P., Buhmann J.M., Gerlich D.W., Unsupervised modeling of cell morphology dynamics for time-lapse microscopy, Nat Methods, 9, 7, pp. 711-713, (2012); Ferro A., Mestre T., Carneiro P., Sahumbaiev I., Seruca R., Sanches J.M., Blue intensity matters for cell cycle profiling in fluorescence DAPI-stained images, Laboratory Investigation, 97, 5, pp. 615-625, (2017); Jose A., Ottlik E.S., Rohlfing C., Ohm J.R., Optimized feature space learning for generating efficient binary codes for image retrieval, Signal Processing: Image Communication, 100, (2022); Jose A., Filbert D., Rohlfing C., Ohm J.R., Deep hashing with hash center update for efficient image retrieval, ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4773-4777, (2022); Jose A., Lopez R.D., Heisterklaus I., Wien M. Pyramid pooling of convolutional feature maps for image retrieval, 2018 25Th IEEE International Conference on Image Processing (ICIP), pp. 480-484, (2018); Jose A., Yan S., Heisterklaus I., Binary hashing using siamese neural networks, 2017 IEEE International Conference on Image Processing (ICIP), pp. 2916-2920, (2017); Allehaibi K.H.S., Nugroho L.E., Lazuardi L., Prabuwono A.S., Mantoro T., Et al., Segmentation and classification of cervical cells using deep learning, IEEE Access, 7, pp. 116925-116941, (2019); Narotamo H., Fernandes M.S., Moreira A.M., Melo S., Seruca R., Silveira M., Et al., A machine learning approach for single cell interphase cell cycle staging, Sci Rep, 11, 1, pp. 1-13, (2021); Jin X., Zou Y., Huang Z., An imbalanced image classification method for the cell cycle phase, Information, 12, 6, (2021); Saha M., Chakraborty C., Racoceanu D., Efficient deep learning model for mitosis detection using breast histopathology images, Computerized Medical Imaging and Graphics, 64, pp. 29-40, (2018); Albayrak A., Bilgin G., Mitosis detection using convolutional neural network based features, 2016 IEEE 17Th International Symposium on Computational Intelligence and Informatics (CINTI), pp. 335-340, (2016); Jose A., Roy R., Eschweiler D., Laube I., Azad R., Moreno-Andres D., Et al., End-To-End Classification of Cell-Cycle Stages with Center-Cell Focus Tracker Using Recurrent Neural Networks, (2022); Richard A., Kuehne H., Iqbal A., Gall J., Et al., Neuralnetwork-viterbi: a framework for weakly supervised video learning, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7386-7395, (2018); Ho Y., Wookey S., Et al., The real-world-weight cross-entropy loss function: modeling the costs of mislabeling, IEEE Access, pp. 4806-4813, (2019)","A. Jose; Institute of Imaging and Computer Vision, RWTH Aachen University, Germany; email: abin.jose@lfb.rwth-aachen.de","Deserno T.M.; Handels H.; Maier A.; Maier-Hein K.; Palm C.; Tolxdorff T.","Springer Science and Business Media Deutschland GmbH","","Bildverarbeitung für die Medizin Workshop, BVM 2023","2 July 2023 through 4 July 2023","Braunschweig","297059","1431472X","978-365841656-0","","","English","Inf. aktuell","Conference paper","Final","","Scopus","2-s2.0-85164964949"
"Asif S.; Zheng X.; Zhu Y.","Asif, Sohaib (57221248320); Zheng, Xiaolong (57957660700); Zhu, Yusen (56172378600)","57221248320; 57957660700; 56172378600","An optimized fusion of deep learning models for kidney stone detection from CT images","2024","Journal of King Saud University - Computer and Information Sciences","36","7","102130","","","","0","10.1016/j.jksuci.2024.102130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198985257&doi=10.1016%2fj.jksuci.2024.102130&partnerID=40&md5=1f81bfe7987e3d620998e6bff837a323","School of Computer Science and Engineering, Central South University, Changsha, China; Xi'an Research Institute of High Tech, Xi'an, China; School of Mathematics, Hunan University, Changsha, China","Asif S., School of Computer Science and Engineering, Central South University, Changsha, China; Zheng X., Xi'an Research Institute of High Tech, Xi'an, China; Zhu Y., School of Mathematics, Hunan University, Changsha, China","Accurate diagnosis of kidney disease is crucial, as it is a significant health concern that demands precise identification for effective and appropriate treatment. Deep learning methods are increasingly recognized as valuable tools for disease diagnosis in the biomedical field. However, current models utilizing deep networks often encounter challenges of overfitting and low accuracy, necessitating further refinement for optimal performance. To overcome these challenges, this paper proposes the introduction of two ensemble models designed for kidney stone detection in CT images. The first model, called StackedEnsembleNet, is a two-level deep stack ensemble model that effectively integrates the predictions from four base models: InceptionV3, InceptionResNetV2, MobileNet, and Xception. By leveraging the collective knowledge of these models, StackedEnsembleNet improves the accuracy and reliability of kidney stone detection. The second model PSOWeightedAvgNet, leverages the Particle Swarm Optimization (PSO) algorithm to determine the optimal weights for the weighted average ensemble. Through PSO, this ensemble approach assigns optimized weights to each model during the ensembling process, effectively enhancing the performance by optimizing the combination of their predictions. Experimental results conducted on a large dataset of 1799 CT images demonstrate that both StackedEnsembleNet and PSOWeightedAvgNet outperform the individual base models, achieving high accuracy rates in kidney stone detection. Furthermore, additional experiments on an unseen dataset validate the models’ ability to generalize. The comparison with previous methods confirms the superior performance of the proposed ensemble models. The paper also presents Grad-CAM visualizations and error case analysis to provide insights into the decision-making processes of the models. By overcoming the limitations of existing deep learning models, StackedEnsembleNet and PSOWeightedAvgNet offer a promising approach for accurate kidney stone detection, contributing to improved diagnosis and treatment outcomes in the field of nephrology. © 2024 The Author(s)","Biomedical image classification; Deep neural networks; Kidney stone detection; Particle swarm optimization; Stack ensemble","","","","","","","","Ahsan M.M., Uddin M.R., Ali M.S., Islam M.K., Farjana M., Sakib A.N., Al Momin K., Luna S.A., Deep transfer learning approaches for Monkeypox disease diagnosis, Expert Syst. Appl., (2023); Alelign T., Petros B., Kidney stone disease: an update on current concepts, Advances in Urology, 2018, (2018); Alzu'bi D., Abdullah M., Hmeidi I., AlAzab R., Gharaibeh M., El-Heis M., Almotairi K.H., Forestiero A., Hussein A.M., Abualigah L., Kidney tumor detection and classification based on deep learning approaches: A new dataset in CT scans, Journal of Healthcare Engineering, 2022, (2022); Asif S., Wenhui Y., Jinhai S., Ain Q.U., Yueyang Y., Jin H., Modeling a fine-tuned deep convolutional neural network for diagnosis of kidney diseases from CT images, 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pp. 2571-2576, (2022); Asif S., Zhao M., Tang F., Zhu Y., Zhao B., Metaheuristics optimization-based ensemble of deep neural networks for Mpox disease detection, Neural Netw., (2023); Asif S., Zhao M., Chen X., Zhu Y., StoneNet: An efficient lightweight model based on depthwise separable convolutions for kidney stone detection from CT images, Interdiscip Sci., (2023); Asif S., Awais M., Khan S.U.R., IR-CNN: Inception residual network for detecting kidney abnormalities from CT images, Network Modeling Analysis in Health Informatics and Bioinformatics, 12, (2023); Baygin M., Yaman O., Barua P.D., Dogan S., Tuncer T., Acharya U.R., Exemplar Darknet19 feature generation technique for automated kidney stone detection with coronal CT images, Artif. Intell. Med., 127, (2022); Blau N., Klang E., Kiryati N., Amitai M., Portnoy O., Mayer A., Fully automatic detection of renal cysts in abdominal CT scans, Int. J. Comput. Assist. Radiol. Surg., 13, pp. 957-966, (2018); Brisbane W., Bailey M.R., Sorensen M.D., An overview of kidney stone imaging techniques, Nat. Rev. Urol., 13, pp. 654-662, (2016); Chollet F., Xception: Deep learning with depthwise separable convolutions, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1251-1258, (2017); De Perrot T., Hofmeister J., Burgermeister S., Martin S.P., Feutry G., Klein J., Montet X., Differentiating kidney stones from phleboliths in unenhanced low-dose computed tomography using radiomics and machine learning, Eur. Radiol., 29, pp. 4776-4782, (2019); Edvardsson V.O., Indridason O.S., Haraldsson G., Kjartansson O., Palsson R., Temporal trends in the incidence of kidney stone disease, Kidney Int., 83, pp. 146-152, (2013); Gunasekara T., De Silva P.M.C., Ekanayake E., Thakshila W., Pinipa R., Sandamini P., Gunarathna S., Chandana E., Jayasinghe S., Herath C., Urinary biomarkers indicate pediatric renal injury among rural farming communities in Sri Lanka, Sci. Rep., 12, (2022); Howard A.G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., (2017); Islam M.N., Hasan M., Hossain M., Alam M., Rabiul G., Uddin M.Z., Soylu A., Vision transformer and explainable transfer learning models for auto detection of kidney cyst, stone and tumor from CT-radiography, Sci. Rep., 12, pp. 1-14, (2022); Jakubovitz D., Giryes R., Rodrigues M.R., Generalization error in deep learning, Compressed Sensing and its Applications: Third International MATHEON Conference, pp. 153-193, (2017); Jendeberg J., Thunberg P., Liden M., Differentiation of distal ureteral stones and pelvic phleboliths using a convolutional neural network, Urolithiasis, 49, pp. 41-49, (2021); Kennedy J., Eberhart R., Particle swarm optimization, Proceedings of ICNN'95-international conference on neural networks, pp. 1942-1948, (1995); Ma F., Sun T., Liu L., Jing H., Detection and diagnosis of chronic kidney disease using deep learning-based heterogeneous modified artificial neural network, Futur. Gener. Comput. Syst., 111, pp. 17-26, (2020); Nabavi-Kerizi S., Abadi M., Kabir E., A PSO-based weighting method for linear combination of neural networks, Comput. Electr. Eng., 36, pp. 886-894, (2010); Naser M., Alavi A.H., Error metrics and performance fitness indicators for artificial intelligence and machine learning in engineering and sciences, Architecture, Structures and Construction, pp. 1-19, (2021); Parakh A., Lee H., Lee J.H., Eisner B.H., Sahani D.V., Do S., Urinary stone detection on CT images using deep convolutional neural networks: evaluation of model performance and generalization, Radiology. Artificial Intelligence, 1, (2019); Polat H., Danaei Mehr H., Cetin A., Diagnosis of chronic kidney disease based on support vector machine by feature selection methods, J. Med. Syst., 41, pp. 1-11, (2017); Polikar R., Ensemble learning, Ensemble machine learning: Methods and applications, pp. 1-34, (2012); Rajinikanth V., Vincent P.D.R., Srinivasan K., Prabhu G.A., Chang C.-Y., A framework to distinguish healthy/cancer renal CT images using the fused deep features, Front. Public Health, 11, (2023); Shen D., Wu G., Suk H.-I., Deep learning in medical image analysis, Annu. Rev. Biomed. Eng., 19, pp. 221-248, (2017); Shlipak M.G., Fried L.F., Cushman M., Manolio T.A., Peterson D., Stehman-Breen C., Bleyer A., Newman A., Siscovick D., Psaty B., Cardiovascular mortality risk in chronic kidney disease: comparison of traditional and novel risk factors, JAMA, 293, pp. 1737-1745, (2005); Sorokin I., Mamoulakis C., Miyazawa K., Rodgers A., Talati J., Lotan Y., Epidemiology of stone disease across the world, World J. Urol., 35, pp. 1301-1320, (2017); Sudharson S., Kokil P., An ensemble of deep neural networks for kidney ultrasound image classification, Comput. Methods Programs Biomed., 197, (2020); Sung H., Ferlay J., Siegel R.L., Laversanne M., Soerjomataram I., Jemal A., Bray F., Global cancer statistics 2020: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries, CA Cancer J. Clin., 71, pp. 209-249, (2021); Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., Rethinking the inception architecture for computer vision, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2818-2826, (2016); Szegedy C., Ioffe S., Vanhoucke V., Alemi A.A., Inception-v4, inception-resnet and the impact of residual connections on learning, Thirty-first AAAI conference on artificial intelligence, (2017); Vupputuri S., Soucie J.M., McClellan W., Sandler D.P., History of kidney stones as a possible risk factor for chronic kidney disease, Ann. Epidemiol., 14, pp. 222-228, (2004); Wu Y., Yi Z., Automated detection of kidney abnormalities using multi-feature fusion convolutional neural networks, Knowl.-Based Syst., 200, (2020); Yang Y., Lv H., Chen N., A survey on ensemble learning under the era of deep learning, Artif. Intell. Rev., pp. 1-45, (2022); Yildirim K., Bozdag P.G., Talo M., Yildirim O., Karabatak M., Acharya U.R., Deep learning model for automated kidney stone detection using coronal CT images, Comput. Biol. Med., 135, (2021); Zhang Y., Zhang H., Cai J., Yang B., A weighted voting classifier based on differential evolution, Abstract and applied analysis, Hindawi, (2014)","S. Asif; School of Computer Science and Engineering, Central South University, Changsha, China; email: punjabians1592@gmail.com; X. Zheng; Xi'an Research Institute of High Tech, Xi'an, China; email: Xiaolong.zheng.7712@outlook.com","","King Saud bin Abdulaziz University","","","","","","13191578","","","","English"," J. King Saud Univ. - Comput. Inform. Sci.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85198985257"
"Contino S.; Cruciata L.; Gambino O.; Pirrone R.","Contino, Salvatore (57211202805); Cruciata, Luca (58752332700); Gambino, Orazio (14015507500); Pirrone, Roberto (6603614874)","57211202805; 58752332700; 14015507500; 6603614874","IODeep: An IOD for the introduction of deep learning in the DICOM standard","2024","Computer Methods and Programs in Biomedicine","248","","108113","","","","0","10.1016/j.cmpb.2024.108113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187197133&doi=10.1016%2fj.cmpb.2024.108113&partnerID=40&md5=a3495bbfa202199428925edb28fe80a8","Department of Engineering, University of Palermo, Sicily, Palermo, 90128, Italy","Contino S., Department of Engineering, University of Palermo, Sicily, Palermo, 90128, Italy; Cruciata L., Department of Engineering, University of Palermo, Sicily, Palermo, 90128, Italy; Gambino O., Department of Engineering, University of Palermo, Sicily, Palermo, 90128, Italy; Pirrone R., Department of Engineering, University of Palermo, Sicily, Palermo, 90128, Italy","Background and objective: In recent years, Artificial Intelligence (AI) and in particular Deep Neural Networks (DNN) became a relevant research topic in biomedical image segmentation due to the availability of more and more data sets along with the establishment of well known competitions. Despite the popularity of DNN based segmentation on the research side, these techniques are almost unused in the daily clinical practice even if they could support effectively the physician during the diagnostic process. Apart from the issues related to the explainability of the predictions of a neural model, such systems are not integrated in the diagnostic workflow, and a standardization of their use is needed to achieve this goal. Methods: This paper presents IODeep a new DICOM Information Object Definition (IOD) aimed at storing both the weights and the architecture of a DNN already trained on a particular image dataset that is labeled as regards the acquisition modality, the anatomical region, and the disease under investigation. Results: The IOD architecture is presented along with a DNN selection algorithm from the PACS server based on the labels outlined above, and a simple PACS viewer purposely designed for demonstrating the effectiveness of the DICOM integration, while no modifications are required on the PACS server side. Also a service based architecture in support of the entire workflow has been implemented. Conclusion: IODeep ensures full integration of a trained AI model in a DICOM infrastructure, and it is also enables a scenario where a trained model can be either fine-tuned with hospital data or trained in a federated learning scheme shared by different hospitals. In this way AI models can be tailored to the real data produced by a Radiology ward thus improving the physician decision making process. Source code is freely available at https://github.com/CHILab1/IODeep.git. © 2024 The Author(s)","Artificial Intelligence; Decision making in medical diagnosis; Deep Neural Networks; DICOM; Information Object Definition; Medical image segmentation","Artificial Intelligence; Computers; Deep Learning; Radiology Information Systems; Software; Clinical research; Computer aided diagnosis; Deep neural networks; Hospitals; Image segmentation; Learning systems; Medical imaging; Network architecture; Biomedical image segmentation; Decision making in medical diagnose; Decisions makings; DICOM; Information object; Information object definition; Intelligence models; Medical image segmentation; Research topics; Work-flows; algorithm; article; artificial intelligence; clinical practice; decision making; deep learning; deep neural network; diagnosis; digital imaging and communications in medicine; human; image segmentation; infrastructure; learning; physician; prediction; standardization; ward; workflow; artificial intelligence; software; Decision making","","","","","Sicilian MicronanoTech Research And Innovation Center, (B73C22000810001, DM 1061/2021, ECS_00000022)","This work has been partially supported by project:, 1.“SAMOTHRACE” (Sicilian MicronanoTech Research And Innovation Center), cup project B73C22000810001, project code ECS_00000022. 2. PON “Ricerca e Innovazione” 2014-2020, Asse IV “Istruzione e ricerca per il recupero” con riferimento all'Azione IV.4 “Dottorati e contratti di ricerca su tematiche dell'innovazione” e all'Azione IV.5 “Dottorati su tematiche green”, DM 1061/2021.","Waite S., Kolla S., Jeudy J., Legasto A., Macknik S.L., Martinez-Conde S., Krupinski E.A., Reede D.L., Tired in the reading room: the influence of fatigue in radiology, J. Am. Coll. Radiol., 14, 2, pp. 191-197, (2017); Savage N., How AI is improving cancer diagnostics, Nature, 579, 7800, pp. S14-S16, (2020); Rundo L., Pirrone R., Vitabile S., Sala E., Gambino O., Recent advances of HCI in decision-making tasks for optimized clinical workflows and precision medicine, J. Biomed. Inform., 108, (2020); Ukharov A., Shlivko I., Klemenova I., Garanina O., Uskova K., Mironycheva A., Stepanova Y., Skin cancer risk self-assessment using AI as a mass screening tool, Inform. Med. Unlocked, 38, (2023); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., U-Net++: a nested U-Net architecture for medical image segmentation, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 839-848, (2018); Schlemper J., Oktay O., Schaap M., Heinrich M., Kainz B., Glocker B., Attention U-Net: learning where to look for the pancreas, Med. Image Anal., 52, pp. 201-211, (2019); Fu J., Liu J., Tian H., Li Y., Bao Y., Fang Z., Dual attention network for scene segmentation, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3146-3154, (2019); Dou Q., Chen H., Yu L., Qin J., Heng P.-A., 3D anisotropic hybrid network: translating convolutional neural networks for 3D medical image segmentation, IEEE Trans. Med. Imaging, 39, 5, pp. 1462-1473, (2020); Milletari F., Navab N., Ahmadi S.-A., V-Net family: convolutional networks for volumetric medical image segmentation, IEEE Trans. Med. Imaging, 40, 5, pp. 1256-1268, (2021); Christ P.F., Ettlinger F., Grun F., Elshaera M.E.A., Lipkova J., Schlecht S., Ahmaddy F., Tatavarty S., Bickel M., Bilic P., Rempfler M., Hofmann F., Anastasi M.D., Ahmadi S.-A., Kaissis G., Holch J., Sommer W., Braren R., Heinemann V., Menze B., Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks, (2017); Akkus Z., Galimzianova A., Hoogi A., Rubin D.L., Erickson B.J., Deep learning for brain MRI segmentation: state of the art and future directions, J. Digit. Imag., 30, 4, pp. 449-459, (2017); Qu Y., Li X., Yan Z., Zhao L., Zhang L., Liu C., Xie S., Li K., Metaxas D., Wu W., Hao Y., Dai K., Zhang S., Tao X., Ai S., Surgical planning of pelvic tumor using multi-view CNN with relation-context representation learning, Med. Image Anal., 69, (2021); Wang Y., Zhou Y., Shen W., Park S., Fishman E.K., Yuille A.L., Abdominal multi-organ segmentation with organ-attention networks and statistical fusion, Med. Image Anal., 55, pp. 88-102, (2019); Yan Y., Zhang D., Multi-scale U-like network with attention mechanism for automatic pancreas segmentation, PLoS ONE, 16, 5, (2021); Roth H.R., Lu L., Farag A., Shin H.-C., Liu J., Turkbey E.B., Summers R.M., Deeporgan: multi-level deep convolutional networks for automated pancreas segmentation, Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part I 18, pp. 556-564, (2015); Zhou Q., Huang Z., Ding M., Zhang X., Medical image classification using light-weight CNN with spiking cortical model based attention module, IEEE J. Biomed. Health Inform., 27, 4, pp. 1991-2002, (2023); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, (2017); Dosovitskiy A., Beyer L., Kolesnikov A., Weissenborn D., Zhai X., Unterthiner T., Dehghani M., Minderer M., Heigold G., Gelly S., Uszkoreit J., Houlsby N., An image is worth 16x16 words: transformers for image recognition at scale, (2021); Punn N.S., Agarwal S., Modality specific U-Net variants for biomedical image segmentation: a survey, Artif. Intell. Rev., 55, 7, pp. 5845-5889, (2022); Zhang J., Zhang Y., Jin Y., Xu J., Xu X., MDU-Net: multi-scale densely connected U-Net for biomedical image segmentation, Health Inf. Sci. Syst., 11, 1, (2023); Song H., Wang Y., Zeng S., Guo X., Li Z., OAU-Net: outlined attention U-net for biomedical image segmentation, Biomed. Signal Process. Control, 79, (2023); Zhang D., Han J., Cheng G., Yang M., Weakly supervised object localization and detection: a survey, (2021); Shen W., Peng Z., Wang X., Wang H., Cen J., Jiang D., Xie L., Yang X., Tian Q., A survey on label-efficient deep image segmentation: bridging the gap between weak supervision and dense prediction, (2023); Zhou B., Khosla A., Lapedriza A., Oliva A., Torralba A., Learning deep features for discriminative localization, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2921-2929, (2016); Lin J., Han G., Xu X., Liang C., Wong T.-T., Chen C.L.P., Liu Z., Han C., BroadCAM: outcome-agnostic class activation mapping for small-scale weakly supervised applications, (2023); Jorritsma W., Cnossen F., van Ooijen P., Adaptive support for user interface customization: a study in radiology, Int. J. Hum.-Comput. Stud., 77, pp. 1-9, (2015); Fedorov A., Longabaugh W.J., Pot D., Clunie D.A., Pieper S.D., Gibbs D.L., Bridge C., Herrmann M.D., Homeyer A., Lewis R., Et al., National cancer institute imaging data commons: toward transparency, reproducibility, and scalability in imaging artificial intelligence, Radiographics, 43, 12, (2023); Darzidehkalani E., Ghasemi-Rad M., van Ooijen P., Federated learning in medical imaging: part I: toward multicentral health care ecosystems, J. Am. Coll. Radiol., 19, 8, pp. 969-974, (2022); Guan H., Yap P.-T., Bozoki A., Liu M., Federated learning for medical image analysis: a survey, (2023); Van der Velden B.H., Kuijf H.J., Gilhuijs K.G., Viergever M.A., Explainable artificial intelligence (XAI) in deep learning-based medical image analysis, Med. Image Anal., 79, (2022); Jesus R., Bastiao Silva L., Sousa V., Carvalho L., Garcia Gonzalez D., Carias J., Costa C., Personalizable AI platform for universal access to research and diagnosis in digital pathology, Comput. Methods Programs Biomed., 242, (2023); Lajara N., Espinosa-Aranda J.L., Deniz O., Bueno G., Optimum web viewer application for DICOM whole slide image visualization in anatomical pathology, Comput. Methods Programs Biomed., 179, (2019); Herrmann M.D., Clunie D.A., Fedorov A., Doyle S.W., Pieper S., Klepeis V., Le L.P., Mutter G.L., Milstone D.S., Schultz T.J., Kikinis R., Kotecha G.K., Hwang D.H., Andriole K.P., lafrate A.J., Brink J.A., Boland G.W., Dreyer K.J., Michalski M., Golden J.A., Louis D.N., Lennerz J.K., Implementing the DICOM standard for digital pathology, J. Pathol. Inform., 9, 1, (2018); Jansen C., Lindequist B., Strohmenger K., Romberg D., Kuster T., Weiss N., Franz M., Schwen L.O., Evans T., Homeyer A., Zerbe N., The vendor-agnostic EMPAIA platform for integrating AI applications into digital pathology infrastructures, Future Gener. Comput. Syst., 140, 100, pp. 209-224, (2023); Dikici E., Bigelow M., Prevedello L.M., White R.D., Erdal B.S., Integrating AI into radiology workflow: levels of research, production, and feedback maturity, J. Med. Imag., 7, 1, (2020); Kathiravelu P., Sharma P., Sharma A., Banerjee I., Trivedi H., Purkayastha S., Sinha P., Cadrin-Chenevert A., Safdar N., Gichoya J.W., A DICOM framework for machine learning and processing pipelines against real-time radiology images, J. Digit. Imag., 34, 4, pp. 1005-1013, (2021); Osorno-Castillo K., Fonnegra R.D., Diaz G.M., Integration of machine learning models in PACS systems to support diagnostic in radiology services, Applied Computer Sciences in Engineering, pp. 233-244, (2020); Pham H.H., Do D.V., Nguyen H.Q., DICOM imaging router: an open deep learning framework for classification of body parts from DICOM X-ray scans, (2021); Recht M.P., Dewey M., Dreyer K., Langlotz C., Niessen W., Prainsack B., Smith J.J., Integrating artificial intelligence into the clinical practice of radiology: challenges and recommendations, Eur. Radiol., 30, 6, pp. 3576-3584, (2020); Rufenacht E., Kamath A., Suter Y., Poel R., Ermis E., Scheib S., Reyes M., PyRaDiSe: a Python package for DICOM-RT-based auto-segmentation pipeline construction and DICOM-RT data conversion, Comput. Methods Programs Biomed., 231, (2023); Clunie D.A., DICOM Structured Reporting, (2000); Gambino O., Rundo L., Cannella V., Pirrone R., Vitabile S., A framework for data-driven adaptive GUI generation based on DICOM, J. Biomed. Inform., 88, pp. 37-52, (2018); Ronneberger O., Fischer P., Brox T., U-Net: convolutional networks for biomedical image segmentation, Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015, Lecture Notes in Computer Science, pp. 234-241, (2015)","O. Gambino; Department of Engineering, University of Palermo, Palermo, Sicily, 90128, Italy; email: orazio.gambino@unipa.it","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","38479148","English","Comput. Methods Programs Biomed.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85187197133"
"Myriam H.; Abdelhamid A.A.; El-Kenawy E.-S.M.; Ibrahim A.; Eid M.M.; Jamjoom M.M.; Khafaga D.S.","Myriam, Hadjouni (23396729500); Abdelhamid, Abdelaziz A. (55328560100); El-Kenawy, El-Sayed M. (57191347112); Ibrahim, Abdelhameed (34876676400); Eid, Marwa Metwally (35795379100); Jamjoom, Mona M. (57142648900); Khafaga, Doaa Sami (58088844800)","23396729500; 55328560100; 57191347112; 34876676400; 35795379100; 57142648900; 58088844800","Advanced Meta-Heuristic Algorithm Based on Particle Swarm and Al-Biruni Earth Radius Optimization Methods for Oral Cancer Detection","2023","IEEE Access","11","","","23681","23700","19","14","10.1109/ACCESS.2023.3253430","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149834542&doi=10.1109%2fACCESS.2023.3253430&partnerID=40&md5=4ff93881a313e0eba3ffe3a4d5ca444c","Princess Nourah Bint Abdulrahman University, College of Computer and Information Science, Department of Computer Sciences, Riyadh, 11671, Saudi Arabia; Shaqra University, College of Computing and Information Technology, Department of Computer Science, Shaqra, 11961, Saudi Arabia; Ain Shams University, Faculty of Computer and Information Sciences, Department of Computer Science, Cairo, 11566, Egypt; Delta Higher Institute for Engineering and Technology (DHIET), Department of Communications and Electronics, Mansoura, 35111, Egypt; Mansoura University, Faculty of Engineering, Computer Engineering and Control Systems Department, Mansoura, 35516, Egypt; Delta University for Science and Technology, Faculty of Artificial Intelligence, Mansoura, 35712, Egypt","Myriam H., Princess Nourah Bint Abdulrahman University, College of Computer and Information Science, Department of Computer Sciences, Riyadh, 11671, Saudi Arabia; Abdelhamid A.A., Shaqra University, College of Computing and Information Technology, Department of Computer Science, Shaqra, 11961, Saudi Arabia, Ain Shams University, Faculty of Computer and Information Sciences, Department of Computer Science, Cairo, 11566, Egypt; El-Kenawy E.-S.M., Delta Higher Institute for Engineering and Technology (DHIET), Department of Communications and Electronics, Mansoura, 35111, Egypt; Ibrahim A., Mansoura University, Faculty of Engineering, Computer Engineering and Control Systems Department, Mansoura, 35516, Egypt; Eid M.M., Delta University for Science and Technology, Faculty of Artificial Intelligence, Mansoura, 35712, Egypt; Jamjoom M.M., Princess Nourah Bint Abdulrahman University, College of Computer and Information Science, Department of Computer Sciences, Riyadh, 11671, Saudi Arabia; Khafaga D.S., Princess Nourah Bint Abdulrahman University, College of Computer and Information Science, Department of Computer Sciences, Riyadh, 11671, Saudi Arabia","Oral cancer is a deadly form of cancerous tumor that is widely spread in low and middle-income countries. An early and affordable oral cancer diagnosis might be achieved by automating the detection of precancerous and malignant lesions in the mouth. There are many research attempts to develop a robust machine-learning model that can detect oral cancer from images. However, these are still lacking high precision in oral cancer detection. Therefore, this work aims to propose a new approach capable of detecting oral cancer in medical images with higher accuracy. In this work, a novel and robust oral cancer detection based on a convolutional neural network (CNN) and optimized deep belief network (DBN). The design parameters of CNN and DBN are optimized using a new optimization algorithm, which is developed as a hybrid of Particle Swarm Optimization (PSO) and Al-Biruni Earth Radius (BER) Optimization algorithms and is denoted by (PSOBER). Using a standard biomedical images dataset available on the Kaggle repository, the proposed approach shows promising results outperforming various competing approaches with an accuracy of 97.35%. In addition, a set of statistical tests, such as One-way analysis-of-variance (ANOVA) and Wilcoxon signed-rank tests, are conducted to prove the significance and stability of the proposed approach. The proposed methodology is solid and efficient, and specialists can adopt it. However, additional research on a larger scale dataset is required to confirm the findings and highlight other oral features that can be utilized for cancer detection.  © 2013 IEEE.","Al-Biruni earth radius algorithm; convolutional neural network; deep belief network; metaheuristic optimization; Oral cancer; particle swarm optimization","Analysis of variance (ANOVA); Convolution; Deep neural networks; Diagnosis; Diseases; Heuristic algorithms; Heuristic methods; Medical imaging; Particle swarm optimization (PSO); Al-biruni earth radius algorithm; Cancer; Cancer detection; Convolutional neural network; Deep belief networks; Deep learning; Earth radii; Features extraction; Lesion; Metaheuristic; Metaheuristic optimization; Oral cancer; Particle swarm; Particle swarm optimization; Swarm optimization; Feature extraction","","","","","","","He S., Chakraborty R., Ranganathan S., Proliferation and apoptosis pathways and factors in oral squamous cell carcinoma, Int. J. Mol. ScL, 23, 3, (2022); Welikala R.A., Remagnino P., Lim J.H., Chan C.S., Rajendran S., Kallarakkal T.G., Zain R.B., Jayasinghe R.D., Rimal J., Kerr A.R., Amtha R., Patil K., Tilakaratne W.M., Gibson J., Cheong S.C., Barman S.A., Automated detection and classification of oral lesions using deep learning for early detection of oral cancer, IEEE Access, 8, pp. 132677-132693, (2020); Javed A.R., Sarwar M.U., Beg M.O., Asim M., Baker T., Tawfk H., A collaborative healthcare framework for shared healthcare plan with ambient intelligence, Hum.-Centric Comput. Inf. Sci., 10, 1, (2020); Javed A.R., Fahad L.G., Farhan A.A., Abbas S., Srivastava G., Parizi R.M., Khan M.S., Automated cognitive health assessment in smart Homes using machine learning, Sustain. Cities Soc., 65, (2021); Musulin J., Stifanic D., Zulijani A., Segota S.B., Lorencin I., Andelic N., Car Z., Automated grading of oral squamous cell carcinoma into multiple classes using deep learning methods, Proc. IEEE 21st Int. Conf. Bioinf. Bioeng. (BIBE), Kragujevac, Serbia, 2021, pp. 1-6; Singh A., Sahu A., Verma S., Computer intelligence in detection of malignant or premalignant oral lesions: The story so far, Computational Intelligence in Oncology: Applications in Diagnosis, Prognosis and Therapeutics of Cancers (Studies in Computational Intelligence), pp. 187-200, (2022); Saleem K., Saleem M., Ahmad R.Z., Javed A.R., Alazab M., Gadekallu T.R., Suleman A., Situation-aware BDI reasoning to detect early symptoms of COVID 19 using smartwatch, IEEE Sensors J., 23, 2, pp. 898-905, (2023); Hasan M.K., Islam S., Memon I., Ismail A.F., Abdullah S., Budati A.K., Naf N.S., A novel resource oriented DMA framework for Internet of Medical Things devices in 5G network, IEEE Trans. Ind. Informat., 18, 12, pp. 8895-8904, (2022); Siddiqui S.Y., Haider A., Ghazal T.M., Khan M.A., Naseer I., Abbas S., Rahman M., Khan J.A., Ahmad M., Hasan M.K., Mohammed A.A., Ateeq K., IoMT cloud-based intelligent prediction of breast cancer stages empowered with deep learning, IEEE Access, 9, pp. 146478-146491, (2021); Mansour R.F., Alfar N.M., Abdel-Khalek S., Abdelhaq M., Saeed R.A., Alsaqour R., Optimal deep learning based fusion model for biomed-ical image classifcation, Expert Syst., 39, 3, (2022); Bhandari B., Alsadoon A., Prasad P.W.C., Abdullah S., Haddad S., Deep learning neural network for texture feature extraction in oral cancer: Enhanced loss function, Multimedia Tools Appl., 79, 37-38, pp. 27867-27890, (2020); Rahman T.Y., Mahanta L.B., Das A.K., Sarma J.D., Histopatho-logical imaging database for oral cancer analysis, Data Brief, 29, (2020); Lu J., Sladoje N., Stark C.R., Ramqvist E.D., Hirsch J.-M., Lindblad J., A deep learning based pipeline for effcient oral cancer screening on whole slide images, Image Analysis and Recognition (Lecture Notes in Computer Science), pp. 249-261, (2020); Panda N., Majhi S.K., Oppositional salp swarm algorithm with mutation operator for global optimization and application in training higher order neural networks, Multimedia Tools Appl., 80, 28-29, pp. 35415-35439, (2021); Figueroa K.C., Et al., Interpretable deep learning approach for oral cancer classifcation using guided attention inference network, Proc. SPIE, 27, 1, (2022); Sharma A.K., Nandal A., Dhaka A., Dixit R., Medical image classif-cation techniques and analysis using deep learning networks: A review, Health Informatics: A Computational Perspective in Healthcare (Studies in Computational Intelligence), pp. 233-258, (2021); Lim J.H., Tan C.S., Chan C.S., Welikala R.A., Remagnino P., Rajendran S., Kallarakkal T.G., Zain R.B., Jayasinghe R.D., Rimal J., Kerr A.R., Amtha R., Patil K., Tilakaratne W.M., Gibson J., Cheong S.C., Barman S.A., D'OraCa: Deep learning-based classifcation of oral lesions with mouth landmark guidance for early detection of oral cancer, Medical Image Understanding and Analysis(Lecture Notes inComputer Science), pp. 408-422, (2021); Martinez F., Martinez F., Jacinto E., Performance evaluation of the NASNet convolutional network in the automatic identifcation of COVID-19, Int. J. Adv. Sci., Eng. Inf. Technol., 10, 2, pp. 662-667, (2020); Shamim M.Z.M., Syed S., Shiblee M., Usman M., Ali S.J., Hussein H.S., Farrag M., Automated detection of oral pre-cancerous tongue lesions using deep learning for early diagnosis of oral cavity cancer, Comput. J., 65, 1, pp. 91-104, (2022); Li H.-A., Fan J., Yu K., Qi X., Wen Z., Hua Q., Zhang M., Zheng Q., Medical image coloring based on Gabor fltering for Internet of Medical Things, IEEE Access, 8, pp. 104016-104025, (2020); Yu Z., Jiang X., Zhou F., Qin J., Ni D., Chen S., Lei B., Wang T., Melanoma recognition in dermoscopy images via aggregated deep convolutional features, IEEE Trans. Biomed. Eng., 66, 4, pp. 1006-1016, (2019); Rokhana R., Herulambang W., Indraswari R., Deep convolutional neural network for melanoma image classifcation, Proc. Int. Electron. Symp. (IES), pp. 481-486, (2020); Liberman G., Acevedo D., Mejail M., Classifcation of melanoma images with Fisher vectors and deep learning, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications (Lecture Notes in Computer Science), pp. 732-739, (2019); Zhou Q., Shi Y., Xu Z., Qu R., Xu G., Classifying melanoma skin lesions using convolutional spiking neural networks with unsupervised S learning rule, IEEE Access, 8, pp. 101309-101319, (2020); Hosny K.M., Kassem M.A., Foaud M.M., Skin melanoma classi-fcation using ROI and data augmentation with deep convolutional neural networks, Multimedia Tools Appl., 79, 33-34, pp. 24029-24055, (2020); Mukherjee S., Adhikari A., Roy M., Malignant melanoma classifca-tion using cross-platform dataset with deep learning CNN architecture, Recent Trends in Signal and Image Processing (Advances in Intelligent Systems and Computing), pp. 31-41, (2019); Xu S., Liu Y., Hu W., Zhang C., Liu C., Zong Y., Chen S., Lu Y., Yang L., Ng E.Y.K., Wang Y., Wang Y., An early diagnosis of oral cancer based on three-dimensional convolutional neural networks, IEEE Access, 7, pp. 158603-158611, (2019); Gupta R.K., Kaur M., Manhas J., Tissue level based deep learning framework for early detection of dysplasia in oral squamous epithelium, J. Multimedia Inf. Syst., 6, 2, pp. 81-86, (2019); Jeyaraj P.R., Nadar E.R.S., Computer-assisted medical image classifcation for early diagnosis of oral cancer employing deep learning algorithm, J. Cancer Res. Clin. Oncol., 145, 4, pp. 829-837, (2019); Song B., Sunny S., Uthoff R.D., Patrick S., Suresh A., Kolur T., Keerthi G., Anbarani A., Wilder-Smith P., Kuriakose M.A., Birur P., Rodriguez J.J., Liang R., Automatic classifcation of dual-modalilty, smartphone-based oral dysplasia and malignancy images using deep learning, Biomed. Opt. Exp., 9, 11, pp. 5318-5329, (2018); Uthoff R.D., Song B., Sunny S., Patrick S., Suresh A., Kolur T., Keerthi G., Spires O., Anbarani A., Wilder-Smith P., Kuriakose M.A., Birur P., Liang R., Point-of-care, smartphone-based, dual-modality, dual-view, oral cancer screening device with neural network classifcation for low-resource communities, PLoS ONE, 13, 12, (2018); Folmsbee J., Liu X., Brandwein-Weber M., Doyle S., Active deep learning: Improved training effciency of convolutional neural networks for tissue classifcation in oral cavity cancer, Proc. IEEE 15th Int. Symp. Biomed. Imag. (ISBI), pp. 770-773, (2018); Rana A., Yauney G., Wong L.C., Gupta O., Muftu A., Shah P., Automated segmentation of gingival diseases from oral images, Proc. IEEE Healthcare Innov. Point Care Technol. (HI-POCT), pp. 144-147, (2017); Anantharaman R., Velazquez M., Lee Y., Utilizing mask R-CNN for detection and segmentation of oral diseases, Proc. IEEE Int. Conf. Bioinf. Biomed. (BIBM), pp. 2197-2204, (2018); Thomas B., Kumar V., Saini S., Texture analysis based segmentation and classifcation of oral cancer lesions in color images using ANN, Proc. IEEE Int. Conf. Signal Process., Comput. Control (ISPCC), pp. 1-5, (2013); Anantharaman R., Anantharaman V., Lee Y., Oro vision: Deep learning for classifying orofacial diseases, Proc. IEEE Int. Conf. Healthcare Informat. (ICHI), pp. 39-45, (2017); Krishnan M.M.R., Venkatraghavan V., Acharya U.R., Pal M., Paul R.R., Min L.C., Ray A.K., Chatterjee J., Chakraborty C., Automated oral cancer identifcation using histopathological images: A hybrid feature extraction paradigm, Micron, 43, 2-3, pp. 352-364, (2012); Aubreville M., Knipfer C., Oetter N., Jaremenko C., Rodner E., Denzler J., Bohr C., Neumann H., Stelzle F., Maier A., Automatic classifcation of cancerous tissue in laserendomicroscopy images of the oral cavity using deep learning, Sci. Rep., 7, 1, (2017); Cakmak M., Tenekeci M.E., Melanoma detection from dermoscopy images using nasnet mobile with transfer learning, Proc. 29th Signal Process. Commun. Appl. Conf. (SIU), pp. 1-4, (2021); Brinker T.J., Hekler A., Enk A.H., Berking C., Haferkamp S., Hauschild A., Weichenthal M., Klode J., Schadendorf D., Holland-Letz T., Von Kalle C., Frohling S., Schilling B., Utikal J.S., Deep neural networks are superior to dermatologists in melanoma image classifcation, Eur. J. Cancer, 119, pp. 11-17, (2019); Han S.S., Kim M.S., Lim W., Park G.H., Park I., Chang S.E., Clas-sifcation of the clinical images for benign and malignant cutaneous tumors using a deep learning algorithm, J. Investigative Dermatol., 138, 7, pp. 1529-1538, (2018); Hosny K.M., Kassem M.A., Foaud M.M., Classifcation of skin lesions using transfer learning and augmentation with Alex-Net, PLoS ONE, 14, 5, (2019); Esteva A., Kuprel B., Novoa R.A., Ko J., Swetter S.M., Blau H.M., Thrun S., Dermatologist-level classifcation of skin cancer with deep neural networks, Nature, 542, 7639, pp. 115-118, (2017); Anthony G., Greg H., Tshilidzi M., Classifcation of Images Using Support Vector Machines, (2007); Charbuty B., Abdulazeez A., Classifcation based on decision tree algorithm for machine learning, J. Appl. Sci. Technol. Trends, 2, 1, pp. 20-28, (2021); Dang Y., Jiang N., Hu H., Ji Z., Zhang W., Image classifcation based on quantum K-nearest-neighbor algorithm, Quantum Inf. Process., 17, 9, (2018); Zhou M., Samiappan S., Worch E., Ball J.E., Hyperspectral image classifcation using Fisher's linear discriminant analysis feature reduction with Gabor fltering and CNN, Proc. IEEE Int. Geosci. Remote Sens. Symp. (IGARSS), 2020, pp. 493-496; O'Shea K., Nash R., An Introduction To Convolutional Neural Networks, (2015); Wang S.-H., Phillips P., Sui Y., Liu B., Yang M., Cheng H., Classi-fcation of Alzheimer's disease based on eight-layer convolutional neural network with leaky rectifed linear unit and max pooling, J. Med. Syst., 42, 5, (2018); Wang S., Jiang Y., Hou X., Cheng H., Du S., Cerebral micro-bleed detection based on the convolution neural network with rank based average pooling, IEEE Access, 5, pp. 16576-16583, (2017); Li C., Wang Y., Zhang X., Gao H., Yang Y., Wang J., Deep belief network for spectral-spatial classifcation of hyperspectral remote sensor data, Sensors, 19, 1, (2019); Bello R., Gomez Y., Nowe A., Garcia M.M., Two-step particle swarm optimization to solve the feature selection problem, Proc. 7th Int. Conf. Intell. Syst. Des. Appl. (ISDA), pp. 691-696, (2007); El-Kenawy E.-S.M., Abdelhamid A.A., Ibrahim A., Mirjalili S., Khodadad N., Al Duailij M.A., Ali Alhussan A., Sami Khafaga D., Al-Biruni Earth radius (BER) metaheuristic search optimization algorithm, Comput. Syst. Sci. Eng., 45, 2, pp. 1917-1934, (2023); Ouyang M., Xi J., Bai W., Li K., Band-area resource management platform and accelerated particle swarm optimization algorithm for container deployment in Internet-of-Things cloud, IEEE Access, 10, pp. 86844-86863, (2022); Tseng H.-E., Chang C.-C., Chung T.-W., Applying improved particle swarm optimization to asynchronous parallel disassembly planning, IEEE Access, 10, pp. 80555-80564, (2022); Bento M.E.C., Dotta D., Kuiava R., Ramos R.A., A procedure to design fault-tolerant wide-area damping controllers, IEEE Access, 6, pp. 23383-23405, (2018); Fahad S., Yang S., Khan S.U., Khan S.A., Khan R.A., A hybrid smart quantum particle swarm optimization for multimodal electromagnetic design problems, IEEE Access, 10, pp. 72339-72347, (2022); Khafaga D.S., Alhussan A.A., El-Kenawy E.-S.-M., Ibrahim A., Eid M.M., Abdelhamid A.A., Solving optimization problems of metamaterial and double T-shape antennas using advanced meta-heuristics algorithms, IEEE Access, 10, pp. 74449-74471, (2022); Alhussan A.A., Khafaga D.S., El-Kenawy E.-S.-M., Ibrahim A., Eid M.M., Abdelhamid A.A., Pothole and plain road classifca-tion using adaptive mutation dipper throated optimization and transfer learning for self driving cars, IEEE Access, 10, pp. 84188-84211, (2022); Oksuz C., Urhan O., Gullu M.K., Brain tumor classifcation using the fused features extracted from expanded tumor region, Biomed. Signal Process. Control, 72, (2022); Baro S., Oral Cancer (Lips and Tongue) Images Dataset, (2020); Saber A., Sakr M., Abo-Seida O.M., Keshk A., Chen H., A novel deep-learning model for automatic detection and classifcation of breast cancer using the transfer-learning technique, IEEE Access, 9, pp. 71194-71209, (2021); Rashid J., Ishfaq M., Ali G., Saeed M.R., Hussain M., Alkhali-Fah T., Alturise F., Samand N., Skin cancer disease detection using transfer learning technique, Appl. Sci., 12, 11, (2022); Al-Tashi Q., Kadir S.J.A., Rais H.M., Mirjalili S., Alhussian H., Binary optimization using hybrid grey wolf optimization for feature selection, IEEE Access, 7, pp. 39496-39508, (2019); Mirjalili S., Lewis A., The whale optimization algorithm, Adv. Eng. Softw., 95, pp. 51-67, (2016); Immanuel S.D., Chakraborty U.K., Genetic algorithm: An approach on optimization, Proc. Int. Conf. Commun. Electron. Syst. (ICCES), pp. 701-708, (2019); Storn R., Price K., Differential evolution-A simple and effcient heuristic for global optimization over continuous spaces, J. Global Optim., 11, 4, pp. 341-359, (1997)","M.M. Jamjoom; Princess Nourah Bint Abdulrahman University, College of Computer and Information Science, Department of Computer Sciences, Riyadh, 11671, Saudi Arabia; email: mfhaojouni@pnu.edu.sa; A.A. Abdelhamid; Shaqra University, College of Computing and Information Technology, Department of Computer Science, Shaqra, 11961, Saudi Arabia; email: abdelaziz@su.edu.sa; E.-S.M. El-Kenawy; Delta Higher Institute for Engineering and Technology (DHIET), Department of Communications and Electronics, Mansoura, 35111, Egypt; email: skenawy@ieee.org","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85149834542"
"Sonneck J.; Zhou Y.; Chen J.","Sonneck, Justin (57892839100); Zhou, Yu (58488105700); Chen, Jianxu (56352708300)","57892839100; 58488105700; 56352708300","MMV_Im2Im: an open-source microscopy machine vision toolbox for image-to-image transformation","2024","GigaScience","13","","giad120","","","","0","10.1093/gigascience/giad120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183847155&doi=10.1093%2fgigascience%2fgiad120&partnerID=40&md5=436270eaa2e3acee493454ee3e8306a9","Leibniz-Institut für Analytische Wissenschaften – ISAS – e.V., Bunsen-Kirchhoff-Str. 11, Dortmund, 44139, Germany; Faculty of Computer Science, Ruhr-University Bochum, Universitätsstraße 150, Bochum, 44801, Germany; Bunsen-Kirchhoff-Str. 11, Dortmund, 44139, Germany","Sonneck J., Leibniz-Institut für Analytische Wissenschaften – ISAS – e.V., Bunsen-Kirchhoff-Str. 11, Dortmund, 44139, Germany, Faculty of Computer Science, Ruhr-University Bochum, Universitätsstraße 150, Bochum, 44801, Germany; Zhou Y., Leibniz-Institut für Analytische Wissenschaften – ISAS – e.V., Bunsen-Kirchhoff-Str. 11, Dortmund, 44139, Germany; Chen J., Leibniz-Institut für Analytische Wissenschaften – ISAS – e.V., Bunsen-Kirchhoff-Str. 11, Dortmund, 44139, Germany, Bunsen-Kirchhoff-Str. 11, Dortmund, 44139, Germany","Over the past decade, deep learning (DL) research in computer vision has been growing rapidly, with many advances in DL-based image analysis methods for biomedical problems. In this work, we introduce MMV_Im2Im, a new open-source Python package for image-to-image transformation in bioimaging applications. MMV_Im2Im is designed with a generic image-to-image transformation framework that can be used for a wide range of tasks, including semantic segmentation, instance segmentation, image restoration, image generation, and so on. Our implementation takes advantage of state-of-the-art machine learning engineering techniques, allowing researchers to focus on their research without worrying about engineering details. We demonstrate the effectiveness of MMV_Im2Im on more than 10 different biomedical problems, showcasing its general potentials and applicabilities. For computational biomedical researchers, MMV_Im2Im provides a starting point for developing new biomedical image analysis or machine learning algorithms, where they can either reuse the code in this package or fork and extend this package to facilitate the development of new methods. Experimental biomedical researchers can benefit from this work by gaining a comprehensive view of the image-to-image transformation concept through diversified examples and use cases. We hope this work can give the community inspirations on how DL-based image-to-image transformation can be integrated into the assay development process, enabling new biomedical studies that cannot be done only with traditional experimental assays. To help researchers get started, we have provided source code, documentation, and tutorials for MMV_Im2Im at [https://github.com/MMV-Lab/mmv_im2im] under MIT license. © The Author(s) 2024.","deep learning; microscopy image analysis; open-source","Algorithms; Image Processing, Computer-Assisted; Machine Learning; Microscopy; Software; Article; artificial intelligence; cell structure; cellular neural network; computer simulation; computer vision; confocal microscopy; deep learning; fluorescence microscopy; image analysis; image reconstruction; image segmentation; immunofluorescence; immunohistochemistry; learning algorithm; machine learning; microscopy; prediction; stimulated emission depletion microscopy; article; controlled study; human; vision","","","ImageJ","","Ministry of Culture and Science of the State of North Rhine-Westphalia; Bundesministerium für Bildung und Forschung, BMBF, (161L0272); Bundesministerium für Bildung und Forschung, BMBF; Ministerium für Kultur und Wissenschaft des Landes Nordrhein-Westfalen, MKW NRW","This work is supported by the Federal Ministry of Education and Research (Bundesministerium für Bildung und Forschung, BMBF) under the funding reference 161L0272 and by the Ministry of Culture and Science of the State of North Rhine-Westphalia (Ministerium für Kultur und Wissenschaft des Landes Nordrhein-Westfalen, MKW NRW). ","Lim B, Son S, Kim H, Et al., Enhanced deep residual networks for single image super-resolution, 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), (2017); Isola P, Zhu J-Y, Zhou T, Et al., Image-to-Image translation with conditional adversarial networks, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (2017); Kirillov A, He K, Girshick R, Et al., Panoptic segmentation, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), (2019); Ounkomol C, Seshamani S, Maleckar MM, Et al., Label-free prediction of three-dimensional fluorescence images from transmitted-light microscopy, Nat Methods, 15, pp. 917-920, (2018); Ghahremani P, Li Y, Kaufman A, Et al., Deep learning-inferred multiplex immunofluorescence for immunohistochemical image quantification, Nat Mach Intell, 4, pp. 401-412, (2022); Fang L, Monroe F, Novak SW, Et al., Deep learning-based point-scanning super-resolution imaging, Nat Methods, 18, pp. 406-416, (2021); Edlund C, Jackson TR, Khalid N, Et al., LIVECell—a large-scale dataset for label-free live cell segmentation, Nat Methods, 18, pp. 1038-1045, (2021); Chen J, Sasaki H, Lai H, Et al., Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes, Nat Methods, 18, pp. 678-687, (2021); Ronneberger O, Fischer P, Brox T., U-Net: convolutional networks for biomedical image segmentation, Medical Image Computing and Computer-Assisted Intervention (MICCAI), 9351, (2015); Lalit M, Tomancak P, Jug F., EmbedSeg: embedding-based instance segmentation for biomedical microscopy data, Med Image Anal, 81, (2022); Lalit M, Tomancak P, Jug F., Embedding-based instance segmentation in microscopy, Proceedings of the Fourth Conference on Medical Imaging with Deep Learning, (2021); Ihle SJ, Reichmuth AM, Girardin S, Et al., Unsupervised data to content transformation with histogram-matching cycle-consistent generative adversarial networks, Nat Mach Intell, 1, pp. 461-470, (2019); Zhu J-Y, Park T, Isola P, Et al., Unpaired image-to-image translation using cycle-consistent adversarial networks, 2017 IEEE International Conference on Computer Vision (ICCV), (2017); Falcon W, Borovec J, Walchli A, Et al., PyTorchLightning/pytorchlightning: 0.7.6 release, Zenodo, (2020); Izmailov P, Podoprikhin D, Garipov T, Et al., Averaging weights leads to wider optima and better generalization, 34th Conference on Uncertainty in Artificial Intelligence 2018, (2018); OpenMMLab; MMSegmentation: openMMLab semantic segmentation toolbox and benchmark, GitHub, (2023); Deng J, Dong W, Socher R, Et al., ImageNet: a large-scale hierarchical image database, 2009 IEEE Conference on Computer Vision and Pattern Recognition, (2009); Project MONAI. Zenodo, (2020); Brown EM, Toloudis D, Sherman J, Et al., AICSImageIO: image reading, metadata conversion, and image writing for microscopy images in pure Python, GitHub, (2021); Chen J, Ding L, Viana MP, Et al., The Allen Cell and Structure Segmenter: a new open source toolkit for segmenting 3D intracellular structures in fluorescence microscopy images, Biorxiv, (2018); GitHub, (2023); Himmelstein DS, Rubinetti V, Slochower DR, Et al., Open collaborative writing with Manubot, PLoS Comput Biol, 15, (2019); MMV_Im2im: an open source toolbox for image-to-image transformation in microscopy images, GitHub, (2023); LaChance J, Cohen DJ., Practical fluorescence reconstruction microscopy for large samples and low-magnification imaging, PLoS Comput Biol, 16, (2020); Reinke A, Tizabi MD, Baumgartner M, Et al., Understanding metric-related pitfalls in image analysis validation, (2023); Chen J, Viana MP, Rafelski SM., When seeing is not believing: application-appropriate validation matters for quantitative bioimage analysis, Nat Methods, 20, pp. 968-970, (2023); Guiet R., HeLa “Kyoto” cells under the scope, Zenodo, (2022); Viana MP, Chen J, Knijnenburg TA, Et al., Integrated intracellular organization and its variations in human iPS cells, Nature, 613, pp. 345-354, (2023); Kerfoot E, Clough J, Oksuz I, Et al., Left-ventricle quantification using residual U-net, Statistical Atlases and Computational Models of the Heart Atrial Segmentation and LV Quantification Challenges, (2019); Oktay O, Schlemper J, Folgoc LL, Et al., Attention U-Net: learning where to look for the Pancreas, Proceedings of Medical Imaging with Deep Learning, (2018); Hatamizadeh A, Nath V, Tang Y, Et al., Swin UNETR: swin transformers for semantic segmentation of brain tumors in MRI images, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, (2022); Hatamizadeh A, Tang Y, Nath V, Et al., UNETR: transformers for 3D medical image segmentation, 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), (2022); Sirinukunwattana K, Snead DRJ, Rajpoot NM., A stochastic polygons model for glandular structures in colon histology images, IEEE Trans Med Imaging, 34, pp. 2366-2378, (2015); Sirinukunwattana K, Pluim JPW, Chen H, Et al., Gland segmentation in colon histology images: the glas challenge contest, Med Image Anal, 35, pp. 489-502, (2017); Macenko M, Niethammer M, Marron JS, Et al., A method for normalizing histology slides for quantitative analysis, 2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro, (2009); Schmidt U, Weigert M, Broaddus C, Et al., Cell detection with star-convex polygons, Medical Image Computing and Computer Assisted Intervention—MICCAI, (2018); Weigert M, Schmidt U, Haase R, Et al., Star-convex polyhedra for 3D object detection and segmentation in microscopy, 2020 IEEE Winter Conference on Applications of Computer Vision (WACV), (2020); Mandal S, Uhlmann V., Splinedist: automated cell segmentation with spline curves, 2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI), (2021); Stringer C, Wang T, Michaelos M, Et al., Cellpose: a generalist algorithm for cellular segmentation, Nat Methods, 18, pp. 100-106, (2021); Cutler KJ, Stringer C, Lo TW, Et al., Omnipose: a high-precision morphology-independent solution for bacterial cell segmentation, Nat Methods, 19, pp. 1438-1448, (2022); He K, Gkioxari G, Dollar P, Et al., Mask R-CNN, IEEE Trans Pattern Anal Mach Intell, 42, pp. 386-397, (2020); Romera E, Alvarez JM, Bergasa LM, Et al., ERFNet: efficient residual factorized ConvNet for real-time semantic segmentation, IEEE Trans Intell Transport Syst, 19, pp. 263-272, (2018); Moy TI, Conery AL, Larkins-Ford J, Et al., High-throughput screen for novel antimicrobials using a whole animal infection model, ACS Chem Biol, 4, pp. 527-533, (2009); Prakash M, Delbracio M, Milanfar P, Et al., Interpretable unsupervised diversity denoising and artefact removal, Proceedings of the Tenth International Conference on Learning Representations, (2021); Weigert M, Schmidt U, Boothe T, Et al., Content-aware image restoration: pushing the limits of fluorescence microscopy, Nat Methods, 15, pp. 1090-1097, (2018); Richardson E, Weiss I, Feldman Y., Pyrallis—simple configuration with dataclasses, Github, (2023); Liu Y, Weiss K, Navab N, Et al., DeStripe: a Self2Self spatiospectral graph neural network with unfolded Hessian for stripe artifact removal in light-sheet microscopy, Medical Image Computing and Computer Assisted Intervention (MICCAI), (2022); Waibel DJE, Roell E, Rieck B, Et al., A diffusion model predicts 3D shapes from 2D microscopy images, (2022); Imaginaire. GitHub, (2023); Ahlers J, More DA, Amsalem O, Et al., napari: a multi-dimensional image viewer for Python, Zenodo, (2023); Jing L, Tian Y., Self-supervised visual feature learning with deep neural networks: a survey, IEEE Trans Pattern Anal Mach Intell, 43, pp. 4037-4058, (2021); Mok TCW, Chung ACS., Fast symmetric diffeomorphic image registration with convolutional neural networks, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), (2020); Sonneck J., MMV_Im2Im, WorkflowHub, (2023); Sonneck J, Chen J., Supporting data for “MMV_Im2Im: An Open-Source Microscopy Machine Vision Toolbox for Image-to-Image Transformation, GigaScience Database, (2023); Sonneck J, Zhou Y, Chen J., MMV_Im2Im: an open source microscopy machine vision toolbox for image-to-image transformation, Zenodo, (2023); Guiet R., Automatic labelling of HeLa “Kyoto” cells using deep learning tools, Zenodo, (2022); The hiPSC single-cell image dataset; Sirinukunwattana K, Et al., Gland segmentation in colon histology images: The glas challenge contest, Med Image Anal, 35, pp. 489-502, (2017); Gland segmentation in histology images challenge (GlaS) dataset; Broad Bioimage Benchmark Collection: C. elegangs live/dead assay; Ljosa V, Sokolnicki KL, Carpenter AE., Annotated high-throughput microscopy image sets for validation, Nat Methods, 9, (2012); Weigert M, Schmidt U, Boothe T, Et al., Content aware image restoration: pushing the limits of fluorescence microscopy—supplemental data; Chen J., 3D residual channel attention networks denoise and sharpen fluorescence microscopy image volumes, Zenodo, (2021); Ghahremani P, Li Y, Kaufman A, Et al., Deep learning-inferred multiplex immunofluorescence for immunohistochemical image quantification, Zenodo, (2021)","J. Chen; Leibniz-Institut für Analytische Wissenschaften – ISAS – e.V., Dortmund, Bunsen-Kirchhoff-Str. 11, 44139, Germany; email: jianxu.chen@isas.de","","Oxford University Press","","","","","","2047217X","","","38280188","English","GigaScience","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85183847155"
"Schilling M.P.; Ahuja N.; Rettenberger L.; Scherr T.; Reischl M.","Schilling, Marcel P. (57221699120); Ahuja, Niket (57888644700); Rettenberger, Luca (57361094700); Scherr, Tim (57211299072); Reischl, Markus (6602490688)","57221699120; 57888644700; 57361094700; 57211299072; 6602490688","Impact of Annotation Noise on Histopathology Nucleus Segmentation","2022","Current Directions in Biomedical Engineering","8","2","","197","200","3","4","10.1515/cdbme-2022-1051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137934248&doi=10.1515%2fcdbme-2022-1051&partnerID=40&md5=576fc3b0dc2fcb6783a408e023f4a48d","Institute for Automation and Applied Informatics, Karlsruhe Institute of Technology, Hermann-von-Helmholtz-Platz 1, Eggenstein-Leopoldshafen, 76344, Germany","Schilling M.P., Institute for Automation and Applied Informatics, Karlsruhe Institute of Technology, Hermann-von-Helmholtz-Platz 1, Eggenstein-Leopoldshafen, 76344, Germany; Ahuja N., Institute for Automation and Applied Informatics, Karlsruhe Institute of Technology, Hermann-von-Helmholtz-Platz 1, Eggenstein-Leopoldshafen, 76344, Germany; Rettenberger L., Institute for Automation and Applied Informatics, Karlsruhe Institute of Technology, Hermann-von-Helmholtz-Platz 1, Eggenstein-Leopoldshafen, 76344, Germany; Scherr T., Institute for Automation and Applied Informatics, Karlsruhe Institute of Technology, Hermann-von-Helmholtz-Platz 1, Eggenstein-Leopoldshafen, 76344, Germany; Reischl M., Institute for Automation and Applied Informatics, Karlsruhe Institute of Technology, Hermann-von-Helmholtz-Platz 1, Eggenstein-Leopoldshafen, 76344, Germany","Deep learning is often used for automated diagnosis support in biomedical image processing scenarios. Annotated datasets are essential for the supervised training of deep neural networks. The problem of consistent and noise-free annotation remains for experts such as pathologists. The variability within an annotator (intra) and the variability between annotators (inter) are current challenges. In clinical practice or biology, instance segmentation is a common task, but a comprehensive and quantitative study regarding the impact of noisy annotations lacks. In this paper, we present a concept to categorize and simulate various types of annotation noise as well as an evaluation of the impact on deep learning pipelines. Thereby, we use the multi-organ histology image dataset MoNuSeg to discuss the influence of annotator variability. We provide annotation recommendations for clinicians to achieve high-quality automated diagnostic algorithms. © 2022 The Author(s), published by De Gruyter.","Annotator Variability; Deep Learning; Image Processing; Instance Segmentation","Image annotation; Image segmentation; 'current; Annotated datasets; Annotator variability; Automated diagnosis; Deep learning; Diagnosis support; Images processing; Instance segmentation; Nucleus segmentation; Supervised trainings; Deep neural networks","","","","","","","Caicedo J.C., Et al., Nucleus segmentation across imaging experiments: The 2018 Data Science Bowl, Nature Methods, 16, 12, pp. 1247-1253, (2019); Graham S., Et al., Hover-Net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images, Medical Image Analysis, (2019); Karimi D., Et al., Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis, Medical Image Analysis, 65, 5, (2020); Kumar N., Et al., A multi-organ nucleus segmentation challenge, IEEE Transactions on Medical Imaging, 39, 5, pp. 1380-1391, (2020); Loffler K., Et al., A graph-based cell tracking algorithm with few manually tunable parameters and automated segmentation error correction, PLOS ONE, 16, 9, pp. 1-28, (2021); Northcutt C., Et al., Pervasive label errors in test sets destabilize machine learning benchmarks, Neural Information Processing Systems Track on Datasets and Benchmarks, 1; Ronneberger O., Et al., U-Net: Convolutional networks for biomedical image segmentation, Medical Image Computing and Computer-Assisted Intervention, 9351, pp. 234-241, (2015); Schilling M.P., Et al., Automated annotator variability inspection for biomedical image segmentation, IEEE Access, 10, 2022, pp. 2753-2765; Yu S., Et al., Robustness study of noisy annotation in deep learning based medical image segmentation, Physics in Medicine & Biology, 65, 17, (2020)","M.P. Schilling; Institute for Automation and Applied Informatics, Karlsruhe Institute of Technology, Eggenstein-Leopoldshafen, Hermann-von-Helmholtz-Platz 1, 76344, Germany; email: marcel.schilling@kit.edu","","Walter de Gruyter GmbH","","","","","","23645504","","","","English","Curr. Dir. Biomed. Eng.","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85137934248"
"Maiello L.; Ball L.; Micali M.; Iannuzzi F.; Scherf N.; Hoffmann R.-T.; Gama de Abreu M.; Pelosi P.; Huhle R.","Maiello, Lorenzo (57222163638); Ball, Lorenzo (55667696400); Micali, Marco (57215719490); Iannuzzi, Francesca (8672810400); Scherf, Nico (22935625000); Hoffmann, Ralf-Thorsten (55263364700); Gama de Abreu, Marcelo (57205413819); Pelosi, Paolo (7006547963); Huhle, Robert (55192776400)","57222163638; 55667696400; 57215719490; 8672810400; 22935625000; 55263364700; 57205413819; 7006547963; 55192776400","Automatic Lung Segmentation and Quantification of Aeration in Computed Tomography of the Chest Using 3D Transfer Learning","2022","Frontiers in Physiology","12","","725865","","","","5","10.3389/fphys.2021.725865","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124901369&doi=10.3389%2ffphys.2021.725865&partnerID=40&md5=278d2df56926a150cd69fa0770170ab3","Pulmonary Engineering Group, Department of Anaesthesiology and Intensive Care Therapy, University Hospital Carl Gustav Carus, Technische Universität Dresden, Dresden, Germany; Department of Surgical Sciences and Integrated Diagnostics, IRCCS AOU San Martino IST, University of Genoa, Genoa, Italy; Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Department of Diagnostic and Interventional Radiology, University Hospital Carl Gustav Dresden, Technische Universität Dresden, Dresden, Germany; Department of Intensive Care and Resuscitation, Anesthesiology Institute, Cleveland Clinic, Cleveland, OH, United States; Department of Outcomes Research, Anesthesiology Institute, Cleveland Clinic, Cleveland, OH, United States","Maiello L., Pulmonary Engineering Group, Department of Anaesthesiology and Intensive Care Therapy, University Hospital Carl Gustav Carus, Technische Universität Dresden, Dresden, Germany, Department of Surgical Sciences and Integrated Diagnostics, IRCCS AOU San Martino IST, University of Genoa, Genoa, Italy; Ball L., Department of Surgical Sciences and Integrated Diagnostics, IRCCS AOU San Martino IST, University of Genoa, Genoa, Italy; Micali M., Department of Surgical Sciences and Integrated Diagnostics, IRCCS AOU San Martino IST, University of Genoa, Genoa, Italy; Iannuzzi F., Department of Surgical Sciences and Integrated Diagnostics, IRCCS AOU San Martino IST, University of Genoa, Genoa, Italy; Scherf N., Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Hoffmann R.-T., Department of Diagnostic and Interventional Radiology, University Hospital Carl Gustav Dresden, Technische Universität Dresden, Dresden, Germany; Gama de Abreu M., Pulmonary Engineering Group, Department of Anaesthesiology and Intensive Care Therapy, University Hospital Carl Gustav Carus, Technische Universität Dresden, Dresden, Germany, Department of Intensive Care and Resuscitation, Anesthesiology Institute, Cleveland Clinic, Cleveland, OH, United States, Department of Outcomes Research, Anesthesiology Institute, Cleveland Clinic, Cleveland, OH, United States; Pelosi P., Department of Surgical Sciences and Integrated Diagnostics, IRCCS AOU San Martino IST, University of Genoa, Genoa, Italy; Huhle R., Pulmonary Engineering Group, Department of Anaesthesiology and Intensive Care Therapy, University Hospital Carl Gustav Carus, Technische Universität Dresden, Dresden, Germany","Background: Identification of lung parenchyma on computer tomographic (CT) scans in the research setting is done semi-automatically and requires cumbersome manual correction. This is especially true in pathological conditions, hindering the clinical application of aeration compartment (AC) analysis. Deep learning based algorithms have lately been shown to be reliable and time-efficient in segmenting pathologic lungs. In this contribution, we thus propose a novel 3D transfer learning based approach to quantify lung volumes, aeration compartments and lung recruitability. Methods: Two convolutional neural networks developed for biomedical image segmentation (uNet), with different resolutions and fields of view, were implemented using Matlab. Training and evaluation was done on 180 scans of 18 pigs in experimental ARDS (u2NetPig) and on a clinical data set of 150 scans from 58 ICU patients with lung conditions varying from healthy, to COPD, to ARDS and COVID-19 (u2NetHuman). One manual segmentations (MS) was available for each scan, being a consensus by two experts. Transfer learning was then applied to train u2NetPig on the clinical data set generating u2NetTransfer. General segmentation quality was quantified using the Jaccard index (JI) and the Boundary Function score (BF). The slope between JI or BF and relative volume of non-aerated compartment (SJI and SBF, respectively) was calculated over data sets to assess robustness toward non-aerated lung regions. Additionally, the relative volume of ACs and lung volumes (LV) were compared between automatic and MS. Results: On the experimental data set, u2NetPig resulted in JI = 0.892 [0.88 : 091] (median [inter-quartile range]), BF = 0.995 [0.98 : 1.0] and slopes SJI = −0.2 {95% conf. int. −0.23 : −0.16} and SBF = −0.1 {−0.5 : −0.06}. u2NetHuman showed similar performance compared to u2NetPig in JI, BF but with reduced robustness SJI = −0.29 {−0.36 : −0.22} and SBF = −0.43 {−0.54 : −0.31}. Transfer learning improved overall JI = 0.92 [0.88 : 0.94], P < 0.001, but reduced robustness SJI = −0.46 {−0.52 : −0.40}, and affected neither BF = 0.96 [0.91 : 0.98] nor SBF = −0.48 {−0.59 : −0.36}. u2NetTransfer improved JI compared to u2NetHuman in segmenting healthy (P = 0.008), ARDS (P < 0.001) and COPD (P = 0.004) patients but not in COVID-19 patients (P = 0.298). ACs and LV determined using u2NetTransfer segmentations exhibited < 5% volume difference compared to MS. Conclusion: Compared to manual segmentations, automatic uNet based 3D lung segmentation provides acceptable quality for both clinical and scientific purposes in the quantification of lung volumes, aeration compartments, and recruitability. Copyright © 2022 Maiello, Ball, Micali, Iannuzzi, Scherf, Hoffmann, Gama de Abreu, Pelosi and Huhle.","ARDS; COVID-19; deep learning; Jaccard index; lung recruitment; lung segmentation; transfer learning; uNet","adult respiratory distress syndrome; Article; automation; chronic obstructive lung disease; clinical evaluation; cohort analysis; comparative study; computer assisted tomography; consensus; controlled study; convolutional neural network; coronavirus disease 2019; data analysis software; human; image quality; image segmentation; intensive care unit; lung volume; major clinical study; mathematical computing; mathematical model; quantitative analysis; thorax radiography; three-dimensional imaging; transfer of learning","","","Matlab, Mathworks, United States","Mathworks, United States","Centre for Information Services; Deutsche Forschungsgemeinschaft, DFG, (GA 1256/8-1)","Funding text 1: This work was made possible by institutional funds and in part by German Research Foundation (grant no. GA 1256/8-1).; Funding text 2: The authors are grateful to the Centre for Information Services and High Performance Computing [Zentrum f?r Informationsdienste und Hochleistungsrechnen (ZIH)] TU Dresden for providing its facilities for high throughput calculations.","Brower R.G., Matthay M.A., Morris A., Schoenfeld D., Thompson B.T., Wheeler A., Ventilation with lower tidal volumes as compared with traditional tidal volumes for acute lung injury and the acute respiratory distress syndrome, Nat. Engl. J. Med, 342, pp. 1301-1308, (2009); Ait Skourt B., El Hassani A., Majda A., Lung CT image segmentation using deep neural networks, Procedia Comput. Sci, 127, pp. 109-113, (2018); Amato M.B.P., Barbas C.S.V., Medeiros D.M., Magaldi R.B., Schettino G.P., Lorenzi-Filho G., Et al., Effect of a protective-ventilation strategy on mortality in the acute respiratory distress syndrome, New England J. Med, 338, pp. 347-354, (2009); Anzueto A., Frutos-Vivar F., Esteban A., Alia I., Brochard L., Stewart T., Et al., Incidence, risk factors and outcome of barotrauma in mechanically ventilated patients, Intensive Care Med, 30, pp. 612-619, (2004); Badrinarayanan V., Kendall A., Cipolla R., SegNet: a deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell, 39, pp. 2481-2495, (2017); Ball L., Brusasco C., Corradi F., Paparo F., Garlaschi A., Herrmann P., Quintel M., Pelosi P., Lung hyperaeration assessment by computed tomography: correction of reconstruction-induced bias, BMC Anesthesiol, 16, (2016); Ball L., Robba C., Maiello L., Herrmann J., Gerard S.E., Xin Y., Et al., Computed tomography assessment of PEEP-induced alveolar recruitment in patients with severe COVID-19 pneumonia, Crit. Care, 25, (2021); Ball L., Vercesi V., Costantino F., Chandrapatham K., Pelosi P., Lung imaging: how to get better look inside the lung, Ann. Transl. Med, 5, (2017); Battaglini D., Sottano M., Ball L., Robba C., Rocco P.R., Pelosi P., Ten golden rules for individualized mechanical ventilation in acute respiratory distress syndrome, J. Intensive Med, 1, pp. 42-51, (2021); Bland J.M., Altman D.G., Statistical methods for assessing agreement between two methods of clinical measurement, Lancet, 1, pp. 307-310, (1986); Calfee C.S., Delucchi K., Parsons P.E., Thompson B.T., Ware L.B., Matthay M.A., Subphenotypes in acute respiratory distress syndrome: latent class analysis of data from two randomised controlled trials, Lancet Respiratory Med, 2, pp. 611-620, (2014); Cereda M., Xin Y., Goffi A., Herrmann J., Kaczka D.W., Kavanagh B.P., Et al., Imaging the injured lung: mechanisms of action and clinical use, Anesthesiology, 131, pp. 716-749, (2019); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-net: learning dense volumetric segmentation from sparse annotation, ArXiv160606650 Cs, (2016); Coppola S., Froio S., Chiumello D., Higher vs. lower PEEP in ARDS: just one part of the whole, J. Thorac. Disc, 10, pp. 56-59, (2018); Csurka G., Larlus D., Perronnin F., What is a good evaluation measure for semantic segmentation?, Proceedings of the British Machine Vision Conference, pp. 32.1-32.11, (2013); Cuevas L.M., Spieth P.M., Carvalho A.R., Gama de Abreu M., Koch E., Automatic lung segmentation of helical-CT scans in experimental induced lung injury, 4th European Conference of the International Federation for Medical and Biological Engineering, IFMBE Proceedings, pp. 764-767, (2009); Curley G.F., Laffey J.G., Zhang H., Slutsky A.S., Biotrauma and ventilator-induced lung injury: clinical implications, Chest, 150, pp. 1109-1117, (2016); Ferguson N.D., Fan E., Camporota L., Antonelli M., Anzueto A., Beale R., Et al., The Berlin definition of ARDS: an expanded rationale, justification, and supplementary material, Intensive Care Med, 38, pp. 1573-1582, (2012); Gerard S.E., Herrmann J., Kaczka D.W., Musch G., Fernandez-Bustamante A., Reinhardt J.M., Multi-resolution convolutional neural networks for fully automated segmentation of acutely injured lungs in multiple species, Med. Image Anal, 60, (2020); Gerard S.E., Herrmann J., Xin Y., Martin K.T., Rezoagli E., Ippolito D., Et al., CT image segmentation for inflamed and fibrotic lungs using a multi-resolution convolutional neural network, Sci. Rep, 11, (2021); Guldner A., Braune A., Ball L., Silva P.L., Samary C., Insorsi A., Et al., Comparative effects of volutrauma and atelectrauma on lung inflammation in experimental acute respiratory distress syndrome, Crit. Care Med, 44, pp. e854-e865, (2016); Guldner A., Braune A., Carvalho N., Beda A., Zeidler S., Wiedemann B., Wunderlich G., Andreeff M., Uhlig C., Spieth P.M., Koch T., Pelosi P., Kotzerke J., Gama de Abreu M., Higher levels of spontaneous breathing induce lung recruitment and reduce global stress/strain in experimental lung injury, Anesthesiology, 120, pp. 673-682, (2014); He K., Zhang X., Ren S., Sun J., Delving deep into rectifiers: surpassing human-level performance on ImageNet classification, 2015 IEEE International Conference on Computer Vision (ICCV), pp. 1026-1034, (2015); Hodgson C.L., Cooper D.J., Arabi Y., King V., Bersten A., Bihari S., Et al., Maximal recruitment open lung ventilation in acute respiratory distress syndrome (PHARLAP). a phase II, multicenter randomized controlled clinical trial, Amer. J. Respir. Crit. Care Med, 200, pp. 1363-1372, (2019); Hofmanninger J., Prayer F., Pan J., Rohrich S., Prosch H., Langs G., Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem, Eur. Radiol. Exp, 4, (2020); Hu S., Hoffman E., Reinhardt J., Automatic lung segmentation for accurate quantitation of volumetric X-ray CT images, IEEE Trans. Med. Imag, 20, pp. 490-498, (2001); Karmrodt J., Bletz C., Yuan S., David M., Heussel C.P., Markstaller K., Quantification of atelectatic lung volumes in two different porcine models of ARDS†, Brit. J. Anaesthesia, 97, pp. 883-895, (2006); Mansoor A., Bagci U., Xu Z., Foster B., Olivier K.N., Elinoff J.M., Et al., A generic approach to pathological lung segmentation, IEEE Trans. Med. Imag, 33, pp. 2293-2310, (2014); Mascalchi M., Camiciottoli G., Diciotti S., Lung densitometry: why, how and when, J. Thorac. Dis, 9, pp. 3319-3345, (2017); Muller D., Rey I.S., Kramer F., Automated chest CT image segmentation of COVID-19 lung infection based on 3D U-Net, ArXiv200704774 Cs Eess, (2020); Noshadi A., Kircher M., Pollnow S., Elke G., Frerichs I., Dossel O., Automatic lung segmentation in the presence of alveolar collapse, Curr. Direct. Biomed. Eng, 3, pp. 807-810, (2017); Pelosi P., Rocco P.R., de Abreu M.G., Use of computed tomography scanning to guide lung recruitment and adjust positive-end expiratory pressure, Curr. Opin. Crit. Care, 17, pp. 268-274, (2011); Pelosi P., Rocco P.R.M., de Abreu M.G., Close down the lungs and keep them resting to minimize ventilator-induced lung injury, Crit Care, 22, pp. 1-8, (2018); R Core Team T., R: A Language and Environment for Statistical Computing, (2021); Robba C., Battaglini D., Ball L., Patroniti N., Loconte M., Brunetti I., Et al., Distinct phenotypes require distinct respiratory management strategies in severe COVID-19, Respirat. Physiol. Neurobiol, 279, (2020); Ronneberger O., Fischer P., Brox T., U-Net: convolutional networks for biomedical image segmentation, Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015, Lecture Notes in Computer Science, pp. 234-241, (2015); Shelhamer E., Long J., Darrell T., Fully convolutional networks for semantic segmentation, IEEE Trans. Pattern Anal. Mach. Intell, 39, pp. 640-651, (2017); Slutsky A.S., Lung injury caused by mechanical ventilation, Chest, 116, pp. 9S-15S, (1999); Slutsky A.S., Ranieri V.M., Ventilator-induced lung injury, Nat. Engl. J. Med, 369, pp. 2126-2136, (2013); Sudre C.H., Li W., Vercauteren T., Ourselin S., Cardoso M.J., Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentations, ArXiv170703237 Cs, pp. 240-248, (2017); Acute Respiratory Distress Syndrome: the Berlin Definition, JAMA, 307, pp. 2526-2533, (2012); Tsuchida S., Engelberts D., Peltekova V., Hopkins N., Frndova H., Babyn P., Et al., Atelectasis causes alveolar injury in nonatelectatic lung regions, Amer. J. Respir. Crit. Care Med, 174, pp. 279-289, (2012); Yeghiazaryan V., Voiculescu I., Family of boundary overlap metrics for the evaluation of medical image segmentation, J. Med. Imag. (Bellingham), 5, (2018); Zhou T., Canu S., Ruan S., Automatic COVID-19 CT segmentation using U-Net integrated spatial and channel attention mechanism, Int. J. Imag. Syst. Technol, 31, pp. 16-27, (2021)","L. Maiello; Pulmonary Engineering Group, Department of Anaesthesiology and Intensive Care Therapy, University Hospital Carl Gustav Carus, Technische Universität Dresden, Dresden, Germany; email: lore.maiello@gmail.com; R. Huhle; Pulmonary Engineering Group, Department of Anaesthesiology and Intensive Care Therapy, University Hospital Carl Gustav Carus, Technische Universität Dresden, Dresden, Germany; email: robert.huhle@tu-dresden.de","","Frontiers Media S.A.","","","","","","1664042X","","","","English","Front. Physiol.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85124901369"
"Sharma S.; Gupta S.; Gupta D.; Rashid J.; Juneja S.; Kim J.; Elarabawy M.M.","Sharma, Sandhya (57226023345); Gupta, Sheifali (57072019200); Gupta, Deepali (57208714508); Rashid, Junaid (57203222981); Juneja, Sapna (57210408722); Kim, Jungeun (56600264800); Elarabawy, Mahmoud M. (56294009900)","57226023345; 57072019200; 57208714508; 57203222981; 57210408722; 56600264800; 56294009900","Performance Evaluation of the Deep Learning Based Convolutional Neural Network Approach for the Recognition of Chest X-Ray Images","2022","Frontiers in Oncology","12","","932496","","","","18","10.3389/fonc.2022.932496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134156021&doi=10.3389%2ffonc.2022.932496&partnerID=40&md5=f02ddfb99735a5764fe4d3a3d30ca686","Chitkara University, Institute of Engineering and Technology, Chitkara University, Baddi, India; Chitkara University, Institute of Engineering and Technology, Chitkara University, Rajpura, India; Department of Computer Science and Engineering, Kongju National University, Cheonan, South Korea; KIET Group of Institutions, Ghaziabad, India; Department of Software, Kongju National University, Cheonan, South Korea; Department of Computer Science, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia; Department of Mathematics, Faculty of Science, Suez Canal University, Ismailia, Egypt","Sharma S., Chitkara University, Institute of Engineering and Technology, Chitkara University, Baddi, India; Gupta S., Chitkara University, Institute of Engineering and Technology, Chitkara University, Rajpura, India; Gupta D., Chitkara University, Institute of Engineering and Technology, Chitkara University, Rajpura, India; Rashid J., Department of Computer Science and Engineering, Kongju National University, Cheonan, South Korea; Juneja S., KIET Group of Institutions, Ghaziabad, India; Kim J., Department of Computer Science and Engineering, Kongju National University, Cheonan, South Korea, Department of Software, Kongju National University, Cheonan, South Korea; Elarabawy M.M., Department of Computer Science, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia, Department of Mathematics, Faculty of Science, Suez Canal University, Ismailia, Egypt","Recent advancement in the field of deep learning has provided promising performance for the analysis of medical images. Every year, pneumonia is the leading cause for death of various children under the age of 5 years. Chest X-rays are the first technique that is used for the detection of pneumonia. Various deep learning and computer vision techniques can be used to determine the virus which causes pneumonia using Chest X-ray images. These days, it is possible to use Convolutional Neural Networks (CNN) for the classification and analysis of images due to the availability of a large number of datasets. In this work, a CNN model is implemented for the recognition of Chest X-ray images for the detection of Pneumonia. The model is trained on a publicly available Chest X-ray images dataset having two classes: Normal chest X-ray images and Pneumonic Chest X-ray images, where each class has 5000 Samples. 80% of the collected data is used for the purpose to train the model, and the rest for testing the model. The model is trained and validated using two optimizers: Adam and RMSprop. The maximum recognition accuracy of 98% is obtained on the validation dataset. The obtained results are further compared with the results obtained by other researchers for the recognition of biomedical images. Copyright © 2022 Sharma, Gupta, Gupta, Rashid, Juneja, Kim and Elarabawy.","biomedical images; chest X-rays; convolutional neural network; deep learning; optimizers","ADAM protein; accuracy; area under the curve; Article; biomedical image; computer model; computer vision; convolutional neural network; deep learning; human; image analysis; image segmentation; learning algorithm; lung infection; machine learning; pneumonia; radiodiagnosis; support vector machine; thorax radiography; training; validation process","","","","","Ministry of Science, ICT and Future Planning, MSIP, (2021R1A4A1031509); National Research Foundation of Korea, NRF; Ministry of SMEs and Startups, MSS, (S3033853)","This research was partly supported by the Technology Development Program of MSS [No. S3033853] and by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2021R1A4A1031509). ","Pneumonia, (2019); Neuman M., Lee E., Bixby S., Diperna S., Hellinger J., Markowitz R., Variability in the Interpretation of Chest Radiographs for the Diagnosis of Pneumonia in Children, J Hosp Med, 7, (2012); Williams G., Macaskill P., Kerr M., Fitzgerald D., Isaacs D., Codarini M., Variability and Accuracy in Interpretation of Consolidation on Chest Radiography for Diagnosing Pneumonia in Children Under 5 Years of Age, Pediatr Pulmonol, 48, (2013); Albahli S., Rauf H.T., Algosaibi A., Balas V.E., AI-Driven Deep CNN Approach for Multi-Label Pathology Classification Using Chest X-Rays, PeerJ Comput Sci, 7, (2021); Albahli S., Rauf H., Arif M., Nafis M., Algosaibi A., Identification of Thoracic Diseases by Exploiting Deep Neural Networks, Neural Netw, 5, (2021); Chandra T., Verma K., Pneumonia Detection on Chest X-Ray Using Machine Learning Paradigm, Proceedings of 3rd International Conference on Computer Vision and Image Processing, pp. 21-33, (2020); Yue H., Yu Q., Liu C., Huang Y., Jiang Z., Shao C., Machine Learning-Based CT Radiomics Method for Predicting Hospital Stay in Patients With Pneumonia Associated With SARS-CoV-2 Infection: A Multicenter Study, Ann Trans Med, 8, pp. 1-7, (2020); Kuo K., Talley P., Huang C., Cheng L., Predicting Hospital-Acquired Pneumonia Among Schizophrenic Patients: A Machine Learning Approach, BMC Med Inf Decision Making, 19, pp. 1-8, (2019); Meraj T., Hassan A., Zahoor S., Rauf H., Lali M., Ali L., Lungs Nodule Detection Using Semantic Segmentation and Classification With Optimal Features, Preprints, 10, (2019); Rajinikanth V., Kadry S., Damas evicius R., Taniar D., Rauf H., Machine-Learning- Scheme to Detect Choroidal-Neovascularization in Retinal OCT Image, 2021 Seventh International Conference on Bio Signals, Images, and Instrumentation (ICBSII), pp. 1-5, (2021); Kadry S., Nam Y., Rauf H., Rajinikanth V., Lawal I., Automated Detection of Brain Abnormality Using Deep-Learning-Scheme: A Study, 2021 Seventh International Conference on Bio Signals, Images, and Instrumentation (ICBSII), pp. 1-5, (2021); Rajinikanth V., Kadry S., Taniar D., Damas evicius R., Rauf H., Breast-Cancer Detection Using Thermal Images With Marine-Predators-Algorithm Selected Features, 2021 Seventh International Conference on Bio Signals, Images, And Instrumentation (ICBSII), pp. 1-6, (2021); Tuncer T., Ozyurt F., Dogan S., Subasi A., A Novel Covid-19 and Pneumonia Classification Method Based on F-Transform, Chemometr Intell Lab Syst, 210, (2021); Sharma H., Jain J., Bansal P., Gupta S., Feature Extraction and Classification of Chest X-Ray Images Using Cnn to Detect Pneumonia, 2020 10th International Conference On Cloud Computing, Data Science & Engineering (Confluence), (2020); Stephen O., Sain M., Maduh U., Jeong D., An Efficient Deep Learning Approach to Pneumonia Classification in Healthcare, J Healthcare Eng, 2019, pp. 1-7, (2019); Rajpurkar P., Irvin J., Zhu K., Yang B., Mehta H., Duan T., Chexnet: Radiologist-Level Pneumonia Detection on Chest X-Rays With Deep Learning, (2017); Juneja S., Dhiman G., Kautish S., Viriyasitavat W., Yadav K., A Perspective Roadmap for IoMT-Based Early Detection and Care of the Neural Disorder, Dementia, J Healthcare Eng, 2021, pp. 1-11, (2021); Sharma S., Gupta S., Gupta D., Juneja S., Singal G., Dhiman G., Et al., Recognition of Gurmukhi Handwritten City Names Using Deep Learning and Cloud Computing, Sci Program, 2022, pp. 1-16, (2022); Dhankhar A., Juneja S., Juneja A., Bali V., Kernel Parameter Tuning to Tweak the Performance of Classifiers for Identification of Heart Diseases, Int J E-Health Med Commun, 12, 4, pp. 1-16, (2021); Kumar N., Gupta M., Gupta D., Tiwari S., Novel Deep Transfer Learning Model for COVID-19 Patient Detection Using X-Ray Chest Images, J Ambient Intell Humaniz Comput, 2021, pp. 1-10, (2021); Dhiman G., Juneja S., Viriyasitavat W., Mohafez H., Hadizadeh M., Islam M.A., Et al., A Novel Machine-Learning-Based Hybrid CNN Model for Tumor Identification in Medical Image Processing, Sustainability (Switzerland), 14, 3, pp. 1-13, (2022); Dhiman G., Rashid J., Kim J., Juneja S., Viriyasitavat W., Gulati K., Privacy for Healthcare Data Using the Byzantine Consensus Method, IETE J Res, 2022, pp. 1-12, (2022); Chowdhary C.L., Alazab M., Chaudhary A., Hakak S., Gadekallu T.R., Computer Vision and Recognition Systems Using Machine and Deep Learning Approaches: Fundamentals, Technologies and Application, (2021); Ali T.M., Nawaz A., Rehman A.U., Ahmad R.Z., Javed A.R., Gadekallu T.R., Et al., A Sequential Machine Learning Cum Attention Mechanism for Effective Segmentation of Brain Tumor, Front Oncol, 2129, (2022); Mannan A., Abbasi A., Javed A.R., Ahsan A., Gadekallu T.R., Xin Q., Hypertuned Deep Convolutional Neural Network for Sign Language Recognition, Comput Intell Neurosci, 2022, pp. 1-10, (2022); Sharma S., Gupta S., Gupta D., Juneja S., Gupta P., Dhiman G., Et al., Deep Learning Model for the Automatic Classification of White Blood Cells, Comput Intell Neurosci, 2022, pp. 1-13, (2022); Rahman T., Chowdhury M., Khandakar A., Islam K., Islam K., Mahbub Z., Transfer Learning With Deep Convolutional Neural Network (CNN) for Pneumonia Detection Using Chest X-Ray, Appl Sci, 10, (2020)","J. Rashid; Department of Computer Science and Engineering, Kongju National University, Cheonan, South Korea; email: junaidrashid062@gmail.com; J. Kim; Department of Computer Science and Engineering, Kongju National University, Cheonan, South Korea; email: jekim@kongju.ac.kr","","Frontiers Media S.A.","","","","","","2234943X","","","","English","Front. Oncol.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85134156021"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14450 LNCS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178556551&partnerID=40&md5=b0b91f9a575c994470ccc3db9fb3ab6e","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","03029743","978-981998069-7","","","English","Lect. Notes Comput. Sci.","Conference review","Final","","Scopus","2-s2.0-85178556551"
"Rachmadi M.F.; Byra M.; Skibbe H.","Rachmadi, Muhammad Febrian (54974181500); Byra, Michal (56414988400); Skibbe, Henrik (14021955900)","54974181500; 56414988400; 14021955900","A new family of instance-level loss functions for improving instance-level segmentation and detection of white matter hyperintensities in routine clinical brain MRI","2024","Computers in Biology and Medicine","174","","108414","","","","0","10.1016/j.compbiomed.2024.108414","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189928902&doi=10.1016%2fj.compbiomed.2024.108414&partnerID=40&md5=201cdad67fee8975ed00ebd4596a05d6","Brain Image Analysis Unit, RIKEN Center for Brain Science, Wako-shi, Japan; Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland","Rachmadi M.F., Brain Image Analysis Unit, RIKEN Center for Brain Science, Wako-shi, Japan, Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia; Byra M., Brain Image Analysis Unit, RIKEN Center for Brain Science, Wako-shi, Japan, Institute of Fundamental Technological Research, Polish Academy of Sciences, Warsaw, Poland; Skibbe H., Brain Image Analysis Unit, RIKEN Center for Brain Science, Wako-shi, Japan","In this study, we introduce “instance loss functions”, a new family of loss functions designed to enhance the training of neural networks in the instance-level segmentation and detection of objects in biomedical image data, particularly those of varied numbers and sizes. Intended to be utilized conjointly with traditional loss functions, these proposed functions, prioritize object instances over pixel-by-pixel comparisons. The specific functions, the instance segmentation loss (Linstance), the instance center loss (Lcenter), the false instance rate loss (Lfalse), and the instance proximity loss (Lproximity), serve distinct purposes. Specifically, Linstance improves instance-wise segmentation quality, Lcenter enhances segmentation quality of small instances, Lfalse minimizes the rate of false and missed detections across varied instance sizes, and Lproximity improves detection quality by pulling predicted instances towards the ground truth instances. Through the task of segmenting white matter hyperintensities (WMH) in brain MRI, we benchmarked our proposed instance loss functions, both individually and in combination via an ensemble inference models approach, against traditional pixel-level loss functions. Data were sourced from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and the WMH Segmentation Challenge datasets, which exhibit significant variation in WMH instance sizes. Empirical evaluations demonstrate that combining two instance-level loss functions through ensemble inference models outperforms models using other loss function on both the ADNI and WMH Segmentation Challenge datasets for the segmentation and detection of WMH instances. Further, applying these functions to the segmentation of nuclei in histopathology images demonstrated their effectiveness and generalizability beyond WMH, improving performance even in contexts with less severe instance imbalance. © 2024 The Author(s)","Brain lesions; Ensemble inference; Instance-level detection loss; Instance-level segmentation loss; White matter hyperintensities","Algorithms; Alzheimer Disease; Brain; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; White Matter; Image enhancement; Image segmentation; Magnetic resonance imaging; Neurodegenerative diseases; Neuroimaging; Object detection; Brain lesions; Brain MRI; Detection loss; Ensemble inference; Instance-level detection loss; Instance-level segmentation loss; Level detections; Loss functions; Segmentation quality; White matter hyperintensities; Alzheimer disease; Article; artificial neural network; brain; comparative study; deep learning; fluid-attenuated inversion recovery imaging; human; image segmentation; instance loss function; major clinical study; neuroimaging; nuclear magnetic resonance imaging; qualitative analysis; quantitative analysis; size; T2 weighted imaging; white matter; algorithm; computer assisted diagnosis; diagnostic imaging; procedures; Pixels","","","","","RIKEN; Fakultas Ilmu Komputer, Universitas Indonesia, CS UI; Japan Agency for Medical Research and Development, AMED, (JP15dm0207001); Japan Agency for Medical Research and Development, AMED","Funding text 1: Funds from RIKEN\u2019s Special Postdoctoral Researchers (SPDR) program gratefully acknowledged (MFR). This research was also supported by the program for Brain Mapping by Integrated Neurotechnologies for Disease Studies (Brain/MINDS) from the Japan Agency for Medical Research and Development AMED ( JP15dm0207001 ). Library access provided by the Faculty of Computer Science, Universitas Indonesia is also gratefully acknowledged. ; Funding text 2: Funds from RIKEN's Special Postdoctoral Researchers (SPDR) program, Japan are gratefully acknowledged (MFR). This research was also supported by the program for Brain Mapping by Integrated Neurotechnologies for Disease Studies (Brain/MINDS) from the Japan Agency for Medical Research and Development AMED (JP15dm0207001). Library access provided by the Faculty of Computer Science, Universitas Indonesia is also gratefully acknowledged.","Wardlaw J.M., Smith E.E., Biessels G.J., Cordonnier C., Fazekas F., Frayne R., Lindley R.I., O'Brien J.T., Barkhof F., Benavente O.R., Black S.E., Brayne C., Breteler M., Chabriat H., Decarli C., de Leeuw F.-E., Doubal F., Duering M., Fox N.C., Greenberg S., Hachinski V., Kilimann I., Mok V., Oostenbrugge R.V., Pantoni L., Speck O., Stephan B.C.M., Teipel S., Viswanathan A., Werring D., Chen C., Smith C., van Buchem M., Norrving B., Gorelick P.B., Dichgans M., Neuroimaging standards for research into small vessel disease and its contribution to ageing and neurodegeneration, Lancet Neurol., 12, 8, pp. 822-838, (2013); Rachmadi M.F., Valdes-Hernandez M.D.C., Agan M.L.F., Di Perri C., Komura T., Initiative A.D.N., Et al., Segmentation of white matter hyperintensities using convolutional neural networks with global spatial information in routine clinical brain MRI with none or mild vascular pathology, Comput. Med. Imaging Graph., 66, pp. 28-43, (2018); Sudre C.H., Van Wijnen K., Dubost F., Adams H., Atkinson D., Barkhof F., Birhanu M.A., Bron E.E., Camarasa R., Chaturvedi N., Et al., Where is VALDO? Vascular lesions detection and segmentation challenge at MICCAI 2021, Medical Image Analysis, 91, (2024); Guerrero R., Qin C., Oktay O., Bowles C., Chen L., Joules R., Wolz R., Valdes-Hernandez M.D.C., Dickie D.A., Wardlaw J., Et al., White matter hyperintensity and stroke lesion segmentation and differentiation using convolutional neural networks, NeuroImage: Clin., 17, pp. 918-934, (2018); Kabir Y., Dojat M., Scherrer B., Forbes F., Garbay C., Multimodal MRI segmentation of ischemic stroke lesions, 2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, pp. 1595-1598, (2007); Clerigues A., Valverde S., Bernal J., Freixenet J., Oliver A., Llado X., Acute ischemic stroke lesion core segmentation in CT perfusion images using fully convolutional neural networks, Comput. Biol. Med., 115, (2019); Zeng C., Gu L., Liu Z., Zhao S., Review of deep learning approaches for the segmentation of multiple sclerosis lesions on brain MRI, Front. Neuroinform., 14, (2020); Commowick O., Kain M., Casey R., Ameli R., Ferre J.-C., Kerbrat A., Tourdias T., Cervenansky F., Camarasu-Pop S., Glatard T., Et al., Multiple sclerosis lesions segmentation from multiple experts: The MICCAI 2016 challenge dataset, Neuroimage, 244, (2021); Milletari F., Navab N., Ahmadi S.-A., V-net: Fully convolutional neural networks for volumetric medical image segmentation, 2016 Fourth International Conference on 3D Vision, 3DV, pp. 565-571, (2016); Reinke A., Tizabi M.D., Sudre C.H., Eisenmann M., Radsch T., Baumgartner M., Acion L., Antonelli M., Arbel T., Bakas S., Et al., Common limitations of image processing metrics: A picture story, (2021); Kofler F., Shit S., Ezhov I., Fidon L., Horvath I., Al-Maskari R., Li H.B., Bhatia H., Loehr T., Piraud M., Et al., Blob loss: instance imbalance aware loss functions for semantic segmentation, International Conference on Information Processing in Medical Imaging, pp. 755-767, (2023); Yi-de M., Qing L., Zhi-Bai Q., Automated image segmentation using improved PCNN model based on cross-entropy, Proceedings of 2004 International Symposium on Intelligent Multimedia, Video and Speech Processing, 2004, pp. 743-746, (2004); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection,, Proceedings of the IEEE International Conference on Computer Vision, pp. 2980-2988, (2017); Sudre C.H., Li W., Vercauteren T., Ourselin S., Jorge Cardoso M., Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 240-248, (2017); Yeung M., Sala E., Schonlieb C.-B., Rundo L., Unified focal loss: Generalising dice and cross entropy-based losses to handle class imbalanced medical image segmentation, Comput. Med. Imaging Graph., 95, (2022); Jadon S., A survey of loss functions for semantic segmentation, 2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology, CIBCB, pp. 1-7, (2020); Ma J., Chen J., Ng M., Huang R., Li Y., Li C., Yang X., Martel A.L., Loss odyssey in medical image segmentation, Med. Image Anal., 71, (2021); Rachmadi M.F., Poon C., Skibbe H., Improving segmentation of objects with varying sizes in biomedical images using instance-wise and center-of-instance segmentation loss function, International Conference on Medical Imaging with Deep Learning, (2023); Rensma S.P., van Sloten T.T., Launer L.J., Stehouwer C.D., Cerebral small vessel disease and risk of incident stroke, dementia and depression, and all-cause mortality: A systematic review and meta-analysis, Neurosci. Biobehav. Rev., (2018); Pohjasvaara T., Mantyla R., Salonen O., Aronen H.J., Ylikoski R., Hietanen M., Kaste M., Erkinjuntti T., How complex interactions of ischemic brain infarcts, white matter lesions, and atrophy relate to poststroke dementia, Arch. Neurol., 57, 9, pp. 1295-1300, (2000); Valdes Hernandez M.D.C., Booth T., Murray C., Gow A.J., Penke L., Morris Z., Maniega S.M., Royle N.A., Aribisala B.S., Bastin M.E., Et al., Brain white matter damage in aging and cognitive ability in youth and older age, Neurobiol. Aging, 34, 12, pp. 2740-2747, (2013); Wardlaw J.M., Smith E.E., Biessels G.J., Cordonnier C., Fazekas F., Frayne R., Lindley R.I., T O'Brien J., Barkhof F., Benavente O.R., Et al., Neuroimaging standards for research into small vessel disease and its contribution to ageing and neurodegeneration, Lancet Neurol., 12, 8, pp. 822-838, (2013); Valdes Hernandez M.D.C., Piper R.J., Wang X., Deary I.J., Wardlaw J.M., Towards the automatic computational assessment of enlarged perivascular spaces on brain magnetic resonance images: a systematic review, J. Magn. Reson. Imaging, 38, 4, pp. 774-785, (2013); Maulana R., Rachmadi M.F., Rahadianti L., Robustness of probabilistic U-net for automated segmentation of white matter hyperintensities in different datasets of brain MRI, 2021 International Conference on Advanced Computer Science and Information Systems, ICACSIS, pp. 1-7, (2021); Wang X., Hernandez M.C.V., Doubal F., Chappell F.M., Wardlaw J.M., How much do focal infarcts distort white matter lesions and global cerebral atrophy measures?, Cerebrovasc. Dis., 34, 5-6, pp. 336-342, (2012); Zheng Z., Wang P., Liu W., Li J., Ye R., Ren D., Distance-IoU loss: Faster and better learning for bounding box regression,, Proceedings of the AAAI Conference on Artificial Intelligence,, 34, pp. 12993-13000, (2020); Riba E., Mishkin D., Ponsa D., Rublee E., Bradski G., Kornia: an open source differentiable computer vision library for pytorch,, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 3674-3683, (2020); Mueller S.G., Weiner M.W., Thal L.J., Petersen R.C., Jack C., Jagust W., Trojanowski J.Q., Toga A.W., Beckett L., The Alzheimer's disease neuroimaging initiative, Neuroimaging Clin. North Am., 15, 4, pp. 869-877, (2005); Weiner M.W., Veitch D.P., Aisen P.S., Beckett L.A., Cairns N.J., Green R.C., Harvey D., Jack C.R., Jagust W., Liu E., Et al., The Alzheimer's disease neuroimaging initiative: A review of papers published since its inception, Alzheimer's Dementia, 8, 1, pp. S1-S68, (2012); Lutkenhoff E.S., Rosenberg M., Chiang J., Zhang K., Pickard J.D., Owen A.M., Monti M.M., Optimized brain extraction for pathological brains (optiBET), PLoS One, 9, 12, (2014); Valdes-Hernandez M.D.C., Reid S., Mikhael S., Pernet C., Initiative A.D.N., Et al., Do 2-year changes in superior frontal gyrus and global brain atrophy affect cognition?, Alzheimer's Dementia: Diagn. Assess. Dis. Monit., 10, pp. 706-716, (2018); Harper A.M., Clayson L., Wardlaw J.M., Valdes Hernandez M.D.C., Initiative A.D.N., Considerations on accuracy, pattern and possible underlying factors of brain microbleed progression in older adults with absence or mild presence of vascular pathology, J. Int. Med. Res., 46, 9, pp. 3518-3538, (2018); Jeong Y., Rachmadi M.F., Valdes-Hernandez M.D.C., Komura T., Dilated saliency u-net for white matter hyperintensities segmentation using irregularity age map, Front. Aging Neurosci., 11, (2019); Rachmadi M.F., Valdes-Hernandez M.D.C., Li H., Guerrero R., Meijboom R., Wiseman S., Waldman A., Zhang J., Rueckert D., Wardlaw J., Et al., Limited one-time sampling irregularity map (lots-im) for automatic unsupervised assessment of white matter hyperintensities and multiple sclerosis lesions in structural brain magnetic resonance images, Comput. Med. Imaging Graph., 79, (2020); Valdes Hernandez M., Reference Segmentations of White Matter Hyperintensities from a Subset of 20 Subjects Scanned Three Consecutive Years, 2010–2014 [dataset], (2016); Cosgrove K.P., Mazure C.M., Staley J.K., Evolving knowledge of sex differences in brain structure, function, and chemistry, Biol. Psychiatry, 62, 8, pp. 847-855, (2007); Sled J., Zijdenbos A., Evans A., A nonparametric method for automatic correction of intensity nonuniformity in MRI data, IEEE Trans. Med. Imaging, 17, 1, pp. 87-97, (1998); Deisenroth M.P., Faisal A.A., Ong C.S., Mathematics for Machine Learning, (2020); Hatamizadeh A., Tang Y., Nath V., Yang D., Myronenko A., Landman B., Roth H.R., Xu D., Unetr: Transformers for 3d medical image segmentation,, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 574-584, (2022); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, (2015); Kuijf H.J., Biesbroek J.M., De Bresser J., Heinen R., Andermatt S., Bento M., Berseth M., Belyaev M., Cardoso M.J., Casamitjana A., Et al., Standardized assessment of automatic segmentation of white matter hyperintensities and results of the WMH segmentation challenge, IEEE Trans. Med. Imaging, 38, 11, pp. 2556-2568, (2019); Isensee F., Jaeger P.F., Kohl S.A., Petersen J., Maier-Hein K.H., nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation, Nat. Methods, 18, 2, pp. 203-211, (2021); Salehi S.S.M., Erdogmus D., Gholipour A., Tversky loss function for image segmentation using 3D fully convolutional deep networks, International Workshop on Machine Learning in Medical Imaging, pp. 379-387, (2017); Shirokikh B., Shevtsov A., Kurmukov A., Dalechina A., Krivov E., Kostjuchenko V., Golanov A., Belyaev M., Universal loss reweighting to balance lesion size inequality in 3D medical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 523-532, (2020); Cardoso M.J., Li W., Brown R., Ma N., Kerfoot E., Wang Y., Murray B., Myronenko A., Zhao C., Yang D., Nath V., He Y., Xu Z., Hatamizadeh A., Zhu W., Liu Y., Zheng M., Tang Y., Yang I., Zephyr M., Hashemian B., Alle S., Zalbagi Darestani M., Budd C., Modat M., Vercauteren T., Wang G., Li Y., Hu Y., Fu Y., Gorman B., Johnson H., Genereaux B., Erdal B.S., Gupta V., Diaz-Pinto A., Dourson A., Maier-Hein L., Jaeger P.F., Baumgartner M., Kalpathy-Cramer J., Flores M., Kirby J., Cooper L.A., Roth H.R., Xu D., Bericat D., Floca R., Zhou S.K., Shuaib H., Farahani K., Maier-Hein K.H., Aylward S., Dogra P., Ourselin S., Feng A., MONAI: An open-source framework for deep learning in healthcare, (2022); Eisenmann M., Reinke A., Weru V., Tizabi M.D., Isensee F., Adler T.J., Ali S., Andrearczyk V., Aubreville M., Baid U., Et al., pp. 19955-19966, (2023); Kirillov A., He K., Girshick R., Rother C., Dollar P., Panoptic segmentation, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9404-9413, (2019); Kofler F., Moller H., Buchner J.A., de la Rosa E., Ezhov I., Rosier M., Mekki I., Shit S., Negwer M., Al-Maskari R., Et al., Panoptica–instance-wise evaluation of 3D semantic and instance segmentation maps, (2023); Park G., Hong J., Duffy B.A., Lee J.-M., Kim H., White matter hyperintensities segmentation using the ensemble U-net with multi-scale highlighting foregrounds, Neuroimage, 237, (2021); Naylor P., Lae M., Reyal F., Walter T., Segmentation of nuclei in histopathology images by deep regression of the distance map, IEEE Trans. Med. Imaging, 38, 2, pp. 448-459, (2018); Balakrishnan R., Hernandez M.D.C.V., Farrall A.J., Automatic segmentation of white matter hyperintensities from brain magnetic resonance images in the era of deep learning and big data–A systematic review, Comput. Med. Imaging Graph., 88, (2021); Kohl S., Romera-Paredes B., Meyer C., De Fauw J., Ledsam J.R., Maier-Hein K., Eslami S., Jimenez Rezende D., Ronneberger O., A probabilistic u-net for segmentation of ambiguous images, Adv. Neural Inf. Process. Syst., 31, (2018); Rahman A., Valanarasu J.M.J., Hacihaliloglu I., Patel V.M., Ambiguous medical image segmentation using diffusion models,, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 11536-11546, (2023)","M.F. Rachmadi; Brain Image Analysis Unit, RIKEN Center for Brain Science, Wako-shi, Japan; email: febrian.rachmadi@riken.jp","","Elsevier Ltd","","","","","","00104825","","CBMDA","38599072","English","Comput. Biol. Med.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85189928902"
"Ghosh A.; Jana N.D.; Mallik S.; Zhao Z.","Ghosh, Arjun (57219433879); Jana, Nanda Dulal (54795488300); Mallik, Saurav (56213777000); Zhao, Zhongming (57755838500)","57219433879; 54795488300; 56213777000; 57755838500","Designing optimal convolutional neural network architecture using differential evolution algorithm","2023","Patterns","","","100567","","","","15","10.1016/j.patter.2022.100567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141740726&doi=10.1016%2fj.patter.2022.100567&partnerID=40&md5=e3c68f927cd38442a20565a288744ac9","Department of Computer Science and Engineering, National Institute of Technology Durgapur, West Bengal, Durgapur, 713209, India; Center for Precision Health, School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Molecular and Integrative Physiological Sciences, Department of Environmental Health, Harvard T. H. Chan School of Public Health, Boston, 02115, MA, United States","Ghosh A., Department of Computer Science and Engineering, National Institute of Technology Durgapur, West Bengal, Durgapur, 713209, India; Jana N.D., Department of Computer Science and Engineering, National Institute of Technology Durgapur, West Bengal, Durgapur, 713209, India; Mallik S., Center for Precision Health, School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States, Molecular and Integrative Physiological Sciences, Department of Environmental Health, Harvard T. H. Chan School of Public Health, Boston, 02115, MA, United States; Zhao Z., Center for Precision Health, School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States","Convolutional neural networks (CNNs) are deep learning models used widely for solving various tasks like computer vision and speech recognition. CNNs are developed manually based on problem-specific domain knowledge and tricky settings, which are laborious, time consuming, and challenging. To solve these, our study develops an improved differential evolution of convolutional neural network (IDECNN) algorithm to design CNN layer architectures for image classification. Variable-length encoding is utilized to represent the flexible layer architecture of a CNN model in IDECNN. An efficient heuristic mechanism is proposed in IDECNN to evolve CNN architecture through mutation and crossover to prevent premature convergence during the evolutionary process. Eight well-known imaging datasets were utilized. The results showed that IDECNN could design suitable architecture compared with 20 existing CNN models. Finally, CNN architectures are applied to pneumonia and coronavirus disease 2019 (COVID-19) X-ray biomedical image data. The results demonstrated the usefulness of the proposed approach to generate a suitable CNN model. © 2022 The Author(s)","CNN; convolutional neural network; DE; differential evolution; DSML3: Development/pre-production: data science output has been rolled out/validated across multiple domains/problems; image classification; NAS; neural architecture search; neuroevolution; optimal neural architecture","Convolution; Convolutional neural networks; Deep learning; Domain Knowledge; Evolutionary algorithms; Image enhancement; Multilayer neural networks; Network architecture; Optimization; Speech recognition; Convolutional neural network; DE; Differential Evolution; Domain problems; DSML3: development/pre-production: data science output have been rolled out/validated across multiple domain/problem; Images classification; Multiple domains; NAS; Neural architecture search; Neural architectures; Neuro evolutions; Optimal neural architecture; Pre-production; Production data; Image classification","","","","","Cancer Prevention and Research Institute of Texas, CPRIT, (180734); Cancer Prevention and Research Institute of Texas, CPRIT","The authors thank Dr. Irmgard Willcockson for professional English editing services. Z.Z. was partially supported by the Cancer Prevention and Research Institute of Texas ( CPRIT 180734 ). The funders did not participate in the study design, data analysis, decision to publish, or preparation of the manuscript. ","Gaur L., Bhandari M., Razdan T., Mallik S., Zhao Z., Explanation-driven deep learning model for prediction of brain tumour status using mri image data, Front. Genet., 13, (2022); Sharma P., Balabantaray B.K., Bora K., Mallik S., Kasugai K., Zhao Z., An ensemble-based deep convolutional neural network for computer-aided polyps identification from colonoscopy, Front. Genet., 13, (2022); Karri M., Annavarapu C.S.R., Mallik S., Zhao Z., Acharya U.R., Multi-class nucleus detection and classification using deep convolutional neural network with enhanced high dimensional dissimilarity translation model on cervical cells, Biocybern. Biomed. Eng., 42, pp. 797-814, (2022); Voulodimos A., Doulamis N., Doulamis A., Protopa- padakis E., Deep learning for computer vision: a brief review, Comput. Intell. Neurosci., 2018, pp. 7068349-7068361, (2018); Nassif A.B., Shahin I., Attili I., Azzeh M., Shaalan K., Speech recognition using deep neural networks: a systematic review, IEEE Access, 7, pp. 19143-19165, (2019); Pei G., Hu R., Jia P., Zhao Z., Deepfun: a deep learning sequence-based model to decipher non-coding variant effect in a tissue-and cell type-specific manner, Nucleic Acids Res., 49, pp. W131-W139, (2021); Xu H., Jia P., Zhao Z., Deepvisp: deep learning for virus site integration prediction and motif discovery, Adv. Sci., 8, (2021); Umer S., Mondal R., Pandey H.M., Rout R.K., Deep features based convolutional neural network model for text and non-text region segmentation from document images, Appl. Soft Comput., 113, (2021); Umer S., Mohanta P.P., Rout R.K., Pandey H.M., Machine learning method for cosmetic product recognition: a visual searching approach, Multimed. Tool. Appl., 80, pp. 34997-35023, (2021); Lecun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc. IEEE, 86, pp. 2278-2324, (2001); Simonyan K., Zisserman A., Very deep convo- lutional networks for large-scale image recognition, axRiv, (2015); Krizhevsky A., Hinton G., Learning Multiple Layers of Features from Tiny Images, (2009); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1-9, (2015); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778, (2016); Ren P., Xiao Y., Chang X., Huang P.-Y., Li Z., Chen X., Wang X., A comprehensive survey of neural architecture search: challenges and solutions, ACM Comput. Surv., 54, pp. 1-34, (2022); Bandyopadhyay S., Mallik S., Mukhopadhyay A., A survey and comparative study of statistical tests for identifying differential expression from microarray data, IEEE ACM Trans. Comput. Biol. Bioinf, 11, pp. 95-115, (2014); Mallik S., Zhao Z., Graph- and rule-based learning algorithms: a comprehensive review of their applications for cancer type classification and prognosis using genomic data, Briefings Bioinf., 21, pp. 368-394, (2020); Elsken T., Metzen J.H., Hutter F., Neural architecture search: a survey, J. Mach. Learn. Res., 20, pp. 1-21, (2019); Liu Y., Sun Y., Xue B., Zhang M., Yen G.G., Tan K.C., A survey on evolutionary neural architecture search, IEEE Transact. Neural Networks Learn. Syst., pp. 1-21, (2021); White C., Neiswanger W., Nolen S., Savani Y., A study on encodings for neural architecture search, Adv. Neural Inf. Process. Syst., 33, pp. 20309-20319, (2020); Ahmad M., Abdullah M., Han D., A novel encoding scheme for complex neural architecture search, 34th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC), pp. 1-4, (2019); Kang D., Ahn C.W., Efficient neural network space with genetic search, International Conference on Bio-Inspired Computing: Theories and Applications, pp. 638-646, (2019); Real E., Moore S., Selle A., Saxena S., Suematsu Y.L., Tan J., Le Q.V., Kurakin A., Large-scale evolution of image classifiers, International Conference on Machine Learning, pp. 2902-2911, (2017); Zheng X., Ji R., Wang Q., Ye Q., Li Z., Tian Y., Tian Q., Rethinking performance estimation in neural architecture search, IEEE Conference on Computer Vision and Pattern Recognition, pp. 11356-11365, (2020); Sun Y., Sun X., Fang Y., Yen G.G., Liu Y., A novel training protocol for performance predictors of evolutionary neural architecture search algorithms, IEEE Trans. Evol. Comput., 25, pp. 524-536, (2021); Tan H., Cheng R., Huang S., He C., Qiu C., Yang F., Luo P., Relativenas: Relative neural architecture search via slow-fast learning, IEEE Transact. Neural Networks Learn. Syst., pp. 1-15, (2021); Real E., Aggarwal A., Huang Y., Le Q.V., Regularized evolution for image classifier architecture search, AAAI Conference on Artificial Intelligence, 33, pp. 4780-4789, (2019); Sun Y., Xue B., Zhang M., Yen G.G., Evolving deep convolutional neural networks for image classification, IEEE Trans. Evol. Comput., 24, pp. 394-407, (2020); Suganuma M., Shirakawa S., Nagao T., A genetic programming approach to designing convolutional neural network architectures, 27th International Joint Conference on Artificial Intelligence, pp. 5369-5373, (2018); Byla E., Pang W., Deepswarm: Optimising Convo- Lutional Neural Networks Using Swarm Intelligence, pp. 119-130, (2019); Fernandes Junior F.E., Yen G.G., Particle swarm optimization of deep neural networks architectures for image classification, Swarm Evol. Comput., 49, pp. 62-74, (2019); Wang B., Sun Y., Xue B., Zhang M., A hybrid differential evolution approach to designing deep convo- lutional neural networks for image classification, Australasian Joint Conference on Artificial Intelligence, pp. 237-250, (2018); Das S., Mullick S.S., Suganthan P.N., Recent advances in differential evolution-an updated survey, Swarm Evol. Comput., 27, pp. 1-30, (2016); Al-Dabbagh R.D., Neri F., Idris N., Baba M.S., Algorithmic design issues in adaptive differential evolution schemes: review and taxonomy, Swarm Evol. Comput., 43, pp. 284-311, (2018); Segredo E., Lalla-Ruiz E., Hart E., Voss S., A similarity-based neighbourhood search for enhancing the balance exploration-exploitation of differential evolution, Comput. Oper. Res., 117, (2020); Awad N., Mallik N., Hutter F., Differential evolution for neural architecture search, 1st workshop on neural architecture search(@ICLR'20), (2020); Li Z., Liu F., Yang W., Peng S., Zhou J., A survey of convolutional neural networks: analysis, applications, and prospects, IEEE Transact. Neural Networks Learn. Syst., pp. 1-21, (2021); Pei G., Hu R., Dai Y., Manuel A.M., Zhao Z., Jia P., Predicting regulatory variants using a dense epige- nomic mapped cnn model elucidated the molecular basis of trait-tissue associations, Nucleic Acids Res., 49, pp. 53-66, (2021); Li B., Pei G., Yao J., Ding Q., Jia P., Zhao Z., Cell-type deconvolution analysis identifies cancer-associated myofibroblast component as a poor prognostic factor in multiple cancer types, Oncogene, 40, pp. 4686-4694, (2021); Rawat W., Wang Z., Deep convolutional neural networks for image classification: a comprehensive review, Neural Comput., 29, pp. 2352-2449, (2017); Jogin M., Madhulika M.S., Divya G.D., Meghana R.K., Apoorva S., Feature extraction using convolution neural networks (cnn) and deep learning, 2018 3rd IEEE International Conference on Recent Trends in Electronics, pp. 2319-2323, (2018); Das S., Suganthan P.N., Differential evolution: a survey of the state-of-the-art, IEEE Trans. Evol. Comput., 15, pp. 4-31, (2011); Xie L., Yuille A.L., Genetic cnn, IEEE International Conference on Computer Vision (ICCV), pp. 1388-1397, (2017); Dong J., Zhang L., Hou B., Feng L., A memetic algorithm for evolving deep convolutional neural network in image classification, 2020 IEEE Symposium Series on Computational Intelligence (SSCI), pp. 2663-2669, (2020); Wang B., Sun Y., Xue B., Zhang M., Evolving deep convolutional neural networks by variable-length particle swarm optimization for image classification, IEEE Congress on Evolutionary Computation (CEC), pp. 1-8, (2018); Wistuba M., Rawat A., Pedapati T., A survey on neural architecture search, arXiv, (2019); Xu Y., Goodacre R., On splitting training and validation set: a comparative study of cross-validation, bootstrap and systematic sampling for estimating the generalization performance of supervised learning, J. Anal. Test., 2, pp. 249-262, (2018); Chang O., Flokas L., Lipson H., Principled weight initialization for hypernetworks, International Conference on Learning Representations, (2020); Agarap A.F., Deep learning using rectified linear units (relu), arXiv, (2018); Kingma D.P., Ba J.L., Adam: a method for stochastic optimization, International Conference on Learning Representations, (2015); Zhou Y., Wang X., Zhang M., Zhu J., Zheng R., Wu Q., Mpce: a maximum probability based cross entropy loss function for neural network classification, IEEE Access, 7, pp. 146331-146341, (2019); Larochelle H., Erhan D., Courville A., Bergstra J., Ben- gio Y., An empirical evaluation of deep architectures on problems with many factors of variation, Proceedings of the 24th international conference on Machine learning, pp. 473-480, (2007); Sohn K., Lee H., Learning invariant representations with local transformations, Proceedings of the 29th International Conference on Machine Learning, pp. 1339-1346, (2012); Sohn K., Zhou G., Lee C., Lee H., Learning and selecting features jointly with point-wise gated Boltzmann machines, 30th International Conference on Machine Learning, pp. 217-225, (2013); Chan T.H., Jia K., Gao S., Lu J., Zeng Z., Ma Y., Pcanet: a simple deep learning baseline for image classification?, IEEE Trans. Image Process., 24, pp. 5017-5032, (2015); Gamperle R., Muller S.D., Koumoutsakos P., A parameter study for differential evolution, Advances in intelligent systems, fuzzy systems, evolutionary computation, 10, pp. 293-298, (2002); Guo Y., Liu Y., Oerlemans A., Lao S., Wu S., Lew M.S., Deep learning for visual understanding: a review, Neurocomputing, 187, pp. 27-48, (2016); Ioffe S., Szegedy C., Batch normalization: accelerating deep network training by reducing internal covariate shift, International conference on machine learning, pp. 448-456, (2015); Guo D., Wang X., Gao K., Jin Y., Ding J., Chai T., Evolutionary optimization of high-dimensional multi- objective and many-objective expensive problems assisted by a dropout neural network, IEEE Trans. Syst. Man Cybern. Syst., 52, pp. 2084-2097, (2022); Kermany D., Zhang K., Goldbaum M., Labeled optical coherence tomography (oct) and chest x-ray images for classification, Mendeley data, 2, (2018); Ruby U., Yendapalli V., Binary cross entropy with deep learning technique for image classification, Int. J. Adv. Trends Comput. Sci. Eng., 9, pp. 5393-5397, (2020); Pratiwi H., Windarto A.P., Susliansyah S., Aria R.R., Susilowati S., Rahayu L.K., Fitriani Y., Merdekawati A., Rahadjeng I.R., Sigmoid activation function in selecting the best model of artificial neural networks, J. Phys, Conf. Ser., 1471, (2020); Rahman T., Khandakar A., Qiblawey Y., Tahir A., Kiranyaz S., Abul Kashem S.B., Islam M.T., Al Maadeed S., Zughaier S.M., Khan M.S., Chowdhury M.E.H., Exploring the effect of image enhancement techniques on covid-19 detection using chest x- ray images, Comput. Biol. Med., 132, (2021)","Z. Zhao; Center for Precision Health, School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, United States; email: zhongming.zhao@uth.tmc.edu","","Cell Press","","","","","","26663899","","","","English","Patterns","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85141740726"
"Wu H.; Lu H.; Ping M.; Zhu W.; Li Z.","Wu, Hongli (57796712300); Lu, Huijuan (55729819200); Ping, Mingzhu (57796619100); Zhu, Wenjie (57217050076); Li, Zhao (57191700056)","57796712300; 55729819200; 57796619100; 57217050076; 57191700056","A Deep Learning Method for Pneumonia Detection Based on Fuzzy Non-Maximum Suppression","2024","IEEE/ACM Transactions on Computational Biology and Bioinformatics","21","4","","902","911","9","0","10.1109/TCBB.2023.3247483","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149418789&doi=10.1109%2fTCBB.2023.3247483&partnerID=40&md5=ac5ea2f2a002e4d56b6955c7593bde58","China Jiliang University, College of Information Engineering, Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, Zhejiang, Hangzhou, 310018, China; Zhejiang Dahua Technology Co., Ltd, Zhejiang, Hangzhou, 310051, China; Zhejiang University, Zhejiang, Hangzhou, 310058, China","Wu H., China Jiliang University, College of Information Engineering, Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, Zhejiang, Hangzhou, 310018, China; Lu H., China Jiliang University, College of Information Engineering, Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, Zhejiang, Hangzhou, 310018, China; Ping M., Zhejiang Dahua Technology Co., Ltd, Zhejiang, Hangzhou, 310051, China; Zhu W., China Jiliang University, College of Information Engineering, Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, Zhejiang, Hangzhou, 310018, China; Li Z., Zhejiang University, Zhejiang, Hangzhou, 310058, China","Pneumonia is one of the largest causes of death in the world. Deep learning techniques can assist doctors to detect the areas of pneumonia in the chest X-rays images. However, existing methods lack sufficient consideration for the large variation scale and the blurred boundary of the pneumonia area. Here, we present a deep learning method based on Retinanet for pneumonia detection. First, we introduce Res2Net into Retinanet to get the multi-scale feature of pneumonia. Then, we proposed a novel predicted boxes fusion algorithm, named Fuzzy Non-Maximum Suppression (FNMS), which gets a more robust predicted box by fusing the overlapping detection boxes. Finally, we get the performance outperforms than existing methods by integrating two models with different backbones. We report the experimental result in the single model case and the model ensemble case. In the single model case, RetinaNet with FNMS algorithm and Res2Net backbone is better than RetinaNet and other models. In the model ensemble case, the final score of predicted boxes that fused by the FNMS algorithm is better than NMS, Soft-NMS, and weighted boxes fusion. Experimental results on the pneumonia detection dataset verify the superiority of the FNMS algorithm and the proposed method in the pneumonia detection task.  © 2004-2012 IEEE.","Biomedical image; deep learning; model ensemble; pneumonia detection","Algorithms; Deep Learning; Fuzzy Logic; Humans; Pneumonia; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Bioinformatics; Deep neural networks; Job analysis; Biomedical images; Convolutional neural network; Deep learning; Features extraction; Model ensembles; Pneumonia detection; Prediction algorithms; Predictive models; Task analysis; algorithm; computer assisted diagnosis; deep learning; diagnosis; diagnostic imaging; fuzzy logic; human; pneumonia; procedures; thorax radiography; Feature extraction","","","","","","","Wu Y.C., Chen C.S., Chan Y.J., The outbreak of COVID-19: An overview, J. Chin. Med. Assoc, 83, pp. 217-220, (2020); Rothan H.A., Byrareddy S.N., The epidemiology and pathogenesis of coronavirus disease (COVID-19) outbreak, J. Autoimmun, 109, (2020); Shih G., Et al., Augmenting the national institutes of health chest radiograph dataset with expert annotations of possible pneumonia, Radiol. Artif. Intell, 1, (2019); Frid-Adar M., Amer R., Gozes O., Nassar J., Greenspan H., COVID-19 in CXR: From detection and severity scoring to patient disease monitoring, IEEE J. Biomed.Health, 25, 6, pp. 1892-1903, (2021); Zhou X., Et al., Intelligent small object detection based on digital twinning for smart manufacturing in industrial CPS, IEEE Trans. Industr. Inform, 18, 2, pp. 1377-1386, (2022); Zhou X., XuW. Liang X., Zeng Z., Yan Z., Deep-learning-enhanced multitarget detection for end-edge-cloud surveillance in smart IoT, IEEE Internet Things J, 8, 16, pp. 12588-12596, (2021); Zhou X., Li AndW. Liang Y., CNN-RNN based intelligent recommendation for onlinemedical pre-diagnosis support, IEEE/ACMTrans. Comput. Biol. Bioinf, 18, 3, pp. 912-921, (2021); Zhou X., Liang W., Wang K.I.K., Huang R., Jin Q., Academic influence aware and multidimensional network analysis for research collaboration navigation based on scholarly Big Data, IEEE Trans. Emerg. Top. Comput, 9, 1, pp. 246-257, (2021); Zhou X., Liang W., Wang K.I.K., Shimizu S., Multi-modality behavioral influence analysis for personalized recommendations in health social media environment, IEEE Trans. Comput. Soc. Syst, 6, 5, pp. 888-897, (2019); Zhou X., Yang X., Ma J., Wang K.I.K., Energy efficient smart routing based on link correlation mining for wireless edge computing in IoT, IEEE Internet Things J, 9, 16, pp. 14988-14997, (2022); Guan Q., Huang Y., Multi-label chest X-ray image classification via category-wise residual attention learning, Pattern Recognit. Lett, 130, pp. 259-266, (2020); WangY. Peng X., Lu L., Lu Z., Bagheri M., Summers R.M., Chestxray8: Hospital-scale chest X-ray database and benchmarks on weaklysupervised classification and localization of common thorax diseases, Proc IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 2097-2106, (2017); Mei X., Et al., Artificial intelligence-enabled rapid diagnosis of patients with COVID-19, Nat. Med, 26, pp. 1224-1228, (2020); Lin T.Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, IEEE Trans. Pattern. Anal. Mach. Intell, 42, pp. 318-327, (2020); Ren S., He K., Girshick R., Sun J., Faster R-CNN: Towards real-time object detection with region proposal networks, IEEE Trans. Pattern. Anal. Mach. Intell, 39, 6, pp. 1137-1149, (2017); Gao S.H., Cheng M.M., Zhao K., Zhang X.Y., Yang M.H., Torr P., Res2Net:Anewmulti-scale backbone architecture, IEEE Trans.Pattern. Anal. Mach. Intell, 43, 2, pp. 652-662, (2021); Wang G., Et al., A noise-robust framework for automatic segmentation of COVID-19 pneumonia lesions from CT images, IEEE Trans. Med. Imag, 39, 8, pp. 2653-2663, (2020); Bakator M., Radosav D., Deep learning and medical diagnosis: A reviewof literature, Multimodal Technol. Interact, 2, (2018); Milletari F., Navab N., Ahmadi S.A., V-Net: Fully convolutional neural networks for volumetric medical image segmentation, Proc. Int. Conf. 3D Vis, pp. 565-571, (2016); Kim E., Kim S., Seo M., Yoon S., XProtoNet: Diagnosis in chest radiography with global and local explanations, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 15719-15728, (2021); Jaiswal A.K., Tiwari P., Kumar S., Gupta D., Khanna A., Rodrigues J.J.P.C., Identifying pneumonia in chest X-rays: A deep learning approach, Measurement, 145, pp. 511-518, (2019); Gabruseva T., Poplavskiy D., Kalinin A., Deep learning for automatic pneumonia detection, Proc. Conf. Comput. Vis. Pattern Recognit. Workshops, pp. 1436-1443, (2020); Sirazitdinov I., Kholiavchenko M., Mustafaev T., Yixuan Y., Kuleev R., Ibragimov B., Deep neural network ensemble for pneumonia localization from a large-scale chest X-ray database, Comput. Elect. Eng, 78, pp. 388-399, (2019); Yan K., Lu H., An extended genetic algorithm based gene selection framework for cancer diagnosis, Proc. 9th Int. Conf. Inf. Technol.Med. Educ, pp. 43-47, (2018); Yan K., Cheng H.L., Ji Z., Zhang X., Lu H., Accelerating smooth molecular surface calculation, J. Math. Biol, 76, pp. 779-793, (2018); Yan K., Wang B., Cheng H., Ji Z., Huang J., Gao Z., Molecular skin surface-based transformation visualization between biological macromolecules, J. Healthc. Eng, 2017, (2017); Pan I., Cadrin-Chenevert A., Cheng P.M., Tackling the radiological society of North America pneumonia detection challenge, AJR Am. J. Roentgenol, 213, pp. 568-574, (2019); DaiY. LiK.He J., Sun J., R-FCN:Object detection via region-based fully convolutional networks, Proc. 30th Int. Conf. Neural Inf. Process. Syst, pp. 379-387, (2016); Hu H., Gu J., Zhang Z., Dai J., Wei Y., Relation networks for object detection, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 3588-3597, (2018); He K., Gkioxari G., Dollar P., Girshick R., Mask R-CNN, IEEE Trans. Pattern. Anal. Mach. Intell, 42, 2, pp. 386-397, (2020); Yao S., Chen Y., Tian X., Jiang R., Ma S., An improved algorithm for detecting pneumonia based on YOLOv3, Appl. Sci, 10, 5, (2020); Dey N., Zhang Y.-D., Rajinikanth V., Pugalenthi R., Raja N.S.M., Customized VGG19 architecture for pneumonia detection in chest Xrays, Pattern Recognit. Lett, 143, pp. 67-74, (2021); Yao S., Chen Y., Tian X., Jiang R., GeminiNet: Combine fully convolution networkwith structure of receptive fields for object detection, IEEE Access, 8, pp. 60305-60313, (2020); Neubeck A., Van Gool L., Efficient non-maximum suppression, Proc. Int. Conf. Pattern Recognit, pp. 850-855, (2006); Bodla N., Singh B., Chellappa R., Davis L.S., Soft-NMS - Improving object detection with one line of code, Proc. IEEE Int. Conf. Comput. Vis, pp. 5562-5570, (2017); Solovyev R., Wang W., Gabruseva T., Weighted boxes fusion: Ensembling boxes from different object detection models, Image Vis Comput, 107, (2021); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proc IEEE Comput. Vis. Pattern Recognit, pp. 770-778, (2016); Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., Rethinking the inception architecture for computer vision, Proc. IEEE Comput. Vis. Pattern Recognit, pp. 2818-2826, (2016); Hu J., Shen L., Albanie S., Sun G., Wu E., Squeeze-and-excitation networks, IEEE Trans. Pattern. Anal. Mach. Intell, 42, 8, pp. 2011-2023, (2020); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Proc. Int. Conf. Neural Inf. Process. Syst, pp. 1097-1105, (2012)","H. Lu; China Jiliang University, College of Information Engineering, Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, Hangzhou, Zhejiang, 310018, China; email: hjlu@cjlu.edu.cn","","Institute of Electrical and Electronics Engineers Inc.","","","","","","15455963","","","37027655","English","IEEE/ACM Trans. Comput. BioL. Bioinf.","Article","Final","","Scopus","2-s2.0-85149418789"
"Wang K.; Zhang X.; Lu Y.; Zhang X.; Zhang W.","Wang, Kun (57213024990); Zhang, Xiaohong (55276997400); Lu, Yuting (57221641587); Zhang, Xiangbo (57219114472); Zhang, Wei (57225164170)","57213024990; 55276997400; 57221641587; 57219114472; 57225164170","CGRNet: Contour-guided graph reasoning network for ambiguous biomedical image segmentation","2022","Biomedical Signal Processing and Control","75","","103621","","","","16","10.1016/j.bspc.2022.103621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125710797&doi=10.1016%2fj.bspc.2022.103621&partnerID=40&md5=885d0cb7f8b7928b8336770d11e69113","Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, 400044, China; School of Big Data and Software Engineering, Chongqing University, Chongqing, 401331, China","Wang K., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data and Software Engineering, Chongqing University, Chongqing, 401331, China; Zhang X., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data and Software Engineering, Chongqing University, Chongqing, 401331, China; Lu Y., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data and Software Engineering, Chongqing University, Chongqing, 401331, China; Zhang X., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data and Software Engineering, Chongqing University, Chongqing, 401331, China; Zhang W., Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, 400044, China, School of Big Data and Software Engineering, Chongqing University, Chongqing, 401331, China","In this work, we propose to address the existing problem of biomedical image segmentation that often produces results, which fail to capture the exact contours of the target and suffer from ambiguity. Most previous techniques are suboptimal because they often simply concatenate contour information to alleviate this problem, while ignoring the correlation between regions and contours. As a matter of fact, the relationship between cross-domain features is an important clue for ambiguous pixel segmentation in biomedical images. To this end, we contribute a simple yet effective framework called Contour-Guided Graph Reasoning Network (CGRNet) for more accurate segmentation against ambiguity, which is capable of capturing the semantic relations between object regions and contours through graph reasoning. Specifically, we first perform a global graph representation of the low-level and high-level features extracted by the feature extractor, where clusters of pixels with similar features are mapped to each vertex. Further, we explicitly combine contour information as the geometric prior, which can aggregate features of contour pixels to graph vertices and focus on features along the boundaries. Then, the cross-domain features propagate information through the vertices on the graph to efficiently learn and reason about the semantic relations. Finally, the learned refinement graph features are projected back to the original pixel coordinate space for the final pixel-wise segmentation task. Extensive experiments on the three publicly available Kvasir, CVC-612, and COVID19-100 datasets show the effectiveness of our CGRNet with superior performance to existing state-of-the-art methods. Our code is publicly available at: https://github.com/DLWK/CGRNet. © 2022 Elsevier Ltd","Biomedical image segmentation; Computer-aided diagnosis (CAD); Contour-guided; Deep learning; Graph convolution network","Computer aided instruction; Deep learning; Graph theory; Medical imaging; Pixels; Semantic Segmentation; Semantics; Biomedical image segmentation; Computer-aided diagnose; Contour information; Contour-guided; Cross-domain; Deep learning; Domain feature; Existing problems; Graph convolution network; Semantic relations; Article; colonoscopy; computer assisted tomography; computer model; conceptual framework; contour guided graph reasoning network; controlled study; convolution algorithm; convolutional neural network; coronavirus disease 2019; data accuracy; data aggregation; feature extraction; image analysis; image segmentation; interferometry; measurement precision; reasoning; semantic web; sensitivity and specificity; Computer aided diagnosis","","","","","Chongqing Major Theme Projects, (cstc2018jszx-cyzt-zxX0017); Special key project of Chongqing technology innovation and application development, (cstc2019jscx-mbdxX0064); National Key Research and Development Program of China, NKRDPC, (2018YFB2101200); Fundamental Research Funds for the Central Universities, (2019CDYGYB014)","This work was supported in part by the National Key Research and Development Project of China under Grant 2018YFB2101200, in part by the Chongqing Major Theme Projects under Grant cstc2018jszx-cyzt-zxX0017, in part by the Fundamental Research Funds for the Central Universities under Grant 2019CDYGYB014, and in part by the Special key project of Chongqing technology innovation and application development under Grant cstc2019jscx-mbdxX0064.","(2019); (2020); (2019); (2016); Shen D., Guorong W., Suk H.-I., Deep learning in medical image analysis, Annual Review of Biomedical Engineering, 19, pp. 221-248, (2017); Piccialli F., Di Somma V., Giampaolo F., Cuomo S., Fortino G., A survey on deep learning in medicine: Why, how and when?, Information Fusion, 66, pp. 111-137, (2021); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical image computing and computer-assisted intervention, pp. 234-241, (2015); Zaiwang G., Cheng J., Huazhu F., Zhou K., Hao H., Zhao Y., Zhang T., Gao S., Liu J., Ce-net: Context encoder network for 2d medical image segmentation, IEEE Transactions on Medical Imaging, 38, 10, pp. 2281-2292, (2019); Zongwei Zhou M., Siddiquee M.R., Tajbakhsh N., Liang J., Unet++: Redesigning skip connections to exploit multiscale features in image segmentation, IEEE Transactions on Medical Imaging, 39, 6, pp. 1856-1867, (2019); Feng S., Zhao H., Shi F., Cheng X., Wang M., Ma Y., Xiang D., Zhu W., Chen X., Cpfnet: Context pyramid fusion network for medical image segmentation, IEEE Transactions on Medical Imaging, 39, 10, pp. 3008-3018, (2020); (2021); (2017); Kamnitsas K., Ledig C., Newcombe V.F., Simpson J.P., Kane A.D., Menon D.K., Rueckert D., Glocker B., Efficient multi-scale 3d cnn with fully connected crf for accurate brain lesion segmentation, Medical Image Analysis, 36, pp. 61-78, (2017); Chen H., Qi X., Lequan Y., Dou Q., Qin J., Heng P.-A., Dcan: Deep contour-aware networks for object instance segmentation from histology images, Medical Image Analysis, 36, pp. 135-146, (2017); (2019); Fan D.-P., Zhou T., Ji G.-P., Zhou Y., Chen G., Huazhu F., Shen J., Shao L., Inf-net: Automatic covid-19 lung infection segmentation from ct images, IEEE Transactions on Medical Imaging, 39, 8, pp. 2626-2637, (2020); Badrinarayanan V., Kendall A., Cipolla R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, 12, pp. 2481-2495, (2017); Milletari F., Navab N., Ahmadi S.-A., V-net: Fully convolutional neural networks for volumetric medical image segmentation, 2016 fourth international conference on 3D vision (3DV), pp. 565-571, (2016); Wang K., Zhang X., Huang S., Chen F., Zhang X., Huangfu L., Learning to recognize thoracic disease in chest x-rays with knowledge-guided deep zoom neural networks, IEEE Access, 8, pp. 159790-159805, (2020); Wang K., Zhang X., Huang S., Wang Q., Chen F., Ctf-net: Retinal vessel segmentation via deep coarse-to-fine supervision network, 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI), pp. 1237-1241, (2020); Huisi W., Wang W., Zhong J., Lei B., Wen Z., Qin J., Scs-net: A scale and context sensitive network for retinal vessel segmentation, Medical Image Analysis, 70, (2021); Wang K., Zhang X., Zhang X., Huang S., Li J., HuangFu L., Multi-granularity scale-aware networks for hard pixels segmentation of pulmonary nodules, Biomedical Signal Processing and Control, 69, (2021); Shuo Wang M., Zhou Z.L., Liu Z., Dongsheng G., Zang Y., Dong D., Gevaert O., Tian J., Central focused convolutional neural networks: Developing a data-driven model for lung nodule segmentation, Medical Image Analysis, 40, pp. 172-183, (2017); Arsalan M., Kim D.S., Owais M., Park K.R., Or-skip-net: Outer residual skip network for skin segmentation in non-ideal situations, Expert Systems with Applications, 141, (2020); Fisher Y., Koltun V., Multi-scale context aggregation by dilated convolutions, ICLR, (2015); (2021); Te G., Liu Y., Hu W., Shi H., Mei T., Edge-aware graph representation learning and reasoning for face parsing, European Conference on Computer Vision, pp. 258-274, (2020); 34, (2020); Mohamed A., Qian K., Elhoseiny M., Claudel C., Social-stgcnn: A social spatio-temporal graph convolutional neural network for human trajectory prediction, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 14424-14432, (2020); Wei X., Ruixuan Y., Sun J., View-gcn: View-based graph convolutional network for 3d shape analysis, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1850-1859, (2020); Li Y., Gupta A., Beyond grids: Learning graph representations for visual recognition, Advances in Neural Information Processing Systems, 31, pp. 9225-9235, (2018); Pourian N., Karthikeyan S., Manjunath B.S., Weakly supervised graph based semantic segmentation by learning communities of image-parts, Proceedings of the IEEE international conference on computer vision, pp. 1359-1367, (2015); (2019); Shin S.Y., Lee S., Yun I.D., Lee K.M., Deep vessel segmentation by learning graphical connectivity, Medical Image Analysis, 58, (2019); (2017); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Russakovsky O., Deng J., Hao S., Krause J., Satheesh S., Ma S., Huang Z., Karpathy A., Khosla A., Bernstein M., Et al., Imagenet large scale visual recognition challenge, International Journal of Computer Vision, 115, 3, pp. 211-252, (2015); (2017); Li Q., Han Z., Wu X.-M., Deeper insights into graph convolutional networks for semi-supervised learning, Thirty-Second AAAI conference on artificial intelligence, (2018); (2019); Wei J., Wang S., Huang Q., F<sup>3</sup>net: Fusion, feedback and focus for salient object detection, Proceedings of the AAAI Conference on Artificial Intelligence, 34, pp. 12321-12328, (2020); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, Proceedings of the IEEE international conference on computer vision, pp. 2980-2988, (2017); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3431-3440, (2015); (2020); Jorge Bernal F., Sanchez J., Fernandez-Esparrach G., Gil D., Rodriguez C., Vilarino F., Wm-dova maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians, Computerized Medical Imaging and Graphics, 43, pp. 99-111, (2015); (2020); Xian M., Zhang Y., Cheng H.-D., Fei X., Zhang B., Ding J., Automatic breast ultrasound image segmentation: A survey, Pattern Recognition, 79, pp. 340-355, (2018); Paszke A., Gross S., Massa F., Lerer A., Bradbury J., Chanan G., Killeen T., Lin Z., Gimelshein N., Antiga L., Et al., Pytorch: An imperative style, high-performance deep learning library, Advances in neural information processing systems, 32, pp. 8026-8037, (2019); Zhou B., Khosla A., Lapedriza A., Oliva A., Torralba A., Learning deep features for discriminative localization, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2921-2929, (2016)","X. Zhang; Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, 400044, China; email: xhongz@cqu.edu.cn","","Elsevier Ltd","","","","","","17468094","","","","English","Biomed. Signal Process. Control","Article","Final","","Scopus","2-s2.0-85125710797"
"Gupta K.; Bajaj V.; Jain D.K.; Hussain A.","Gupta, Kapil (57198261212); Bajaj, Varun (57209289122); Jain, Deepak Kumar (56206778300); Hussain, Amir (19734290900)","57198261212; 57209289122; 56206778300; 19734290900","Multi-model deep learning system for screening human monkeypox using skin images","2024","Expert Systems","","","","","","","0","10.1111/exsy.13651","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195513858&doi=10.1111%2fexsy.13651&partnerID=40&md5=2acc0808aed8db5dfb2a71d421dcb4e9","School of Computer Sciences, UPES, Uttrakhand, Dehradun, India; Department of Electronics and Communication Engineering, MANIT, Madhya Pradesh, Bhopal, India; Key Laboratory of Intelligent Control and Optimization for Industrial Equipment of Ministry of Education, Dalian University of Technology, Dalian, China; Centre of AI and Robotics, Edinburgh Napier University, Edinburgh, United Kingdom","Gupta K., School of Computer Sciences, UPES, Uttrakhand, Dehradun, India; Bajaj V., Department of Electronics and Communication Engineering, MANIT, Madhya Pradesh, Bhopal, India; Jain D.K., Key Laboratory of Intelligent Control and Optimization for Industrial Equipment of Ministry of Education, Dalian University of Technology, Dalian, China; Hussain A., Centre of AI and Robotics, Edinburgh Napier University, Edinburgh, United Kingdom","Purpose: Human monkeypox (MPX) is a viral infection that transmits between individuals via direct contact with animals, bodily fluids, respiratory droplets, and contaminated objects like bedding. Traditional manual screening for the MPX infection is a time-consuming process prone to human error. Therefore, a computer-aided MPX screening approach utilizing skin lesion images to enhance clinical performance and alleviate the workload of healthcare providers is needed. The primary objective of this work is to devise an expert system that accurately classifies MPX images for the automatic detection of MPX subjects. Methods: This work presents a multi-modal deep learning system through the fusion of convolutional neural network (CNN) and machine learning algorithms, which effectively and autonomously detect MPX-infected subjects using skin lesion images. The proposed framework, termed MPXCN-Net is developed by fusing deep features of three pre-trained CNNs: MobileNetV2, DarkNet19, and ResNet18. Three classifiers—K-nearest neighbour, support vector machine (SVM), and ensemble classifier—with various kernel functions, are used to identify infected patients. To validate the efficacy of our proposed system, we employ a publicly accessible MPX skin lesion dataset. Results: By amalgamating features extracted from all three CNNs and utilizing the medium Gaussian kernel of the SVM classifier, our proposed system achieves an outstanding average classification accuracy of 90.4%. Conclusions: Developed MPXCN-Net is suitable for testing with a large diversified dataset before being used in clinical settings. © 2024 John Wiley & Sons Ltd.","biomedical image classification; convolutional neural network; machine learning algorithm; monkeypox infection","Bioinformatics; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Expert systems; Image classification; Image enhancement; Large datasets; Learning algorithms; Nearest neighbor search; Statistical tests; Support vector machines; Biomedical image classification; Biomedical images; Convolutional neural network; Images classification; Machine learning algorithms; Monkeypox infection; Multi-modelling; Skin images; Skin lesion images; Support vector machine classifiers; Learning systems","","","","","Engineering and Physical Sciences Research Council, EPSRC, (EP/T021063/1, EP/T024917/1)","Prof Hussain acknowledges the support of the UK Engineering and Physical Sciences Research Council (EPSRC) Grants Ref. EP/T021063/1, EP/T024917/1. ","Acharya U.R., Fernandes S.L., WeiKoh J.E., Ciaccio E.J., Fabell M.K.M., Tanik U.J., Rajinikanth V., Yeong C.H., Automated detection of Alzheimer's disease using brain MRI images—A study with various feature extraction techniques, Journal of Medical Systems, 43, 9, pp. 1-14, (2019); Ahsan M.M., Uddin M.R., Ali M.S., Islam M.K., Farjana M., Sakib A.N., Momin K.A., Luna S.A., Deep transfer learning approaches for monkeypox disease diagnosis, Expert Systems with Applications, 216, (2023); Baygin M., Dogan S., Tuncer T., Barua P.D., Faust O., Arunkumar N., Abdulhay E.W., Emma Palmer E., Rajendra Acharya U., Automated ASD detection using hybrid deep lightweight features extracted from EEG signals, Computers in Biology and Medicine, 134, (2021); Baygin M., Yaman O., Barua P.D., Dogan S., Tuncer T., Acharya U.R., Exemplar Darknet19 feature generation technique for automated kidney stone detection with coronal CT images, Artificial Intelligence in Medicine, 127, (2022); Chadaga K., Prabhu S., Sampathila N., Nireshwalya S., Katta S.S., Tan R.S., Acharya U.R., Application of artificial intelligence techniques for monkeypox: A systematic review, Diagnostics, 13, 5, (2023); Cheema A.Y., Ogedegbe O.J., Munir M., Alugba G., Ojo T.K., Monkeypox: A review of clinical features, diagnosis, and treatment, Cureus, 14, 7, pp. 1-4, (2022); Choudhry Z.A., Shahid H., Aziz S., Naqvi S.Z.H., Khan M.U., DarkNet-19 based intelligent diagnostic system for ocular diseases, Iranian Journal of Science and Technology, Transactions of Electrical Engineering, 46, 4, pp. 959-970, (2022); Cover T., Hart P., Nearest neighbor pattern classification, IEEE Transactions on Information Theory, 13, 1, pp. 21-27, (1967); Di Giulio D.B., Eckburg P.B., Human monkeypox: An emerging zoonosis, The Lancet Infectious Diseases, 4, 1, pp. 15-25, (2004); Dietterich T.G., Ensemble methods in machine learning, International workshop on multiple classifier systems, pp. 1-15, (2000); Farman M., Akgul A., Garg H., Baleanu D., Hincal E., Shahzeen S., Mathematical analysis and dynamical transmission of monkeypox virus model with fractional operator, Expert Systems, (2023); Gupta K., Bajaj V., Deep learning models-based CT-scan image classification for automated screening of COVID-19, Biomedical Signal Processing and Control, 80, (2023); Gupta K., Bajaj V., Ansari I.A., OSACN-Net: Automated classification of sleep apnea using deep learning model and smoothed Gabor spectrograms of ECG signal, IEEE Transactions on Instrumentation and Measurement, 71, (2021); Gupta K., Bajaj V., Ansari I.A., An improved deep learning model for automated detection of BBB using ST spectrograms of smoothed VCG signal, IEEE Sensors Journal, 22, 9, pp. 8830-8837, (2022); Gupta K., Bajaj V., Ansari I.A., Integrated s-transform-based learning system for detection of arrhythmic fetus, IEEE Transactions on Instrumentation and Measurement, (2023); Gupta K., Bajaj V., Ansari I.A., Acharya U.R., Hyp-Net: Automated detection of hypertension using deep convolutional neural network and Gabor transform techniques with ballistocardiogram signals, Biocybernetics and Biomedical Engineering, 42, 3, pp. 784-796, (2022); Gupta S., Gupta A., Kumar A., Gupta S., Singh A., Multi-class classification of colorectal cancer tissues using pre-trained CNN models, TENCON 2022-2022 IEEE region 10 conference (TENCON), pp. 1-6, (2022); Happi C., Adetifa I., Mbala P., Njouom R., Nakoune E., Happi A., Ndodo N., Ayansola O., Mboowa G., Bedford T., Neher R.A., Roemer C., Hodcroft E., Tegally H., O'Toole A., Rambaut A., Pybus O., Kraemer M.U.G., Wilkinson E., de Oliveira T., Urgent need for a non-discriminatory and non-stigmatizing nomenclature for monkeypox virus, PLoS Biology, 20, 8, (2022); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Hraib M., Jouni S., Albitar M.M., Alaidi S., Alshehabi Z., The outbreak of monkeypox 2022: An overview, Annals of Medicine and Surgery, 79, (2022); Jahangeer G.S.B., Thambidurai D.R., Detecting breast cancer using novel mask R-CNN techniques, Expert Systems, 39, 9, (2022); Kaler J., Hussain A., Flores G., Kheiri S., Desrosiers D., Monkeypox: A comprehensive review of transmission, pathogenesis, and manifestation, Cureus, 14, 7, (2022); Kassani S.H., Kassani P.H., Wesolowski M.J., Schneider K.A., Deters R., Deep transfer learning based model for colorectal cancer histopathology segmentation: A comparative study of deep pre-trained models, International Journal of Medical Informatics, 159, (2022); Loh H.W., Ooi C.P., Aydemir E., Tuncer T., Dogan S., Acharya U.R., Decision support system for major depression detection using spectrogram and convolution neural network with EEG signals, Expert Systems, 39, 3, (2022); Matuszewski D.J., Sintorn I.M., TEM virus images: Benchmark dataset and deep learning classification, Computer Methods and Programs in Biomedicine, 209, (2021); McCollum A.M., Damon I.K., Human monkeypox, Clinical Infectious Diseases, 58, 2, pp. 260-267, (2014); Mileto D., Riva A., Cutrera M., Moschese D., Mancon A., Meroni L., Giacomelli A., Bestetti G., Rizzardini G., Gismondo M.R., Antinori S., New challenges in human monkeypox outside Africa: A review and case report from Italy, Travel Medicine and Infectious Disease, 49, (2022); Mumtaz W., Qayyum A., A deep learning framework for automatic diagnosis of unipolar depression, International Journal of Medical Informatics, 132, (2019); Nafisa Ali S., Ahmed T., Paul J., Jahan T., Sakeef Sani S., Noor N., Hasan T., Monkeypox skin lesion detection using deep learning models: A feasibility study. arXiv e-prints;p.arXiv-2207, (2022); Ozcan A., Donmez E., Bacterial disease detection for pepper plant by utilizing deep features acquired from DarkNet-19 CNN model, Dicle Üniversitesi Mühendislik Fakültesi Mühendislik Dergisi, 12, 4, pp. 573-579, (2021); Rabie A.H., Saleh A.I., Monkeypox diagnosis using ensemble classification, Artificial Intelligence in Medicine, 143, (2023); Sahin V.H., Oztel I., Yolcu O.G., Human monkeypox classification from skin lesion images with deep pre-trained network using mobile application, Journal of Medical Systems, 46, 11, pp. 1-10, (2022); Saleh A.I., Hussien S.A., Monkeypox diagnosis based on dynamic recursive gray wolf (DRGW) optimization, Biomedical Signal Processing and Control, 87, (2024); Sandler M., Howard A., Zhu M., Zhmoginov A., Chen L.C., Mobilenetv2: Inverted residuals and linear bottlenecks, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4510-4520, (2018); Simoes P., Bhagani S., A viewpoint: The 2022 monkeypox outbreak, Journal of Virus Eradication, 8, 2, (2022); Umer M.J., Sharif M., Raza M., Kadry S., A deep feature fusion and selection-based retinal eye disease detection from OCT images, Expert Systems, 40, (2023); Vapnik V., The support vector method of function estimation, Nonlinear modeling, pp. 55-85, (1998); Weiss K., Khoshgoftaar T.M., Wang D., A survey of transfer learning, Journal of Big data, 3, 1, pp. 1-40, (2016); Wong T.T., Yeh P.Y., Reliable accuracy estimates from k-fold cross validation, IEEE Transactions on Knowledge and Data Engineering, 32, 8, pp. 1586-1594, (2019); Yadav N., Alfayeed S.M., Khamparia A., Pandey B., Thanh D.N., Pande S., HSV model-based segmentation driven facial acne detection using deep learning, Expert Systems, 39, 3, (2022)","D.K. Jain; Key Laboratory of Intelligent Control and Optimization for Industrial Equipment of Ministry of Education, Dalian University of Technology, Dalian, China; email: dkj@dlut.edu.cn","","John Wiley and Sons Inc","","","","","","02664720","","EXSYE","","English","Expert Syst","Article","Article in press","All Open Access; Green Open Access","Scopus","2-s2.0-85195513858"
"Thamilselvan R.; Kalpana T.; Natesan P.; Sheik Alaudeen Y.; Surendiran S.; Showket S.","Thamilselvan, R. (56683185600); Kalpana, T. (57921074200); Natesan, P. (56829436200); Sheik Alaudeen, Y. (59155407600); Surendiran, S. (59155307400); Showket, Sayeem (59155407700)","56683185600; 57921074200; 56829436200; 59155407600; 59155307400; 59155407700","Autism Spectrum Disorder Diagnosis using Deep Learning Techniques","2024","2024 International Conference on Cognitive Robotics and Intelligent Systems, ICC - ROBINS 2024","","","","402","407","5","0","10.1109/ICC-ROBINS60238.2024.10533978","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195123955&doi=10.1109%2fICC-ROBINS60238.2024.10533978&partnerID=40&md5=bef1a0ea8d420436151b6d91d7c4f7eb","Kongu Engineering College, Computer Science and Engineering, Tamilnadu, Erode, India; Kongu Engineering College, Computer Applications, Tamilnadu, Erode, India","Thamilselvan R., Kongu Engineering College, Computer Science and Engineering, Tamilnadu, Erode, India; Kalpana T., Kongu Engineering College, Computer Applications, Tamilnadu, Erode, India; Natesan P., Kongu Engineering College, Computer Science and Engineering, Tamilnadu, Erode, India; Sheik Alaudeen Y., Kongu Engineering College, Computer Science and Engineering, Tamilnadu, Erode, India; Surendiran S., Kongu Engineering College, Computer Science and Engineering, Tamilnadu, Erode, India; Showket S., Kongu Engineering College, Computer Science and Engineering, Tamilnadu, Erode, India","Autism spectrum disorder (ASD) represents a neurological condition rather than a mental illness, characterized by atypical brain development that can subsequently manifest in distinct facial features. Children with ASD often exhibit unique facial landmarks that differentiate them from Typically Developed individuals. This pioneering research introduces a novel approach, focusing on the detection of ASD through the analysis of both social media data and biomedical images, specifically by harnessing the power of face recognition technology and Convolutional Neural Networks (CNN). Deep learning techniques are precise identification of these facial features. The research aims to benefit both communities and mental health professionals by providing an accessible web application based on a CNN with transfer learning and Flask integration. In this refined approach, two robust models are exclusively retained, DenseNet121 with an accuracy of 54% and EfficientNetB0 with an impressive 90% accuracy rate. These models are intended for improving the accuracy and convenience for determining ASD using face traits, which will simplify the process of early diagnosis and intervention for those who need it. The dataset contains 2,940 images of faces that were retrieved from the Kaggle platform. Standard evaluation metrics are used to evaluate the effectiveness of the two CNN models, including sensitivity, specificity and accuracy. This research hopes to help people with ASD by finding a way to identify it early. Early help is very important for making things better for people with autism. So, the study aims to create a useful tool that can tell if someone might have ASD when the patients are very young.  © 2024 IEEE.","accuracy; Autism; DenseNet121; EfficientNetB0; Facial expression","Convolutional neural networks; Deep learning; Diseases; Face recognition; Learning algorithms; Learning systems; Neural network models; Transfer learning; Accuracy; Autism; Autism spectrum disorders; Condition; Convolutional neural network; Densenet121; Efficientnetb0; Facial Expressions; Facial feature; Learning techniques; Diagnosis","","","","","","","Alsaade W.F., Saeed Alzahrani M., Classification and Detection of Autism Spectrum Disorder Based on Deep Learning Algorithms, Computational Intelligence and Neuroscience, (2022); Carette R., Cilia F., Dequen G., Bosche J., Guerin J.-L., Vandromme L., Automatic Autism Spectrum Disorder Detection Thanks to Eye-Tracking and Neural Network-Based Approach, (2018); Yolcu G., Oztel I., Kazan S., Oz C., Palaniappan K., Lever T.E., Bunyak F., Deep learning-based facial expression recognition for monitoring neurological disorders, 2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pp. 1652-1657, (2017); Paula C.S., Ribeiro S.H., Fombonne E., Mercadante M.T., Brief report: prevalence of pervasive developmental disorder in Brazil: A pilot study, J Autism Dev Disord., 41, 12, pp. 1738-1742, (2011); Nunes L.C., Et al., A Hybrid Model to Guide the Consultation of Children with Autism Spectrum Disorder, Research & Innovation Forum 2019. RIIFORUM 2019. Springer Proceedings in Complexity, (2019); Cohmer S., Autistic Disturbances of Affective Contact, (1943); Yolcu G., Oztel I., Kazan S., Oz C., Palaniappan K., Lever T.E., Bunyak F., Facial expression recognition for monitoring neurological disorders based on convolutional neural network, Multimedia Tools and Applications, 78, pp. 31581-31603, (2019); Fombonne E., Epidemiology of Pervasive Developmental Disorders, Pediatr Res, 65, pp. 591-598, (2009); Haque Ul I.M., Valles D., Facial Expression Recognition from Different Angles Using DCNN for Children with ASD to Identify Emotions, 2018 International Conference on Computational Science and Computational Intelligence (CSCI), pp. 446-449, (2018); Diagnostic and statistical manual of mental disorders: DSM-5™ (5th ed.), (2013); International statistical classification of diseases and related health problems (ICD)","","","Institute of Electrical and Electronics Engineers Inc.","","1st IEEE International Conference on Cognitive Robotics and Intelligent Systems, ICC - ROBINS 2024","17 April 2024 through 19 April 2024","Coimbatore","199666","","979-835037274-8","","","English","Int. Conf. Cogn. Robot. Intell. Syst., ICC - ROBINS","Conference paper","Final","","Scopus","2-s2.0-85195123955"
"Al-Shahari E.A.; Obayya M.; Alotaibi F.A.; Alsafari S.; Salama A.S.; Assiri M.","Al-Shahari, Eman A. (57218120186); Obayya, Marwa (6505869929); Alotaibi, Faiz Abdullah (57217736578); Alsafari, Safa (57218956797); Salama, Ahmed S. (56480035100); Assiri, Mohammed (57219344932)","57218120186; 6505869929; 57217736578; 57218956797; 56480035100; 57219344932","Accelerating biomedical image segmentation using equilibrium optimization with a deep learning approach","2024","AIMS Mathematics","9","3","","5905","5924","19","0","10.3934/math.2024288","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183902386&doi=10.3934%2fmath.2024288&partnerID=40&md5=5e3b7178cfd3a22e5cb4a4ddde2303ce","Department of Biology, College of Science & Arts at Mahayil, King Khalid University, Mohail Asser, Saudi Arabia; Department of Biomedical Engineering, College of Engineering, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Information Science, College of Humanities and Social Sciences, King Saud University, P. O Box 28095, Riyadh, 11437, Saudi Arabia; Department of Computer Science and Artificial Intelligence, College of Computer Science and Engineering, University of Jeddah, Jeddah, 23890, Saudi Arabia; Department of Electrical Engineering, Faculty of Engineering & Technology, Future University in Egypt, New Cairo, 11845, Egypt; Department of Computer Science, College of Sciences and Humanities-Aflaj, Prince Sattam bin Abdulaziz University, Aflaj, 16273, Saudi Arabia","Al-Shahari E.A., Department of Biology, College of Science & Arts at Mahayil, King Khalid University, Mohail Asser, Saudi Arabia; Obayya M., Department of Biomedical Engineering, College of Engineering, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Alotaibi F.A., Department of Information Science, College of Humanities and Social Sciences, King Saud University, P. O Box 28095, Riyadh, 11437, Saudi Arabia; Alsafari S., Department of Computer Science and Artificial Intelligence, College of Computer Science and Engineering, University of Jeddah, Jeddah, 23890, Saudi Arabia; Salama A.S., Department of Electrical Engineering, Faculty of Engineering & Technology, Future University in Egypt, New Cairo, 11845, Egypt; Assiri M., Department of Computer Science, College of Sciences and Humanities-Aflaj, Prince Sattam bin Abdulaziz University, Aflaj, 16273, Saudi Arabia","Biomedical image segmentation is a vital task in the analysis of medical imaging, including the detection and delineation of pathological regions or anatomical structures within medical images. It has played a pivotal role in a variety of medical applications, involving diagnoses, monitoring of diseases, and treatment planning. Conventionally, clinicians or expert radiologists have manually conducted biomedical image segmentation, which is prone to human error, subjective, and time-consuming. With the advancement in computer vision and deep learning (DL) algorithms, automated and semi-automated segmentation techniques have attracted much research interest. DL approaches, particularly convolutional neural networks (CNN), have revolutionized biomedical image segmentation. With this motivation, we developed a novel equilibrium optimization algorithm with a deep learning-based biomedical image segmentation (EOADL-BIS) technique. The purpose of the EOADL-BIS technique is to integrate EOA with the Faster RCNN model for an accurate and efficient biomedical image segmentation process. To accomplish this, the EOADL-BIS technique involves Faster R-CNN architecture with ResNeXt as a backbone network for image segmentation. The region proposal network (RPN) proficiently creates a collection of a set of region proposals, which are then fed into the ResNeXt for classification and precise localization. During the training process of the Faster RCNN algorithm, the EOA was utilized to optimize the hyperparameter of the ResNeXt model which increased the segmentation results and reduced the loss function. The experimental outcome of the EOADL-BIS algorithm was tested on distinct benchmark medical image databases. The experimental results stated the greater efficiency of the EOADL-BIS algorithm compared to other DL-based segmentation approaches. © 2024 the Author(s).","biomedical image segmentation; computer vision; deep learning; equilibrium optimizer; image processing","","","","","","Abdulrahman University, (PNURSP2023R203); Prince Sattam bin Abdulaziz University, PSAU, (PSAU/2023/R/1444); King Saud University, KSU; Princess Nourah Bint Abdulrahman University, PNU, (RSPD2024R838); Deanship of Scientific Research, King Khalid University, (RGP2/ 242 /44); Future University in Egypt, FUE","The authors extend their appreciation to the Deanship of Scientific Research at King Khalid University for funding this work through a large group Research Project under grant number (RGP2/ 242 /44). Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2023R203), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia. Research Supporting Project number (RSPD2024R838), King Saud University, Riyadh, Saudi Arabia. This study is supported via funding from Prince Sattam bin Abdulaziz University project number (PSAU/2023/R/1444). This study is partially funded by the Future University in Egypt (FUE).","Chakraborty S., Mali K., An overview of biomedical image analysis from the deep learning perspective, Research Anthology on Improving Medical Imaging Techniques for Analysis and Intervention, 2023, pp. 43-59; Punn N. S., Agarwal S., Modality specific U-Net variants for biomedical image segmentation: a survey, Artif. Intell. Rev, 55, pp. 5845-5889, (2022); Yeung M., Rundo L., Nan Y., Sala E., Schonlieb C.B., Yang G., Calibrating the Dice loss to handle neural network overconfidence for biomedical image segmentation, J. Digit. Imaging, 36, pp. 739-752, (2023); Lou A., Guan S., Loew M., Cfpnet-m: A lightweight encoder-decoder-based network for multimodal biomedical image real-time segmentation, Comput. Biol. Med, 154, (2023); Davamani K. A., Robin C. R., Amudha S., Anbarasi L. J., Biomedical image segmentation by deep learning methods, Computational Analysis and Deep Learning for Medical Care: Principles, Methods, and Applications, pp. 131-154, (2021); Shrivastava A., Chakkaravathy M., Shah M. A., A Comprehensive Analysis of Machine Learning Techniques in Biomedical Image Processing Using Convolutional Neural Networks, 2022 5th International Conference on Contemporary Computing and Informatics (IC3I), 2022, pp. 1363-1369; Iqbal A., Sharif M., Khan M. A., Nisar W., Alhaisoni M., FF-UNet: A U-shaped deep convolutional neural network for multimodal biomedical image segmentation, Cogn. Comput, 14, pp. 1287-1302, (2022); Punn N. S., Agarwal S., BT-Unet: A self-supervised learning framework for biomedical image segmentation using barlow twins with U-net models, Machine Learning, 111, pp. 4585-4600, (2022); Larrazabal A. J., Martinez C., Dolz J., Ferrante E., Orthogonal ensemble networks for biomedical image segmentation, Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part III 24, pp. 594-603; Liu Q., Jiang H., Liu T., Liu Z., Li S., Wen W., Shi Y., Defending deep learning-based biomedical image segmentation from adversarial attacks: A low-cost frequency refinement approach, Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part IV 23, pp. 342-351; Zhang J., Zhang Y., Jin Y., Xu J., Xu X., MDU-Net: multi-scale densely connected U-Net for biomedical image segmentation, Health Information Science and Systems, 11, (2023); Pan S., Liu X., Xie N., Chong Y., EG-TransUNet: A transformer-based U-Net with enhanced and guided models for biomedical image segmentation, BMC Bioinformatics, 24, (2023); Tomar N. K., Jha D., Riegler M. A., Johansen H. D., Johansen D., Rittscher J., Et al., Fanet: A feedback attention network for improved biomedical image segmentation, IEEE Transactions on Neural Networks and Learning Systems, (2022); Shuvo M. B., Ahommed R., Reza S., Hashem M. M. A., CNL-UNet: A novel lightweight deep learning architecture for multimodal biomedical image segmentation with false output suppression, Biomed. Signal Proces, 70, (2021); Srivastava A., Jha D., Chanda S., Pal U., Johansen H. D., Johansen D., Et al., MSRF-Net: a multi-scale residual fusion network for biomedical image segmentation, IEEE J. Biomed. Health, 26, pp. 2252-2263, (2021); Zhao Z., Zeng Z., Xu K., Chen C., Guan C., Dsal: Deeply supervised active learning from strong and weak labelers for biomedical image segmentation, IEEE J. Biomed. Health, 25, pp. 3744-3751, (2021); Meng Y., Wei M., Gao D., Zhao Y., Yang X., Huang X., Et al., CNN-GCN aggregation enabled boundary regression for biomedical image segmentation, Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part IV 23, pp. 352-362; Ibtehaz N., Rahman M. S., MultiResUNet: Rethinking the U-Net architecture for multimodal biomedical image segmentation, Neural networks, 121, pp. 74-87, (2020); Ma T., Dalca A. V., Sabuncu M. R., Hyper-convolution networks for biomedical image segmentation, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 1933-1942, (2022); Song H., Wang Y., Zeng S., Guo X., Li Z., OAU-net: Outlined Attention U-net for biomedical image segmentation, Biomed. Signal Proces. Control, 79, (2023); Schilling M. P., Scherr T., Munke F. R., Neumann O., Schutera M., Mikut R., Et al., Automated annotator variability inspection for biomedical image segmentation, IEEE Access, 10, pp. 2753-2765, (2022); Mansour R. F., Alfar N. M., Abdel-Khalek S., Abdelhaq M., Saeed R. A., Alsaqour R., Optimal deep learning based fusion model for biomedical image classification, Expert Syst, 39, (2022); Xie F., Li G., Hu W., Fan Q., Zhou S., Intelligent Fault Diagnosis of Variable-Condition Motors Using a Dual-Mode Fusion Attention Residual, J. Mar. Sci. Eng, 11, (2023); Tang W., Zou D., Yang S., Shi J., Dan J., Song G., A two-stage approach for automatic liver segmentation with Faster R-CNN and DeepLab, Neural Comput. Appl, 32, pp. 6769-6778, (2020); Makhadmeh S. N., Al-Betar M. A., Assaleh K., Kassaymeh S., A Hybrid White Shark Equilibrium Optimizer for Power Scheduling Problem Based IoT, IEEE Access, 10, pp. 132212-132231, (2022)","M. Assiri; Department of Computer Science, College of Sciences and Humanities-Aflaj, Prince Sattam bin Abdulaziz University, Aflaj, 16273, Saudi Arabia; email: m.assiri@psau.edu.sa","","American Institute of Mathematical Sciences","","","","","","24736988","","","","English","AIMS Math.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85183902386"
"Morís D.I.; Hervella Á.S.; Rouco J.; Novo J.; Ortega M.","Morís, Daniel I. (57226478610); Hervella, Álvaro S. (57204014400); Rouco, José (23475243900); Novo, Jorge (57695901400); Ortega, Marcos (24475406900)","57226478610; 57204014400; 23475243900; 57695901400; 24475406900","Context encoder transfer learning approaches for retinal image analysis","2023","Computers in Biology and Medicine","152","","106451","","","","2","10.1016/j.compbiomed.2022.106451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144614337&doi=10.1016%2fj.compbiomed.2022.106451&partnerID=40&md5=89d0cd40210315db135ec150a75daaa7","Centro de Investigación CITIC, Universidade da Coruña, Campus de Elviña, s/n, A Coruña, 15071, Spain; Grupo VARPA, Instituto de Investigación Biomédica de A Coruña (INIBIC), Universidade da Coruña, Xubias de Arriba, 84, A Coruña, 15006, Spain","Morís D.I., Centro de Investigación CITIC, Universidade da Coruña, Campus de Elviña, s/n, A Coruña, 15071, Spain, Grupo VARPA, Instituto de Investigación Biomédica de A Coruña (INIBIC), Universidade da Coruña, Xubias de Arriba, 84, A Coruña, 15006, Spain; Hervella Á.S., Centro de Investigación CITIC, Universidade da Coruña, Campus de Elviña, s/n, A Coruña, 15071, Spain, Grupo VARPA, Instituto de Investigación Biomédica de A Coruña (INIBIC), Universidade da Coruña, Xubias de Arriba, 84, A Coruña, 15006, Spain; Rouco J., Centro de Investigación CITIC, Universidade da Coruña, Campus de Elviña, s/n, A Coruña, 15071, Spain, Grupo VARPA, Instituto de Investigación Biomédica de A Coruña (INIBIC), Universidade da Coruña, Xubias de Arriba, 84, A Coruña, 15006, Spain; Novo J., Centro de Investigación CITIC, Universidade da Coruña, Campus de Elviña, s/n, A Coruña, 15071, Spain, Grupo VARPA, Instituto de Investigación Biomédica de A Coruña (INIBIC), Universidade da Coruña, Xubias de Arriba, 84, A Coruña, 15006, Spain; Ortega M., Centro de Investigación CITIC, Universidade da Coruña, Campus de Elviña, s/n, A Coruña, 15071, Spain, Grupo VARPA, Instituto de Investigación Biomédica de A Coruña (INIBIC), Universidade da Coruña, Xubias de Arriba, 84, A Coruña, 15006, Spain","During the last years, deep learning techniques have emerged as powerful alternatives to solve biomedical image analysis problems. However, the training of deep neural networks usually needs great amounts of labeled data to be done effectively. This is even more critical in the case of biomedical imaging due to the added difficulty of obtaining data labeled by experienced clinicians. To mitigate the impact of data scarcity, one of the most commonly used strategies is transfer learning. Nevertheless, the success of this approach depends on the effectiveness of the available pre-training techniques for learning from little or no labeled data. In this work, we explore the application of the Context Encoder paradigm for transfer learning in the domain of retinal image analysis. To this aim, we propose several approaches that allow to work with full resolution images and improve the recognition of the retinal structures. In order to validate the proposals, the Context Encoder pre-trained models are fine-tuned to perform two relevant tasks in the domain: vessels segmentation and fovea localization. The experiments performed on different public datasets demonstrate that the proposed Context Encoder approaches allow mitigating the impact of data scarcity, being superior to previous alternatives in this domain. © 2022 The Author(s)","Biomedical imaging; Context Encoder; Deep learning; Eye fundus; Self-supervised learning; Transfer learning","Diagnostic Imaging; Image Processing, Computer-Assisted; Machine Learning; Neural Networks, Computer; Retina; Deep neural networks; Image analysis; Learning algorithms; Learning systems; Medical imaging; Ophthalmology; Signal encoding; Biomedical imaging; Context encoder; Data scarcity; Deep learning; Eye fundus; Labeled data; Learning approach; Retinal image analysis; Self-supervised learning; Transfer learning; article; deep learning; eye fundus; human; image analysis; learning; retina fovea; retina image; transfer of learning; diagnostic imaging; image processing; machine learning; procedures; retina; Image enhancement","","","","","CITIC; Centro de Investigación de Galicia, (ED431G 2019/01); Consellería de Educación, Universidade e Formación Profesional; Ministerio de Ciencia e Innovación y Universidades, Government of Spain, (RTI2018-095894-B-I00); Secretaría Xeral de Universidades; Instituto de Salud Carlos III, ISCIII, (DTS18/00136); Instituto de Salud Carlos III, ISCIII; Ministerio de Ciencia e Innovación, MICINN, (PID2019-108435RB-I00); Ministerio de Ciencia e Innovación, MICINN; Consellería de Cultura, Educación e Ordenación Universitaria, Xunta de Galicia, (ED431C 2020/24, ED481A 2021/196, ED481B-2022-025); Consellería de Cultura, Educación e Ordenación Universitaria, Xunta de Galicia; European Regional Development Fund, ERDF; Axencia Galega de Innovación, GAIN; Xunta de Galicia, (IN845D 2020/38); Xunta de Galicia; Universidade da Coruña","Funding text 1: This research was funded by Instituto de Salud Carlos III, Government of Spain, DTS18/00136 research project; Ministerio de Ciencia e Innovación y Universidades, Government of Spain, RTI2018-095894-B-I00 research project; Ministerio de Ciencia e Innovación, Government of Spain through the research project with reference PID2019-108435RB-I00; Consellería de Cultura, Educación e Universidade, Xunta de Galicia, Spain through the predoctoral grant contract ref. ED481A 2021/196 and postdoctoral grant contract ref. ED481B-2022-025; and Grupos de Referencia Competitiva, grant ref. ED431C 2020/24; Axencia Galega de Innovación (GAIN), Spain, Xunta de Galicia, grant ref. IN845D 2020/38; CITIC, Centro de Investigación de Galicia, Spain ref. ED431G 2019/01, receives financial support from Consellería de Educación, Universidade e Formación Profesional, Xunta de Galicia, Spain, through the ERDF (80%) and Secretaría Xeral de Universidades (20%). Funding for open access charge: Universidade da Coruña/CISUG.; Funding text 2: This research was funded by Instituto de Salud Carlos III, Government of Spain , DTS18/00136 research project; Ministerio de Ciencia e Innovación y Universidades, Government of Spain , RTI2018-095894-B-I00 research project; Ministerio de Ciencia e Innovación, Government of Spain through the research project with reference PID2019-108435RB-I00 ; Consellería de Cultura, Educación e Universidade, Xunta de Galicia, Spain through the predoctoral grant contract ref. ED481A 2021/196 and postdoctoral grant contract ref. ED481B-2022-025 ; and Grupos de Referencia Competitiva , grant ref. ED431C 2020/24 ; Axencia Galega de Innovación (GAIN), Spain , Xunta de Galicia, grant ref. IN845D 2020/38 ; CITIC, Centro de Investigación de Galicia, Spain ref. ED431G 2019/01 , receives financial support from Consellería de Educación, Universidade e Formación Profesional, Xunta de Galicia, Spain , through the ERDF (80%) and Secretaría Xeral de Universidades (20%). Funding for open access charge: Universidade da Coruña/CISUG.","Lim L.S., Mitchell P., Seddon J.M., Holz F.G., Wong T.Y., Age-related macular degeneration, Lancet, 379, 9827, pp. 1728-1738, (2012); Lee D.A., Higginbotham E.J., Glaucoma and its treatment: a review, Am. J. Health-Syst. Pharma., 62, 7, pp. 691-699, (2005); Faust O., U. R.A., Ng E.Y.K., Ng K.-H., Suri J.S., Algorithms for the automated detection of diabetic retinopathy using digital fundus images: A review, J. Med. Syst., 36, 1, pp. 145-157, (2010); Chatterjee S., Chattopadhya S., Hope-Ross M., Lip P., Hypertension and the eye: changing perspectives, J. Hum. Hypertens., 16, 10, pp. 667-675, (2002); Doi K., Computer-aided diagnosis in medical imaging: historical review, current status and future potential, Comput. Med. Imaging Graph., 31, 4-5, pp. 198-211, (2007); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Bansal M.A., Sharma D.R., Kathuria D.M., A systematic review on data scarcity problem in deep learning: Solution and applications, ACM Comput. Surv., (2021); Shorten C., Khoshgoftaar T.M., A survey on image data augmentation for deep learning, J. Big Data, 6, 1, pp. 1-48, (2019); Creswell A., White T., Dumoulin V., Arulkumaran K., Sengupta B., Bharath A.A., Generative adversarial networks: An overview, IEEE Signal Process. Mag., 35, 1, pp. 53-65, (2018); Moris D.I., de Moura J., Novo J., Ortega M., Cycle generative adversarial network approaches to produce novel portable chest X-Rays images for Covid-19 diagnosis, ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP, pp. 1060-1064, (2021); Moris D.I., de Moura J., Novo J., Ortega M., Data augmentation approaches using cycle-consistent adversarial networks for improving COVID-19 screening in portable chest X-ray images, Expert Syst. Appl., 185, (2021); Yang Q., Zhang Y., Dai W., Pan S.J., Transfer Learning, (2020); Li X., Yang H., Lin Z., Krishnaswamy P., Transfer learning with joint optimization for label-efficient medical image anomaly detection, Interpretable and Annotation-Efficient Learning for Medical Image Computing, pp. 146-154, (2020); Jiang Z., Zhang H., Wang Y., Ko S.-B., Retinal blood vessel segmentation using fully convolutional network with transfer learning, Comput. Med. Imaging Graph., 68, pp. 1-15, (2018); Zhang S., Fu H., Yan Y., Zhang Y., Wu Q., Yang M., Tan M., Xu Y., Attention guided network for retinal image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI’2019), pp. 797-805, (2019); Zhang Y., Yang Q., An overview of multi-task learning, Nat. Sci. Rev., 5, 1, pp. 30-43, (2018); Hendrycks D., Mazeika M., Kadavath S., Song D., Using self-supervised learning can improve model robustness and uncertainty, (2019); Jing L., Tian Y., Self-supervised visual feature learning with deep neural networks: A survey, IEEE Trans. Pattern Anal. Mach. Intell., 43, 11, pp. 4037-4058, (2021); Raman C., Hung H., Loog M., Social processes: Self-supervised forecasting of nonverbal cues in social conversations, (2021); Xiao C., Han C., Zhang Z., Qin J., Wong T.-T., Han G., He S., Example-based colourization via dense encoding pyramids, Comput. Graph. Forum, 39, 1, pp. 20-33, (2020); Pathak D., Krahenbuhl P., Donahue J., Darrell T., Efros A.A., Context encoders: Feature learning by inpainting, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2536-2544, (2016); Zeng Y., Fu J., Chao H., Guo B., Learning pyramid-context encoder network for high-quality image inpainting, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1486-1494, (2019); Armanious K., Kumar V., Abdulatif S., Hepp T., Gatidis S., Yang B., ipA-MedGAN: Inpainting of arbitrary regions in medical imaging, 2020 IEEE International Conference on Image Processing, ICIP, pp. 3005-3009, (2020); Hu S.-Y., Wang S., Weng W.-H., Wang J., Wang X., Ozturk A., Li Q., Kumar V., Samir A.E., Weakly supervised context encoder using DICOM metadata in ultrasound imaging, (2020); Hervella A.S., Rouco J., Novo J., Ortega M., Learning the retinal anatomy from scarce annotated data using self-supervised multimodal reconstruction, Appl. Soft Comput., 91, (2020); Moris D.I., Hervella A.S., Rouco J., Novo J., Ortega M., Context encoder self-supervised approaches for eye fundus analysis, 2021 International Joint Conference on Neural Networks, IJCNN, pp. 1-8, (2021); Zhao H., Gallo O., Frosio I., Kautz J., Loss functions for neural networks for image processing, (2015); Hervella A.S., Rouco J., Novo J., Ortega M., Retinal image understanding emerges from self-supervised multimodal reconstruction, MICCAI, (2018); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, (2015); Hervella A.S., Rouco J., Novo J., Ortega M., Self-supervised multimodal reconstruction of retinal images over paired datasets, Expert Syst. Appl., 161, (2020); Morano J., Hervella A.S., Barreira N., Novo J., Rouco J., Multimodal transfer learning-based approaches for retinal vascular segmentation, (2020); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); He K., Zhang X., Ren S., Sun J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification, Proceedings of the IEEE International Conference on Computer Vision, pp. 1026-1034, (2015); Alipour S.H.M., Rabbani H., Akhlaghi M.R., Diabetic retinopathy grading by digital curvelet transform, Comput. Math. Methods Med., 2012, (2012); Staal J., Abramoff M., Niemeijer M., Viergever M., van Ginneken B., Ridge-based vessel segmentation in color images of the retina, IEEE Trans. Med. Imaging, 23, 4, pp. 501-509, (2004); Porwal P., Pachade S., Kamble R., Kokare M., Deshmukh G., Sahasrabuddhe V., Meriaudeau F., Indian diabetic retinopathy image dataset (idrid), (2018)","D.I. Morís; Centro de Investigación CITIC, Universidade da Coruña, A Coruña, Campus de Elviña, s/n, 15071, Spain; email: daniel.iglesias.moris@udc.es","","Elsevier Ltd","","","","","","00104825","","CBMDA","36571941","English","Comput. Biol. Med.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85144614337"
"Güler M.; Namlı E.","Güler, Mustafa (58984022900); Namlı, Ersin (55499104800)","58984022900; 55499104800","Skin Cancer Detection with Deep Learning Methods Using Medical Image; [Medikal Görüntüler Kullanılarak Derin Öğrenme Yöntemleriyle Cilt Kanseri Tespiti]","2022","Romaya Journal: Researches on Multidisciplinary Approaches","2","2","","1","10","9","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200895608&partnerID=40&md5=0222909f46514a14afa0dbdd2033f009","İstanbul Üniversitesi-Cerrahpaşa, Endüstri Mühendisliği Anabilim Dalı, Turkey","Güler M., İstanbul Üniversitesi-Cerrahpaşa, Endüstri Mühendisliği Anabilim Dalı, Turkey; Namlı E., İstanbul Üniversitesi-Cerrahpaşa, Endüstri Mühendisliği Anabilim Dalı, Turkey","With the development of machine learning and deep learning models, very successful results have been obtained in recent years, especially in the field of biomedical image processing. Medical imaging techniques such as computed tomography (CT), magnetic resonance imaging (MR), mammography, X-ray, and ultrasound serve as a preliminary reference for specialists for the diagnosis and treatment of diseases. However, in recent years, deep learning techniques have been used in the field of health in order to diagnose diseases earlier and to reduce the density of specialists, as well as to minimize the mistakes that can be made in diagnosis and diagnosis. With the increasing amount of data and the development of mathematical models, deep learning techniques have started to be preferred a lot. In this study, the application of deep learning methods in the field of medical image processing is examined. The skin cancer dataset, which is considered as a dataset, classification and disease diagnosis, image creation, improvement and transformation processes are examined, and the classification results obtained with four different pre-trained Convolutional neural network architectures (CNN) are examined. The results obtained are also classified by classical machine learning techniques. As a result, an accuracy rate of 87% was obtained in the classification made with ResNet, one of the CNN algorithms, and the Support vector machines (SVM) algorithm, which had the highest rate in the classification made with machine learning techniques, achieved success with an accuracy rate of 0.848%. © 2022, Ebru Bagci. All rights reserved.","Classification; Convolutional Neural Network; Deep Learning; Image Processing","","","","","","","","Balaji V. R., Suganthi S. T., Rajadevi R., Kumar V. K., Balaji B. S., Pandiyan S., Skin Disease Detection and Segmentation Using Dynamic Graph Cut Algorithm and Classification Through Naive Bayes Classifier, Measurement, (2020); Bezdan T., Dzakula N. B., Convolutional Neural Network Layers and Architectures in Sinteza, International Scientific Conference on Information Technology and Data Related Research, pp. 445-451, (2019); Chen L. C., Papandreou G., Kokkinos I., Murphy K., Yuille A. L., Deeplab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution and Fully Connected Crfs, (2016); Filali Y., Ennouni A., Sabri M. A., Aarab A., A Study of Lesion Skin Segmentation, Features Selection and Classification Approaches, International Conference on Intelligent Systems and Computer Vision (ISCV), pp. 1-7, (2018); Goodfellow I., Bengio Y., Courville A., Deep Learning, pp. 164-341, (2016); The International Society for Digital Imaging of the Skin (ISDIS) Archive; Ismail K. E., AbouRizka M. A., Maghraby F. A., Machine Learning Model for Multiclass Lesion Diagnoses, 2nd Novel Intelligent and Leading Emerging Sciences Conference (NILES), pp. 397-402, (2020); Kaggle; Kostopoulos S. A., Asvestas P. A., Kalatzis I. K., Sakellaropoulos G. C., Sakkis T. H., Cavouras D. A., Glotsos D. T., Adaptable Pattern Recognition System for Discriminating Melanocytic Nevi from Malignant Melanomas Using Plain Photography Images from Different Image Databases, International Journal of Medical İnformatics, 105, pp. 1-10, (2017); Kumar R., Adding Binary Search Connections to Improve Densenet Performance, (2019); Mathew A., Amudha P., Sivakumari S., Deep Learning Techniques, an Overview in International Conference on Advanced Machine Learning Technologies and Applications, pp. 599-608, (2020); Medium; Monika M. K., Vignesh N. A., Kumari C. U., Kumar M. N. V. S. S., Lydia E. L., Skin Cancer Detection and Classification Using Machine Learning, Materials Today: Proceedings, 33, pp. 4266-4270, (2020); Oliveira R. B., Marranghello N., Pereira A. S., Tavares J. M. R., A Computational Approach For Detecting Pigmented Skin Lesions in Macroscopic Images, Expert Systems with Applications, 61, pp. 53-63, (2016); Ozyurt F., Sert E., Avci D., An Expert System for Brain Tumor Detection: Fuzzy C-Means with Super Resolution and Convolutional Neural Network with Extreme Learning Machine, Medical Hypotheses, 134, pp. 1-8, (2020); Waheed Z., Waheed A., Zafar M., Riaz F., An Efficient Machine Learning Approach for the Detection of Melanoma Using Dermoscopic Images, International Conference on Communication, Computing and Digital Systems (C-CODE), pp. 316-319, (2017); Yang S., Oh B., Hahm S., Chung K. Y., Lee B. U., Ridge and Furrow Pattern Classification for Acral Lentiginous Melanoma Using Dermoscopic Images, Biomedical Signal Processing and Control, 32, pp. 90-96, (2017)","","","Ebru Bagci","","","","","","27919099","","","","Turkish","Romaya J. Res. Multidisciplinary Approaches","Article","Final","","Scopus","2-s2.0-85200895608"
"Rajput G.; Agrawal S.; Biyani K.; Vishvakarma S.K.","Rajput, Gunjan (57212573692); Agrawal, Shashank (57224899713); Biyani, Kunika (57415320400); Vishvakarma, Santosh Kumar (6506346978)","57212573692; 57224899713; 57415320400; 6506346978","Early breast cancer diagnosis using cogent activation function-based deep learning implementation on screened mammograms","2022","International Journal of Imaging Systems and Technology","32","4","","1101","1118","17","4","10.1002/ima.22701","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122957265&doi=10.1002%2fima.22701&partnerID=40&md5=f3ea1d48334fcd75f2a4551f353d08ae","Department of Electrical Engineering, Indian Institute of Technology, Indore, India","Rajput G., Department of Electrical Engineering, Indian Institute of Technology, Indore, India; Agrawal S., Department of Electrical Engineering, Indian Institute of Technology, Indore, India; Biyani K., Department of Electrical Engineering, Indian Institute of Technology, Indore, India; Vishvakarma S.K., Department of Electrical Engineering, Indian Institute of Technology, Indore, India","Breast cancer is detected in one out of eight females worldwide. Principally biomedical image processing techniques work with images captured by a microscope and then analyzed with the help of different algorithms and methods. Instead of microscopic image diagnosis, machine learning algorithms are now incorporated to detect and diagnose therapeutic imagery. Computer-aided mechanisms are used for better efficiency and reliability compared with manual pathological detection systems. Machine learning algorithms detect tumors by extracting features through a convolutional neural network (CNN) and then classifying them using a fully connected network. As Machine learning does not require prior expertise, it is profoundly used in biomedical imaging. This article has customized a convolutional neural network by mathematical modeling of a proposed activation function. We have obtained an appreciable prediction accuracy of up to 99%, along with a precision of 0.97. © 2022 Wiley Periodicals LLC.","breast cancer classification; convolutional neural network; deep learning; detection; Mias dataset","Bioinformatics; Chemical activation; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Functions; Learning algorithms; Medical imaging; Activation functions; Breast Cancer; Breast cancer diagnosis; Computer-aided; Convolutional neural network; Early breast cancer; Image diagnosis; Image processing technique; Machine learning algorithms; Microscopic image; Convolution","","","","","Council of Scientific and Industrial Research, India, CSIR, (09/1022(0026)/2016‐EMR‐I)","Grant sponsor CSIR (Council of Scientific & Industrial Research), Grant Number: 09/1022(0026)/2016‐EMR‐I. Funding Information ","Siegel R., DeSantis C., Jemal A., Colorectal cancer statistics, 2014, CA Cancer J Clin, 64, 2, pp. 104-117, (2014); Harford J.B., Breast-cancer early detection in low-income and middle-income countries: do what you can versus one size fits all, Lancet Oncol, 12, 3, pp. 306-312, (2011); Seely J.M., Alhassan T., Screening for breast cancer in 2018: what should we be doing today?, Curr Oncol, 25, pp. S115-S124, (2018); Huynh P.T., Jarolimek A.M., Daye S., The false-negative mammogram, Radiographics, 18, 5, pp. 1137-1154, (1998); Uysal E., Top 100 cited classic articles in breast cancer research, Eur J Breast Health, 13, 3, pp. 129-137, (2017); Tzikopoulos S.D., Mavroforakis M.E., Georgiou H.V., Dimitropoulos N., Theodoridis S., A fully automated scheme for mammographic segmentation and classification based on breast density and asymmetry, Comput Methods Programs Biomed, 102, 1, pp. 47-63, (2011); Pereira D.C., Ramos R.P., Do Nascimento M.Z., Segmentation and detection of breast cancer in mammograms combining wavelet analysis and genetic algorithm, Comput Methods Programs Biomed, 114, 1, pp. 88-101, (2014); Arena P., Basile A., Bucolo M., Fortuna L., Image processing for medical diagnosis using CNN, Nucl Instrum Methods Phys Res, Sect A, 497, pp. 174-178, (2003); Pandey A., Wang D., A new framework for CNN-based speech enhancement in the time domain, IEEE/ACM Trans Audio Speech Lang Process, 27, 7, pp. 1179-1188, (2019); Bashar M.A., Nayak R., Suzor N., Weir B., Misogynistic tweet detection: modelling cnn with small datasets, Australasian Conference on Data Mining, pp. 3-16, (2018); Ramachandran P., Zoph B., Le Q.V., Searching for activation functions, arXiv preprint, (2017); Pedamonti D., Comparison of non-linear activation functions for deep neural networks on MNIST classification task, arXiv preprint, (2018); Ding B., Qian H., Zhou J., Activation functions and their characteristics in deep neural networks, 2018 Chinese Control and Decision Conference (CCDC), pp. 1836-1841, (2018); Rajput G., Raut G., Chandra M., Vishvakarma S.K., VLSI implementation of transcendental function hyperbolic tangent for deep neural network accelerators, Microprocess Microsyst, 84, (2021); Malvia S., Bagadi S., Dubey U., Saxena S., Epidemiology of breast cancer in Indian women: breast cancer epidemiology, Asia Pac J Clin Oncol, 13, pp. 289-295, (2017); Gotzsche P.C., Olsen O., Is screening for breast cancer with mammography justifiable?, The Lancet, 355, 9198, pp. 129-134, (2000); Dalm S.U., Verzijlbergen J.F., De Jong M., Receptor targeted nuclear imaging of breast cancer, Int J Mol Sci, 18, 2, (2017); Menezes G.L., Knuttel F.M., Stehouwer B.L., Pijnappel R.M., van den Bosch M.A., Magnetic resonance imaging in breast cancer: a literature review and future perspectives, World J Clin Oncol, 5, 2, pp. 61-70, (2014); Sun X., Qian W., Song D., Ipsilateral-mammogram computer-aided detection of breast cancer, Comput Med Imaging Graph, 28, 3, pp. 151-158, (2004); Huang M.W., Chen C.W., Lin W.C., Ke S.W., Tsai C.F., SVM and SVM ensembles in breast cancer prediction, PLoS One, 12, 1, (2017); Saidin N., Ngah U.K., Sakim H.A.M., Siong D.N., Hoe M.K., Shuaib I.L., Density based breast segmentation for mammograms using graph cut and seed based region growing techniques, 2010 Second International Conference on Computer Research and Development, pp. 246-250, (2010); Kornilov A.S., Safonov I.V., An overview of watershed algorithm implementations in open source libraries, J Imaging, 4, 10, (2018); Xu S., Liu H., Song E., Marker-controlled watershed for lesion segmentation in mammograms, J Digit Imaging, 24, 5, pp. 754-763, (2011); Hu K., Gao X., Li F., Detection of suspicious lesions by adaptive thresholding based on multiresolution analysis in mammograms, IEEE Trans Instrum Meas, 60, 2, pp. 462-472, (2010); Yap M.H., Pons G., Marti J., Et al., Automated breast ultrasound lesions detection using convolutional neural networks, IEEE J Biomed Health Inform, 22, 4, pp. 1218-1226, (2017); Amiri M., Brooks R., Behboodi B., Rivaz H., Two-stage ultrasound image segmentation using U-Net and test time augmentation, Int J Comput Assist Radiol Surg, 15, 6, pp. 981-988, (2020); Rajput G., Agrawal S., Raut G., Vishvakarma S.K., An accurate and noninvasive skin cancer screening based on imaging technique, International Journal of Imaging Systems and Technology, 32, 1, pp. 354-368, (2022); Punitha S., Amuthan A., Joseph K.S., Benign and malignant breast cancer segmentation using optimized region growing technique, Fut Comput Inform J, 3, 2, pp. 348-358, (2018); Kahn C.E., Roberts L.M., Shaffer K.A., Haddawy P., Construction of a Bayesian network for mammographic diagnosis of breast cancer, Comput Biol Med, 27, 1, pp. 19-29, (1997); Toprak A., Extreme learning machine (elm)-based classification of benign and malignant cells in breast cancer, Med Sci Monit Int Med J Exp Clin Res, 24, pp. 6537-6543, (2018); Wang Z., Yu G., Kang Y., Zhao Y., Qu Q., Breast tumor detection in digital mammography based on extreme learning machine, Neurocomputing, 128, pp. 175-184, (2014); Qiu Y., Wang Y., Yan S., Et al., An initial investigation on developing a new method to predict short-term breast cancer risk based on deep learning technology, Medical Imaging 2016: Computer-Aided Diagnosis, 9785, (2016); Chanda P.B., Sarkar S.K., Detection and classification of breast cancer in mammographic images using efficient image segmentation technique, Advances in Control, Signal Processing and Energy Systems, pp. 107-117, (2020); Sun W., Tseng T.L.B., Zheng B., Qian W., A preliminary study on breast cancer risk analysis using deep neural network, International Workshop on Breast Imaging, pp. 385-391, (2016); Scott Mader K., Mias-Mammography from, (2017); Chawla N.V., Bowyer K.W., Hall L.O., Kegelmeyer W.P., SMOTE: synthetic minority over-sampling technique, J Artif Intellig Res, 16, pp. 321-357, (2002); Suckling J., The mammographic image analysis society digital mammogram database, The Second International Workshop on Digital Mammography, pp. 375-378, (1994); Malebary S.J., Hashmi A., Automated breast mass classification system using deep learning and ensemble learning in digital mammogram, IEEE Access, 9, pp. 55312-55328, (2021); Sinha V.K., Gupta M., Jangra S., Ahmed S., Early ductal carcinoma revealing in mammography images using machine learning. Paper presented at 2021 International Conference of Women in Data Science at Taif University (WiDSTaif), 2021, pp. 1-5, (2021); Dhivya S., Subramaniam M., Subbaraj K., Shivani S., Mageswari R., GAN based data augmentation for enhanced tumor classification. Paper presented at 4th International Conference on Computer, Communication and Signal Processing (ICCCSP), 2020, pp. 1-5, (2020); Al-Antari M.A., Al-Masni M.A., Choi M.T., Han S.M., Kim T.S., A fully integrated computer-aided diagnosis system for digital X-ray mammograms via deep learning detection, segmentation, and classification, Int J Med Inform, 117, pp. 44-54, (2018); Al-Masni M.A., Al-Antari M.A., Park J.M., Et al., Simultaneous detection and classification of breast masses in digital mammograms via a deep learning YOLO-based CAD system, Comput Methods Programs Biomed, 157, pp. 85-94, (2018); Al-antari M.A., Al-masni M.A., Park S.U., Et al., An automatic computer-aided diagnosis system for breast cancer in digital mammograms via deep belief network, J Med Biol Eng, 38, 3, pp. 443-456, (2018); Jiang F., Liu H., Yu S., Xie Y., Breast mass lesion classification in mammograms by transfer learning, Proceedings of the 5th International Conference on Bioinformatics and Computational Biology, pp. 59-62, (2017); Samala R.K., Chan H.P., Hadjiiski L.M., Helvie M.A., Cha K.H., Richter C.D., Multi-task transfer learning deep convolutional neural network: application to computer-aided diagnosis of breast cancer on mammograms, Phys Med Biol, 62, 23, pp. 8894-8908, (2017); Levy D., Jain A., Breast mass classification from mammograms using deep convolutional neural networks, arXiv Preprint, (2016); Yuan Z.W., Zhang J., Feature extraction and image retrieval based on AlexNet. Paper presented at Eighth International Conference on Digital Image Processing (ICDIP 2016) (Vol. 10033, p. 100330E). International Society for Optics and Photonics, (2016)","S.K. Vishvakarma; Department of Electrical Engineering, Indian Institute of Technology, Indore, India; email: skvishvakarma@iiti.ac.in","","John Wiley and Sons Inc","","","","","","08999457","","IJITE","","English","Int J Imaging Syst Technol","Article","Final","","Scopus","2-s2.0-85122957265"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Communications in Computer and Information Science","1966 CCIS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178645226&partnerID=40&md5=cb77862583ffbc833416c3a13f9affec","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","18650929","978-981998147-2","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85178645226"
"Pei R.; Yao K.; Xu X.; Zhang X.; Yang X.; Fu W.; Zhang Y.","Pei, Ronghao (57202691051); Yao, Kang (57211110694); Xu, Xiaobin (56427119400); Zhang, Xin (36622009600); Yang, Xiaodong (55265540400); Fu, Weiwei (57199403057); Zhang, Yang (57840371300)","57202691051; 57211110694; 56427119400; 36622009600; 55265540400; 57199403057; 57840371300","TransFusion-net for multifocus microscopic biomedical image fusion","2023","Computer Methods and Programs in Biomedicine","240","","107688","","","","3","10.1016/j.cmpb.2023.107688","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165534150&doi=10.1016%2fj.cmpb.2023.107688&partnerID=40&md5=2ee972e7e1f7de02660f164337ba8a87","School of Biomedical Engineering (Suzhou), Division of Life Science and Medicine, University of Science and Technology of China, Hefei, 230026, China; Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science, Suzhou, 215163, China; College of Mechanical & Electrical Engineering, Hohai University, Changzhou, 213022, China","Pei R., School of Biomedical Engineering (Suzhou), Division of Life Science and Medicine, University of Science and Technology of China, Hefei, 230026, China, Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science, Suzhou, 215163, China; Yao K., School of Biomedical Engineering (Suzhou), Division of Life Science and Medicine, University of Science and Technology of China, Hefei, 230026, China, Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science, Suzhou, 215163, China; Xu X., College of Mechanical & Electrical Engineering, Hohai University, Changzhou, 213022, China; Zhang X., School of Biomedical Engineering (Suzhou), Division of Life Science and Medicine, University of Science and Technology of China, Hefei, 230026, China, Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science, Suzhou, 215163, China; Yang X., Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science, Suzhou, 215163, China; Fu W., School of Biomedical Engineering (Suzhou), Division of Life Science and Medicine, University of Science and Technology of China, Hefei, 230026, China, Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science, Suzhou, 215163, China; Zhang Y., Suzhou Institute of Biomedical Engineering and Technology, Chinese Academy of Science, Suzhou, 215163, China","Background and objective: Due to the depth of focus (DOF) limitations of the optical systems of microscopes, it is often difficult to achieve full clarity from microscopic biomedical images under high-magnification microscopy. Multifocus microscopic biomedical image fusion (MFBIF) can effectively solve this problem. Considering both information richness and visual authenticity, this paper proposes a transformer network for MFBIF called TransFusion-Net. Methods: TransFusion-Net consists of two modules. One module is an interlayer cross-attention module, which is used to obtain feature mappings under the long-range dependencies observed among multiple nonfocus source images. The other module is a spatial attention upsampling network (SAU-Net) module, which is used to obtain global semantic information after further spatial attention is applied. Thus, TransFusion-Net can simultaneously receive multiple input images from a nonfull-focus microscope and make full use of the strong correlations between the source images to output accurate fusion results in an end-to-end manner. Results: The fusion results were quantitatively and qualitatively compared with those of eight state-of-the-art algorithms. In the quantitative experiments, five evaluation metrics, QAB/F, QMI, QAVG, QCB, and PSNR, were used to evaluate the performance of each method, and the proposed method achieved values of 0.6574, 8.4572, 5.6305, 0.7341, and 89.5685, respectively, which are higher than those of the current state-of-the-art algorithms. In the qualitative experiments, a differential image was used for further validation, and the near-zero residuals visually verified the adequacy of the proposed method for fusion. Furthermore, we showed some fusion results of multifocused biomedical microscopy images to verify the reliability of the proposed method, which shows high-quality fusion results. Conclusion: Multifocus biomedical microscopic image fusion can be accurately and effectively achieved by devising a deep convolutional neural network with joint cross-attention and spatial attention mechanisms. © 2023","Deep learning; End-to-end transformer network; Hybrid attention mechanism; Microscopic image fusion","Algorithms; Benchmarking; Electric Power Supplies; Image Processing, Computer-Assisted; Microscopy; Reproducibility of Results; Convolutional neural networks; Deep neural networks; Semantics; Attention mechanisms; Biomedical images; Deep learning; End to end; End-to-end transformer network; Hybrid attention mechanism; Microscopic image; Microscopic image fusion; Multi-focus; Spatial attention; Article; controlled study; convolutional neural network; deep learning; depth of focus; discrete wavelet transform; dual tree complex wavelet transform; genetic algorithm; human; imaging algorithm; intestine cancer; invasive ductal breast carcinoma; lung cancer; microscopy; multifocus microscopic biomedical image fusion; qualitative analysis; quantitative analysis; spatial analysis; stomach adenocarcinoma; transfusion; wavelet analysis; algorithm; benchmarking; image processing; microscopy; power supply; reproducibility; Image fusion","","","","","Natural Science Foundation of Shandong Province, (ZR2021QE205); Natural Science Foundation of Shandong Province","This work was supported by the Natural Science Foundation of Shandong Province (grant number ZR2021QE205 ). ","Burt P.J., Adelson E.H., The Laplacian Pyramid as a Compact Image Code, Read. Comput. Vis., 31, pp. 671-679, (1987); Toet A., Image fusion by a ratio of low-pass pyramid, Pattern Recognit. Lett., (1989); Toet A., Valeton J.M., Ruyven L.V., Merging thermal and visual images by a contrast pyramid, Optic. Eng., (1989); Toet A., Multiscale contrast enhancement with applications to image fusion, Optical Engineering, (1992); Toet A., A morphological pyramidal image decomposition, Pattern Recognit. Lett., 9, pp. 255-261, (1989); Jing Z., Image fusion using a low-redundancy and nearly shift-invariant discrete wavelet frame, Optic. Eng., 46, (2007); Bhatnagar G., Raman B., A new image fusion technique based on directive contrast, Electron. Lett. Comput. Vis. Image Anal., 8, pp. 18-38, (2009); Miao Q., Wang B., (2006); Multifocus image fusion using the nonsubsampled contourlet transform, Signal Processing, 89, pp. 1334-1346, (2009); Hui L., Manjunath B.S., Mitra S.K., Multi-sensor image fusion using the wavelet transform, Graphic. Models Image Processing, 57, pp. 235-245, (2002); Lewis J.J., O'Callaghan R., Nikolov S.G., Bull D.R., Canagarajah N., Pixel- and region-based image fusion with complex wavelets, Inf. Fus., 8, pp. 119-130, (2007); Li S., Kwok J.T., Wang Y., Combination of images with diverse focuses using the spatial frequency, Inf. Fus., 2, pp. 169-176, (2001); Kong J., Zheng K., Zhang J., Xue F., Multi-focus image fusion using spatial frequency and genetic algorithm, Int. J. Comput. Netw. Secur., (2008); Aslantas V., Kurban R., Fusion of multi-focus images using differential evolution algorithm, Expert. Syst. Appl., 37, pp. 8861-8870, (2010); De I., Chanda B., Multi-focus image fusion using a morphology-based focus measure in a quad-tree structure, Inf. Fus., 14, pp. 136-146, (2013); Fedorov D., Sumengen B., Manjunath B.S., Multi-focus imaging using local focus estimation and mosaicking, Proceedings of the International Conference on Image Processing, ICIP 2006, October 8-11, Atlanta, Georgia, USA, (2007); Li S., Kang X., Hu J., Image fusion with guided filtering, IEEE Trans. Image Processing, 22, pp. 2864-2875, (2013); Zhou Z., Li S., Wang B., Multi-scale weighted gradient-based fusion for multi-focus images, Inf. Fus., 20, pp. 60-72, (2014); Yu L., Liu S., Wang Z., Multi-focus image fusion with dense SIFT, Inf. Fus., 23, pp. 139-155, (2015); Zhang Y., Liu Y., Sun P., Yan H., Zhao X., Zhang L., IFCNN: a general image fusion framework based on convolutional neural network, Inf. Fus., (2020); Hao Z.A., Zl A., Zs B., Han X.A., Jm A., MFF-GAN: an unsupervised generative adversarial network with adaptive and gradient joint constraints for multi-focus image fusion, Inf. Fus., 66, pp. 40-53, (2021); Liu Y., Chen X., Peng H., Wang Z., Multi-focus image fusion with a deep convolutional neural network, Inf. Fus., 36, pp. 191-207, (2017); Tang H., Xiao B., Li W., Wang G., Pixel convolutional neural network for multi-focus image fusion, Inf. Sci. (Ny), (2018); Guo X., Nie R., Cao J., Zhou D., Qian W., Fully convolutional network-based multifocus image fusion, Neural Comput., 30, pp. 1-26, (2018); Orlando J.I., Prokofyeva E., Blaschko M.B., A discriminatively trained fully connected conditional random field model for blood vessel segmentation in fundus images, IEEE Trans. Biomed. Eng., 64, pp. 16-27, (2016); Pei R., Fu W., Yao K., Zheng T., Zhang Y., Real-time multi-focus biomedical microscopic image fusion based on m-SegNet, IEEE Photonics J., (2021); Yan H., Yu X., Zhang Y., Zhanga S., Zhao X., Zhang L., Single image depth estimation with normal guided scale invariant deep convolutional fields, IEEE Trans. Circuits Syst. Video Technol., (2017); Li L., Zhang S., Yu X., Zhang L., PMSC: patchMatch-based superpixel cut for accurate stereo matching, IEEE Trans. Circuits Syst. Video Technol., (2016); Dosovitskiy A., Beyer L., Kolesnikov A., Weissenborn D., Houlsby N., (2020); Wu B., Xu C., Dai X., Wan A., Zhang P., Yan Z., Tomizuka M., Gonzalez J., Keutzer K., Vajda P., (2020); Touvron H., Cord M., Douze M., Massa F., Sablayrolles A., Jegou H., Training data-efficient image transformers & distillation through attention, International Conference on Machine Learning, PMLR, pp. 10347-10357, (2021); Carion N., Massa F., Synnaeve G., Usunier N., Kirillov A., Zagoruyko S., End-to-end Object Detection With transformers, European conference On Computer Vision, pp. 213-229, (2020); Li Y., Mao H., Girshick R., He K., (2022); Zheng S., Lu J., Zhao H., Zhu X., Zhang L., (2020); Chen J., Lu Y., Yu Q., Luo X., Zhou Y., (2021); Xie E., Wang W., Yu Z., Anandkumar A., Alvarez J.M., Luo P., (2021); Wang H., Zhu Y., Adam H., Yuille A., Chen L.C., (2021); Wang W., Xie E., Li X., Fan D.P., Shao L., (2021); Fu J., Liu J., Tian H., Li Y., Bao Y., Fang Z., Lu H., Dual attention network for scene segmentation, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 3146-3154, (2019); Wang X., Girshick R., Gupta A., He K., (2017); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., (2017); Devlin J., Chang M.W., Lee K., Toutanova K., (2018); Jie H., Li S., Gang S., Albanie S., Squeeze-and-excitation networks, IEEE Trans. Pattern Anal. Mach. Intell., (2017); Bello I., Zoph B., Le Q., Vaswani A., Shlens J., Attention augmented convolutional networks, 2019 IEEE/CVF International Conference on Computer Vision (ICCV), (2020); Schlemper J., Oktay O., Schaap M., Heinrich M., Kainz B., Glocker B., Rueckert D., (2018); Liu Z., Blasch E., Xue Z., Zhao J., Laganiere R., Wu W., Objective assessment of multiresolution image fusion algorithms for context enhancement in night vision: a comparative study, IEEE Trans. Pattern Anal. Mach. Intell., 34, pp. 94-109, (2011); Selvaraju R.R., Cogswell M., Das A., Vedantam R., Parikh D., Batra D., Grad-CAM: visual explanations from deep networks via gradient-based localization, Int. J. Comput. Vis., 128, pp. 336-359, (2020)","W. Fu; School of Biomedical Engineering (Suzhou), Division of Life Science and Medicine, University of Science and Technology of China, Hefei, 230026, China; email: fuww@sibet.ac.cn","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","37487310","English","Comput. Methods Programs Biomed.","Article","Final","","Scopus","2-s2.0-85165534150"
"Alzakari S.A.; Maashi M.; Alahmari S.; Arasi M.A.; Alharbi A.A.K.; Sayed A.","Alzakari, Sarah A. (57220890847); Maashi, Mashael (57216199758); Alahmari, Saad (57924413000); Arasi, Munya A. (57200158993); Alharbi, Abeer A. K. (59076056000); Sayed, Ahmed (58872962100)","57220890847; 57216199758; 57924413000; 57200158993; 59076056000; 58872962100","Towards laryngeal cancer diagnosis using Dandelion Optimizer Algorithm with ensemble learning on biomedical throat region images","2024","Scientific Reports","14","1","19713","","","","0","10.1038/s41598-024-70525-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201977162&doi=10.1038%2fs41598-024-70525-0&partnerID=40&md5=1c1904975c5ce2060b207f25be6ab435","Department of Computer Sciences, College of Computer and Information Sciences, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Po Box 103786, Riyadh, 11543, Saudi Arabia; Department of Computer Science, Applied College, Northern Border University, Arar, Saudi Arabia; Department of Computer Science, Applied College at RijalAlmaa, King Khalid University, Abha, Saudi Arabia; Department Information Systems, College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, 11432, Saudi Arabia; Research Center, Future University in Egypt, New Cairo, 11835, Egypt","Alzakari S.A., Department of Computer Sciences, College of Computer and Information Sciences, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Maashi M., Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Po Box 103786, Riyadh, 11543, Saudi Arabia; Alahmari S., Department of Computer Science, Applied College, Northern Border University, Arar, Saudi Arabia; Arasi M.A., Department of Computer Science, Applied College at RijalAlmaa, King Khalid University, Abha, Saudi Arabia; Alharbi A.A.K., Department Information Systems, College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, 11432, Saudi Arabia; Sayed A., Research Center, Future University in Egypt, New Cairo, 11835, Egypt","Laryngeal cancer exhibits a notable global health burden, with later-stage detection contributing to a low mortality rate. Laryngeal cancer diagnosis on throat region images is a pivotal application of computer vision (CV) and medical image diagnoses in the medical sector. It includes detecting and analysing abnormal or cancerous tissue from the larynx, an integral part of the vocal and respiratory systems. The computer-aided system makes use of artificial intelligence (AI) through deep learning (DL) and machine learning (ML) models, including convolution neural networks (CNN), for automated disease diagnoses and detection. Various DL and ML approaches are executed to categorize the extraction feature as healthy and cancerous tissues. This article introduces an automated Laryngeal Cancer Diagnosis using the Dandelion Optimizer Algorithm with Ensemble Learning (LCD-DOAEL) method on Biomedical Throat Region Image. The LCD-DOAEL method aims to investigate the images of the throat region for the presence of laryngeal cancer. In the LCD-DOAEL method, the Gaussian filtering (GF) approach is applied to eliminate the noise in the biomedical images. Besides, the complex and intrinsic feature patterns can be extracted by the MobileNetv2 model. Meanwhile, the DOA model carries out the hyperparameter selection of MobileNetV2 architecture. Finally, the ensemble of three classifiers such as bidirectional long short-term memory (BiLSTM), regularized extreme learning machine (ELM), and backpropagation neural network (BPNN) models, are utilized for the classification process. A comprehensive set of simulations is conducted on the biomedical image dataset to highlight the efficient performance of the LCD-DOAEL technique. The comparison analysis of the LCD-DOAEL method exhibited a superior accuracy outcome of 97.54% over other existing techniques. © The Author(s) 2024.","Biomedical image; Dandelion Optimizer Algorithm; Ensemble learning; Laryngeal cancer; Narrow-band imaging","Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Laryngeal Neoplasms; Machine Learning; Neural Networks, Computer; Pharynx; algorithm; artificial neural network; computer assisted diagnosis; deep learning; diagnosis; diagnostic imaging; human; image processing; larynx tumor; machine learning; pharynx; procedures","","","","","","","Young G.O., Synthetic structure of industrial plastics, Plastics, 2nd ed, pp. 15-64, (1964); Bur A.M., Zhang T., Chen X., Kavookjian H., Kraft S., Karadaghy O., Farrokhian N., Mussatto C., Penn J., Wang G., Interpretable computer vision to detect and classify structural laryngeal lesions in digital flexible laryngoscopic images, Otolaryngol.-Head Neck Surg, 169, pp. 1564-1572, (2023); Raoof S.S., Jabbar M.A., Fathima S.A., Lung cancer prediction using machine learning: A comprehensive approach, In Proc. 2Nd Int. Conf. Innov. Mech. Ind. Appl. (ICIMIA), pp. 108-115, (2020); Raoof S.S., Jabbar M.A., Fathima S.A., Lung cancer prediction using feature selection and recurrent residual convolutional neural network (RRCNN), Machine Learning Methods for Signal, Image and Speech Processing, pp. 23-46, (2022); Jabbar M.A., Breast cancer data classification using ensemble machine learning, Eng. Appl. Sci. Res, 48, 1, pp. 65-72, (2021); Wellenstein D.J., Woodburn J., Marres H.A.M., van den Broek G.B., Detection of laryngeal carcinoma during endoscopy using artificial intelligence, Head Neck, 45, 9, pp. 2217-2226, (2023); Huang P., He P., Tian S., Ma M., Feng P., Xiao H., Mercaldo F., Santone A., Qin J., A ViT-AMC network with adaptive model fusion and multiobjective optimization for interpretable laryngeal tumor grading from histopathological images, IEEE Trans. Med. Imag, 42, 1, pp. 15-28, (2023); Bhattacharya D., Et al., Learning robust representation for laryngeal cancer classification in vocal folds from narrow-band images, In Med. Imag. Deep Learn., (2022); Meyer-Veit F., Rayyes R., Gerstner A.O.H., Steil J., Hyperspectral wavelength analysis with U-Net for larynx cancer detection, In Proc. Eur. Symp. Artif. Neural Netw. (ESANN), Comput. Intell. Mach. Learn., Bruges, Belgium, (2022); Timurzieva A., Kotov V., Popadyuk V., Ganshin I., Rapid diagnosis of laryngeal cancer using Raman fluorescence spectroscopy, J. Clin. Physiol. Pathol, 1, 1, pp. 21-27, (2022); Gharehchopogh F.S., Ghafouri S., Namazi M., Arasteh B., Advances in manta ray foraging optimization: A comprehensive survey, J. Bionic Eng, 21, 2, pp. 953-990, (2024); Sharma S., Khodadadi N., Saha A.K., Gharehchopogh F.S., Mirjalili S., Non-dominated sorting advanced butterfly optimization algorithm for multi-objective problems, J. Bionic Eng, 20, pp. 819-843, (2022); Khodadadi N., Soleimanian Gharehchopogh F., Mirjalili S., MOAVOA: A new multi-objective artificial vultures optimization algorithm, Neural Comput. Appl, 34, 23, pp. 20791-20829, (2022); Alrowais F., Mahmood K., Alotaibi S.S., Hamza M.A., Marzouk R., Mohamed A., Laryngeal cancer detection and classification using aquila optimization algorithm with deep learning on throat region images, IEEE Access, 11, pp. 115306-115315, (2023); Detecting laryngeal cancer lesions from endoscopy images using deep ensemble model, In 2023 International Conference on Signal Processing, Computation, Electronics, Power and Telecommunication (Iconscept), pp. 1-6, (2023); Kwon I., Wang S.G., Shin S.C., Cheon Y.I., Lee B.J., Lee J.C., Lim D.W., Jo C., Cho Y., Shin B.J., Diagnosis of early glottic cancer using laryngeal image and voice based on ensemble learning of convolutional neural network classifiers, J. Voice, (2022); Sahoo P.K., Mishra S., Panigrahi R., Bhoi A.K., Barsocchi P., An improvised deep-learning-based mask R-CNN model for laryngeal cancer detection using CT images, Sensors, 22, 22, (2022); An improved approach for initial stage detection of laryngeal cancer using effective hybrid features and ensemble learning method, Multimed. Tools Appl., pp. 1-23, (2023); Ding H., Cen Q., Si X., Pan Z., Chen X., Automatic glottis segmentation for laryngeal endoscopic images based on U-Net, Biomedical Signal Process. Control, 71, (2022); Pan X., Ma M., Bai W., Zhang S., PISDGAN: Perceive image structure and details for laryngeal image enhancement, Biomedical Signal Process. Control, 80, (2023); Pan X., Bai W., Ma M., Zhang S., RANT: A cascade reverse attention segmentation framework with a hybrid transformer for laryngeal endoscope images, Biomedical Signal Process. Control, 78, (2022); Gharehchopogh F.S., Nadimi-Shahraki M.H., Barshandeh S., Abdollahzadeh B., Zamani H., Cqffa: A chaotic quasi-oppositional farmland fertility algorithm for solving engineering optimization problems, J. Bionic Eng, 20, 1, pp. 158-183, (2023); Gharehchopogh F.S., Ibrikci T., An improved African vultures optimization algorithm using different fitness functions for multi-level thresholding image segmentation, Multimed. Tools Appl, 83, 6, pp. 16929-16975, (2024); Gharehchopogh F.S., Khargoush A.A., A chaotic-based interactive autodidactic school algorithm for data clustering problems and its application on COVID-19 disease detection, Symmetry, 15, 4, (2023); Abuya T.K., Rimiru R.M., Okeyo G.O., an image denoising technique using wavelet-anisotropic Gaussian filter-based denoising convolutional neural network for CT images, Appl. Sci, 13, 21, (2023); Hossen M.M., Majid M.E., Kashem S.B.A., Khandakar A., Nashbat M., Ashraf A., Hasan M., Kunju A.K.A., Kabir S., Chowdhury M.E., A reliable and robust deep learning model for effective recyclable waste classification, IEEE Access, 12, pp. 13809-13821, (2024); Zhang B., Mi Y., Zhang L., Zhang Y., Li M., Zhai Q., Li M., Dynamic community detection method of a social network based on node embedding representation, Mathematics, 10, 24, (2022); Zheng P., Wang L., Ji Y., Zeng Y., Chen X., Backpropagation neural network modeling for a pulse tube refrigerator with passive displacer, Appl. Therm. Eng, 211, (2022); Li J., Zhang X., Yao Y., Qi Y., Peng L., Regularized extreme learning machine based on remora optimization algorithm for printed matter illumination correction, IEEE Access, 12, pp. 3718-3735, (2024); Kondepogu V., Bhattacharyya B., Hybrid AE and Bi-LSTM-aided sparse multipath channel estimation in OFDM systems, IEEE Access, 12, pp. 7952-7965, (2024)","S. Alahmari; Department of Computer Science, Applied College, Northern Border University, Arar, Saudi Arabia; email: Saad.alahmari@nbu.edu.sa","","Nature Research","","","","","","20452322","","","39181918","English","Sci. Rep.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85201977162"
"Nie X.; Zhou X.; Li Z.; Wang L.; Lin X.; Tong T.","Nie, Xingqing (57734381900); Zhou, Xiaogen (57210120226); Li, Zhiqiang (59067610400); Wang, Luoyan (57734668400); Lin, Xingtao (57734193300); Tong, Tong (55625986800)","57734381900; 57210120226; 59067610400; 57734668400; 57734193300; 55625986800","LogTrans: Providing Efficient Local-Global Fusion with Transformer and CNN Parallel Network for Biomedical Image Segmentation","2022","Proceedings - 24th IEEE International Conference on High Performance Computing and Communications, 8th IEEE International Conference on Data Science and Systems, 20th IEEE International Conference on Smart City and 8th IEEE International Conference on Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2022","","","","769","776","7","7","10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152242975&doi=10.1109%2fHPCC-DSS-SmartCity-DependSys57074.2022.00128&partnerID=40&md5=60e730cbd07d16a103cd4bab3eb5c961","College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou University, Fuzhou, China; Imperial Vision Technology, Fuzhou, China","Nie X., College of Physics and Information Engineering, Fuzhou University, Fuzhou, China, Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou University, Fuzhou, China; Zhou X., College of Physics and Information Engineering, Fuzhou University, Fuzhou, China, Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou University, Fuzhou, China; Li Z., College of Physics and Information Engineering, Fuzhou University, Fuzhou, China, Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou University, Fuzhou, China; Wang L., College of Physics and Information Engineering, Fuzhou University, Fuzhou, China, Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou University, Fuzhou, China; Lin X., College of Physics and Information Engineering, Fuzhou University, Fuzhou, China, Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou University, Fuzhou, China; Tong T., College of Physics and Information Engineering, Fuzhou University, Fuzhou, China, Fujian Key Lab of Medical Instrumentation and Pharmaceutical Technology, Fuzhou University, Fuzhou, China, Imperial Vision Technology, Fuzhou, China","Accurate biomedical image segmentation is a prerequisite for excellent computer-aided diagnosis (CAD) systems. A series of researches have shown that convolutional neural networks (CNNs) have made impressive progress in segmentation tasks. Nevertheless, owing to the finite receptive field of CNN-based algorithms, such networks are focused too much on local area features rather than global context. While the Transformer architecture can encode global dependencies information through the self-attention mechanism, this mechanism typically ignores the local pixel-level structural information within each divided patch. Therefore, a better solution is still needed for how to integrate CNN architecture with Transformer architecture efficiently. In this essay, we propose an originative parallel segmentation algorithm called LogTrans. First, in the encoder path, the local details and global contour dependencies on the entire image are captured by the CNN branch and the Transformer branch, respectively. Then these two branches complement each other by a novel separate-combiner (SeCo) module, leading to better fused features. Moreover, we attempt to further enhance the segmentation properties by using a residual stackable dilated (ReSD) block, which applies residual shortcut connections to resolve dimension alterations in the target region and stacks dilated convolutions to capture more spatial information. The proposed LogTrans framework was evaluated on two biomedical datasets, including ISIC-2017 and UITNS-2022 datasets. Collectively, multiple results have indicated that our LogTrans performs superior with other state-of-the-art architectures in both visual comparison and quantitative appraisal.  © 2022 IEEE.","Biomedical image segmentation; Convolutional neural networks; Deep Learning; Global context; Transformer","Bioinformatics; Computer aided diagnosis; Convolution; Deep learning; Image segmentation; Network architecture; Biomedical image segmentation; Computer aided diagnosis systems; Convolutional neural network; Deep learning; Global context; Local areas; Network-based algorithm; Parallel network; Receptive fields; Transformer; Convolutional neural networks","","","","","","","LeCun Y., Bengio Y., Hinton G., Deep learning, nature, 521, 7553, pp. 436-444, (2015); Isensee F., Jager P.F., Kohl S.A., Petersen J., Maier-Hein K.H., Automated design of deep learning methods for biomedical image segmentation, (2019); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical image computing and computer-assisted intervention, pp. 234-241, (2015); Fu H., Cheng J., Xu Y., Wong D.W.K., Liu J., Cao X., Joint optic disc and cup segmentation based on multi-label deep network and polar transformation, IEEE transactions on medical imaging, 37, 7, pp. 1597-1605, (2018); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., Unet++: A nested u-net architecture for medical image segmentation, Deep learning in medical image analysis and multimodal learning for clinical decision support, pp. 3-11, (2018); Valanarasu J.M.J., Oza P., Hacihaliloglu I., Patel V.M., Medical transformer: Gated axial-attention for medical image segmentation, International Conference on Medical Image Computing and Computer- Assisted Intervention, pp. 36-46, (2021); Reza A., Moein H., Yuli W., Dorit M., Contextual attention network: Transformer meets u-net, (2022); Chen L.-C., Zhu Y., Papandreou G., Schroff F., Adam H., Encoderdecoder with atrous separable convolution for semantic image segmentation, Proceedings of the European conference on computer vision (ECCV), pp. 801-818, (2018); Gu Z., Cheng J., Fu H., Zhou K., Hao H., Zhao Y., Zhang T., Gao S., Liu J., Ce-net: Context encoder network for 2d medical image segmentation, IEEE transactions on medical imaging, 38, 10, pp. 2281-2292, (2019); Oktay O., Schlemper J., Folgoc L.L., Lee M., Heinrich M., Misawa K., Mori K., McDonagh S., Hammerla N.Y., Kainz B., Et al., Attention u-net: Learning where to look for the pancreas, (2018); Zhang S., Fu H., Yan Y., Zhang Y., Wu Q., Yang M., Tan M., Xu Y., Attention guided network for retinal image segmentation, International conference on medical image computing and computerassisted intervention, pp. 797-805, (2019); Tan M., Le Q., Efficientnet: Rethinking model scaling for convolutional neural networks, International conference on machine learning. PMLR, pp. 6105-6114, (2019); Sinha A., Dolz J., Multi-scale self-guided attention for medical image segmentation, IEEE journal of biomedical and health informatics, 25, 1, pp. 121-130, (2020); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in neural information processing systems, 30, (2017); Dosovitskiy A., Beyer L., Kolesnikov A., Weissenborn D., Zhai X., Unterthiner T., Dehghani M., Minderer M., Heigold G., Gelly S., Et al., An image is worth 16x16 words: Transformers for image recognition at scale, (2020); Zheng S., Lu J., Zhao H., Zhu X., Luo Z., Wang Y., Fu Y., Feng J., Xiang T., Torr P.H., Et al., Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 6881-6890, (2021); Liu Z., Lin Y., Cao Y., Hu H., Wei Y., Zhang Z., Lin S., Guo B., Swin transformer: Hierarchical vision transformer using shifted windows, Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 10012-10022, (2021); Zhang Y., Liu H., Hu Q., Transfuse: Fusing transformers and cnns for medical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 14-24, (2021); Chen J., Lu Y., Yu Q., Luo X., Adeli E., Wang Y., Lu L., Yuille A.L., Zhou Y., Transunet: Transformers make strong encoders for medical image segmentation, (2021); He Z., Lin M., Xu Z., Yao Z., Chen H., Alhudhaif A., Alenezi F., Deconv-transformer (dect): A histopathological image classification model for breast cancer based on color deconvolution and transformer architecture, Information Sciences, 608, pp. 1093-1112, (2022); Cao H., Wang Y., Chen J., Jiang D., Zhang X., Tian Q., Wang M., Swin-unet: Unet-like pure transformer for medical image segmentation, (2021); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Woo S., Park J., Lee J.-Y., Kweon I.S., Cbam: Convolutional block attention module, Proceedings of the European conference on computer vision (ECCV), pp. 3-19, (2018); Szegedy C., Ioffe S., Vanhoucke V., Alemi A.A., Inception-v4, inception-resnet and the impact of residual connections on learning, Thirty-first AAAI conference on artificial intelligence, (2017); Huang G., Liu Z., Van Der Maaten L., Weinberger K.Q., Densely connected convolutional networks, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700-4708, (2017); Sandler M., Howard A., Zhu M., Zhmoginov A., Chen L.-C., Mobilenetv2: Inverted residuals and linear bottlenecks, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4510-4520, (2018)","T. Tong; College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; email: ttraveltong@gmail.com","","Institute of Electrical and Electronics Engineers Inc.","IEEE; IEEE Computer Society","24th IEEE International Conference on High Performance Computing and Communications, 8th IEEE International Conference on Data Science and Systems, 20th IEEE International Conference on Smart City and 8th IEEE International Conference on Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2022","18 December 2022 through 20 December 2022","Chengdu","187557","","979-835031993-4","","","English","Proc. - IEEE Int. Conf. High Perform. Comput. Commun., IEEE Int. Conf. Data Sci. Syst., IEEE Int. Conf. Smart City IEEE Int. Conf. Dependability Sens., Cloud Big Data Syst. Appl., HPCC/DSS/SmartCity/DependSys","Conference paper","Final","","Scopus","2-s2.0-85152242975"
"Obayya M.; Saeed M.K.; Alruwais N.; Alotaibi S.S.; Assiri M.; Salama A.S.","Obayya, Marwa (6505869929); Saeed, Muhammad Kashif (57202381130); Alruwais, Nuha (58000746700); Alotaibi, Saud S. (57202829227); Assiri, Mohammed (57219344932); Salama, Ahmed S. (56480035100)","6505869929; 57202381130; 58000746700; 57202829227; 57219344932; 56480035100","Hybrid Metaheuristics with Deep Learning-Based Fusion Model for Biomedical Image Analysis","2023","IEEE Access","11","","","117149","117158","9","1","10.1109/ACCESS.2023.3326369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174859346&doi=10.1109%2fACCESS.2023.3326369&partnerID=40&md5=63fe7da16e2472f5531f57306a513e45","Princess Nourah Bint Abdulrahman University, College of Engineering, Department of Biomedical Engineering, Riyadh, 11671, Saudi Arabia; King Khalid University, Applied College at Muhayil, Department of Computer Science, Abha, 61421, Saudi Arabia; King Saud University, College of Applied Studies and Community Services, Department of Computer Science and Engineering, Riyadh, 11495, Saudi Arabia; Umm Al-Qura University, College of Computing and Information System, Department of Information Systems, Makkah, 21421, Saudi Arabia; Prince Sattam Bin Abdulaziz University, College of Sciences and Humanities-Aflaj, Department of Computer Science, Al-Kharj, 16273, Saudi Arabia; Future University in Egypt, Faculty of Engineering and Technology, Department of Electrical Engineering, New Cairo, 11845, Egypt","Obayya M., Princess Nourah Bint Abdulrahman University, College of Engineering, Department of Biomedical Engineering, Riyadh, 11671, Saudi Arabia; Saeed M.K., King Khalid University, Applied College at Muhayil, Department of Computer Science, Abha, 61421, Saudi Arabia; Alruwais N., King Saud University, College of Applied Studies and Community Services, Department of Computer Science and Engineering, Riyadh, 11495, Saudi Arabia; Alotaibi S.S., Umm Al-Qura University, College of Computing and Information System, Department of Information Systems, Makkah, 21421, Saudi Arabia; Assiri M., Prince Sattam Bin Abdulaziz University, College of Sciences and Humanities-Aflaj, Department of Computer Science, Al-Kharj, 16273, Saudi Arabia; Salama A.S., Future University in Egypt, Faculty of Engineering and Technology, Department of Electrical Engineering, New Cairo, 11845, Egypt","Biomedical image analysis has played a pivotal role in modern healthcare by facilitating automated analysis and interpretation of medical images. Biomedical image classification is the process of automatically labelling or categorizing medical images based on their content. In recent years, this field has received considerable attention because of the abundance of bio-medical image data and the potential for deep learning (DL) algorithms to assist medical staff in identifying diseases and making treatment decisions. DL methods are mostly convolutional neural networks (CNN) has illustrated outstanding performance in analyzing and classifying biomedical images. Therefore, this study presents a new Hybrid Metaheuristics with Deep Learning based Fusion Model Biomedical Image Analysis (HMDL-MFMBIA) technique. The HMDL-MFMBIA technique initially performs image pre-processing and Swin-UNet-based segmentation. Besides, a fusion of multiple DL-based feature extractors takes place using Xception and Residual Network (ResNet) model. Moreover, a hybrid salp swarm algorithm (HSSA) was employed for the optimal hyperparameter selection of the DL models. Finally, the gated recurrent unit (GRU) algorithm can be exploited for the detection and classification of bio-medical images. A widespread of simulated is conducted to establish the enhanced biomedical image classification results of the HMDL-MFMBIA method. The simulation outcomes inferred the greater outcome of the HMDL-MFMBIA algorithm over other DL models.  © 2013 IEEE.","Biomedical image analysis; computer vision; deep learning; fusion model; image classification","Bioinformatics; Computer vision; Convolution; Deep learning; Diagnosis; Feature extraction; Heuristic algorithms; Image analysis; Image classification; Image enhancement; Image fusion; Medical image processing; Neural networks; Biological system modeling; Biomedical image analysis; Classification algorithm; Convolutional neural network; Deep learning; Features extraction; Fusion model; Images classification; Images segmentations; Medical diagnostic imaging; Tuning; Image segmentation","","","","","","","Nazir S., Dickson D.M., Akram M.U., Survey of explainable artificial intelligence techniques for biomedical imaging with deep neural networks, Comput. Biol. Med., 156, (2023); Obayya M., Alamgeer M., Alzahrani J.S., Alabdan R., Al-Wesabi F.N., Mohamed A., Hassan M.I.A., Artificial intelligence driven biomedical image classification for robust rheumatoid arthritis classification, Biomedicines, 10, 11, (2022); Chakraborty S., Mali K., An overview of biomedical image analysis from the deep learning perspective, Research Anthology on Improving Medical Imaging Techniques for Analysis and Intervention., pp. 197-218, (2023); Di Giammarco M., Mercaldo F., Martinelli F., Santone A., Explainable deep learning methodologies for biomedical images classification, Proc. IEEE 42nd Int. Conf. Distrib. Comput. Syst. (ICDCS), pp. 1262-1264, (2022); Yang J., Shi R., Wei D., Liu Z., Zhao L., Ke B., Pfister H., Ni B., MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification, Sci. Data, 10, 1, (2023); Zhu J., Ma Y., Huang J., Wang L., Image segmentation combining pulse coupled neural network and adaptive glowworm algorithm, Inf. Technol. Control, 52, 2, pp. 487-499, (2023); Li F., Du X., Zhang L., Liu A., Image feature fusion method based on edge detection, Inf. Technol. Control, 52, 1, pp. 5-24, (2023); Maqsood S., Damasevicius R., Multiclass skin lesion localization and classification using deep learning based features fusion and selection framework for smart healthcare, Neural Netw., 160, pp. 238-258, (2023); Shrivastava A., Chakkaravathy M., Shah M.A., A comprehensive analysis of machine learning techniques in biomedical image processing using convolutional neural network, Proc. 5th Int. Conf. Contemp. Comput. Informat. (ICI), pp. 1363-1369, (2022); Sharma D., Mishra I., Parepalli R., Jayanth S., Biomedical image classification using convolutional neural networks, Proc. Int. Conf. Intell. Innov. Technol. Comput., Electr. Electron. (IITCEE), pp. 840-845, (2023); Dash S., Parida P., Mohanty J.R., Illumination robust deep convolutional neural network for medical image classification, Soft Comput., pp. 1-13, (2023); Vanhorn K., Cobanoglu M.C., Democratizing AI in biomedical image classification using virtual reality, Virtual Reality, 26, 1, pp. 159-171, (2022); Patel S., Patel R., Ganatra N., Patel A., Spatial feature fusion for biomedical image classification based on ensemble deep CNN and transfer learning, Int. J. Adv. Comput. Sci. Appl., 13, 5, (2022); Pradhan A.K., Das K., Mishra D., Chithaluru P., Optimizing CNNLSTM hybrid classifier using HCA for biomedical image classification, Exp. Syst., 40, 5, (2023); Ahmed M.R., Fahim M.A.I., Islam A.K.M.M., Islam S., Shatabda S., DOLG-NeXt: Convolutional neural network with deep orthogonal fusion of local and global features for biomedical image segmentation, Neurocomputing, 546, (2023); Barzekar H., Yu Z., C-Net: A reliable convolutional neural network for biomedical image classification, Exp. Syst. Appl., 187, (2022); Mansour R.F., Alfar N.M., Abdel-Khalek S., Abdelhaq M., Saeed R.A., Alsaqour R., Optimal deep learning based fusion model for biomedical image classification, Exp. Syst., 39, 3, (2022); Habib G., Qureshi S., Biomedical image classification using CNN by exploiting deep domain transfer learning, Int. J. Comput. Digit. Syst., 10, pp. 2-11, (2020); Assad M.B., Kiczales R., Deep biomedical image classification using diagonal bilinear interpolation and residual network, Int. J. Intell. Netw., 1, pp. 148-156, (2020); Pang S., Du A., Orgun M.A., Yu Z., A novel fused convolutional neural network for biomedical image classification, Med. Biol. Eng. Comput., 57, 1, pp. 107-121, (2019); Alanazi A.A., Khayyat M.M., Khayyat M.M., Elnaim B.M.E., Abdel-Khalek S., Intelligent deep learning enabled oral squamous cell carcinoma detection and classification using biomedical images, Comput. Intell. Neurosci., 2022, (2022); Jaszcz A., Polap D., Damasevicius R., Lung X-ray image segmentation using heuristic red fox optimization algorithm, Sci. Program., 2022, pp. 1-8, (2022); Kurdi S.Z., Ali M.H., Jaber M.M., Saba T., Rehman A., Damasevicius R., Brain tumor classification using meta-heuristic optimized convolutional neural networks, J. Personalized Med., 13, 2, (2023); Khan M.A., Arshad H., Damasevicius R., Alqahtani A., Alsubai S., Binbusayyis A., Nam Y., Kang B.-G., Human gait analysis: A sequential framework of lightweight deep learning and improved mothflame optimization algorithm, Comput. Intell. Neurosci., 2022, (2022); Cao H., Wang Y., Chen J., Jiang D., Zhang X., Tian Q., Wang M., Swin-UNet: UNet-like pure transformer for medical image segmentation, Computer Vision-ECCV., pp. 205-218, (2023); Aziz M.T., Mahmud S.M.H., Elahe M.F., Jahan H., Rahman M.H., Nandi D., Smirani L.K., Ahmed K., Bui F.M., Moni M.A., A novel hybrid approach for classifying osteosarcoma using deep feature extraction and multilayer perceptron, Diagnostics, 13, 12, (2023); Liu L., Zeng Y., Intelligent ISSA-based non-singular terminal slidingmode control of DC-DC boost converter feeding a constant power load system, Energies, 16, 13, (2023); Kartha R.S., Localized Skin Disease Detection and Classification Using An Optimized Hybrid Deep Learning Model with Attention Mechanism","M. Assiri; Prince Sattam Bin Abdulaziz University, College of Sciences and Humanities-Aflaj, Department of Computer Science, Al-Kharj, 16273, Saudi Arabia; email: m.assiri@psau.edu.sa","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85174859346"
"Sumathy V.; Pretty Diana Cyril C.","Sumathy, V. (57212708697); Pretty Diana Cyril, C. (57222521426)","57212708697; 57222521426","Systematic Literature Review on Early Diagnosis of Oral Squamous Cell Carcinoma by Deep Learning Techniques","2023","2023 IEEE International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering, RMKMATE 2023","","","","","","","0","10.1109/RMKMATE59243.2023.10369110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183537880&doi=10.1109%2fRMKMATE59243.2023.10369110&partnerID=40&md5=579ea4a0fdf99e1ecbd4722613076a1f","Department of Computing Technologies, SRM Institute of Science and Technology SRM Nagar, TN, Kattankulathur, 603203, India; Department of Computing Technologies, College of Engineering and Technology, Faculty of Engineering and Technology, SRM Institute of Science and Technology, SRM Nagar, TN, Kattankulathur, 603203, India","Sumathy V., Department of Computing Technologies, SRM Institute of Science and Technology SRM Nagar, TN, Kattankulathur, 603203, India; Pretty Diana Cyril C., Department of Computing Technologies, College of Engineering and Technology, Faculty of Engineering and Technology, SRM Institute of Science and Technology, SRM Nagar, TN, Kattankulathur, 603203, India","Oral Squamous Cell Carcinoma (OSCC) is the seventh most prevalent type of cancer in the neck and head. The prognosis and survival rate of the patient is significantly improved by early identification of OSCC. Due to tumor heterogeneity, such a diagnosis requires much time and a high-efficiency human experience. As a result, artificial intelligence systems assist professionals and physicians in making precise diagnoses. Recent advances in computer vision-based techniques and Computational Intelligence (CI) improve accuracy in medical images. This study aims to develop hybrid methodologies based on fused features to produce excellent outcomes for the early detection of OSCC. This systematic review aims to estimate deep learning (DL) based algorithms for early diagnosis OSCC to assist clinicians in oral cancer diagnosis and screening. The terms ""squamous cell carcinoma, "" ""early diagnosis, "" ""oral cavity, "" ""histopathological image, "" ""biomarker, "" ""Optical Coherence Tomography (OCT) image, "" and ""deep learning"" were used in a Google Scholar Cochrane and MEDLINE (PubMed), Embase and WoS databases (January 2018 to July 2023) to find relevant articles. The inclusion criteria were the use of deep learning approaches for early diagnosis of OSCC, articles older than 5 years, and publications written in English. Case reports and studies written in foreign languages met the exclusion criteria. 70 publications were chosen to be included in the systematic review out of the 194 studies that were initially found through the search. Deep learning techniques based on hybrid features are examined in evaluating performance metrics and superior results of the present systems employing biomedical images for OSCC diagnosis. It has been established that the deep learning-based early identification method for biomedical images has the ability to offer decision support for efficient oral cancer diagnosis and screening. © 2023 IEEE.","convolutional neural network; deep learning; hybrid method; OCT; Oral Squamous Cell Carcinoma","Cells; Convolutional neural networks; Cytology; Decision support systems; Deep learning; Diseases; Image enhancement; Learning algorithms; Learning systems; Medical imaging; Optical tomography; Cancer diagnosis; Cancer screening; Convolutional neural network; Deep learning; Early diagnosis; Hybrid method; Learning techniques; Oral cancer; Oral squamous cell carcinomata; Systematic Review; Diagnosis","","","","","","","Siegel R.L., Miller K.D., Wagle N.S., Jemal A., Cancer statistics, CA Cancer J. Clin., 73, 1, pp. 17-48, (2023); Rahman T.Y., Mahanta L.B., Chakraborty C., Das A.K., Sarma J.D., Textural pattern classification for oral squamous cell carcinoma, J. Microsc., 269, 1, pp. 85-93, (2018); Javed A.R., Fahad L.G., Farhan A.A., Abbas S., Srivastava G., Parizi R.M., Khan M.S., Automated cognitive health assessment in smart homes using machine learning, Sustain. Cities Soc., 65, (2021); Musulin J., Stifani D., Zulijani A., Segota S.B., Lorencin I., Andelic N., Car Z., Automated grading 'of oral squamous cell carcinoma into multiple classes using deep learning methods, Proc. 2021 IEEE 21st International Conference on Bioinformatics and Bioengineering (BIBE), pp. 1-6, (2021); Siddiqui S.Y., Haider A., Ghazal T.M., Khan M.A., Naseer I., Abbas S., Ateeq K., IoMT Cloudbased intelligent prediction of breast cancer stages empowered with deep learning, IEEE Access, 9, pp. 146478-146491, (2021); Mansour R.F., Alfar N.M., Abdel-Khalek S., Abdelhaq M., Saeed R.A., Alsaqour R., Optimal deep learning based fusion model for biomedical image classification, Expert Syst, 39, 3, (2022); Warnakulasuriya S., Oral potentially malignant disorders: A comprehensive review on clinical aspects and management, Oral Oncol, 102, (2020); Ali S., Gilani S.B.S., Shabbir J., Almulhim K.S., Bugshan A., Farooq I., Optical coherence tomography's current clinical medical and dental applications: A review, F1000Res, 10, (2021); Canavesi C., Rolland J.P., Ten years of gabor-domain optical coherence microscopy, Appl. Sci. (Basel), 9, 12, (2019); van Manen L., Dijkstra J., Boccara C., Benoit E., Vahrmeijer A.L., Gora M.J., Mieog J.S.D., e clinical usefulness of optical coherence tomography during cancer interventions, Journal of Cancer Research and Clinical Oncology, 144, 10, pp. 1967-1990, (2018); Welikala R.A., Remagnino P., Lim J.H., Chan C.S., Rajendran S., Kallarakkal T.G., Barman S.A., Fine-tuning deep learning architectures for early detection of oral cancer, Mathematical and Computational Oncology, Proc. 2: Second International Symposium, ISMCO 2020, pp. 25-31, (2020); Heidari A.E., Sunny S.P., James B.L., Lam T.M., Tran A.V., Yu J., Wilder-Smith P., Optical coherence tomography as an oral cancer screening adjunct in a low resource settings, IEEE J. Sel. Top. Quantum Electron., 25, 1, pp. 1-8, (2018); Song B., Sunny S., Uthoff R.D., Patrick S., Suresh A., Kolur T., Liang R., Automatic classification of dual-modalilty, smartphone-based oral dysplasia and malignancy images using deep learning, Biomed. Opt. Express, 9, 11, pp. 5318-5329, (2018); Uthoff R.D., Song B., Sunny S., Patrick S., Suresh A., Kolur T., Liang R., Small form factor, flexible, dual-modality handheld probe for smartphone-based, point-of-care oral and oropharyngeal cancer screening, J. Biomed. Opt., 24, 10, pp. 1-8, (2019); Uthoff R.D., Song B., Sunny S., Patrick S., Suresh A., Kolur T., Liang R., Point-of-care, smartphone-based, dual-modality, dual-view, oral cancer screening device with neural network classification for low-resource communities, PLOS ONE, 13, 12, (2018); Uthoff R., Wilder-Smith P., Sunny S., Suresh A., Patrick S., Anbarani A., Song B., Birur P., Kuriakose M.A., Spires O., Development of a dual-modality, dual-view smartphone-based imaging system for oral cancer detection, Des. Qual., “Biomed, ” Technol. Xi, 10486, (2018); Siegel R.L., Miller K.D., Goding Sauer A., Fedewa S.A., Butterly L.F., Anderson J.C., Cercek A., Smith R.A., Jemal A., Colorectal cancer statistics, 2020, CA Cancer J. Clin., 70, 3, pp. 145-164, (2020); Singh A., Sahu A., Verma S., Computer intelligence in detection of malignant or premalignant oral lesions: The story so far, Computational Intelligence in Oncology, 1016, pp. 187-200, (2022); Jeyaraj P.R., Samuel Nadar E.R.S., Computer-assisted medical image classification for early diagnosis of oral cancer employing deep learning algorithm, J. Cancer Res. Clin. Oncol., 145, 4, pp. 829-837, (2019); Lalithmani K., Punitha A., Detection of oral cancer using deep neural based adaptive fuzzy system in data mining techniques, Int J Rec Tech Eng, 7, pp. 397-404, (2019); Azam S., Rafid A.K.M.R.H., Montaha S., Karim A., Jonkman M., De Boer F., Automated detection of broncho-arterial pairs using CT scans employing different approaches to classify lung diseases, Biomedicines, 11, 1, (2023); Ali Z., Alturise F., Alkhalifah T., Khan Y.D., IGPred-HDnet: Prediction of immunoglobulin proteins using graphical features and the hierarchal deep learning-based approach, Comput. Intell. Neurosci., (2023); Hassan A., Alkhalifah T., Alturise F., Khan Y.D., RCCC_Pred: A novel method for sequence-based identification of renal clear cell carcinoma genes through DNA mutations and a blend of features, Diagnostics, 12, 12, (2022); Dargan S., Kumar M., Ayyagari M.R., A survey of deep learning and its applications: A new paradigm to machine learning, Arch. Comp. Methods Eng., 20, pp. 1071-1092, (2020); Prabhakaran R., Mohana J., Detection of oral cancer using machine learning classification methods, Int. J. Elect. Eng. Tech., 11, 3, pp. 384-393, (2020); Mohiyuddin A., Basharat A., Ghani U., Peter V., Abbas S., Naeem O.B., Rizwan M., Breast tumor detection and classification in mammogram images using modified YOLOv5 network, Comp. Math. Methods Med., (2022); Shamim M.Z.M., Syed S., Shiblee M., Usman M., Ali S.J., Hussein H.S., Farrag M., Automated detection of oral pre-cancerous tongue lesions using deep learning for early diagnosis of oral cavity cancer, Fe Comput. J., 65, 1, pp. 91-104, (2022); Luque A., Romero-Lemos J., Carrasco A., Barbancho J., Non-sequential automatic classification of anuran sounds for the estimation of climate-change indicators, Expert Syst. Appl., 95, pp. 248-260, (2018); Kolarevic D., Tomasevic Z., Dzodic R., Kanjer K., Vukosavljevic D.N., Radulovic M., Early prognosis of metastasis risk in inflammatory breast cancer by texture analysis of tumour microscopic images, Biomed. Microdevices, 17, 5, (2015); Rahman T.Y., Mahanta L.B., Chakraborty C., Das A.K., Sarma J.D., Textural pattern classification for oral squamous cell carcinoma, J. Microsc., 269, 1, pp. 85-93, (2018); Alkhadar H., Macluskey M., White S., Ellis I., Gardner A., Comparison of machine learning algorithms for the prediction of five-year survival in oral squamous cell carcinoma, J. Oral Pathol. Med., 50, 4, pp. 378-384, (2021); Bur A.M., Holcomb A., Goodwin S., Woodroof J., Karadaghy O., Shnayder Y., Kakarala K., Machine learning to predict occult nodal metastasis in early oral squamous cell carcinoma, Oral Oncol, 92, pp. 20-25, (2019); Kumar R., Srivastava R., Srivastava S., Detection and classification of Cancer from microscopic biopsy images using clinically significant and biologically interpretable features, J. Med. Eng., (2015); Hardle W.K., Simar L., Applied Multivariate Statistical Analysis, (2012); Nanditha B.R., Geetha Kiran A., Sanathkumar M.P., Oral cancer detection using machine learning and deep learning techniques, Int. J. Curr. Res. Rev., 14, 1, pp. 64-70, (2022); Li H.-A., Fan J., Yu K., Qi X., Wen Z., Hua Q., Zhang M., Zheng Q., Medical image coloring based on gabor filtering for internet of medical things, IEEE Access, 8, pp. 104016-104025, (2020); Mohammed B.A., Senan E.M., Rassem T.H., Makbol N.M., Alanazi A.A., Al-Mekhlafi Z.G., Almurayziq T.S., Ghaleb F.A., Multi-method analysis of medical records and MRI images for early diagnosis of dementia and Alzheimer's disease based on deep learning and hybrid methods, Electronics, 10, 22, (2021); James B.L., Sunny S.P., Heidari A.E., Ramanjinappa R.D., Lam T., Tran A.V., Kuriakose M.A., Validation of a point-of-care optical coherence tomography device with machine learning algorithm for detection of oral potentially malignant and malignant lesions, Cancers, 13, 14, (2021); Rahman T.Y., Mahanta L.B., Chakraborty C., Das A.K., Sarma J.D., Textural pattern classification for oral squamous cell carcinoma, J. Microsc., 269, 1, pp. 85-93, (2018); Rahman T.Y., Mahanta L.B., Das A.K., Sarma J.D., Automated oral squamous cell carcinoma identification using shape, texture and color features of whole image strips, Tissue Cell, 63, (2020); Fati S.M., Senan E.M., Javed Y., Early diagnosis of oral squamous cell carcinoma based on histopathological images using deep and hybrid learning approaches, Diagnostics (Basel), 12, 8, (2022); Warin K., Limprasert W., Suebnukarn S., Jinaporntham S., Jantana P., Vicharueang S., AI-based analysis of oral lesions using novel deep convolutional neural networks for early detection of oral cancer, PLOS ONE, 17, 8, (2022); Alanazi A.A., Khayyat M.M., Khayyat M.M., Elamin Elnaim B.M., Abdel-Khalek S., Intelligent deep learning enabled oral squamous cell carcinoma detection and classification using biomedical images, Comp. Intell. Neurosci., (2022); Rahman T.Y., Mahanta L.B., Choudhury H., Das A.K., Sarma J.D., Study of morphological and textural features for classification of oral squamous cell carcinoma by traditional machine learning techniques, Cancer Rep. (Hoboken), 3, 6, (2020); Yang Z., Pan H., Shang J., Zhang J., Liang Y., Deep-learning-based automated identification and visualization of oral cancer in optical coherence tomography images, Biomedicines, 11, 3, (2023); Yang Z., Shang J., Liu C., Zhang J., Liang Y., Identification of oral squamous cell carcinoma in optical coherence tomography images based on texture features, J. Innov. Opt. Health Sci., 14, 1, (2021); Ramezani K., Tofangchiha M., Oral cancer screening by artificial intelligence-oriented interpretation of optical coherence tomography images, Rad. Res. Pract., (2022); Yuan W., Yang J., Yin B., Fan X., Yang J., Sun H., Liu Y., Su M., Li S., Huang X., Noninvasive diagnosis of oral squamous cell carcinoma by multi-level deep residual learning on optical coherence tomography images, Oral Dis, (2022); Yang Z., Shang J., Liu C., Zhang J., Liang Y., Identification of oral cancer in OCT images based on an optical attenuation model, Lasers Med. Sci., 35, 9, pp. 1999-2007, (2020)","","","Institute of Electrical and Electronics Engineers Inc.","","2023 IEEE International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering, RMKMATE 2023","1 November 2023 through 2 November 2023","Chennai","196097","","979-835030570-8","","","English","IEEE Int. Conf. Res. Methodol. Knowl. Manag., Artif. Intell. Telecommun. Eng., RMKMATE","Conference paper","Final","","Scopus","2-s2.0-85183537880"
"Lu H.; Tian S.; Yu L.; Liu L.; Cheng J.; Wu W.; Kang X.; Zhang D.","Lu, Hongchun (57214780414); Tian, Shengwei (35119846500); Yu, Long (55272883600); Liu, Lu (57365898200); Cheng, Junlong (57217079223); Wu, Weidong (57226092151); Kang, Xiaojing (58729267200); Zhang, Dezhi (57274431700)","57214780414; 35119846500; 55272883600; 57365898200; 57217079223; 57226092151; 58729267200; 57274431700","DCACNet: Dual context aggregation and attention-guided cross deconvolution network for medical image segmentation","2022","Computer Methods and Programs in Biomedicine","214","","106566","","","","13","10.1016/j.cmpb.2021.106566","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120821466&doi=10.1016%2fj.cmpb.2021.106566&partnerID=40&md5=8e7891fddfb51791027b5740e4bd98d8","School of Software, Xinjiang University, Urumqi, 830046, Xinjiang, China; School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, 610031, Sichuan, China; Network Center, Xinjiang University, Urumqi, 830046, Xinjiang, China; School of Teacher Educaiton, Jining University, Qufu, 273199, Shandong, China; College of Computer Science, Sichuan University, Chengdu, 610065, China; People's Hospital of Xinjiang Uygur Autonomous Region, Xinjiang Key Laboratory of Dermatology Research, China","Lu H., School of Software, Xinjiang University, Urumqi, 830046, Xinjiang, China, School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, 610031, Sichuan, China; Tian S., School of Software, Xinjiang University, Urumqi, 830046, Xinjiang, China; Yu L., Network Center, Xinjiang University, Urumqi, 830046, Xinjiang, China; Liu L., School of Teacher Educaiton, Jining University, Qufu, 273199, Shandong, China; Cheng J., College of Computer Science, Sichuan University, Chengdu, 610065, China; Wu W., People's Hospital of Xinjiang Uygur Autonomous Region, Xinjiang Key Laboratory of Dermatology Research, China; Kang X., People's Hospital of Xinjiang Uygur Autonomous Region, Xinjiang Key Laboratory of Dermatology Research, China; Zhang D., People's Hospital of Xinjiang Uygur Autonomous Region, Xinjiang Key Laboratory of Dermatology Research, China","Background and Objective: Segmentation is a key step in biomedical image analysis tasks. Recently, convolutional neural networks (CNNs) have been increasingly applied in the field of medical image processing; however, standard models still have some drawbacks. Due to the significant loss of spatial information at the coding stage, it is often difficult to restore the details of low-level visual features using simple deconvolution, and the generated feature maps are sparse, which results in performance degradation. This prompted us to study whether it is possible to better preserve the deep feature information of the image in order to solve the sparsity problem of image segmentation models. Methods: In this study, we (1) build a reliable deep learning network framework, named DCACNet, to improve the segmentation performance for medical images; (2) propose a multiscale cross-fusion encoding network to extract features; (3) build a dual context aggregation module to fuse the context features at different scales and capture more fine-grained deep features; and (4) propose an attention-guided cross deconvolution decoding network to generate dense feature maps. We demonstrate the effectiveness of the proposed method on two publicly available datasets. Results: DCACNet was trained and tested on the prepared dataset, and the experimental results show that our proposed model has better segmentation performance than previous models. For 4-class classification (CHAOS dataset), the mean DSC coefficient reached 91.03%. For 2-class classification (Herlev dataset), the accuracy, precision, sensitivity, specificity, and Dice score reached 96.77%, 90.40%, 94.20%, 97.50%, and 97.69%, respectively. The experimental results show that DCACNet can improve the segmentation effect for medical images. Conclusion: DCACNet achieved promising results on the prepared dataset and improved segmentation performance. It can better retain the deep feature information of the image than other models and solve the sparsity problem of the medical image segmentation model. © 2021","Attention mechanism; Convolutional neural network; Cross deconvolution; Dual context aggregation; Medical image segmentation","Attention; Data Collection; Image Processing, Computer-Assisted; Neural Networks, Computer; Convolution; Convolutional neural networks; Deep learning; Image enhancement; Image segmentation; Medical image processing; Attention mechanisms; Convolutional neural network; Cross deconvolution; Deconvolutions; Dual context aggregation; Feature information; Feature map; Medical image segmentation; Segmentation performance; Sparsity problems; Article; convolutional neural network; deconvolution algorithm; deep learning; image segmentation; information processing; sensitivity and specificity; attention; image processing; Classification (of information)","","","","","Xinjiang Autonomous Region key research and development project, (2020E0234, 2021B01-002); National Natural Science Foundation of China, NSFC, (62162058, U2003208); National Natural Science Foundation of China, NSFC; Xinjiang Uygur Autonomous Region Department of Education, (XJ2020G072, XJ2020G073); Xinjiang Uygur Autonomous Region Department of Education","This research is partially supported by the National Natural Science Foundation of China ( 62162058 , U2003208 ), and Education Department of Xinjiang Uyghur Autonomous Region (XJ2020G072, XJ2020G073), and Xinjiang Autonomous Region key research and development project(2021B01-002, 2020E0234). We would also like to thank our tutor for the careful guidance and all the participants for their insightful comments.","Papandreou G., Chen L., Murphy K., Yuille A.L., Weakly- and semi-supervised learning of a DCNN for semantic image segmentation, CoRR, (2015); Long J., Shelhamer E., Darrell T., pp. 3431-3440, (2015); Badrinarayanan V., Kendall A., Cipolla R., SegNet: a deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, 12, pp. 2481-2495, (2017); Noh H., Hong S., Han B., pp. 1520-1528, (2015); Lin G., Milan A., Shen C., Reid I., pp. 5168-5177, (2017); Peng C., Zhang X., Yu G., Luo G., Sun J., pp. 1743-1751, (2017); Fu J., Liu J., Tian H., Li Y., Bao Y., Fang Z., Lu H., pp. 3146-3154, (2019); Zhang H., Dana K.J., Shi J., Zhang Z., Wang X., Tyagi A., Agrawal A., pp. 7151-7160, (2018); Hu J., Shen L., Sun G., pp. 7132-7141, (2018); Woo S., Park J., Lee J., Kweon I.S., pp. 3-19, (2018); Ronneberger O., Fischer P., Brox T., pp. 234-241, (2015); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-Net: learning dense volumetric segmentation from sparse annotation, Medical Image Computing and Computer-Assisted Intervention – MICCAI 2016, pp. 424-432, (2016); Milletari F., Navab N., Ahmadi S., pp. 565-571, (2016); Zhou Z., Rahman Siddiquee M.M., Tajbakhsh N., Liang J., UNet++: a nested U-Net architecture for medical image segmentation, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 3-11, (2018); Badrinarayanan V., Kendall A., Cipolla R., SegNet: a deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, 12, pp. 2481-2495, (2017); Zhao H., Shi J., Qi X., Wang X., Jia J., pp. 6230-6239, (2017); He K., Zhang X., Ren S., Sun J., pp. 770-778, (2016); Chen L., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., DeepLab: semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs, IEEE Trans. Pattern Anal. Mach. Intell., 40, 4, pp. 834-848, (2018); Mehta S., Rastegari M., Shapiro L.G., Hajishirzi H., pp. 9190-9200, (2019); Huang Z., Wang X., Huang L., Huang C., Wei Y., Liu W., CCNet: criss-cross attention for semantic segmentation, Comput. Vis. Pattern Recognit., (2018); Oktay O., Schlemper J., Folgoc L.L., Lee M.C.H., Heinrich M.P., Misawa K., Mori K., Mcdonagh S., Hammerla N., Kainz B., Et al., Attention U-Net: learning where to look for the pancreas, Comput. Vis. Pattern Recognit., (2018); Schlemper J., Oktay O., Schaap M., Heinrich M.P., Kainz B., Glocker B., Rueckert D., Attention gated networks: learning to leverage salient regions in medical images, Med. Image Anal., 53, pp. 197-207, (2019); Alom Z., Yakopcic C., Hasan M., Taha T.M., Asari V.K., Recurrent residual U-Net for medical image segmentation, J. Med. Imaging, 6, 1, (2019); Sinha A., Dolz J., Multi-scale guided attention for medical image segmentation, CoRR, (2019); Yang M., Yu K., Zhang C., Li Z., Yang K., pp. 3684-3692, (2018); He J., Li L., Xu J., Zheng C., ReLU deep neural networks and linear finite elements, Numer. Anal., (2018); Ioffe S., Szegedy C., pp. 448-456, (2015); Xie S., Girshick R., Dollar P., Tu Z., He K., pp. 5987-5995, (2017); Zang F., Zhang J., pp. 16-19, (2011); Selvi E., Selver M.A., Kavur A.E., Guzelis C., Dicle O., Segmentation of abdominal organs from mr images using multi-level hierarchical classification, J. Faculty Eng., 30, 3, pp. 533-546, (2015); Zhao J., Dai L., Zhang M., Yu F., Li M., Li H., Wang W., Zhang L., PGU-net+: progressive growing of U-net+ for automated cervical nuclei segmentation, Multiscale Multimodal Medical Imaging, pp. 51-58, (2020); Zhang L., Lu L., Nogues I., Summers R.M., Liu S., Yao J., DeepPap: deep convolutional networks for cervical cell classification, IEEE J. Biomed. Health Inform., 21, 6, pp. 1633-1643, (2017); Liu G., Zhou Z., Zhong H., Xie S., Gradient descent with adaptive momentum for active contour models, IET Comput. Vis., 8, 4, pp. 287-298, (2014); De Boer P., Kroese D.P., Mannor S., Rubinstein R.Y., A tutorial on the cross-entropy method, Ann. Oper. Res., 134, 1, pp. 19-67, (2005)","S. Tian; School of Software, Xinjiang University, Urumqi, 830046, China; email: tsw@xju.edu.cn","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","34890992","English","Comput. Methods Programs Biomed.","Article","Final","","Scopus","2-s2.0-85120821466"
"Yang Q.; Geng C.; Chen R.; Pang C.; Han R.; Lyu L.; Zhang Y.","Yang, Qinghan (57226687891); Geng, Chong (58894356800); Chen, Ruyue (57679297900); Pang, Chen (57242601700); Han, Run (57388803600); Lyu, Lei (57204062203); Zhang, Yuang (24451415400)","57226687891; 58894356800; 57679297900; 57242601700; 57388803600; 57204062203; 24451415400","DMU-Net: Dual-route mirroring U-Net with mutual learning for malignant thyroid nodule segmentation","2022","Biomedical Signal Processing and Control","77","","103805","","","","12","10.1016/j.bspc.2022.103805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130414984&doi=10.1016%2fj.bspc.2022.103805&partnerID=40&md5=75ff24c29c2638fd1d0d31f0596e285c","School of Information Science and Engineering, Shandong Normal University, Jinan, 250358, China; Department of Breast and Thyroid Surgery, Shandong Provincial Hospital Affiliated to Shandong First Medical University, Jinan, 250021, China","Yang Q., School of Information Science and Engineering, Shandong Normal University, Jinan, 250358, China; Geng C., Department of Breast and Thyroid Surgery, Shandong Provincial Hospital Affiliated to Shandong First Medical University, Jinan, 250021, China; Chen R., Department of Breast and Thyroid Surgery, Shandong Provincial Hospital Affiliated to Shandong First Medical University, Jinan, 250021, China; Pang C., School of Information Science and Engineering, Shandong Normal University, Jinan, 250358, China; Han R., School of Information Science and Engineering, Shandong Normal University, Jinan, 250358, China; Lyu L., School of Information Science and Engineering, Shandong Normal University, Jinan, 250358, China; Zhang Y., School of Information Science and Engineering, Shandong Normal University, Jinan, 250358, China","It is meaningful for radiologists to segment thyroid nodules in ultrasound images quickly and accurately using an effective segmentation algorithm. With the rise of deep learning in computer vision, many deep learning-based methods have been proposed to assist radiologists in diagnosing thyroid diseases, such as thyroid nodule classification, detection and segmentation, but there exist few methods paying attention to malignant thyroid nodule segmentation. The goal of thyroid nodule segmentation is to identify the type of thyroid nodule. However, the identification of thyroid nodule type has been relatively well developed and the identification work almost can't bother radiologists. The more important for radiologists is to detect the inconspicuous malignant nodules precisely in ultrasonic images, avoiding radiologists confusing tissues and malignant thyroid nodules during their diagnosis. This paper proposes a deep learning-based CAD (Computer-aided diagnosis) method called Dual-route Mirroring U-Net (DMU-Net) to segment malignant thyroid nodules automatically. The method uses two subnets (U-shape subnet, inversed U-shape subnet) and three modules (pyramid attention module (PAM), margin refinement module (MRM), aggregation module (AM)) to extract contextual information of thyroid nodules and margin details in ultrasonic images. Further, the strategy of mutual learning is introduced from the natural image classification task to enhance the performance of DMU-Net. We train and evaluate our method on the self-built Malignant Thyroid Nodule Segmentation (MTNS) dataset. Finally, we compare the DMU-Net with several classical deep learning-based methods on the MTNS dataset and other public datasets. The results show our DMU-Net can achieve superior performance on these datasets. © 2022 Elsevier Ltd","Biomedical image segmentation; Convolutional neural network; Malignant thyroid nodule; Margin details extraction; U-Net","Computer aided instruction; Convolutional neural networks; Deep learning; Image enhancement; Image segmentation; Learning systems; Ultrasonic imaging; Biomedical image segmentation; Convolutional neural network; Details extractions; Dual route; Malignant thyroid nodule; Margin detail extraction; Nodule segmentation; Subnets; Thyroid nodule; U-net; Article; convolutional neural network; deep learning; feature extraction; human; image segmentation; methodology; radiologist; thyroid cancer; thyroid gland; thyroid nodule; ultrasound; Computer aided diagnosis","","","","","Jinan Science and technology innovation development Foundation, (202126003); National Natural Science Foundation of China, NSFC, (61976127); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Shandong Province, (ZR2019MF071, ZR2021LZL012); Natural Science Foundation of Shandong Province","This work was supported in part by the National Natural Science Foundation of China under Grant 61976127, in part by the Shandong Provincial Natural Science Foundation under Grants ZR2021LZL012, ZR2019MF071, in part by the Jinan Science and technology innovation development Foundation under Grant 202126003.","Abdolali F., Kapur J., Jaremko J.L., Noga M., Hareendranathan A.R., Punithakumar K., Automated thyroid nodule detection from ultrasound imaging using deep convolutional neural networks, Comput. Biol. Med., 122, (2020); Akbari M., Mohrekesh M., Nasr-Esfahani E., Soroushmehr S.R., Karimi N., Samavi S., Najarian K., Polyp segmentation in colonoscopy images using fully convolutional network, 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), IEEE, pp. 69-72, (2018); Alrubaidi W.M., Peng B., Yang Y., Chen Q., An interactive segmentation algorithm for thyroid nodules in ultrasound images, International Conference on Intelligent Computing, Springer, pp. 107-115, (2016); Badrinarayanan V., Kendall A., Cipolla R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, pp. 2481-2495, (2017); Brandao P., Mazomenos E., Ciuti G., Calio R., Bianchi F., Menciassi A., Dario P., Koulaouzidis A., Arezzo A., Stoyanov D., Fully convolutional neural networks for polyp segmentation in colonoscopy, Medical Imaging 2017: Computer-Aided Diagnosis, (2017); Chen J., You H., Li K., A review of thyroid gland segmentation and thyroid nodule segmentation methods for medical ultrasound images, Comput. Methods Programs Biomed., 185, (2020); Chi J., Walia E., Babyn P., Wang J., Groot G., Eramian M., Thyroid nodule classification in ultrasound images by fine-tuning deep convolutional neural network, J. Digital Imaging, 30, pp. 477-486, (2017); Du W., Sang N., An effective method for ultrasound thyroid nodules segmentation, 2015 International Symposium on Bioelectronics and Bioinformatics (ISBB), IEEE, pp. 207-210, (2015); Fan D.P., Ji G.P., Zhou T., Chen G., Fu H., Shen J., Shao L., Pranet: Parallel reverse attention network for polyp segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 263-273, (2020); Fang Y., Chen C., Yuan Y., pp. 302-310, (2019); Gharib H., Papini E., Paschke R., Duick D., Valcavi R., Hegedus L., Vitti P., Nodules aaetfot. american association of clinical endocrinologists, associazione medici endocrinologi, and european thyroid association medical guidelines for clinical practice for the diagnosis and management of thyroid nodules: executive summary of recommendations, Endocr Pract, 16, pp. 1-43, (2010); Gulame M.B., Dixit V.V., Suresh M., Thyroid nodules segmentation methods in clinical ultrasound images: A review, Mater. Today: Proc., 45, pp. 2270-2276, (2021); Gyorki D.E., Untch B., Tuttle R.M., Shaha A.R., Prophylactic central neck dissection in differentiated thyroid cancer: an assessment of the evidence, Ann. Surg. Oncol., 20, pp. 2285-2289, (2013); Haugen B.R., Alexander E.K., Bible K.C., Doherty G.M., Mandel S.J., Nikiforov Y.E., Pacini F., Randolph G.W., Sawka A.M., Schlumberger M., Et al., 2015 american thyroid association management guidelines for adult patients with thyroid nodules and differentiated thyroid cancer: the american thyroid association guidelines task force on thyroid nodules and differentiated thyroid cancer, Thyroid, 26, pp. 1-133, (2016); He K., Zhang X., Ren S., Sun J., Spatial pyramid pooling in deep convolutional networks for visual recognition, IEEE Trans. Pattern Anal. Mach. Intell., 37, pp. 1904-1916, (2015); Horvath E., Majlis S., Rossi R., Franco C., Niedmann J.P., Castro A., Dominguez M., An ultrasonogram reporting system for thyroid nodules stratifying cancer risk for clinical management, J. Clin. Endocrinol. Metab., 94, pp. 1748-1751, (2009); Hu Q., Abramoff M.D., Garvin M.K., Automated separation of binary overlapping trees in low-contrast color retinal images, International conference on medical image computing and computer-assisted intervention, Springer, pp. 436-443, (2013); Huang Q., Huang Y., Luo Y., Yuan F., Li X., Segmentation of breast ultrasound image with semantic classification of superpixels, Med. Image Anal., 61, (2020); Iakovidis D.K., Savelonas M.A., Karkanis S.A., Maroulis D.E., A genetically optimized level set approach to segmentation of thyroid ultrasound images, Appl. Intell., 27, pp. 193-203, (2007); Jha D., Riegler M.A., Johansen D., Halvorsen P., Johansen H.D., Doubleu-net: A deep convolutional neural network for medical image segmentation, 2020 IEEE 33rd International symposium on computer-based medical systems (CBMS), IEEE, pp. 558-564, (2020); Jha D., Smedsrud P.H., Riegler M.A., Johansen D., De Lange T., Halvorsen P., Johansen H.D., Resunet++: An advanced architecture for medical image segmentation, 2019 IEEE International Symposium on Multimedia (ISM), IEEE, pp. 225-2255, (2019); Koundal D., Gupta S., Singh S., Computer aided thyroid nodule detection system using medical ultrasound images, Biomed. Signal Process. Control, 40, pp. 117-130, (2018); La Vecchia C., Malvezzi M., Bosetti C., Garavello W., Bertuccio P., Levi F., Negri E., Thyroid cancer mortality and incidence: a global overview, Int. J. Cancer, 136, pp. 2187-2195, (2015); Li C., Xu C., Gui C., Fox M.D., Distance regularized level set evolution and its application to image segmentation, IEEE Trans. Image Process., 19, pp. 3243-3254, (2010); Liu T., Guo Q., Lian C., Ren X., Liang S., Yu J., Niu L., Sun W., Shen D., Automated detection and classification of thyroid nodules in ultrasound images using clinical-knowledge-guided convolutional neural networks, Med. Image Anal., 58, (2019); LiVolsi V.A., Papillary thyroid carcinoma: an update, Mod. Pathol., 24, pp. S1-S9, (2011); Ma J., Wu F., Jiang T., Zhao Q., Kong D., Ultrasound image-based thyroid nodule automatic segmentation using convolutional neural networks, Int. J. Comput. Assisted Radiol. Surgery, 12, pp. 1895-1910, (2017); Maroulis D.E., Savelonas M.A., Iakovidis D.K., Karkanis S.A., Dimitropoulos N., Variable background active contour model for computer-aided delineation of nodules in thyroid ultrasound images, IEEE Trans. Inf Technol. Biomed., 11, pp. 537-543, (2007); Maroulis D.E., Savelonas M.A., Karkanis S.A., Iakovidis D.K., Dimitropoulos N., Computer-aided thyroid nodule detection in ultrasound images, pp. 271-276, (2005); Nguyen T.C., Nguyen T.P., Diep G.H., Tran-Dinh A.H., Nguyen T.V., Tran M.T., Ccbanet: Cascading context and balancing attention for polyp segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 633-643, (2021); Nugroho H.A., Nugroho A., Choridah L., Thyroid nodule segmentation using active contour bilateral filtering on ultrasound images, 2015 International Conference on Quality in Research (QiR), IEEE, pp. 43-46, (2015); Papini E., Pacella C.M., Solbiati L.A., Achille G., Barbaro D., Bernardi S., Cantisani V., Cesareo R., Chiti A., Cozzaglio L., Et al., Minimally-invasive treatments for benign thyroid nodules: a delphi-based consensus statement from the italian minimally-invasive treatments of the thyroid (mitt) group, Int. J. Hyperthermia, (2019); Pellegriti G., Frasca F., Regalbuto C., Squatrito S., Vigneri R., (2013); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical image computing and computer-assisted intervention, Springer, pp. 234-241, (2015); Savelonas M.A., Iakovidis D.K., Legakis I., Maroulis D., Active contours guided by echogenicity and texture for delineation of thyroid nodules in ultrasound images, IEEE Trans. Inf Technol. Biomed., 13, pp. 519-527, (2008); Siegel R.L., Miller K.D., Fuchs H.E., Jemal A., pp. 7-33, (2021); Sirinukunwattana K., Pluim J.P., Chen H., Qi X., Heng P.A., Guo Y.B., Wang L.Y., Matuszewski B.J., Bruni E., Sanchez U., Et al., Gland segmentation in colon histology images: The glas challenge contest, Med. Image Anal., 35, pp. 489-502, (2017); Song R., Zhang L., Zhu C., Liu J., Yang J., Zhang T., Thyroid nodule ultrasound image classification through hybrid feature cropping network, IEEE Access, 8, pp. 64064-64074, (2020); Tong Y., Liu Y., Zhao M., Meng L., Zhang J., Improved u-net malf model for lesion segmentation in breast ultrasound images, Biomed. Signal Process. Control, 68, (2021); Tsantis S., Dimitropoulos N., Cavouras D., Nikiforidis G., A hybrid multi-scale model for thyroid nodule boundary detection on ultrasound images, Comput. Methods Programs Biomed., 84, pp. 86-98, (2006); Vakanski A., Xian M., Freer P.E., Attention-enriched deep learning model for breast tumor segmentation in ultrasound images, Ultrasound Med. Biol., 46, pp. 2819-2833, (2020); Wang J., Li S., Song W., Qin H., Zhang B., Hao A., Learning from weakly-labeled clinical data for automatic thyroid nodule classification in ultrasound images, 2018 25th IEEE International Conference on Image Processing (ICIP), IEEE, pp. 3114-3118, (2018); Wang K., Liang S., Zhang Y., Residual feedback network for breast lesion segmentation in ultrasound image, International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 471-481, (2021); Wang L., Yang S., Yang S., Zhao C., Tian G., Gao Y., Chen Y., Lu Y., Automatic thyroid nodule recognition and diagnosis in ultrasound imaging with the yolov2 neural network, World J. Surg. Oncol., 17, pp. 1-9, (2019); Wang X., Girshick R., Gupta A., He K., Non-local neural networks, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 7794-7803, (2018); Wei J., Hu Y., Zhang R., Li Z., Zhou S.K., Cui S., Shallow attention network for polyp segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 699-708, (2021); Wei X., Li Y., Zhang S., Gao M., Meta-analysis of thyroid imaging reporting and data system in the ultrasonographic diagnosis of 10,437 thyroid nodules, Head & Neck, 38, pp. 309-315, (2016); Xiao X., Lian S., Luo Z., Li S., Weighted res-unet for high-quality retina vessel segmentation, 2018 9th international conference on information technology in medicine and education (ITME), IEEE, pp. 327-331, (2018); Xie S., Yu J., Liu T., Chang Q., Niu L., Sun W., Thyroid nodule detection in ultrasound images with convolutional neural networks, 2019 14th IEEE Conference on Industrial Electronics and Applications (ICIEA), IEEE, pp. 1442-1446, (2019); Xu C., Qi Y., Wang Y., Lou M., Pi J., Ma Y., Arf-net: An adaptive receptive field network for breast mass segmentation in whole mammograms and ultrasound images, Biomed. Signal Process. Control, 71, (2022); Yan Y., Liu Y., Wu Y., Zhang H., Zhang Y., Meng L., Accurate segmentation of breast tumors using ae u-net with hdc model in ultrasound images, Biomed. Signal Process. Control, 72, (2022); Yang W., Dong Y., Du Q., Qiang Y., Wu K., Zhao J., Yang X., Zia M.B., Integrate domain knowledge in training multi-task cascade deep learning model for benign–malignant thyroid nodule classification on ultrasound images, Eng. Appl. Artif. Intell., 98, (2021); Ying X., Yu Z., Yu R., Li X., Yu M., Zhao M., Liu K., Thyroid nodule segmentation in ultrasound images based on cascaded convolutional neural network, International Conference on Neural Information Processing, Springer, pp. 373-384, (2018); Zhang Y., Xiang T., Hospedales T.M., Lu H., Deep mutual learning, in, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4320-4328, (2018); Zhong J., Wang W., Wu H., Wen Z., Qin J., Polypseg: An efficient context-aware network for polyp segmentation from colonoscopy videos, International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 285-294, (2020); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., pp. 3-11, (2018); Zhu Y.C., AlZoubi A., Jassim S., Jiang Q., Zhang Y., Wang Y.B., Ye X.D., Hongbo D., A generic deep learning framework to classify thyroid and breast lesions in ultrasound images, Ultrasonics, 110, (2021)","C. Geng; Department of Breast and Thyroid Surgery, Shandong Provincial Hospital Affiliated to Shandong First Medical University, Jinan, 250021, China; email: gengchong2021@163.com","","Elsevier Ltd","","","","","","17468094","","","","English","Biomed. Signal Process. Control","Article","Final","","Scopus","2-s2.0-85130414984"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14448 LNCS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178549397&partnerID=40&md5=cd53510390634e0e25fb8bc1b0bfb5e0","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","03029743","978-981998081-9","","","English","Lect. Notes Comput. Sci.","Conference review","Final","","Scopus","2-s2.0-85178549397"
"Hamzehei S.; Bai J.; Raimondi G.; Tripp R.; Ostroff L.; Nabavi S.","Hamzehei, Sahand (58074812700); Bai, Jun (57221616470); Raimondi, Gianna (57653961200); Tripp, Rebecca (58176501400); Ostroff, Linnaea (6506542847); Nabavi, Sheida (56229091400)","58074812700; 57221616470; 57653961200; 58176501400; 6506542847; 56229091400","3D Biological/Biomedical Image Registration with enhanced Feature Extraction and Outlier Detection","2023","ACM-BCB 2023 - 14th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics","","","1","","","","0","10.1145/3584371.3612965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175838560&doi=10.1145%2f3584371.3612965&partnerID=40&md5=4d91e845806c9386dec23c04b76eb04f","University of Connecticut, Department of Computer Science & Engineering, Storrs, CT, United States; University of Connecticut, Department of Physiology & Neurobiology, Storrs, CT, United States","Hamzehei S., University of Connecticut, Department of Computer Science & Engineering, Storrs, CT, United States; Bai J., University of Connecticut, Department of Computer Science & Engineering, Storrs, CT, United States; Raimondi G., University of Connecticut, Department of Physiology & Neurobiology, Storrs, CT, United States; Tripp R., University of Connecticut, Department of Physiology & Neurobiology, Storrs, CT, United States; Ostroff L., University of Connecticut, Department of Physiology & Neurobiology, Storrs, CT, United States; Nabavi S., University of Connecticut, Department of Computer Science & Engineering, Storrs, CT, United States","In various applications, such as computer vision, medical imaging, and robotics, three-dimensional (3D) image registration is a significant step. It enables the alignment of various datasets into a single coordinate system, consequently providing a consistent perspective that allows further analysis. By precisely aligning images, we can compare, analyze, and combine data collected in different situations. This paper presents a novel approach for 3D or z-stack microscopy and medical image registration, utilizing a combination of conventional and deep learning techniques for feature extraction and adaptive likelihood-based methods for outlier detection. The proposed method uses the Scale-invariant Feature Transform (SIFT) and the Residual Network (ResNet50) deep neural learning network to extract effective features and obtain precise and exhaustive representations of image contents. The registration approach also employs the adaptive Maximum Likelihood Estimation SAmple Consensus (MLESAC) method that optimizes outlier detection and increases noise and distortion resistance to improve the efficacy of these combined extracted features. This integrated approach demonstrates robustness, flexibility, and adaptability across a variety of imaging modalities, enabling the registration of complex images with higher precision. Experimental results show that the proposed algorithm outperforms state-of-the-art image registration methods, including conventional SIFT, SIFT with Random Sample Consensus (RANSAC), and Oriented FAST and Rotated BRIEF (ORB) methods, as well as registration software packages such as bUnwrapJ and TurboReg, in terms of Mutual Information (MI), Phase Congruency-Based (PCB) metrics, and Gradiant-based metrics (GBM), using 3D MRI and 3D serial sections of multiplex microscopy images. © 2023 ACM.","3D biomedical images; deep learning; feature extraction; image registration; maximum likelihood estimation sample consensus (MLESAC); scale-invariant feature transform (SIFT); z-stack microscopy images","Anomaly detection; Data handling; Deep neural networks; Extraction; Image enhancement; Image registration; Learning systems; Magnetic resonance imaging; Maximum likelihood estimation; Medical imaging; Polychlorinated biphenyls; Statistics; 3d biomedical image; Biomedical images; Deep learning; Features extraction; Images registration; Invariant feature transforms; Maximum likelihood estimation sample consensus; Maximum-likelihood estimation; Microscopy images; Sample consensus; Scale invariant features; Scale-invariant feature transform; Z-stack microscopy image; Feature extraction","","","","","Computer Science and Engineering departmental at UConn; National Institutes of Health, NIH, (RF1MH130472); National Institutes of Health, NIH","This work is supported by the National Institutes of Health (NIH) under grant No. RF1MH130472, PI: Ostroff, Co-I: Nabavi, and Hamze-hei’s Cigna fellowship from the Computer Science and Engineering departmental at UConn.","Ames Caroline, Et al., Evaluation of laparoscopic performance with alteration in angle of vision, Journal of Endourology, 20, 4, pp. 281-283, (2006); Arganda-Carreras Ignacio, Sorzano Carlos OS, Marabini Roberto, Carazo Jose Maria, Ortiz-de Solorzano Carlos, Kybic Jan, Consistent and elastic registration of histological sections using vector-spline regularization, Computer Vision Approaches to Medical Image Analysis: Second International ECCV Workshop, CVAMIA 2006 Graz, pp. 85-95, (2006); Bentley Jon Louis, Multidimensional binary search trees used for associative searching, Commun. ACM, 18, 9, pp. 509-517, (1975); Bottou Leon, Stochastic gradient descent tricks, Neural Networks: Tricks of the Trade: Second Edition, pp. 421-436, (2012); Buades Antoni, Coll Bartomeu, Morel J-M, A non-local algorithm for image denoising, 2005 IEEE computer society conference on computer vision and pattern recognition (CVPR'05), 2, pp. 60-65, (2005); Cardona Albert, Saalfeld Stephan, Preibisch Stephan, Schmid Benjamin, Cheng Anchi, Pulokas Jim, Tomancak Pavel, Hartenstein Volker, An integrated micro-and macroarchitectural analysis of the Drosophila brain by computerassisted serial section electron microscopy, PLoS biology, 8, 10, (2010); Cardona Albert, Saalfeld Stephan, Schindelin Johannes, Arganda-Carreras Ignacio, Preibisch Stephan, Longair Mark, Tomancak Pavel, Hartenstein Volker, Douglas Rodney J, TrakEM2 software for neural circuit reconstruction, PloS one, 7, 6, (2012); Collignon Andre, Maes Frederik, Delaere Dominique, Vandermeulen Dirk, Suetens Paul, Marchal Guy, Automated multi-modality image registration based on information theory, Information processing in medical imaging, 3, pp. 263-274, (1995); Copeland Craig R., Et al., Accurate localization microscopy by intrinsic aberration calibration, Nature Communications, 12, (2021); Deng Jia, Dong Wei, Socher Richard, Li Li-Jia, Li Kai, Fei-Fei Li, Imagenet: A large-scale hierarchical image database, 2009 IEEE conference on computer vision and pattern recognition, pp. 248-255, (2009); Fan Jingfan, Cao Xiaohuan, Yap Pew-Thian, Shen Dinggang, BIRNet: Brain image registration using dual-supervised fully convolutional networks, Medical image analysis, 54, pp. 193-206, (2019); Fischler Martin A, Bolles Robert C, Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography, Commun. ACM, 24, 6, pp. 381-395, (1981); Gonzalez Rafael C, Digital image processing, (2009); Guzowski John F, Timlin Jerilyn A, Roysam Badri, McNaughton Bruce L, Worley Paul F, Barnes Carol A, Mapping behaviorally relevant neural circuits with immediate-early gene expression, Current opinion in neurobiology, 15, 5, pp. 599-606, (2005); Hand A., Sun T., Barber D., Hose D. R., Macneil S., Automated tracking of migrating cells in phase-contrast video microscopy sequences using image registration, Journal of Microscopy, 234, (2009); Hartley Richard, Zisserman Andrew, Multiple view geometry in computer vision, (2003); Haskins G., Kruger U., Yan P., Deep learning in medical image registration: A survey, Machine Vision and Applications, 31, 8, (2020); He Kaiming, Zhang Xiangyu, Ren Shaoqing, Sun Jian, Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Hill Derek LG, Batchelor Philipp G, Holden Mark, Hawkes David J, Medical image registration, Physics in medicine & biology, 46, 3, (2001); Hofmann M., Steinke F., Scheel V., Charpiat G., Farquhar J., Aschoff P., Brady M., Scholkopf B., Pichler B. J., MRI-Based Attenuation Correction for PET/MRI: A Novel Approach Combining Pattern Recognition and Atlas Registration, Journal of Nuclear Medicine, 49, 11, pp. 1875-1883, (2008); Kajihara Takehiro, Funatomi Takuya, Makishima Haruyuki, Aoto Takahito, Kubo Hiroyuki, Yamada Shigehito, Mukaigawa Yasuhiro, Non-rigid registration of serial section images by blending transforms for 3D reconstruction, Pattern Recognition, 96, (2019); Klein Arno, Andersson Jesper, Ardekani Babak A, Ashburner John, Avants Brian, Chiang Ming-Chang, Christensen Gary E, Louis Collins D, Gee James, Hellier Pierre, Et al., Evaluation of 14 nonlinear deformation algorithms applied to human brain MRI registration, Neuroimage, 46, 3, pp. 786-802, (2009); Kovesi Peter, Et al., Image features from phase congruency, Videre: Journal of computer vision research, 1, 3, pp. 1-26, (1999); Krizhevsky Alex, Sutskever Ilya, Hinton Geoffrey E, Imagenet classification with deep convolutional neural networks, Commun. ACM, 60, 6, pp. 84-90, (2017); Kudryavtsev Andrey V., Dembele Sounkalo, Piat Nadine, Full 3d rotation estimation in scanning electron microscope, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), (2017); Kwak J. T., Hewitt S. M., Sinha S., Et al., Multimodal microscopy for automated histologic analysis of prostate cancer, BMC Cancer, 11, (2011); LeCun Yann, Bottou Leon, Bengio Yoshua, Haffner Patrick, Gradientbased learning applied to document recognition, Proc. IEEE, 86, 11, pp. 2278-2324, (1998); Lowe G, Sift-the scale invariant feature transform, Int. J, 2, pp. 91-110, (2004); Lucas Bruce D, Kanade Takeo, An Iterative Image Registration Technique with an Application to Stereo Vision, IJCAI'81: 7th international joint conference on Artificial intelligence, pp. 674-679, (1981); Marr David, Hildreth Ellen, Theory of edge detection, Proceedings of the Royal Society of London. Series B. Biological Sciences, 207, 1167, pp. 187-217, (1980); Matsuyama Taka-aki, Inoue Shin, Kobayashi Youichi, Sakai Tetsuo, Saito Tsukasa, Katagiri Takashi, Ota Hidekazu, Anatomical diversity and age-related histological changes in the human right atrial posterolateral wall, EP Europace, 6, 4, pp. 307-315, (2004); Muja Marius, Lowe David G, Fast approximate nearest neighbors with automatic algorithm configuration, VISAPP (1), 2, pp. 331-340, (2009); Nan Jiaofen, Su Junya, Zhang Jincan, Methodological Research on Image Registration Based on Human Brain Tissue In Vivo, Electronics, 12, 3, (2023); Nister David, Stewenius Henrik, Scalable recognition with a vocabulary tree, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), 2, pp. 2161-2168, (2006); Pietrzyk U., Herholz K., Fink G., Jacobs A., Mielke R., Slansky I., Wurker M., Heiss WD, An interactive technique for three-dimensional image registration: validation for PET, SPECT, MRI and CT brain studies, J Nucl Med, 35, 12, pp. 2011-2018, (1994); Pluim Josien PW, Antoine Maintz JB, Viergever Max A, Mutualinformation-based registration of medical images: A survey, IEEE transactions on medical imaging, 22, 8, pp. 986-1004, (2003); Radtke Andrea J, Kandov Evelyn, Lowekamp Bradley, Speranza Emily, Chu Colin J, Gola Anita, Thakur Nishant, Shih Rochelle, Yao Li, Yaniv Ziv Rafael, Et al., IBEX: A versatile multiplex optical imaging approach for deep phenotyping and spatial analysis of cells in complex tissues, Proceedings of the National Academy of Sciences, 117, 52, pp. 33455-33465, (2020); Roberts Nicholas, Magee Derek, Song Yi, Brabazon Keeran, Shires Mike, Crellin Doreen, Orsi Nicolas M, Quirke Richard, Quirke Philip, Treanor Darren, Toward routine use of 3D histopathology as a research tool, The American journal of pathology, 180, 5, pp. 1835-1842, (2012); Rublee Ethan, Rabaud Vincent, Konolige Kurt, Bradski Gary, ORB: An efficient alternative to SIFT or SURF, 2011 International conference on computer vision, pp. 2564-2571, (2011); Rueden Curtis T, Schindelin Johannes, Hiner Mark C, DeZonia Barry E, Walter Alison E, Arena Ellen T, Eliceiri Kevin W, ImageJ2: ImageJ for the next generation of scientific image data, BMC bioinformatics, 18, pp. 1-26, (2017); Saalfeld Stephan, Fetter Richard, Cardona Albert, Tomancak Pavel, Elastic volume reconstruction from series of ultra-thin microscopy sections, Nature methods, 9, 7, pp. 717-720, (2012); Salvi Joaquim, Matabosch Carles, Fofi David, Forest Josep, A review of recent range image registration methods with accuracy evaluation, Image and Vision Computing, 25, pp. 578-596, (2007); Sanderson Michael J, Smith Ian, Parker Ian, Bootman Martin D, Fluorescence microscopy, Cold Spring Harbor Protocols 2014, 10, (2014); Schindelin Johannes, Arganda-Carreras Ignacio, Frise Erwin, Kaynig Verena, Longair Mark, Pietzsch Tobias, Preibisch Stephan, Rueden Curtis, Saalfeld Stephan, Schmid Benjamin, Et al., Fiji: An open-source platform for biologicalimage analysis, Nature methods, 9, 7, pp. 676-682, (2012); Schindelin Johannes, Rueden Curtis T, Hiner Mark C, Eliceiri Kevin W, The ImageJ ecosystem: An open platform for biomedical image analysis, Molecular reproduction and development, 82, 7-8, pp. 518-529, (2015); Schneider Caroline A, Rasband Wayne S, Eliceiri Kevin W, NIH Image to ImageJ: 25 years of image analysis, Nature methods, 9, 7, pp. 671-675, (2012); Sharkey James P., Et al., A one-piece 3D printed flexure translation stage for open-source microscopy, Review of Scientific Instruments, 87, 2, (2016); Oscar Sanchez Sorzano Carlos, Thevenaz Philippe, Unser Michael, Elastic registration of biological images using vector-spline regularization, IEEE Transactions on Biomedical Engineering, 52, 4, pp. 652-663, (2005); Torr Philip HS, Zisserman Andrew, MLESAC: A new robust estimator with application to estimating image geometry, Computer vision and image understanding, 78, 1, pp. 138-156, (2000); Wang Zhou, Bovik Alan C, Sheikh Hamid R, Simoncelli Eero P, Image quality assessment: from error visibility to structural similarity, IEEE transactions on image processing, 13, 4, pp. 600-612, (2004); Zhou Shenglong, Xiong Zhiwei, Chen Chang, Chen Xuejin, Liu Dong, Zhang Yueyi, Zha Zheng-Jun, Wu Feng, Fast and accurate electron microscopy image registration with 3D convolution, Medical Image Computing and Computer Assisted Intervention-MICCAI 2019: 22nd International Conference, pp. 478-486, (2019)","","","Association for Computing Machinery, Inc","","14th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics, ACM-BCB 2023","3 September 2023 through 6 September 2023","Houston","193171","","979-840070126-9","","","English","ACM-BCB - ACM Conf. Bioinform., Comput. Biol., Health Informatics","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85175838560"
"Lin Y.; Liang Z.; He Y.; Huang W.; Guan T.","Lin, Yuanhua (58556669500); Liang, Zhendong (57963206100); He, Yonghong (7404941330); Huang, Wenting (57488200300); Guan, Tian (7006929546)","58556669500; 57963206100; 7404941330; 57488200300; 7006929546","End-to-end affine registration framework for histopathological images with weak annotations","2023","Computer Methods and Programs in Biomedicine","241","","107763","","","","1","10.1016/j.cmpb.2023.107763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169299165&doi=10.1016%2fj.cmpb.2023.107763&partnerID=40&md5=1fb902796ebe9648e81415a57f0e3287","Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China; National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital & Shenzhen Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Shenzhen, 518116, China","Lin Y., Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China; Liang Z., Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China; He Y., Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China; Huang W., National Cancer Center/National Clinical Research Center for Cancer/Cancer Hospital & Shenzhen Hospital, Chinese Academy of Medical Sciences and Peking Union Medical College, Shenzhen, 518116, China; Guan T., Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China","Background and Objective: Histopathological image registration is an essential component in digital pathology and biomedical image analysis. Deep-learning-based algorithms have been proposed to achieve fast and accurate affine registration. Some previous studies assume that the pairs are free from sizeable initial position misalignment and large rotation angles before performing the affine transformation. However, large-rotation angles are often introduced into image pairs during the production process in real-world pathology images. Reliable initial alignment is important for registration performance. The existing deep-learning-based approaches often use a two-step affine registration pipeline because convolutional neural networks (CNNs) cannot correct large-angle rotations. Methods: In this manuscript, a general framework ARoNet is developed to achieve end-to-end affine registration for histopathological images. We use CNNs to extract global features of images and fuse them to construct correspondent information for affine transformation. In ARoNet, a rotation recognition network is implemented to eliminate great rotation misalignment. In addition, a self-supervised learning task is proposed to assist the learning of image representations in an unsupervised manner. Results: We applied our model to four datasets, and the results indicate that ARoNet surpasses existing affine registration algorithms in alignment accuracy when large angular misalignments (e.g., 180 rotation) are present, providing accurate affine initialization for subsequent non-rigid alignments. Besides, ARoNet shows advantages in execution time (0.05 per pair), registration accuracy, and robustness. Conclusion: We believe that the proposed general framework promises to simplify and speed up the registration process and has the potential for clinical applications. © 2023 Elsevier B.V.","Affine estimation; ANHIR; Histopathological image registration","Algorithms; Image Processing, Computer-Assisted; Neural Networks, Computer; Alignment; Convolutional neural networks; Deep learning; Image annotation; Large dataset; Learning systems; Pathology; Rotation; Affine estimations; Affine registration; Affine transformations; ANHIR; Convolutional neural network; End to end; Histopathological image registration; Histopathological images; Images registration; Large rotation angles; affine transform; article; convolutional neural network; deep learning; histopathology; image registration; learning; pipeline; rotation; velocity; algorithm; artificial neural network; image processing; Image registration","","","","","Science and Technology Research Program of Shenzhen City, (JCYJ20200109110606054, WDZC20200821141349001); National Natural Science Foundation of China, NSFC, (61875102); National Natural Science Foundation of China, NSFC","Funding text 1: This work was supported in part by the National Science Foundation of China (No. 61875102 ), and in part by the Science and Technology Research Program of Shenzhen City under Grant JCYJ20200109110606054 and Grant WDZC20200821141349001 . ; Funding text 2: The authors would like to thank Xin Wang (the New H3C Technologies Co., Ltd, China) for his support in computing resources. This work was supported in part by the National Science Foundation of China (No. 61875102 ), and in part by the Science and Technology Research Program of Shenzhen City under Grant JCYJ20200109110606054 and Grant WDZC20200821141349001 . ","Chen Z., Zhao S., Hu K., Han J., Ji Y., Ling S., Gao X., A hierarchical and multi-view registration of serial histopathological images, Pattern Recognit. Lett., 152, pp. 210-217, (2021); Shao W., Banh L., Kunder C.A., Fan R.E., Soerensen S.J.C., Wang J.B., Teslovich N.C., Madhuripan N., Jawahar A., Ghanouni P., Et al., Prosregnet: a deep learning framework for registration of mri and histopathology images of the prostate, Med. Image Anal., 68, (2021); Deng R., Yang H., Jha A., Lu Y., Chu P., Fogo A.B., Huo Y., Map3d: registration-based multi-object tracking on 3d serial whole slide images, IEEE Trans. Med. Imaging, 40, 7, pp. 1924-1933, (2021); Rivenson Y., de Haan K., Dean Wallace W., Ozcan A., Emerging advances to transform histopathology using virtual staining, BME Front., (2020); Borovec J., Kybic J., Arganda-Carreras I., Sorokin D.V., Bueno G., Khvostikov A.V., Bakas S., Eric I., Chang C., Heldmann S., Et al., Anhir: automatic non-rigid histological image registration challenge, IEEE Trans. Med. Imaging, 39, 10, pp. 3042-3052, (2020); Cetin O., Shu Y., Flinner N., Ziegler P., Wild P., Koeppl H., Multi-magnification networks for deformable image registration on histopathology images, 10th International Workshop on Biomedical Image Registration, (2022); Shafique A., Babaie M., Sajadi M., Batten A., Skdar S., Tizhoosh H.R., Automatic multi-stain registration of whole slide images in histopathology, EMBC 2021, pp. 3622-3625, (2021); Shao W., Bhattacharya I., Soerensen S.J.C., Kunder C.A., Wang J.B., Fan R.E., Ghanouni P., Brooks J.D., Sonn G.A., Rusu M., Weakly supervised registration of prostate mri and histopathology images, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 98-107, (2021); Wodzinski M., Skalski A., Multistep, automatic and nonrigid image registration method for histology samples acquired using multiple stains, Phys. Med. Biol., 66, 2, (2021); Weitz P., Valkonen M., Solorzano L., Carr C., Kartasalo K., Boissin C., Koivukoski S., Kuusela A., Rasic D., Feng Y., Et al., Acrobat–a multi-stain breast cancer histological whole-slide-image data set from routine diagnostics for computational pathology, (2022); Merveille O., Lampert T., Schmitz J., Forestier G., Feuerhake F., Wemmert C., An automatic framework for fusing information from differently stained consecutive digital whole slide images: a case study in renal histology, Comput. Methods Programs Biomed., 208, (2021); Mok T.C.W., Chung A., Affine medical image registration with coarse-to-fine vision transformer, Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 20835-20844, (2022); Marzahl C., Wilm F., Tharun L., Perner S., Bertram C.A., Kroger C., Voigt J., Klopfleisch R., Maier A., Aubreville M., Et al., Robust quad-tree based registration on whole slide images, MICCAI Workshop on Computational Pathology, pp. 181-190, (2021); Theelke L., Wilm F., Marzahl C., Bertram C.A., Klopfleisch R., Maier A., Aubreville M., Breininger K., Iterative cross-scanner registration for whole slide images, Proc. IEEE Int. Conf. Comput, pp. 582-590, (2021); Venet L., Pati S., Feldman M.D., Nasrallah M.P., Yushkevich P., Bakas S., Accurate and robust alignment of differently stained histologic images based on greedy diffeomorphic registration, Appl. Sci. Basel, 11, 4, (2021); Yao J., Zhu X., Jonnagaddala J., Hawkins N., Huang J., Whole slide images based cancer survival prediction using attention guided deep multiple instance learning networks, Med. Image Anal., 65, (2020); Chandler D., Et al., (2021); Ge L., Wei X., Hao Y., Luo J., Xu Y., Unsupervised histological image registration using structural feature guided convolutional neural network, IEEE Trans. Med. Imaging, (2022); Hoque M.Z., Keskinarkaus A., Nyberg P., Mattila T., Seppanen T., Whole slide image registration via multi-stained feature matching, Comput. Biol. Med., (2022); Liu P., Wang F., Teodoro G., Kong J., Histopathology image registration by integrated texture and spatial proximity based landmark selection and modification, 2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI), pp. 1827-1830, (2021); Zhang C., Jiang Y., Li N., Zhang Z., Tauhidul Islam M., Dai J., Liu L., He W., Qin W., Xiong J., Et al., A hybrid deep feature-based deformable image registration method for pathological images, (2022); Lotz J., Weiss N., van der Laak J., Et al., High-resolution image registration of consecutive and re-stained sections in histopathology, (2021); Vijh S., Saraswat M., Kumar S., A new complete color normalization method for h&e stained histopatholgical images, Appl. Intell., pp. 1-14, (2021); Weitz P., Valkonen M., Solorzano L., Carr C., Kartasalo K., Boissin C., Koivukoski S., Kuusela A., Rasic D., Feng Y., Et al., The acrobat 2022 challenge: automatic registration of breast cancer tissue, (2023); Zhao S., Lau T., Luo J., Eric I., Chang C., Xu Y., Unsupervised 3d end-to-end medical image registration with volume tweening network, IEEE J. Biomed. Health Inform., 24, 5, pp. 1394-1404, (2019); De Vos B.D., Berendsen F.F., Viergever M.A., Sokooti H., Staring M., Isgum I., A deep learning framework for unsupervised affine and deformable image registration, Med. Image Anal., 52, pp. 128-143, (2019); Haskins G., Kruger U., Yan P., Deep learning in medical image registration: a survey, Mach. Vis. Appl., 31, 1, pp. 1-18, (2020); Mansilla L., Milone D.H., Ferrante E., Learning deformable registration of medical images with anatomical constraints, Neural Netw., 124, pp. 269-279, (2020); Mehdi N., Favaro P., Unsupervised learning of visual representations by solving jigsaw puzzles, European Conference on Computer Vision, pp. 69-84, (2016); Wodzinski M., Deephistreg H.M., Unsupervised deep learning registration framework for differently stained histology samples, Comput. Methods Programs Biomed., 198, (2021); Wodzinski M., Muller H., Learning-based affine registration of histological images, International Workshop on Biomedical Image Registration, pp. 12-22, (2020); Ciga O., Xu T., Martel A.L., Self supervised contrastive learning for digital histopathology, Mach. Learn. Appl., 7, (2022); Koohbanani N.A., Unnikrishnan B., Khurram S.A., Krishnaswamy P., Rajpoot N., Self-path: self-supervision for classification of pathology images with limited annotations, IEEE Trans. Med. Imaging, 40, 10, pp. 2845-2856, (2021); Stacke K., Unger J., Lundstrom C., Eilertsen G., Learning representations with contrastive self-supervised learning for histopathology applications, (2021); Yang P., Hong Z., Yin X., Zhu C., Jiang R., Self-supervised visual representation learning for histopathological images, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 47-57, (2021); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 770-778, (2016); Rocco I., Arandjelovic R., Sivic J., Convolutional neural network architecture for geometric matching, Proc. IEEE Comput. Soc. Conf., pp. 6148-6157, (2017); Gidaris S., Singh P., Komodakis N., Unsupervised representation learning by predicting image rotations, (2018); Avants B.B., Epstein C.L., Grossman M., Gee J.C., Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain, Med. Image Anal., 12, 1, pp. 26-41, (2008); Klein S., Staring M., Murphy K., Viergever M.A., Pluim J.P.W., Elastix: a toolbox for intensity-based medical image registration, IEEE Trans. Med. Imaging, 29, 1, pp. 196-205, (2009); Zhao S., Sheng Y., Dong Y., Chang E.I., Xu Y., Et al., Maskflownet: asymmetric feature matching with learnable occlusion mask, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6278-6287, (2020); Arganda-Carreras I., Sorzano C.O.S., Marabini R., Maria Carazo J., Ortiz-de Solorzano C., Kybic J., Consistent and elastic registration of histological sections using vector-spline regularization, Computer Vision Approaches to Medical Image Analysis: Second International ECCV Workshop, CVAMIA 2006, Revised Papers 2, Graz, Austria, May 12, 2006, pp. 85-95, (2006); Schneider C.A., Rasband W.S., Eliceiri K.W., Nih image to imagej: 25 years of image analysis, Nat. Methods, 9, 7, pp. 671-675, (2012); Lowe D.G., Distinctive image features from scale-invariant keypoints, Int. J. Comput. Vis., 60, pp. 91-110, (2004)","; T. Guan; Shenzhen International Graduate School, Tsinghua University, Shenzhen, 518055, China; email: guantian@sz.tsinghua.edu.cn","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","37634308","English","Comput. Methods Programs Biomed.","Article","Final","","Scopus","2-s2.0-85169299165"
"Alanazi A.A.; Abaker A.O.I.; Abdel-Khalek S.; Alhomayani F.M.; Aripov M.","Alanazi, Adwan A. (57212021340); Abaker, Abdelgalal O. I. (58817476400); Abdel-Khalek, Sayed (6506630609); Alhomayani, Fahad Mohammed (57218996816); Aripov, M. (8880099100)","57212021340; 58817476400; 6506630609; 57218996816; 8880099100","Neutrosophic Logic Empowered Machine Learning Algorithm with Salp Swarm Optimization for Biomedical Image Analysis","2024","International Journal of Neutrosophic Science","23","4","","104","116","12","0","10.54216/IJNS.230408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193495422&doi=10.54216%2fIJNS.230408&partnerID=40&md5=e69f6bc87ebd3a1cf5560d89ffcd8151","Department of Computer Science and Information, University of Hail, Saudi Arabia; Applied College, Khamis Mushait, King Khalid University, Abha, Saudi Arabia; Department of Mathematics and Statistics, College of Science, Taif University, P. O Box 11099, Taif, 21944, Saudi Arabia; College of Computers and Information Technology, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia; Applied College, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia; Department of Applied Mathematics and Computer Analysis, Faculty of Mathematics, NUU, Uzbekistan","Alanazi A.A., Department of Computer Science and Information, University of Hail, Saudi Arabia; Abaker A.O.I., Applied College, Khamis Mushait, King Khalid University, Abha, Saudi Arabia; Abdel-Khalek S., Department of Mathematics and Statistics, College of Science, Taif University, P. O Box 11099, Taif, 21944, Saudi Arabia; Alhomayani F.M., College of Computers and Information Technology, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia, Applied College, Taif University, P.O. Box 11099, Taif, 21944, Saudi Arabia; Aripov M., Department of Applied Mathematics and Computer Analysis, Faculty of Mathematics, NUU, Uzbekistan","Leukemia recognition and classification contain the identification of dissimilar kinds of leukemia, a group of blood cancers that affects the bone marrow and blood. A classical model containing microscopic analysis of blood smears to classify abnormal cells analytic of leukemia. Leukemia recognition employing a united technique of neutrosophic logic and deep learning (DL) signifies a new and complete approach to handling uncertainty and difficulty in medical data. Neutrosophic logic permits the representation of unstated or imperfect data, which is general in medical analyses. DL mainly convolutional neural networks (CNN) or recurrent neural networks (RNN), which can mechanically remove difficult patterns from medicinal imageries, improving the accuracy of leukemia recognition. The neutrosophic logic module accommodates the characteristic uncertainty in medicinal data, offering a formalism to manage imperfect or inaccurate data linked with the analysis procedure. The combination of these dual techniques generates a robust structure which capable of leveraging both the control of DL in image analysis and the flexibility of neutrosophic logic in dealing with uncertainties, contributing to more trustworthy and interpretable leukemia recognition methods. This study develops a new Salp Swarm Algorithm with a Neutrosophic Logic SVM (SSA-NSVM) model for Leukemia Detection and Classification. The SSA-NSVM technique mainly exploits Neutrosophic Logic (NL) concepts with the DL model for the detection of leukemia. To attain this, the SSA-NSVM model uses bilateral filtering (BF) based image pre-processing. In addition, the SSA-NSVM approach applies a modified densely connected networks (DenseNet) technique for learning complex and intrinsic feature patterns. Besides, the hyperparameter range of the modified DenseNet system takes place utilizing a SSA. At last, the NSVM technique is employed for the detection and identification of leukemia. The performance validation of the SSA-NSVM algorithm is verified utilizing a benchmark medicinal image dataset. The simulation values emphasized that the SSA-NSVM model reaches better detection outcomes than other existing approaches. © 2024, American Scientific Publishing Group (ASPG). All rights reserved.","Blood Cancer; Bone Marrow; Leukemia Detection; Neutrosophic Logic; Salp Swarm Algorithm","","","","","","Deanship of Scientific Research, King Khalid University, (RGP2/462/44); Deanship of Scientific Research, King Khalid University","\u201CThe authors extend their appreciation to the Deanship of Scientific Research at King Khalid University for funding this work through large group Research Project under grant number RGP2/462/44\u201D.","Ansari S., Et al., A customized efcient deep learning model for the diagnosis of acute leukemia cells based on lymphocyte and monocyte images, Electronics, 12, 2, (2023); Wolach O., Stone R.M., Mixed-phenotype acute leukemia, Curr Opin Hematol, 24, 2, pp. 139-145, (2017); Laosai J., Chamnongthai K., Acute leukemia classifcation by using SVM and K-Means clustering, In Proceedings of the 2014 IEEE International Electrical Engineering Congress (Ieecon), Chonburi, pp. 1-4, (2014); Vogado L.H.S., Veras R.D.M.S., Andrade A.R., de Araujo F.H.D., E Silva R.R.V., Aires KRT (2017) Diagnosing leukemia in blood smear images using an ensemble of classifers and pre-trained convolutional neural networks, In Proceedings of the 2017 IEEE 30Th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI), Niteroi, pp. 367-373; Madhukar M., Agaian S., Chronopoulos A.T., Deterministic model for acute myelogenous leukemia classifcation, Proceedings of the 2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC), pp. 433-438, (2012); Setiawan A., Harjoko A., Ratnaningsih T., Suryani E., Palgunadi S., Classifcation of cell types in Acute Myeloid Leukemia (AML) of M4, M5 and M7 subtypes with support vector machine classifer, Proceedings of the 2018 International Conference on Information and Communications Technology (ICOIACT), pp. 45-49, (2018); Mauricio de Oliveira J., Dantas D., Classifcation of normal versus leukemic cells with data augmentation and convolutional neural networks, In Proceedings of the 16Th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISIGRAPP 2021), 4, pp. 685-692, (2021); Kumar N., Et al., Automatic Diagnosis of Covid-19 Related Pneumonia from CXR and CT-Scan Images, Eng Technol Appl Sci Res, 12, 1, pp. 7993-7997, (2022); Prellberg J., Kramer O., Acute Lymphoblastic Leukemia Classifcationfrom Microscopic Images Using Convolutionalneural Networks, (2020); Patel N., Mishra A., Automated leukemia detection using microscopic images, Procedia Comput Sci, 58, pp. 635-642, (2015); Talaat F.M., Gamel S.A., Machine learning in detection and classification of leukemia using C-NMC_Leukemia, Multimedia Tools and Applications, 83, 3, pp. 8063-8076, (2024); Sriram G., Babu T.R., Praveena R., Anand J.V., Classification of Leukemia and Leukemoid Using VGG-16 Convolutional Neural Network Architecture, Molecular & Cellular Biomechanics, 19, 2, (2022); Jha C.K., Choubey A., Kolekar M.H., Chakraborty C., Automated Acute Lymphoblastic Leukemia Detection Using Blood Smear Image Analysis, Machine Learning and Deep Learning Techniques for Medical Image Recognition, pp. 64-75, (2023); Elrefaie R.M., Mohamed M.A., Marzouk E.A., Ata M.M., A robust classification of acute lymphocytic leukemia‐based microscopic images with supervised Hilbert‐Huang transform, Microscopy Research and Technique, 87, 2, pp. 191-204, (2024); Das P.K., Sahoo B., Meher S., An efficient detection and classification of acute leukemia using transfer learning and orthogonal softmax layer-based model, IEEE/ACM Transactions on Computational Biology and Bioinformatics, (2022); Bhute A., Bhute H., Pande S., Dhumane A., Chiwhane S., Wankhade S., Acute Lymphoblastic Leukemia Detection and Classification Using an Ensemble of Classifiers and Pre-Trained Convolutional Neural Networks, International Journal of Intelligent Systems and Applications in Engineering, 12, 1, pp. 571-580, (2024); Sulaiman A., Kaur S., Gupta S., Alshahrani H., Reshan M.S.A., Alyami S., Shaikh A., ResRandSVM: Hybrid Approach for Acute Lymphocytic Leukemia Classification in Blood Smear Images, Diagnostics, 13, 12, (2023); Ali M., Smarandache F., Vladareanu L., Neutrosophic sets and logic, Emerging Research on Applied Fuzzy Sets and Intuitionistic Fuzzy Matrices, pp. 18-63, (2017); Geng J., Jiang W., Deng X., Multi-scale deep feature learning network with bilateral filtering for SAR image classification, ISPRS Journal of Photogrammetry and Remote Sensing, 167, pp. 201-213, (2020); Javadimoghaddam S., A novel framework based on deep learning for COVID-19 diagnosis from X-ray images, Peerj Computer Science, 9, (2023); Al-Betar M.A., Abasi A.K., Al-Naymat G., Arshad K., Makhadmeh S.N., Bare-Bones Based Salp Swarm Algorithm for Text Document Clustering, IEEE Access, (2023); Ju W., Cheng H.D., A novel neutrosophic logic svm (n-svm) and its application to image categorization, New Mathematics and Natural Computation, 9, 1, pp. 27-42, (2013); Ahmed I.A., Senan E.M., Shatnawi H.S.A., Alkhraisha Z.M., Al-Azzam M.M.A., Hybrid techniques for the diagnosis of acute lymphoblastic leukemia based on fusion of CNN features, Diagnostics, 13, 6, (2023)","A.O.I. Abaker; Applied College, Khamis Mushait, King Khalid University, Abha, Saudi Arabia; email: aoadrees@kku.edu.sa","","American Scientific Publishing Group (ASPG)","","","","","","26926148","","","","English","Int. J. Neutrosophic. Sci.","Article","Final","","Scopus","2-s2.0-85193495422"
"Bhandary S.; Kuhn D.; Babaiee Z.; Fechter T.; Benndorf M.; Zamboglou C.; Grosu A.-L.; Grosu R.","Bhandary, Shrajan (57336379800); Kuhn, Dejan (58251997000); Babaiee, Zahra (57225102627); Fechter, Tobias (55796836400); Benndorf, Matthias (36097606300); Zamboglou, Constantinos (36459419500); Grosu, Anca-Ligia (7005831902); Grosu, Radu (6601973195)","57336379800; 58251997000; 57225102627; 55796836400; 36097606300; 36459419500; 7005831902; 6601973195","Investigation and benchmarking of U-Nets on prostate segmentation tasks","2023","Computerized Medical Imaging and Graphics","107","","102241","","","","7","10.1016/j.compmedimag.2023.102241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159431700&doi=10.1016%2fj.compmedimag.2023.102241&partnerID=40&md5=5d8f7f69265085a103be5273c8597539","Cyber-Physical Systems Division, Institute of Computer Engineering, Faculty of Informatics, Technische Universität Wien, Vienna, 1040, Austria; Division of Medical Physics, Department of Radiation Oncology, Medical Center University of Freiburg, Freiburg, 79106, Germany; Faculty of Medicine, University of Freiburg, Freiburg, 79106, Germany; German Cancer Consortium (DKTK), Partner Site Freiburg, Freiburg, 79106, Germany; Department of Diagnostic and Interventional Radiology, Medical Center University of Freiburg, Faculty of Medicine, University of Freiburg, Freiburg, 79106, Germany; Department of Radiation Oncology, Medical Center University of Freiburg, Freiburg, 79106, Germany; German Oncology Center, European University, Limassol, 4108, Cyprus; Department of Computer Science, State University of New York at Stony Brook, 11794, NY, United States","Bhandary S., Cyber-Physical Systems Division, Institute of Computer Engineering, Faculty of Informatics, Technische Universität Wien, Vienna, 1040, Austria; Kuhn D., Division of Medical Physics, Department of Radiation Oncology, Medical Center University of Freiburg, Freiburg, 79106, Germany, Faculty of Medicine, University of Freiburg, Freiburg, 79106, Germany, German Cancer Consortium (DKTK), Partner Site Freiburg, Freiburg, 79106, Germany; Babaiee Z., Cyber-Physical Systems Division, Institute of Computer Engineering, Faculty of Informatics, Technische Universität Wien, Vienna, 1040, Austria; Fechter T., Division of Medical Physics, Department of Radiation Oncology, Medical Center University of Freiburg, Freiburg, 79106, Germany, Faculty of Medicine, University of Freiburg, Freiburg, 79106, Germany, German Cancer Consortium (DKTK), Partner Site Freiburg, Freiburg, 79106, Germany; Benndorf M., Department of Diagnostic and Interventional Radiology, Medical Center University of Freiburg, Faculty of Medicine, University of Freiburg, Freiburg, 79106, Germany; Zamboglou C., Faculty of Medicine, University of Freiburg, Freiburg, 79106, Germany, German Cancer Consortium (DKTK), Partner Site Freiburg, Freiburg, 79106, Germany, Department of Radiation Oncology, Medical Center University of Freiburg, Freiburg, 79106, Germany, German Oncology Center, European University, Limassol, 4108, Cyprus; Grosu A.-L., Faculty of Medicine, University of Freiburg, Freiburg, 79106, Germany, German Cancer Consortium (DKTK), Partner Site Freiburg, Freiburg, 79106, Germany, Department of Radiation Oncology, Medical Center University of Freiburg, Freiburg, 79106, Germany; Grosu R., Cyber-Physical Systems Division, Institute of Computer Engineering, Faculty of Informatics, Technische Universität Wien, Vienna, 1040, Austria, Department of Computer Science, State University of New York at Stony Brook, 11794, NY, United States","In healthcare, a growing number of physicians and support staff are striving to facilitate personalized radiotherapy regimens for patients with prostate cancer. This is because individual patient biology is unique, and employing a single approach for all is inefficient. A crucial step for customizing radiotherapy planning and gaining fundamental information about the disease, is the identification and delineation of targeted structures. However, accurate biomedical image segmentation is time-consuming, requires considerable experience and is prone to observer variability. In the past decade, the use of deep learning models has significantly increased in the field of medical image segmentation. At present, a vast number of anatomical structures can be demarcated on a clinician's level with deep learning models. These models would not only unload work, but they can offer unbiased characterization of the disease. The main architectures used in segmentation are the U-Net and its variants, that exhibit outstanding performances. However, reproducing results or directly comparing methods is often limited by closed source of data and the large heterogeneity among medical images. With this in mind, our intention is to provide a reliable source for assessing deep learning models. As an example, we chose the challenging task of delineating the prostate gland in multi-modal images. First, this paper provides a comprehensive review of current state-of-the-art convolutional neural networks for 3D prostate segmentation. Second, utilizing public and in-house CT and MR datasets of varying properties, we created a framework for an objective comparison of automatic prostate segmentation algorithms. The framework was used for rigorous evaluations of the models, highlighting their strengths and weaknesses. © 2023 The Author(s)","Automatic prostate segmentation; Comparison framework; Medical imaging; U-net variations","Algorithms; Benchmarking; Humans; Image Processing, Computer-Assisted; Male; Neural Networks, Computer; Prostate; Prostatic Neoplasms; Computerized tomography; Convolutional neural networks; Deep learning; Image segmentation; Learning systems; Medical imaging; Radiotherapy; Urology; Automatic prostate segmentation; Biomedical image segmentation; Comparison framework; Learning models; Observer variability; Prostate cancers; Prostate segmentation; Radiotherapy planning; Support staff; U-net variation; adult; anatomical concepts; automation; benchmarking; cancer patient; clinician; convolutional neural network; deep learning; human; image segmentation; male; multimodal imaging; nuclear magnetic resonance imaging; prostate cancer; Review; segmentation algorithm; u net; x-ray computed tomography; algorithm; artificial neural network; diagnostic imaging; image processing; procedures; prostate; prostate tumor; Diseases","","","","","TU Wien's Faculty of Informatics; TU Wien’s Faculty of Informatics; UAS Technikum Wien; Bundesministerium für Bildung und Forschung, BMBF; Austrian Science Fund, FWF, (I 4718); Austrian Science Fund, FWF","Funding text 1: This research was funded in part by the Austrian Science Fund (FWF) : I 4718 , and the Federal Ministry of Education and Research (BMBF) Germany , under the frame of the Horizon-2020 ERA-PerMed call JTC-2019 Project Personalized Medicine: Multidisciplinary Research Towards Implementation (PersoRad). Z. B. was supported by the Doctoral College Resilient Embedded Systems , which is run jointly by the TU Wien’s Faculty of Informatics and the UAS Technikum Wien.; Funding text 2: This research was funded in part by the Austrian Science Fund (FWF): I 4718, and the Federal Ministry of Education and Research (BMBF) Germany, under the frame of the Horizon-2020 ERA-PerMed call JTC-2019 Project Personalized Medicine: Multidisciplinary Research Towards Implementation (PersoRad). Z. B. was supported by the Doctoral College Resilient Embedded Systems, which is run jointly by the TU Wien's Faculty of Informatics and the UAS Technikum Wien.","Antonelli M., Reinke A., Bakas S., Farahani K., Kopp-Schneider A., Landman B.A., Litjens G., Menze B., Ronneberger O., Summers R.M., van Ginneken B., Bilello M., Bilic P., Christ P.F., Do R.K.G., Gollub M.J., Heckers S.H., Huisman H., Jarnagin W.R., McHugo M.K., Napel S., Pernicka J.S.G., Rhode K., Tobon-Gomez C., Vorontsov E., Meakin J.A., Ourselin S., Wiesenfarth M., Arbelaez P., Bae B., Chen S., Daza L., Feng J., He B., Isensee F., Ji Y., Jia F., Kim I., Maier-Hein K., Merhof D., Pai A., Park B., Perslev M., Rezaiifar R., Rippel O., Sarasua I., Shen W., Son J., Wachinger C., Wang L., Wang Y., Xia Y., Xu D., Xu Z., Zheng Y., Simpson A.L., Maier-Hein L., Cardoso M.J., The medical segmentation decathlon, Nature Commun., 13, 1, (2022); Baid U., Ghodasara S., Bilello M., Mohan S., Calabrese E., Colak E., Farahani K., Kalpathy-Cramer J., Kitamura F.C., Pati S., Prevedello L.M., Rudie J.D., Sako C., Shinohara R.T., Bergquist T., Chai R., Eddy J., Elliott J., Reade W., Schaffter T., Yu T., Zheng J., Annotators B., Davatzikos C., Mongan J., Hess C., Cha S., Villanueva-Meyer J.E., Freymann J.B., Kirby J.S., Wiestler B., Crivellaro P., Colen R.R., Kotrotsou A., Marcus D.S., Milchenko M., Nazeri A., Fathallah-Shaykh H.M., Wiest R., Jakab A., Weber M., Mahajan A., Menze B.H., Flanders A.E., Bakas S., The RSNA-ASNR-MICCAI brats 2021 benchmark on brain tumor segmentation and radiogenomic classification, (2021); Bloch N., Madabhushi A., Huisman H., Freymann J., Kirby J., Grauer M., Enquobahrie A., Jaffe C., Clarke L., Farahani K., NCI-ISBI 2013 challenge: Automated segmentation of prostate structures. the cancer imaging archive, (2015); Caba B., Cafaro A., Lombard A., Arnold D.L., Elliott C., Liu D., Jiang X., Gafson A., Fisher E., Belachew S.M., Paragios N., Single-timepoint low-dimensional characterization and classification of acute versus chronic multiple sclerosis lesions using machine learning, NeuroImage, 265, (2023); Choi M.S., Choi B.S., Chung S.Y., Kim N., Chun J., Kim Y.B., Chang J.S., Kim J.S., Clinical evaluation of atlas-and deep learning-based automatic segmentation of multiple organs and clinical target volumes for breast cancer, Radiother. Oncol., 153, pp. 139-145, (2020); pp. 424-432, (2016); Comelli A., Dahiya N., Stefano A., Vernuccio F., Portoghese M., Cutaia G., Bruno A., Salvaggio G., Yezzi A., Deep learning-based methods for prostate segmentation in magnetic resonance imaging, Appl. Sci., 11, 2, (2021); Consortium M., MONAI: Medical open network for AI, (2020); Crimi A., Bakas S., Brainlesion: Glioma, multiple sclerosis, stroke and traumatic brain injuries, (2022); D'Aviero A., Re A., Catucci F., Piccari D., Votta C., Piro D., Piras A., Di Dio C., Iezzi M., Preziosi F., Menna S., Quaranta F., Boschetti A., Marras M., Micciche F., Gallus R., Indovina L., Bussu F., Valentini V., Cusumano D., Mattiucci G.C., Clinical validation of a deep-learning segmentation software in head and neck: An early analysis in a developing radiation oncology center, Int. J. Environ. Res. Public Health, 19, 15, (2022); Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L., Imagenet: A large-scale hierarchical image database, 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255, (2009); Dias-Santagata D., Heist R.S., Bard A.Z., da Silva A.F.L., Dagogo-Jack I., Nardi V., Ritterhouse L.L., Spring L.M., Jessop N., Farahani A.A., Mino-Kenudson M., Allen J., Goyal L., Parikh A., Misdraji J., Shankar G., Jordan J.T., Martinez-Lage M., Frosch M., Graubert T., Fathi A.T., Hobbs G.S., Hasserjian R.P., Raje N., Abramson J., Schwartz J.H., Sullivan R.J., Miller D., Hoang M.P., Isakoff S., Ly A., Bouberhan S., Watkins J., Oliva E., Wirth L., Sadow P.M., Faquin W., Cote G.M., Hung Y.P., Gao X., Wu C.-L., Garg S., Rivera M., Le L.P., John Iafrate A., Juric D., Hochberg E.P., Clark J., Bardia A., Lennerz J.K., Implementation and clinical adoption of precision oncology workflows across a healthcare network, Oncologist, 27, 11, pp. 930-939, (2022); Estienne T., Lerousseau M., Vakalopoulou M., Alvarez Andres E., Battistella E., Carre A., Chandra S., Christodoulidis S., Sahasrabudhe M., Sun R., Robert C., Talbot H., Paragios N., Deutsch E., Deep learning-based concurrent brain registration and tumor segmentation, Front. Comput. Neurosci., 14, (2020); Falkner S., Klein A., Hutter F.B., pp. 1436-1445, (2018); Ghavami N., Hu Y., Gibson E., Bonmati E., Emberton M., Moore C.M., Barratt D.C., Automatic segmentation of prostate MRI using convolutional neural networks: Investigating the impact of network architecture on the accuracy of volume measurement and MRI-ultrasound registration, Med. Image Anal., 58, (2019); Gibson E., Li W., Sudre C., Fidon L., Shakir D.I., Wang G., Eaton-Rosen Z., Gray R., Doel T., Hu Y., Et al., NiftyNet: a deep-learning platform for medical imaging, Comput. Methods Programs Biomed., 158, pp. 113-122, (2018); Gillespie D., Kendrick C., Boon I., Boon C., Rattay T., Yap M.H., Deep learning in magnetic resonance prostate segmentation: A review and a new perspective, (2020); Goldenberg S.L., Nir G., Salcudean S.E., A new era: artificial intelligence and machine learning in prostate cancer, Nature Rev. Urol., 16, 7, pp. 391-403, (2019); Gong W., Yao Y., Ni J., Jiang H., Jia L., Xiong W., Zhang W., He S., Wei Z., Zhou J., Deep learning-based low-dose CT for adaptive radiotherapy of abdominal and pelvic tumors, Front. Oncol., 12, (2022); Gunashekar D.D., Bielak L., Hagele L., Berlin A., Oerther B., Benndorf M., Grosu A., Zamboglou C., Bock M., Explainable AI for CNN-based prostate tumor segmentation in multi-parametric MRI correlated to whole mount histopathology, Radiat. Oncol., (2022); Haga A., Takahashi W., Aoki S., Nawa K., Yamashita H., Abe O., Nakagawa K., Standardization of imaging features for radiomics analysis, J. Med. Invest., 66, 1.2, pp. 35-37, (2019); Hall W.A., Paulson E., Li X.A., Erickson B., Schultz C., Tree A., Awan M., Low D.A., McDonald B.A., Salzillo T., Glide-Hurst C.K., Kishan A.U., Fuller C.D., Magnetic resonance linear accelerator technology and adaptive radiation therapy: An overview for clinicians, CA Cancer J. Clin., 72, 1, pp. 34-56, (2021); Hatamizadeh A., Nath V., Tang Y., Yang D., Roth H.R., Xu D., Swin unetr: Swin transformers for semantic segmentation of brain tumors in mri images, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 7th International Workshop, BrainLes 2021, Held in Conjunction with MICCAI 2021, Virtual Event, September 27, 2021, Revised Selected Papers, Part I, pp. 272-284, (2022); Hatamizadeh A., Tang Y., Nath V., Yang D., Myronenko A., Landman B., Roth H.R., Xu D., pp. 574-584; He K., Zhang X., Ren S., Sun J., pp. 770-778, (2016); Hekler A., Utikal J.S., Enk A.H., Solass W., Schmitt M., Klode J., Schadendorf D., Sondermann W., Franklin C., Bestvater F., Flaig M.J., Krahl D., von Kalle C., Frohling S., Brinker T.J., Deep learning outperformed 11 pathologists in the classification of histopathological melanoma images, Eur. J. Cancer, 118, pp. 91-96, (2019); Ioffe S., Szegedy C., Batch normalization: Accelerating deep network training by reducing internal covariate shift, Proceedings of the 32nd International Conference on Machine Learning, 37, pp. 448-456, (2015); Isensee F., Jaeger P.F., Kohl S.A.A., Petersen J., Maier-Hein K.H., nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation, Nature Methods, 18, 2, pp. 203-211, (2021); Isensee F., Ulrich C., Wald T., Maier-Hein K.H., Extending nnu-net is all you need, (2022); Jeong H., Ntolkeras G., Alhilani M., Atefi S.R., Zollei L., Fujimoto K., Pourvaziri A., Lev M.H., Grant P.E., Bonmassar G., Development, validation, and pilot MRI safety study of a high-resolution, open source, whole body pediatric numerical simulation model, PLoS One, 16, 1, (2021); Ji Y., Bai H., Yang J., Ge C., Zhu Y., Zhang R., Li Z., Zhang L., Ma W., Wan X., Et al., AMOS: A large-scale abdominal multi-organ benchmark for versatile medical image segmentation, (2022); Jia H., Cai W., Huang H., Xia Y., Learning multi-scale synergic discriminative features for prostate image segmentation, Pattern Recognit., 126, (2022); Jia H., Song Y., Huang H., Cai W., Xia Y., HD-net: Hybrid discriminative network for prostate segmentation in MR images, Medical Image Computing and Computer Assisted Intervention – MICCAI 2019, pp. 110-118, (2019); Jin Y., Yang G., Fang Y., Li R., Xu X., Liu Y., Lai X., 3D PBV-net: An automated prostate MRI data segmentation method, Comput. Biol. Med., 128, (2021); Karimi D., Samei G., Kesch C., Nir G., Salcudean S.E., Prostate segmentation in MRI using a convolutional neural network architecture and training strategy based on statistical shape models, Int. J. Comput. Assist. Radiol. Surg., 13, 8, pp. 1211--1219, (2018); Kawula M., Hadi I., Nierer L., Vagni M., Cusumano D., Boldrini L., Placidi L., Corradini S., Belka C., Landry G., Kurz C., Patient-specific transfer learning for auto-segmentation in adaptive 0.35 T MRgRT of prostate cancer: a bi-centric evaluation, Med. Phys., 50, 3, pp. 1573-1585, (2023); Korreman S., Eriksen J.G., Grau C., The changing role of radiation oncology professionals in a world of AI–just jobs lost–or a solution to the under-provision of radiotherapy?, Clin. Transl. Radiat. Oncol., 26, pp. 104-107, (2021); Kostyszyn D., Fechter T., Bartl N., Grosu A.L., Gratzke C., Sigle A., Mix M., Ruf J., Fassbender T.F., Kiefer S., Bettermann A.S., Nicolay N.H., Spohn S., Kramer M.U., Bronsert P., Guo H., Qiu X., Wang F., Henkenberens C., Werner R.A., Baltas D., Meyer P.T., Derlin T., Chen M., Zamboglou C., Intraprostatic tumour segmentation on PSMA-PET images in patients with primary prostate cancer with a convolutional neural network, J. Nucl. Med., (2020); Krizhevsky A., Sutskever I., Hinton G.E., pp. 1097-1105, (2012); Lee D.K., Sung D.J., Kim C.-S., Heo Y., Lee J.Y., Park B.J., Kim M.J., Three-dimensional convolutional neural network for prostate mri segmentation and comparison of prostate volume measurements by use of artificial neural network and ellipsoid formula, Am. J. Roentgenol., 214, 6, pp. 1229-1238, (2020); Lei Y., Dong X., Tian Z., Liu Y., Tian S., Wang T., Jiang X., Patel P., Jani A.B., Mao H., Curran W.J., Liu T., Yang X., CT prostate segmentation based on synthetic MRI-aided deep attention fully convolution network, Med. Phys., 47, 2, pp. 530-540, (2020); Lei Y., Tian S., He X., Wang T., Wang B., Patel P., Jani A.B., Mao H., Curran W.J., Liu T., Yang X., Ultrasound prostate segmentation based on multidirectional deeply supervised V-Net, Med. Phys., 46, 7, pp. 3194-3206, (2019); Litjens G., Debats O., Barentsz J., Karssemeijer N., Huisman H., Computer-aided detection of prostate cancer in MRI, IEEE Trans. Med. Imaging, 33, 5, pp. 1083-1092, (2014); Litjens G., Debats O., Barentsz J., Karssemeijer N., Huisman H., Prostatex challenge data. The cancer imaging archive, (2017); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., van der Laak J.A., van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Med. Image Anal., 42, pp. 60-88, (2017); Litjens G., Toth R., (van de Ven) W., Hoeks C., Kerkstra S., (van Ginneken) B., Vincent G., Guillard G., Birbeck N., Zhang J., Strand R., Malmberg F., Ou Y., Davatzikos C., Kirschner M., Jung F., Yuan J., Qiu W., Gao Q., Edwards P.E., Maan B., van-der Heijden F., Ghose S., Mitra J., Dowling J., Barratt D., Huisman H., Madabhushi A., Evaluation of prostate segmentation algorithms for MRI: The PROMISE12 challenge, Med. Image Anal., 18, 2, pp. 359-373, (2014); Liu Z., Lin Y., Cao Y., Hu H., Wei Y., Zhang Z., Lin S., Guo B., pp. 10012-10022, (2021); Liu J., Zhang Y., Chen J.-N., Xiao J., Lu Y., Landman B.A., Yuan Y., Yuille A., Tang Y., Zhou Z., CLIP-driven universal model for organ segmentation and tumor detection, (2023); Machireddy A., Meermeier N., Coakley F., Song X., pp. 1520-1523, (2020); Maier-Hein L., Eisenmann M., Reinke A., Onogur S., Stankovic M., Scholz P., Arbel T., Bogunovic H., Bradley A.P., Carass A., Et al., Why rankings of biomedical image analysis competitions should be interpreted with care, Nature Commun., 9, 1, pp. 1-13, (2018); Maier-Hein L., Reinke A., Christodoulou E., Glocker B., Godau P., Isensee F., Kleesiek J., Kozubek M., Reyes M., Riegler M.A., Et al., Metrics reloaded: Pitfalls and recommendations for image analysis validation, (2022); Marhold M., Kramer G., Krainer M., Le Magnen C., The prostate cancer landscape in europe: Current challenges, future opportunities, Cancer Lett., 526, pp. 304-310, (2022); McBee M.P., Awan O.A., Colucci A.T., Ghobadi C.W., Kadom N., Kansagra A.P., Tridandapani S., Auffermann W.F., Deep learning in radiology, Acad. Radiol., 25, 11, pp. 1472-1480, (2018); Milletari F., Navab N., pp. 565-571, (2016); Myronenko A., 3D MRI brain tumor segmentation using autoencoder regularization, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, pp. 311-320, (2019); Nemoto T., Futakami N., Yagi M., Kumabe A., Takeda A., Kunieda E., Shigematsu N., Efficacy evaluation of 2D, 3D U-net semantic segmentation and atlas-based segmentation of normal lungs excluding the trachea and main bronchi, J. Radiat. Res., 61, 2, pp. 257-264, (2020); Nikolov S., Blackwell S., Zverovitch A., Mendes R., Livne M., De Fauw J., Patel Y., Meyer C., Askham H., Romera-Paredes B., Et al., Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy, (2018); Oktay O., Schlemper J., Folgoc L.L., Lee M.C.H., Heinrich M.P., Misawa K., Mori K., McDonagh S.G., Hammerla N.Y., Kainz B., Glocker B., Rueckert D., Attention U-net: Learning where to look for the pancreas, Med. Imaging Deep Learn., (2018); Paszke A., Gross S., Massa F., Lerer A., Bradbury J., Chanan G., Killeen T., Lin Z., Gimelshein N., Antiga L., Et al., Pytorch: An imperative style, high-performance deep learning library, Adv. Neural Inf. Process. Syst., 32, (2019); Pham T.-C., Luong C.-M., Hoang V.-D., Doucet A., AI outperformed every dermatologist in dermoscopic melanoma diagnosis, using an optimized deep-CNN architecture with custom mini-batch logic and loss function, Sci. Rep., 11, 1, (2021); Punn N.S., Agarwal S., Modality specific U-net variants for biomedical image segmentation: a survey, Artif. Intell. Rev., (2022); Qin X., Transfer learning with edge attention for prostate MRI segmentation, (2019); Radici L., Ferrario S., Borca V.C., Cante D., Paolini M., Piva C., Baratto L., Franco P., La Porta M.R., Implementation of a commercial deep learning-based auto segmentation software in radiotherapy: Evaluation of effectiveness and impact on workflow, Life, 12, 12, (2022); Reinke A., Eisenmann M., Tizabi M.D., Sudre C.H., Radsch T., Antonelli M., Arbel T., Bakas S., Cardoso M.J., Cheplygina V., Farahani K., Glocker B., Heckmann-Notzel D., Isensee F., Jannin P., Kahn C.E., Kleesiek J., Kurc T.M., Kozubek M., Landman B.A., Litjens G.J.S., Maier-Hein K.H., Menze B.H., Muller H., Petersen J., Reyes M., Rieke N., Stieltjes B., Summers R.M., Tsaftaris S.A., van Ginneken B., Kopp-Schneider A., Jager P.F., Maier-Hein L., Common limitations of image processing metrics: A picture story, (2021); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015, Lecture Notes in Computer Science, pp. 234-241, (2015); Saha A., Hosseinzadeh M., Huisman H., End-to-end prostate cancer detection in bpMRI via 3D CNNs: Effects of attention mechanisms, clinical priori and decoupled false positive reduction, Med. Image Anal., 73, (2021); Saha A., Twilt J.J., Bosma J.S., van Ginneken B., Yakar D., Elschot M., Veltman J., Futterer J., de Rooij M., Huisman H., Artificial Intelligence and Radiologists at Prostate Cancer Detection in MRI: The PI-CAI Challenge (Study Protocol), (2022); Santomartino S.M., Yi P.H., Systematic review of radiologist and medical student attitudes on the role and impact of AI in radiology, Acad. Radiol., (2022); Santoro M., Strolin S., Paolani G., Della Gala G., Bartoloni A., Giacometti C., Ammendolia I., Morganti A.G., Strigari L., Recent applications of artificial intelligence in radiotherapy: Where we are and beyond, Appl. Sci., 12, 7, (2022); Shahedi M., Halicek M., Guo R., Zhang G., Schuster D.M., Fei B., A semiautomatic segmentation method for prostate in CT images using local texture classification and statistical shape modeling, Med. Phys., 45, 6, pp. 2527-2541, (2018); Simpson A.L., Antonelli M., Bakas S., Bilello M., Farahani K., van Ginneken B., Kopp-Schneider A., Landman B.A., Litjens G., Menze B.H., Ronneberger O., Summers R.M., Bilic P., Christ P.F., Do R.K.G., Gollub M., Golia-Pernicka J., Heckers S., Jarnagin W.R., McHugo M., Napel S., Vorontsov E., Maier-Hein L., Cardoso M.J., A large annotated medical image dataset for the development and evaluation of segmentation algorithms, (2019); Singh S.P., Wang L., Gupta S., Goli H., Padmanabhan P., Gulyas B., 3D deep learning on medical images: A review, Sensors, 20, 18, (2020); Skup M., Longitudinal fMRI analysis: A review of methods, Stat Interface, 3, 2, pp. 235-252, (2010); Spohn S.K., Bettermann A.S., Bamberg F., Benndorf M., Mix M., Nicolay N.H., Fechter T., Holscher T., Grosu R., Chiti A., Grosu A.L., Zamboglou C., Radiomics in prostate cancer imaging for a personalized treatment approach - current aspects of methodology and a systematic review on validated studies, Theranostics, 11, pp. 8027-8042, (2021); Steenbergen P., Haustermans K., Lerut E., Oyen R., De Wever L., Van den Bergh L., Kerkmeijer L.G., Pameijer F.A., Veldhuis W.B., Pos F.J., Et al., Prostate tumor delineation using multiparametric magnetic resonance imaging: Inter-observer variability and pathology validation, Radiother. Oncol., 115, 2, pp. 186-190, (2015); Stojnic R., Taylor R., Kardas M., Kerkez V., Viaud L., Saravia E., Cucurull G., The latest in machine learning - papers with code, (2021); Sudre C.H., Li W., Vercauteren T.K.M., Ourselin S., Cardoso M.J., Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 240-248, (2017); Syed K., Sleeman IV W., Ivey K., Hagan M., Palta J., Kapoor R., Ghosh P., Integrated natural language processing and machine learning models for standardizing radiotherapy structure names, Healthcare, Vol. 8, (2020); Thompson J., van Leeuwen P., Moses D., Shnier R., Brenner P., Delprado W., Pulbrook M., Bohm M., Haynes A., Hayen A., Stricker P., The diagnostic performance of multiparametric magnetic resonance imaging to detect significant prostate cancer, J. Urol., 195, 5, pp. 1428-1435, (2016); Vayena E., Blasimme A., Cohen I.G., Machine learning in medicine: addressing ethical challenges, PLoS Med., 15, 11, (2018); Wong J., Fong A., McVicar N., Smith S., Giambattista J., Wells D., Kolbeck C., Giambattista J., Gondara L., Alexander A., Comparing deep learning-based auto-segmentation of organs at risk and clinical target volumes to expert inter-observer variability in radiotherapy planning, Radiother. Oncol., 144, pp. 152-158, (2020); Wong J., Huang V., Giambattista J.A., Teke T., Kolbeck C., Giambattista J., Atrchian S., Training and validation of deep learning-based auto-segmentation models for lung stereotactic ablative radiotherapy using retrospective radiotherapy planning contours, Front. Oncol., 11, (2021); Zamboglou C., Spohn S.K.B., Adebahr S., Huber M., Kirste S., Sprave T., Gratzke C., Chen R.C., Carl E.G., Weber W.A., Mix M., Benndorf M., Wiegel T., Baltas D., Jenkner C., Grosu A.L., PSMA-PET/MRI-Based focal dose escalation in patients with primary prostate cancer treated with stereotactic body radiation therapy (HypoFocal-SBRT): Study protocol of a randomized, multicentric phase III trial, Cancers, 13, 22, (2021); Zhong Y., Yang Y., Fang Y., Wang J., Hu W., A preliminary experience of implementing deep-learning based auto-segmentation in head and neck cancer: a study on real-world clinical cases, Front. Oncol., 11, (2021); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., Unet++: Redesigning skip connections to exploit multiscale features in image segmentation, IEEE Trans. Med. Imaging, 39, 6, pp. 1856-1867, (2019); Zhu Q., Du B., Yan P., Boundary-weighted domain adaptive neural network for prostate MR image segmentation, IEEE Trans. Med. Imaging, (2019)","S. Bhandary; Cyber-Physical Systems Division, Institute of Computer Engineering, Faculty of Informatics, Technische Universität Wien, Vienna, 1040, Austria; email: shrajan.bhandary@tuwien.ac.at","","Elsevier Ltd","","","","","","08956111","","CMIGE","37201475","English","Comput. Med. Imaging Graph.","Review","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85159431700"
"Jagadesh T.; Kamalesh P.; Kishore A.; Lokin V.; Jaiprakash B.","Jagadesh, T. (56582511400); Kamalesh, P. (57643418800); Kishore, A. (57190295631); Lokin, V. (59223702400); Jaiprakash, B. (59223702500)","56582511400; 57643418800; 57190295631; 59223702400; 59223702500","Oral Cancer Detection Using Convolutional Neural Networks","2024","Proceedings of 9th International Conference on Science, Technology, Engineering and Mathematics: The Role of Emerging Technologies in Digital Transformation, ICONSTEM 2024","","","","","","","0","10.1109/ICONSTEM60960.2024.10568599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198842931&doi=10.1109%2fICONSTEM60960.2024.10568599&partnerID=40&md5=06ba3e9726a885247d2fb4f3b6c22a93","Kpr Institute of Engineering And Technology, Department of Electronics And Communication Engineering, Coimbatore, India","Jagadesh T., Kpr Institute of Engineering And Technology, Department of Electronics And Communication Engineering, Coimbatore, India; Kamalesh P., Kpr Institute of Engineering And Technology, Department of Electronics And Communication Engineering, Coimbatore, India; Kishore A., Kpr Institute of Engineering And Technology, Department of Electronics And Communication Engineering, Coimbatore, India; Lokin V., Kpr Institute of Engineering And Technology, Department of Electronics And Communication Engineering, Coimbatore, India; Jaiprakash B., Kpr Institute of Engineering And Technology, Department of Electronics And Communication Engineering, Coimbatore, India","In developing nation oral cancer makes the significant threat to human life. The existing system uses deep learning technique for detection of oral cancer in medical imaging. The two powerful tools of deep learning techniques are Convolutional Neural Networks and Deep Belief Network [1]. PSOBER- Particle Swarm Optimization and AI-Biruni Earth Radius a hybrid optimization algorithm is used to optimize the CNN and DBN. To overcome the outperformance of the existing method standard dataset of biomedical images are used for demonstration of the promising results. To test and validate the significance and stability one-way ANOVA and Wilcoxon signed-rank is used. For screening oral cancer detection in clinical setting this technique is used. However, the accuracy and to find the early detection of oral cancer and to make the less suffering of the patients the further research is needed. The proposed method of oral cancer detection using deep learning technique includes the enhancement of the images. In this method salt and pepper noise detection is used to find the accurate results using segmentation of the cells for thresholding. Back Propagation Neural Networks (BPNN) is used for the classification of the oral cancer. Tumor partition and features extraction are done in the proposed method. Feeding the loss backward through neural networks layers to fine tune the weights and the BPNN involves the error rate of forward propagation. Back propagation neural networks contain two signals. They are Error signal and Back signal.  © 2024 IEEE.","Back propagation; back signal; deep learning; detection; error signal; hybrid optimization; Medical imaging; neural networks; oral cancer; standard dataset; tumor partition","Backpropagation; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Image enhancement; Learning systems; Multilayer neural networks; Network layers; Particle swarm optimization (PSO); Salt and pepper noise; Tumors; Back Propagation; Back signal; Deep learning; Detection; Error signal; Hybrid optimization; Neural-networks; Oral cancer; Standard dataset; Tumor partition; Medical imaging","","","","","","","Abdelhamid A.A., Et al., Classification of Monkeypox Images Based on Transfer Learning and the Al-Biruni Earth Radius Optimization Algorithm; Gelband H., Jha P., Sankaranarayanan R., Horton S., Disease Control Priorities: Cancer; Rimal J., Shrestha A., Maharjan I.K., Shrestha S., Shah P., Risk assessment of smokeless tobacco among oral precancer and cancer patients in eastern developmental region of Nepal, Asian Pacific J. Cancer Prevention, 20, 2, pp. 411-415, (2019); Doss J.G., Thomson W.M., Drummond B.K., Latifah R.J.R., Validity of the FACT-H&N (v 4.0) among Malaysian oral cancer patients, Oral Oncol, 47, 7, pp. 648-652, (2011); Amarasinghe H., Jayasinghe R.D., Dharmagunawardene D., Attygalla M., Scuffham P.A., Johnson N., Kularatna S., Economic burden of managing oral cancer patients in Sri Lanka: A cross-sectional hospital-based costing study, BMJ Open, 9, 7, (2019); Jayasinghe R.D., Sherminie L.P.G., Amarasinghe H., Sitheeque M.A., Level of awareness of oral cancer and oral potentially malignant disorders among medical and dental undergraduates, Ceylon Med. J, 61, 2, (2016); Haron N., Zain R.B., Nabillah W.M., Saleh A., Kallarakkal T.G., Ramanathan A., Sinon S.H.M., Razak I.A., Cheong S.C., Mobile phone imaging in low resource settings for early detection of oral cancer and concordance with clinical oral examination, Telemed. e-Health, 23, 3, pp. 192-199, (2017); Funk G.F., Hoffman H.T., Karnell L.H., Et al., Cost-identification analysis in oral cavity cancer management, Otolaryngology-Head and Neck Surgery, 118, pp. 211-220, (1998); Goyal S., Tiwari V.K., Nair K.S., Et al., Risk factors and costs of oral cancer in a tertiary care hospital in Delhi, Asian Pac J Cancer Prev, 15, pp. 1659-1665, (2014); Bray F., Laversanne M., Weiderpass E., Soerjomataram I., The ever-increasing importance of cancer as a leading cause of premature death worldwide, Cancer; Omran A.R., The epidemiologic transition. A theory of the epidemiology of population change, Milbank Mem Fund Q, 49, pp. 509-538, (1971); Gersten O., Wilmoth J.R., The cancer transition in Japan since 1951, Demogr Res, 7, pp. 271-306, (2002); Human Development Report 2019. Beyond Income, Beyond Averages","","","Institute of Electrical and Electronics Engineers Inc.","IEEE","9th International Conference on Science, Technology, Engineering and Mathematics, ICONSTEM 2024","4 April 2024 through 5 April 2024","Chennai","200626","","979-835036509-2","","","English","Proc. Int. Conf. Sci., Technol., Eng. Math.: Role Emerg. Technol. Digit. Transform., ICONSTEM","Conference paper","Final","","Scopus","2-s2.0-85198842931"
"Ye S.; Shen L.; Islam M.T.; Xing L.","Ye, Siqi (57200728012); Shen, Liyue (57201327444); Islam, Md Tauhidul (57263730600); Xing, Lei (7103349003)","57200728012; 57201327444; 57263730600; 7103349003","Super-resolution biomedical imaging via reference-free statistical implicit neural representation","2023","Physics in Medicine and Biology","68","20","205020","","","","1","10.1088/1361-6560/acfdf1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175585520&doi=10.1088%2f1361-6560%2facfdf1&partnerID=40&md5=bf8978a5526d0402a0eb039b94eed89f","Department of Radiation Oncology, Stanford University, Stanford, 94305, CA, United States; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, 48109, MI, United States","Ye S., Department of Radiation Oncology, Stanford University, Stanford, 94305, CA, United States; Shen L., Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, 48109, MI, United States; Islam M.T., Department of Radiation Oncology, Stanford University, Stanford, 94305, CA, United States; Xing L., Department of Radiation Oncology, Stanford University, Stanford, 94305, CA, United States","Objective. Supervised deep learning for image super-resolution (SR) has limitations in biomedical imaging due to the lack of large amounts of low- and high-resolution image pairs for model training. In this work, we propose a reference-free statistical implicit neural representation (INR) framework, which needs only a single or a few observed low-resolution (LR) image(s), to generate high-quality SR images. Approach. The framework models the statistics of the observed LR images via maximum likelihood estimation and trains the INR network to represent the latent high-resolution (HR) image as a continuous function in the spatial domain. The INR network is constructed as a coordinate-based multi-layer perceptron, whose inputs are image spatial coordinates and outputs are corresponding pixel intensities. The trained INR not only constrains functional smoothness but also allows an arbitrary scale in SR imaging. Main results. We demonstrate the efficacy of the proposed framework on various biomedical images, including computed tomography (CT), magnetic resonance imaging (MRI), fluorescence microscopy, and ultrasound images, across different SR magnification scales of 2×, 4×, and 8×. A limited number of LR images were used for each of the SR imaging tasks to show the potential of the proposed statistical INR framework. Significance. The proposed method provides an urgently needed unsupervised deep learning framework for numerous biomedical SR applications that lack HR reference images. © 2023 Institute of Physics and Engineering in Medicine.","biomedical imaging; implicit neural representation; inverse problem; maximum likelihood estimation; multi-scale imaging; super-resolution; unsupervised learning","Algorithms; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Microscopy, Fluorescence; Neural Networks, Computer; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Fluorescence microscopy; Learning systems; Magnetic resonance imaging; Maximum likelihood estimation; Medical imaging; Optical resolving power; Biomedical imaging; High-resolution images; Implicit neural representation; Low resolution images; Maximum-likelihood estimation; Multi-scale imaging; Neural representations; Reference-free; Super resolution imaging; Superresolution; algorithm; artificial neural network; fluorescence microscopy; image processing; nuclear magnetic resonance imaging; procedures; x-ray computed tomography; Inverse problems","","","","","National Institutes of Health, NIH, (1R01CA176553, 1R01CA223667, 1R01CA227713); National Institutes of Health, NIH; Shanghai Jiao Tong University, SJTU","The authors would like to thank the support of the Outstanding PhD Graduate Development Fellowship from Shanghai Jiao Tong University, and the support from the National Institutes of Health (NIH) (1R01CA223667, 1R01CA176553, and 1R01CA227713). ","Anger J, Ehret T, de Franchis C, Facciolo G, Fast and accurate multi-frame super-resolution of satellite images, ISPRS Ann. Photogrammetry, Remote Sens. Spatial Inf. Sci, 1, (2020); Baguer D O, Leuschner J, Schmidt M, Computed tomography reconstruction using deep image prior and learned reconstruction methods, Inverse Prob, 36, (2020); Basri R, Galun M, Geifman A, Jacobs D, Kasten Y, Kritchman S, Frequency bias in neural networks for input of non-uniform density, Int. Conf. on Machine Learning PMLR, 685, 694, pp. 685-694, (2020); Bell-Kligler S, Shocher A, Irani M, Blind super-resolution kernel estimation using an internal-GAN Adv, Neural Inf. Process. Syst, (2019); Borman S, Stevenson R L, Super-resolution from image sequences—a review 1998 Midwest Symp. on Circuits and Systems (Cat. No. 98CB36268), 374 378, pp. 374-378, (1998); Bose N K, Kim H C, Valenzuela H M, Recursive implementation of total least squares algorithm for image reconstruction from noisy, undersampled multiframes, IEEE Int. Conf. on Acoustics, Speech, and Signal Processing, 5, (1993); Briand T, Davy A, Optimization of image B-spline interpolation for GPU architectures, Image Process. On Line, 9, pp. 183-204183, (2019); Briand T, Monasse P, Theory and practice of image B-spline interpolation, Image Process. On Line, 8, (2018); Bulat A, Yang J, Tzimiropoulos G, To learn image super-resolution, use a GAN to learn how to do image degradation first, Proc. of the European Conf. on Computer Vision, 185, 200, pp. 185-200, (2018); Chen H, Real-world single image super-resolution: a brief review, Inf. Fusion, 79, pp. 124-145124, (2022); Chen Y, Liu S, Wang X, Learning continuous image representation with local implicit image function, Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, 8628 8638, pp. 8628-8638, (2021); Cheng Z, Gadelha M, Maji S, Sheldon D, A bayesian perspective on the deep image prior, Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, 5443, 5451, pp. 5443-5451, (2019); Dong C, Loy C C, He K, Tang X, Image super-resolution using deep convolutional networks, IEEE Trans. Pattern Anal. Mach. Intell, 38, pp. 295-307295, (2015); Dong C, Loy C C, Tang X, Accelerating the super-resolution convolutional neural network, European Conf. on Computer Vision Springer, 391, 407, pp. 391-407, (2016); Elad M, Feuer A, Restoration of a single superresolution image from several blurred, noisy, and undersampled measured images, IEEE Trans. Image Process, 6, pp. 1646-1658, (1997); Emad M, Peemen M, Corporaal H, DualSR: zero-shot dual learning for real-world super-resolution, Proc. of the IEEE Winter Conf. on Applications of Computer Vision, 1630 1639, pp. 1630-1639, (2021); Farsiu S, Robinson M D, Elad M, Milanfar P, Fast and robust multiframe super resolution, IEEE Trans. Image Process, 13, pp. 1327-13441327, (2004); Gong K, Catana C, Qi J, Li Q, PET image reconstruction using deep image prior, IEEE Trans. Med. Imaging, 38, pp. 1655-16651655, (2018); Hardie R C, Barnard K J, Armstrong E E, Joint MAP registration and high-resolution image estimation using a sequence of undersampled images, IEEE Trans. Image Process, 6, pp. 1621-16331621, (1997); Ing M Z, Ing R B, Ing P C, Ing K, Ř Ultrasound image database; Kim G, Park J, Lee K, Lee J, Min J, Lee B, Unsupervised real-world super resolution with cycle generative adversarial network and domain discriminator, Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition Workshops, 456, 457, pp. 456-457, (2020); Kim J, Jung C, Kim C, Dual back-projection-based internal learning for blind super-resolution, IEEE Signal Process Lett, 27, pp. 1190-1194, (2020); Kim S P, Bose N K, Valenzuela H M, Recursive reconstruction of high-resolution image from noisy undersampled multiframes, IEEE Trans. Acoust. Speech Signal Process, 38, pp. 1013-10271013, (1990); Kingma D P, Ba J, Adam: a method for stochastic optimization, (2014); Kohler T, Huang X, Schebesch F, Aichert A, Maier A, Hornegger J, Robust multiframe super-resolution employing iteratively re-weighted minimization, IEEE Trans. Comput. Imaging, 2, 42, (2016); Mannam V, Super-resolution (SR) fluorescence microscopy dataset Notre Dame, (2021); Milanfar P, Super-resolution Imaging CRC Press, (2017); Park H, Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy, Nat. Commun, 13, pp. 1121-12, (2022); Patti A J, Altunbasak Y, Artifact reduction for set theoretic super resolution image reconstruction with edge adaptive constraints and higher-order interpolants, IEEE Trans. Image Process, 10, pp. 179-186179, (2001); Radford A, Metz L, Chintala S, Unsupervised representation learning with deep convolutional generative adversarial networks, (2015); Rahaman N, On the spectral bias of neural networks, Int. Conf. on Machine Learning PMLR, 5301 5310, pp. 5301-5310, (2019); Shen L, Pauly J, Xing L, NeRP: implicit neural representation learning with prior embedding for sparsely sampled image reconstruction, IEEE Trans Neural Netw. Learn. Syst, (2022); Shi W, Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network, Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, 1874 1883, pp. 1874-1883, (2016); Shocher A, Cohen N, Irani M, Zero-shot super-resolution using deep internal learning, Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, 3118, 3126, pp. 3118-3126, (2018); Sitzmann V, Martel J, Bergman A, Lindell D, Wetzstein G, Implicit neural representations with periodic activation functions, Adv. Neural Inf. Process. Syst, 33, pp. 7462-74737462, (2020); Sitzmann V, Zollhofer M, Wetzstein G, Scene representation networks: continuous 3D-structure-aware neural scene representations, Adv. Neural Inf. Process. Syst, (2019); Sui Y, Afacan O, Jaimes C, Gholipour A, Warfield S K, Scan-specific generative neural network for MRI super-resolution reconstruction, IEEE Trans. Med. Imaging, 41, pp. 1383-13991383, (2022); Sun K, Simon S, Bilateral spectrum weighted total variation for noisy-image super-resolution and image denoising, IEEE Trans. Signal Process, 69, pp. 6329-63416329, (2021); Sun K, Tran T H, Guhathakurta J, Simon S, FL-MISR: fast large-scale multi-image super-resolution for computed tomography based on multi-GPU acceleration, J. Real-Time Image Process, 19, pp. 331-344331, (2022); Sun K, Tran T H, Krawtschenko R, Simon S, Multi-frame super-resolution reconstruction based on mixed Poisson-Gaussian noise, Signal Process. Image Commun, 82, (2020); Tancik M, Fourier features let networks learn high frequency functions in low dimensional domains, Adv. Neural Inf. Process. Syst, 33, pp. 7537-75477537, (2020); Tipping M, Bishop C, Bayesian image super-resolution, Adv. Neural Inf. Process. Syst, (2002); Tom B C, Katsaggelos A K, Galatsanos N P, Reconstruction of a high resolution image from registration and restoration of low resolution images, Proc. of 1st Int. Conf. on Image Processing, 553, 557, pp. 553-557, (1994); Tsai R, Huang T S, Multiframe image restoration and registration, NASA/ADS, 1, (1984); Ulyanov D, Vedaldi A, Lempitsky V, Deep image prior, Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, 9446 9454, pp. 9446-9454, (2018); Van Veen D, Scale-Agnostic Super-Resolution in MRI using Feature-Based Coordinate Networks Medical Imaging with Deep Learning, (2022); Vasudevan V, Implicit neural representation for radiation therapy dose distribution, Phys. Med. Biol, 67, (2022); Wang Z, Chen J, Hoi S C, Deep learning for image super-resolution: a survey, IEEE Trans. Pattern Anal. Mach. Intell, 43, pp. 3365-33873365, (2020); Wu Q, IREM: high-resolution magnetic resonance image reconstruction via implicit neural representation, Int. Conf. on Medical Image Computing and Computer-assisted Intervention Springer, 65, 74, pp. 65-74, (2021); Wu Q, An arbitrary scale super-resolution approach for 3D MR images via implicit neural representation, IEEE J. Biomed. Health Inform, 27, pp. 1004-10151004, (2023); Xing L, Giger M L, Min J K, Artificial Intelligence in Medicine: Technical Basis and Clinical Applications, (2020); Yoo J, Jin K H, Gupta H, Yerly J, Stuber M, Unser M, Time-dependent deep image prior for dynamic MRI, IEEE Trans. Med. Imaging, 40, pp. 3337-3348, (2021); Youla D C, Webb H, Image restoration by the method of convex projections: I, Theory IEEE Trans. Med. Imaging, 1, 81, (1982); Yuan Y, Liu S, Zhang J, Zhang Y, Dong C, Lin L, Unsupervised image super-resolution using cycle-in-cycle generative adversarial networks, Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition Workshops, 701, 710, pp. 701-710, (2018); Yue L, Shen H, Yuan Q, Zhang L, A locally adaptive L1-L2 norm for multi-frame super-resolution of images with mixed noise and outliers, Signal Process, 105, pp. 156-174156, (2014); Yu-Su W, Kim S P, High-resolution restoration of dynamic image sequences, Int. J. Imaging Syst. Technol, 5, pp. 330-339330, (1994); Zhang K, Gool L V, Timofte R, Deep unfolding network for image super-resolution, Proc. of the IEEE Conf. on Computer Vision and Pattern Recognition, 3217, 3226, pp. 3217-3226, (2020); Zhang Y, Liu S, Dong C, Zhang X, Yuan Y, Multiple cycle-in-cycle generative adversarial networks for unsupervised image super-resolution, IEEE Trans. Image Process, 29, pp. 1101-11121101, (2019); Zhu J Y, Park T, Isola P, Efros A A, Unpaired image-to-image translation using cycle-consistent adversarial networks, Proc. of the IEEE Int. Conf. on Computer Vision, 2223, 2232, pp. 2223-2232, (2017)","S. Ye; Department of Radiation Oncology, Stanford University, Stanford, 94305, United States; email: yesiqi@stanford.edu","","Institute of Physics","","","","","","00319155","","PHMBA","37757838","English","Phys. Med. Biol.","Article","Final","","Scopus","2-s2.0-85175585520"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14452 LNCS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190366951&partnerID=40&md5=6ebabd485ea61c047f43d7f7d7fde660","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","03029743","978-981998075-8","","","English","Lect. Notes Comput. Sci.","Conference review","Final","","Scopus","2-s2.0-85190366951"
"Poonia R.C.; Upreti K.; Jafri S.; Parashar J.; Vats P.; Singh J.","Poonia, Ramesh Chandra (56638603100); Upreti, Kamal (57202706345); Jafri, Samreen (57852595500); Parashar, Jyoti (57204113069); Vats, Prashant (56630562900); Singh, Jagendra (56347348900)","56638603100; 57202706345; 57852595500; 57204113069; 56630562900; 56347348900","Biomedical Mammography Image Classification Using Patches-Based Feature Engineering with Deep Learning and Ensemble Classifier","2024","Lecture Notes in Networks and Systems","1046 LNNS","","","275","285","10","0","10.1007/978-3-031-64813-7_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200652501&doi=10.1007%2f978-3-031-64813-7_29&partnerID=40&md5=0ca86de482edf8996bc11e8bb67acd80","Department of Computer Science, CHRIST (Deemed to Be University), Delhi NCR, Ghaziabad, India; Administrative Science Department, Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia; Department of Computer Science and Engineering, Dr. Akhilesh Das Gupta Institute of Technology and Management, Delhi, India; Department of Computer Science and Engineering, SCSE, Manipal University Jaipur, Rajasthan, Jaipur, India; School of Computer Science Engineering and Technology, Bennett University, Greater Noida, India","Poonia R.C., Department of Computer Science, CHRIST (Deemed to Be University), Delhi NCR, Ghaziabad, India; Upreti K., Department of Computer Science, CHRIST (Deemed to Be University), Delhi NCR, Ghaziabad, India; Jafri S., Administrative Science Department, Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia; Parashar J., Department of Computer Science and Engineering, Dr. Akhilesh Das Gupta Institute of Technology and Management, Delhi, India; Vats P., Department of Computer Science and Engineering, SCSE, Manipal University Jaipur, Rajasthan, Jaipur, India; Singh J., School of Computer Science Engineering and Technology, Bennett University, Greater Noida, India","In order to reduce the expense of radiologists, deep learning algorithms have recently been used in the mammograms screening field. Deep learning-based methods, like a Convolutional Neural Network (CNN), are now being used to categorize breast lumps. When it involves classifying mammogram imagery, CNN-based systems clearly outperform machine learning-based systems, but they do have certain disadvantages as well. Additional challenges include a dearth of knowledge on feature engineering and the impossibility of feature analysis for the existing patches of pictures, which are challenging to distinguish in low-contrast mammograms. Inaccurate patch assessments, higher calculation costs, inaccurate patch examinations, and non-recovered patched intensity variation are all results of mammogram image patches. This led to evidence that a CNN-based technique for identifying breast masses had poor classification accuracy. Deep Learning-Based Featured Reconstruction is a novel breast mass classification technique that boosts precision on low-contrast pictures (DFN). This system uses random forest boosting techniques together with CNN architectures like VGG 16 and Resnet 50 to characterize breast masses. Using two publicly accessible datasets of mammographic images, the suggested DFN approach is also contrasted with modern classification methods. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Biomedical images; Breast mass classification technique; CNN; Deep learning; Mammography","Classification (of information); Computer aided diagnosis; Convolutional neural networks; Deep learning; Image classification; Learning algorithms; Learning systems; X ray screens; Biomedical images; Breast mass; Breast mass classification technique; Classification technique; Convolutional neural network; Deep learning; Feature engineerings; Low contrast; Mammography images; Mass classifications; Mammography","","","","","","","Zheng J., Lin D., Gao Z., Wang S., He M., Fan J., Deep learning assisted efficient AdaBoost algorithm for breast cancer detection and early diagnosis, IEEE Access, 8, pp. 96946-96954, (2020); Yadavendra C.S., A comparative study of breast cancer tumor classification by classical machine learning methods and deep learning methods, Mach. Vis. Appl., 31, (2020); Gupta P., Garg S., Breast cancer prediction using varying parameters of machine learning models, Procedia Comput. Sci., 171, pp. 593-601, (2020); Tiwari M., Bharuka R., Shah P., Lokare R., Breast cancer prediction using deep learning and machine learning techniques, SSRN Electron. J., (2020); Das A., Mohanty M.N., Mallick P.K., Tiwari P., Muhammad K., Zhu H., Breast cancer detection using an ensemble deep learning method, Biomed. Signal Process. Control, 70, (2021); Almajalid R., Shan J., Du Y., Zhang M., Development of a deep-learning-based method for breast ultrasound image segmentation, Proceedings of the 2018 17Th IEEE International Conference on Machine Learning and Applications (ICMLA), Orlando, FL, USA, pp. 1103-1108; Kumar K., Rao A.C.S., Breast cancer classification of image using convolutional neural network, Proceedings of the 2018 4Th International Conference on Recent Advances in Information Technology (RAIT), Dhanbad, India, Pp. 1–6, 15–17, (2018); Raman R., Sa P.K., Majhi B., Bakshi S., Direction estimation for pedestrian monitoring system in smart cities: An HMM based approach, IEEE Access, 4, pp. 5788-5808, (2016); Zhang D., Zou L., Zhou X., He F., Integrating feature selection and feature extraction methods with deep learning to predict clinical outcome of breast cancer, IEEE Access, 6, pp. 28936-28944, (2018); Hamidinekoo A., Denton E., Rampun A., Honnor K., Zwiggelaar R., Deep learning in mammography and breast histology, an overview and future trends, Med. Image Anal., 47, pp. 45-67, (2018); Miller J.D., Arasu V.A., Pu A.X., Margolies L.R., Sieh W., Shen L., Self-Supervised Deep Learning to Enhance Breast Cancer Detection on Screening Mammography., (2022); Jiang Y., Chen L., Zhang H., Xiao X., Breast cancer histopathological image classification using convolutional neural networks with small SE-ResNet module, Plos ONE, 14, (2019); Peng T., Boxberg M., Weichert W., Navab N., Marr C., Multi-task learning of a deep K-nearest neighbour network for histopathological image classification and retrieval, MICCAI 2019. LNCS, Vol. 11764, pp. 676-684, (2019); Hu C., Sun X., Yuan Z., Wu Y., Classification of breast cancer histopathological image with deep residual learning, Int. J. Imaging Syst. Technol., 31, pp. 1583-1594, (2021); Shayma'A A.H., Sayed M.S., Abdalla M.I.I., Rashwan M.A., Breast cancer masses classification using deep convolutional neural networks and transfer learning, Multimedia Tools Appl, 79, pp. 30735-30768, (2020); Hameed Z., Zahia S., Garcia-Zapirain B., Javier Aguirre J., Maria Vanegas A., Breast cancer histopathology image classification using an ensemble of deep learning models, Sensors, 20, (2020); Aslam M.A., Cui D., Breast cancer classification using deep convolutional neural network, J. Phys. Conf. Ser., 1584, (2020); Cruz R.M., Sabourin R., Cavalcanti G.D., META-DES.Oracle: Meta-learning and feature selection for dynamic ensemble selection, Inf. Fusion, 38, pp. 84-103, (2017); Assiri A.S., Nazir S., Velastin S.A., Breast tumor classification using an ensemble machine learning method, J. Imaging, 6, (2020); Sharma N., Sharma K.P., Mangla M., Rani R., Breast cancer classification using snapshot ensemble deep learning model and t-distributed stochastic neighbor embedding, Multimedia Tools Appl, 82, pp. 4011-4029, (2022); Sharma S., Mehra R., Conventional machine learning and deep learning approach for multi-classification of breast cancer histopathology images—a comparative insight, J. Digit. Imaging, 33, pp. 632-654, (2020); Gao Z., Lu Z., Wang J., Ying S., Shi J., A convolutional neural network and graph convolutional network based framework for classification of breast histopathological images, IEEE J. Biomed. Health Informatics, 26, pp. 3163-3173, (2022); Zebari D.A., Et al., Systematic review of computing approaches for breast cancer detection based computer-aided diagnosis using mammogram images, Appl. Artif. Intell., 35, pp. 2157-2203, (2021); Amin M.S., Ahn H., FabNet: A features agglomeration-based convolutional neural network for multiscale breast cancer histopathology images classification, Cancers, 15, 4, (2023); Zolfaghari B., Et al., Cancer prognosis and diagnosis methods based on ensemble learning, ACM Comput. Surv., 55, 12, pp. 1-34, (2023); Guevara-Ponce V., Et al., Detection of breast cancer using convolutional neural networks with learning transfer mechanisms, Int. J. Adv. Comput. Sci. Appl., 14, 6, (2023); Rajasekaran G., Shanmugapriya P., Hybrid deep learning and optimization algorithm for breast cancer prediction using data mining, Int. J. Intell. Syst. Appl. Eng., 11, 1s, pp. 14-22, (2023); Bhatnagar S., Dayal M., Singh D., Upreti S., Upreti K., Kumar J., Block-Hash Signature (BHS) for transaction validation in smart contracts for security and privacy using blockchain, JMM, 19, 4, pp. 935-962, (2023); Syed M.H., Upreti K., Nasir M.S., Alam M.S., Kumar Sharma A., Addressing image and Poisson noise deconvolution problem using deep learning approaches, Comput. Intell., pp. 1-15, (2022)","K. Upreti; Department of Computer Science, CHRIST (Deemed to Be University), Ghaziabad, Delhi NCR, India; email: kamalupreti1989@gmail.com","Abraham A.; Bajaj A.; Hanne T.; Siarry P.","Springer Science and Business Media Deutschland GmbH","","23rd International Conference on Intelligent Systems Design and Applications, ISDA 2023","11 December 2023 through 13 December 2023","Olten","315609","23673370","978-303164812-0","","","English","Lect. Notes Networks Syst.","Conference paper","Final","","Scopus","2-s2.0-85200652501"
"Lu P.; Fang F.; Zhang H.; Ling L.; Hua K.","Lu, Pengyue (57344157100); Fang, Faming (35753184800); Zhang, He (55685593900); Ling, Lei (57221232803); Hua, Keqin (57203187482)","57344157100; 35753184800; 55685593900; 57221232803; 57203187482","AugMS-Net:Augmented multiscale network for small cervical tumor segmentation from MRI volumes","2022","Computers in Biology and Medicine","141","","104774","","","","6","10.1016/j.compbiomed.2021.104774","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119263879&doi=10.1016%2fj.compbiomed.2021.104774&partnerID=40&md5=a1b9308dae00ae26169ce5174ff7bb08","Department of Computer Science & Technology, East China Normal University, Shanghai, China; Obstetrics and Gynecology Hospital, Fudan University, Shanghai, China","Lu P., Department of Computer Science & Technology, East China Normal University, Shanghai, China; Fang F., Department of Computer Science & Technology, East China Normal University, Shanghai, China; Zhang H., Obstetrics and Gynecology Hospital, Fudan University, Shanghai, China; Ling L., Obstetrics and Gynecology Hospital, Fudan University, Shanghai, China; Hua K., Obstetrics and Gynecology Hospital, Fudan University, Shanghai, China","Cervical cancer is one of the leading causes of female-specific cancer death. Tumor region segmentation plays a pivotal role in both the clinical analysis and treatment planning of cervical cancer. Due to the heterogeneity and low contrast of biomedical images, current state-of-the-art tumor segmentation approaches are facing the challenge of the insensitive detection of small lesion regions. To tackle this problem, this paper proposes an augmented multiscale network (AugMS-Net) based on 3D U-Net to automatically segment cervical Magnetic Resonance Imaging (MRI) volumes. Since a multiscale strategy is considered one of the most promising algorithms to tackle small object recognition, we introduce a novel 3D module to explore more granular multiscale representations. Besides, we employ a deep multiscale supervision strategy to doubly supervise the side outputs hierarchically. To demonstrate the generalization of our model, we evaluated AugMS-Net on both a cervical dataset from MRI volumes and a liver dataset from Computerized Tomography (CT) volumes. Our proposed AugMS-Net shows superior performance over baseline models, yielding high accuracy while reducing the number of model parameters by nearly 20%. The source code and trained models are available at https://github.com/Cassieyy/AugMS-Net. © 2021 Elsevier Ltd","Augmented multiscale; Biomedical image; Deep learning; Semantic segmentation","Algorithms; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Uterine Cervical Neoplasms; Computerized tomography; Deep learning; Diseases; Object recognition; Semantic Segmentation; Semantics; Tumors; Augmented multiscale; Biomedical images; Cervical cancers; Clinical analysis; Clinical treatments; Deep learning; Imaging volume; Region segmentation; Semantic segmentation; Tumor segmentation; Article; controlled study; convolutional neural network; deep learning; female; human; image segmentation; liver; liver tumor; nuclear magnetic resonance imaging; quantitative analysis; receptive field; segmentation algorithm; uterine cervix cancer; x-ray computed tomography; algorithm; diagnostic imaging; image processing; nuclear magnetic resonance imaging; procedures; uterine cervix tumor; Magnetic resonance imaging","","","PyTorch 1.4.0; V100 GPU, NVIDIA","NVIDIA","NSFC-RGC, (61961160734); Science Foundation of Shanghai, (20ZR1416200); National Natural Science Foundation of China, NSFC, (61731009); Shanghai Rising-Star Program, (21QA1402500, 61871185)","This work was supported by the Key Project of the National Natural Science Foundation of China under Grant 61731009 , the NSFC-RGC under Grant 61961160734 , the Shanghai Rising-Star Program under Grant 21QA1402500 , the National Natural Science Foundation of China under Grant 61871185 , and the Science Foundation of Shanghai under Grant 20ZR1416200 .","Rivera J.B., Klug S.J., Cervical cancer screening in Germany, Bundesgesundheitsblatt - Gesundheitsforsch. - Gesundheitsschutz, 61, 12, pp. 1528-1535, (2018); Jemal A., Center M.M., DeSantis C., Ward E.M., Global patterns of cancer incidence and mortality rates and trends, Cancer Epidemiol. Biomark. Prev., 19, 8, pp. 1893-1907, (2010); Lei T., Wang R., Wan Y., Du X., Meng H., Nandi A.K., Medical Image Segmentation Using Deep Learning: A Survey, (2020); Liu J., Zhang X., Dong B., Shen Z., Gu L., A wavelet frame method with shape prior for ultrasound video segmentation, SIAM J. Imag. Sci., 9, pp. 495-519, (2016); Zhao Y., Gui W., Chen Z., Tang J., Li L., Medical images edge detection based on mathematical morphology, ” in IEEE Engineering in Medicine and Biology 27th Annual Conference, pp. 6492-6495, (2005); Held K., Kops E.R., Krause B.J., Wells W.M., Kikinis R., Muller-Gartner H., Markov random field segmentation of brain MR images, IEEE Trans. Med. Imag., 16, 6, pp. 878-886, (1997); Jiang F., Frater M.R., Pickering M., Threshold-based image segmentation through an improved particle swarm optimisation, ” in 2012 International Conference on Digital Image Computing Techniques and Applications, pp. 1-5, (2012); Khoulqi I., Idrissi N., Segmentation and classification of cervical cancer, ” in 2020 IEEE 6th International Conference on Optimization and Applications, pp. 1-7, (2020); Zimmerman-Moreno G., Greenspan H., Automatic detection of specular reflections in uterine cervix images, Medical Imaging 2006: Image Processing, 6144, pp. 2037-2045, (2006); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Commun. ACM, 60, 6, pp. 84-90, (2017); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, ” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, (2015); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Deeplab, Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs, IEEE Trans. Pattern Anal. Mach. Intell., 40, 4, pp. 834-848, (2017); Chen L.-C., Papandreou G., Schroff F., Adam H., Rethinking Atrous Convolution for Semantic Image Segmentation,” arXiv Preprint arXiv:1706.05587, abs/1706, (2017); Chen L.-C., Zhu Y., Papandreou G., Schroff F., Adam H., Encoder-decoder with atrous separable convolution for semantic image segmentation, ” in Proceedings of the European Conference on Computer Vision, pp. 801-818, (2018); Ronneberger O., Fischer P., Brox T., U-Net, Convolutional networks for biomedical image segmentation, ” in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Li X., Yang X., Zeng T., A three-stage variational image segmentation framework incorporating intensity inhomogeneity information, SIAM J. Imag. Sci., 13, 3, pp. 1692-1715, (2020); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-Net: learning dense volumetric segmentation from sparse annotation, ” in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 424-432, (2016); Milletari F., Navab N., Ahmadi S., V-Net: fully convolutional neural networks for volumetric medical image segmentation, Fourth International Conference on 3D Vision (3DV), pp. 565-571, (2016); Li X., Chen H., Qi X., Dou Q., Fu C.-W., Heng P.-A., H-DenseUNet, Hybrid densely connected unet for liver and tumor segmentation from CT volumes, IEEE Trans. Med. Imag., 37, 12, pp. 2663-2674, (2018); He K., Zhang X., Ren S., Sun J., Spatial pyramid pooling in deep convolutional networks for visual recognition, IEEE Trans. Pattern Anal. Mach. Intell., 37, 9, pp. 1904-1916, (2015); Szegedy C., Ioffe S., Vanhoucke V., Alemi A., “Inception-v4, Inception-Resnet and the Impact of Residual Connections on Learning,” International Conference on Learning Representations, (2016); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, ” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., Rethinking the inception architecture for computer vision, ” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826, (2016); Zhao W., Zeng Z., U-Net M.S.S., 3D segmentation of kidneys and tumors from CT images with a multi-scale supervised U-Net, Informatics in Medicine Unlocked, 19, (2020); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., UNet++, A nested U-Net architecture for medical image segmentation, ” in Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 3-11, (2018); Isensee F., Kickingereder P., Wick W., Bendszus M., Maier-Hein K.H., No new-net, ” in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-244, (2018); Hu J., Shen L., Sun G., Squeeze-and-excitation networks, ” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7132-7141, (2018); Rickmann A.-M., Roy A.G., Sarasua I., Navab N., Wachinger C., ‘Project & Excite'modules for segmentation of volumetric medical scans, ” in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 39-47, (2019); Cheng J., Liu J., Liu L., Pan Y., Wang J., Multi-level glioma segmentation using 3D U-Net combined attention mechanism with atrous convolution, ” in IEEE International Conference on Bioinformatics and Biomedicine, pp. 1031-1036, (2019); Chen C., Liu X., Ding M., Zheng J., Li J., 3D dilated multi-fiber network for real-time brain tumor segmentation in MRI, ” in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 184-192, (2019); Lee K., Zung J., Li P., Jain V., Seung H.S., Superhuman Accuracy on the SNEMI3D Connectomics Challenge, (2017); Zhao H., Shi J., Qi X., Wang X., Jia J., Pyramid scene parsing network, ” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881-2890, (2017); Chollet F., Xception: deep learning with depthwise separable convolutions, ” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1251-1258, (2017); Gu Z., Cheng J., Fu H., Zhou K., Hao H., Zhao Y., Zhang T., Gao S., Liu J., Ce-net, Context encoder network for 2D medical image segmentation, IEEE Trans. Med. Imag., 38, 10, pp. 2281-2292, (2019); Moreno Lopez J., Marcand Ventura, “Dilated convolutions for brain tumor segmentation in mri scans, ” in Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, pp. 253-262, (2018); Gao S., Cheng M.-M., Zhao K., Zhang X.-Y., Yang M.-H., Torr P.H., Res2net, A new multi-scale backbone architecture, ” IEEE Transactions on Pattern Analysis and Machine Intelligence, (2019); Ioffe S., Szegedy C., Batch normalization: accelerating deep network training by reducing internal covariate shift, ” in the International Conference on Machine Learning, (2015); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, ” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Lee C.-Y., Xie S., Gallagher P., Zhang Z., Tu Z., Deeply-supervised Nets, (2014); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, ” in Proceedings of the IEEE International Conference on Computer Vision, pp. 2980-2988, (2017); Bilic P., Christ P.F., Vorontsov E., Chlebus G., Chen H., Dou Q., Fu C.-W., Han X., Heng P.-A., Hesser J., Et al., The Liver Tumor Segmentation Benchmark (LiTS), (2019); Ulyanov D., Vedaldi A., Lempitsky V.S., Instance normalization: the missing ingredient for fast stylization, CoRR, abs/1607.08022, (2016); Shan F., Gao Y., Wang J., Shi W., Shi N., Han M., Xue Z., Shi Y., Lung Infection Quantification of COVID-19 in CT Images with Deep Learning, (2020); Shi F., Xia L., Shan F., Wu D., Wei Y., Yuan H., Jiang H., Gao Y., Sui H., Shen D., Large-scale Screening of COVID-19 from Community Acquired Pneumonia Using Infection Size-Aware Classification, (2020); Dice L.R., Measures of the amount of ecologic association between species, Ecology, 26, 3, pp. 297-302, (1945); Qin X., Zhang Z., Huang C., Dehghan M., Zaiane O.R., Jagersand M., U2-Net: going deeper with nested u-structure for salient object detection, Pattern Recogn., 106, (2020); Roy A.G., Navab N., Wachinger C., Concurrent spatial and channel squeeze & excitation in fully convolutional networks, ” in International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 421-429, (2018)","F. Fang; Department of Computer Science & Technology, East China Normal University, Shanghai, China; email: fmfang@cs.ecnu.edu.cn; K. Hua; Obstetrics and Gynecology Hospital, Fudan University, Shanghai, China; email: huakeqin@126.com","","Elsevier Ltd","","","","","","00104825","","CBMDA","34785076","English","Comput. Biol. Med.","Article","Final","","Scopus","2-s2.0-85119263879"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Communications in Computer and Information Science","1961 CCIS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178608466&partnerID=40&md5=1667dbcda5df4e45fc3ea5633ada31fb","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","18650929","978-981998125-0","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85178608466"
"Wang Z.; Liu Z.; Yu J.; Gao Y.; Liu M.","Wang, Zenan (56695430000); Liu, Zhen (57222562503); Yu, Jianfeng (57694785600); Gao, Yingxin (57212645196); Liu, Ming (58974184300)","56695430000; 57222562503; 57694785600; 57212645196; 58974184300","Multi-scale nested UNet with transformer for colorectal polyp segmentation","2024","Journal of Applied Clinical Medical Physics","25","6","e14351","","","","3","10.1002/acm2.14351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189627172&doi=10.1002%2facm2.14351&partnerID=40&md5=916f5b4ecff8fea38a278b1c02a9da3f","Department of Gastroenterology, Beijing Chaoyang Hospital, the Third Clinical Medical College of Capital Medical University, Beijing, China; Hunan Key Laboratory of Nonferrous Resources and Geological Hazard Exploration, Changsha, China","Wang Z., Department of Gastroenterology, Beijing Chaoyang Hospital, the Third Clinical Medical College of Capital Medical University, Beijing, China; Liu Z., Department of Gastroenterology, Beijing Chaoyang Hospital, the Third Clinical Medical College of Capital Medical University, Beijing, China; Yu J., Department of Gastroenterology, Beijing Chaoyang Hospital, the Third Clinical Medical College of Capital Medical University, Beijing, China; Gao Y., Department of Gastroenterology, Beijing Chaoyang Hospital, the Third Clinical Medical College of Capital Medical University, Beijing, China; Liu M., Hunan Key Laboratory of Nonferrous Resources and Geological Hazard Exploration, Changsha, China","Background: Polyp detection and localization are essential tasks for colonoscopy. U-shape network based convolutional neural networks have achieved remarkable segmentation performance for biomedical images, but lack of long-range dependencies modeling limits their receptive fields. Purpose: Our goal was to develop and test a novel architecture for polyp segmentation, which takes advantage of learning local information with long-range dependencies modeling. Methods: A novel architecture combining with multi-scale nested UNet structure integrated transformer for polyp segmentation was developed. The proposed network takes advantage of both CNN and transformer to extract distinct feature information. The transformer layer is embedded between the encoder and decoder of a U-shape net to learn explicit global context and long-range semantic information. To address the challenging of variant polyp sizes, a MSFF unit was proposed to fuse features with multiple resolution. Results: Four public datasets and one in-house dataset were used to train and test the model performance. Ablation study was also conducted to verify each component of the model. For dataset Kvasir-SEG and CVC-ClinicDB, the proposed model achieved mean dice score of 0.942 and 0.950 respectively, which were more accurate than the other methods. To show the generalization of different methods, we processed two cross dataset validations, the proposed model achieved the highest mean dice score. The results demonstrate that the proposed network has powerful learning and generalization capability, significantly improving segmentation accuracy and outperforming state-of-the-art methods. Conclusions: The proposed model produced more accurate polyp segmentation than current methods on four different public and one in-house datasets. Its capability of polyps segmentation in different sizes shows the potential clinical application. © 2024 The Authors. Journal of Applied Clinical Medical Physics published by Wiley Periodicals LLC on behalf of American Association of Physicists in Medicine.","colorectal polyp; deep learning; polyp segmentation; transformer","Algorithms; Colonic Polyps; Colonoscopy; Colorectal Neoplasms; Databases, Factual; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Neural Networks, Computer; algorithm; artificial neural network; colon polyp; colonoscopy; colorectal tumor; computer assisted diagnosis; diagnostic imaging; factual database; human; image processing; pathology; procedures","","","","","Beijing Municipal Administration of Hospitals, (XXT12); Beijing Municipal Administration of Hospitals","This work was supported by the Digestive Medical Coordinated Development Center of Beijing Hospitals Authority, No. XXT12. ","Leufkens A.M., van Oijen M.G.H., Vleggaar F.P., Siersema P.D., Factors influencing the miss rate of polyps in a back-to-back colonoscopy study, Endoscopy, 44, 5, pp. 470-475, (2012); Van Rijn J.C., Reitsma J.B., Stoker J., Bossuyt P.M., Van Deventer S.J., Dekker E., Polyp miss rate determined by tandem colonoscopy: a systematic review, Am J Gastroenterol, 101, 2, (2006); Urban G., Tripathi P., Alkayali T., Et al., Deep learning localizes and identifies polyps in real time with 96% accuracy in screening colonoscopy, Gastroenterology, 155, 4, pp. 1069-1078, (2018); Hwang S., Celebi M.E., Polyp detection in wireless capsule endoscopy videos based on image segmentation and geometric feature, Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on, pp. 678-681, (2010); Wang Y., Tavanapong W., Wong J., Oh J., De Groen P.C., Part-based multiderivative edge cross-sectional profiles for polyp detection in colonoscopy, IEEE J Biomed Health Inform, 18, 4, pp. 1379-1389, (2014); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical image computing and computer-assisted intervention, (2015); Jha D., Smedsrud P.H., Johansen D., de Lange T., Johansen H.D., Halvorsen P., Riegler M.A., A comprehensive study on colorectal polyp segmentation with resunet++, conditional random field and test-time augmentation, IEEE J Biomed Health Inform, 25, 6, pp. 2029-2040, (2021); Oktay O., Schlemper J., Le Folgoc L., Et al., Attention U-Net: Learning Where to Look for the Pancreas. In Medical Imaging with Deep Learning, (2022); Li X., Chen H., Qi X., Dou Q., Fu C.-W., Heng P.-A., H-denseunet: hybrid densely connected UNet for liver and tumor segmentation from CT volumes, IEEE Trans Med Imaging, 37, 12, pp. 2663-2674, (2018); Alom M.Z., Yakopcic C., Hasan M., Taha T.M., Asari V.K., Recurrent residual U-Net for medical image segmentation, J Med Imaging (Bellingham), 6, 1, (2019); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., Unet++: Redesigning skip connections to exploit multiscale features in image segmentation, IEEE Trans Med Imaging, 39, 6, pp. 1856-1867, (2019); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFS, IEEE Trans Pattern Anal Mach Intell, 40, 4, pp. 834-848, (2018); Gu Z., Cheng J., Fu H., Et al., Ce-net: Context encoder network for 2d medical image segmentation, IEEE Trans Med Imaging, 38, 10, pp. 2281-2292, (2019); Schlemper J., Oktay O., Schaap M., Et al., Attention gated networks: Learning to leverage salient regions in medical images, Med Image Anal, 53, pp. 197-207, (2019); Chen J., Lu Y., Yu Q., Et al., Transunet: Transformers make strong encoders for medical image segmentation, CoRR, abs/2102.04306, (2021); Jiang J., Elguindi S., Berry S.L., Et al., Nested-block self-attention multiple resolution residual network for multi-organ segmentation from CT, Med Phys, 49, 8, pp. 5244-5257, (2022); Dosovitskiy A., Beyer L., Kolesnikov A., Et al., An image is worth 16x16 words: Transformers for image recognition at scale, (2020); Lin A., Chen B., Xu J., Zhang Z., Lu G., Zhang D., Ds-transunet: dual swin transformer u-net for medical image segmentation, IEEE Transactions on Instrumentation and Measurement, (2022); Zhang Y., Liu H., Hu Q., Transfuse: Fusing transformers and cnns for medical image segmentation. In Medical Image Computing and Computer Assisted Intervention-MICCAI 2021: 24th International Conference, Strasbourg, France, September 27-October 1, 2021, Proceedings, Part I 24 (pp. 14-24). Springer International Publishing; Jha D., Smedsrud P.H., Riegler M.A., Et al., Kvasir-seg: a segmented polyp dataset, International Conference on Multimedia Modeling, pp. 451-462, (2020); Bernal J., Sanchez F.J., Fernandez-Esparrach G., Gil D., Rodriguez C., Vilarino F., Wm-dova maps for accurate polyp highlighting in colonoscopy: validation vs. saliency maps from physicians, Comput Med Imaging Graph, 43, pp. 99-111, (2015); Bernal J., Sanchez J., Vilarino F., Towards automatic polyp detection with a polyp appearance model, Pattern Recognit, 45, 9, pp. 3166-3182, (2012); Silva J., Histace A., Romain O., Dray X., Granado B., Toward embedded detection of polyps in WCE images for early diagnosis of colorectal cancer, Int J Comput Assist Radiol Surg, 9, 2, pp. 283-293, (2014); He K., Zhang X., Ren S., Sun J., Identity mappings in deep residual networks, European conference on computer vision, pp. 630-645, (2016); Paszke A., Gross S., Massa F., Et al., Pytorch: an imperative style, high-performance deep learning library, Adv Neural Inf Process Syst, 32, pp. 8026-8037, (2019); Fan D.-P., Ji G.-P., Zhou T., Et al., Pranet: Parallel reverse attention network for polyp segmentation, International conference on medical image computing and computer-assisted intervention, pp. 263-273, (2020); Tomar N.K., Jha D., Riegler M.A., Et al., Fanet: A feedback attention network for improved biomedical image segmentation. IEEE Transactions on Neural Networks and Learning Systems, (2022); Huang C.H., Wu H.Y., Lin Y.L., Hardnet-mseg: A simple encoder-decoder polyp segmentation neural network that achieves over 0.9 mean dice and 86 fps. arXiv preprint arXiv:2101.07172, (2021); Srivastava A., Jha D., Chanda S., Et al., Msrf-net: a multi-scale residual fusion network for biomedical image segmentation, IEEE J Biomed Health Inform, 26, 5, pp. 2252-2263, (2021); Jha D., Riegler M.A., Johansen D., Halvorsen P., Johansen H.D., Doubleu-net: A deep convolutional neural network for medical image segmentation, 2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS), (2020); Jiang J., Tyagi N., Tringale K., Crane C., Veeraraghavan H., Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT). In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 556-566). Cham: Springer Nature Switzerland, (2022); Pan H., Jiang J., Chen G., TDFSSD: Top-down feature fusion single shot multibox detector, Signal Process Image Commun, 89, (2020)","Z. Wang; Department of Gastroenterology, Beijing Chaoyang Hospital, the Third Clinical Medical College of Capital Medical University, Beijing, China; email: wzn0768@qq.com","","John Wiley and Sons Ltd","","","","","","15269914","","","38551396","English","J. Appl. Clin. Med. Phys.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85189627172"
"Subasi A.","Subasi, Abdulhamit (8327241200)","8327241200","Medical image segmentation using artificial intelligence","2024","Applications of Artificial Intelligence in Healthcare and Biomedicine","","","","377","400","23","0","10.1016/B978-0-443-22308-2.00004-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193360200&doi=10.1016%2fB978-0-443-22308-2.00004-4&partnerID=40&md5=a1d159a6c188aa5ac0196dc8dc0c2c60","Institute of Biomedicine, Faculty of Medicine, University of Turku, Turku, Finland; Department of Computer Science, College of Engineering, Effat University, Jeddah, Saudi Arabia","Subasi A., Institute of Biomedicine, Faculty of Medicine, University of Turku, Turku, Finland, Department of Computer Science, College of Engineering, Effat University, Jeddah, Saudi Arabia","A fundamental problem in medical image analysis, biomedical image segmentation, is essential to many therapeutic applications. To facilitate quantitative analysis and support disease diagnosis, treatment planning, and disease monitoring, it requires partitioning images into different regions or objects of interest. Artificial intelligence (AI) methods, in particular deep learning algorithms, have become effective tools for biomedical picture segmentation in recent years. This chapter presents a biomedical image segmentation application of AI, emphasizing its potential to enhance precision, effectiveness, and therapeutic results. It examines several AI techniques, such as generative models and convolutional neural networks, and how they might be used to tackle the difficulties associated with image segmentation. It emphasizes how using AI algorithms can produce precise and reliable segmentation results. We go over the difficulties with biomedical image segmentation as well as the improvements made feasible by AI methods. We also implement a medical image segmentation example with TransResUNet. The impact of AI on biomedical image segmentation and its promise to alter medical imaging and customized healthcare are highlighted in the chapter's conclusion. © 2024 Elsevier Inc. All rights reserved.","Artificial intelligence; Biomedical image segmentation; Clinical applications; Deep learning; TransResUNet","","","","","","","","Akkus Z., Deep learning for brain MRI segmentation: State of the Art and future directions, Journal of Digital Imaging, 30, pp. 449-459, (2017); Al-amri S., Kalyankar N.V., Khatmitkar S.D., Image segmentation by using edge detection, International Journal on Computer Science and Engineering, pp. 804-807, (2010); Bahadure N.B., Ray A.K., Thethi H.P., Comparative approach of MRI-based brain tumor segmentation and classification using Genetic algorithm, Journal of Digital Imaging, 31, 4, (2018); Bovik A., Handbook of image and video processing, (2005); Burnham J., Hardy J., Meadors K., Picone J., Comparison of the roberts, sobel, robinson, canny, and hough image detection algorithms, Comparison of edge detection algorithms MS state DSP conference, (1997); Candemir S., Jaeger S., Palaniappan K., Musco J.P., Singh R.K., Xue Z., Karargyris A., Antani S., Thoma G., McDonald C.J., Lung segmentation in chest radiographs using anatomical atlases with nonrigid registration, IEEE Transactions on Medical Imaging, 33, 2, pp. 577-590, (2013); Chen L., Yu Z., Huang J., Shu L., Kuosmanen P., Shen C., Ma X., Li J., Sun C., Li Z., Development of lung segmentation method in x-ray images of children based on TransResUNet, Frontiers in Radiology, 3, (2023); Ciresan D.C., Giusti A., Gambardella L.M., Schmidhuber J., Deep neural networks segment neuronal membranes in electron microscopy images, Nips, pp. 2852-2860, (2012); Gonzalez R.C., Woods R.E., Masters B.R., Digital image processing, third edition, Journal of Biomedical Optics, 14, 2, (2009); Havaei M., Davy A., Warde-Farley D., Brain tumor segmentation with deep neural networks, (2016); He Y., Deep learning powers cancer diagnosis in digital pathology, Computerized Medical Imaging and Graphics, 88, (2022); Healy S., Threshold-based segmentation of fluorescent and chromogenic images of microglia, astrocytes and oligodendrocytes in FIJI, Journal of Neuroscience Methods, 295, pp. 87-103, (2018); Isin A., Direkoglu C., Sah M., Review of MRI-based brain tumor image segmentation using deep learning methods, Procedia Computer Science, 102, pp. 317-324, (2016); Ji S., Wei B., Yu Z., Yang G., Yin Y., A new multistage medical segmentation method based on superpixel and fuzzy clustering, Computational and Mathematical Methods in Medicine, 2014, (2014); Kang W.-X., Yang Q.-Q., Liang R.-P., The comparative research on image segmentation algorithms, 2009 first international workshop on education technology and computer science, pp. 703-707, (2009); Kim M., Jung S.Y., Park J.E., Jo Y., Park S.Y., Nam S.J., Kim J.H., Kim H.S., Diffusion- and perfusion-weighted MRI radiomics model may predict isocitrate dehydrogenase (IDH) mutation and tumor aggressiveness in diffuse lower grade glioma, European Radiology, 30, 4, (2020); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, 25, (2012); Langote V.B., Chaudhari D.D.S., Segmentation techniques for image analysis, 4, (2012); Lee B., Automatic segmentation of brain MRI using a novel patch-wise U-net deep architecture, Plos One, 15, (2020); Mirzaei G., Segmentation and clustering in brain MRI imaging, Reviews in the Neurosciences, 30, pp. 31-44, (2018); Muthukrishnan R., Radha M., Edge detection techniques for image segmentation, International Journal of Computer Science and Information Technology, 3, 6, pp. 259-267, (2011); Qiaoping W., One image segmentation technique based on wavelet analysis in the context of texture, Data Collection and Processing, 13, pp. 12-16, (1998); Reza S., Amin O.B., Hashem M., Transresunet: Improving u-net architecture for robust lungs segmentation in chest x-rays, pp. 1592-1595, (2020); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, pp. 234-241, (2015); Rosenfeld A., 7—Image analysis, Digital image processing techniques, pp. 257-287, (1984); Sarma R., Gupta Y.K., A comparative study of new and existing segmentation techniques, IOP Conference Series: Materials Science and Engineering, 1022, 1, (2021); Sharma N., Aggarwal L.M., Automated medical image segmentation techniques, Journal of Medical Physics/Association of Medical Physicists of India, 35, 1, pp. 3-14, (2010); Tomar N.K., Shergill A., Rieders B., Bagci U., Jha D., TransResU-Net: Transformer based ResU-Net for real-time colonoscopy polyp segmentation, ArXiv Preprint ArXiv:2206.08985, (2022); Wang Y., Qi Q., Shen X., Image segmentation of brain MRI based on LTriDP and superpixels of improved SLIC, Brain Sciences, 10, 2, (2020); Yanyun L., Zhijian S., Automated brain tumor segmentation in magnetic resonance imaging based on sliding-window technique and symmetry analysis, Chinese Medical Journal, 127, 3, (2014)","","","Elsevier","","","","","","","978-044322308-2; 978-044322309-9","","","English","Applications of Artificial Intelligence in Healthc. and Biomedicine","Book chapter","Final","","Scopus","2-s2.0-85193360200"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Communications in Computer and Information Science","1962 CCIS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178564254&partnerID=40&md5=3829318325536acdf7d9f46a8439ef86","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","18650929","978-981998131-1","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85178564254"
"Zheng W.; Chen J.; Zhang K.; Yan J.; Wang J.; Cheng Y.; Du B.; Chen D.Z.; Gao H.; Wu J.; Xu H.","Zheng, Wenhao (57559381700); Chen, Jintai (57211999917); Zhang, Kai (59041130000); Yan, Jiahuan (58023227100); Wang, Jinhong (57407142300); Cheng, Yi (57750482400); Du, Bang (58739979700); Chen, Danny Z. (7405453271); Gao, Honghao (36442463200); Wu, Jian (56197228100); Xu, Hongxia (57222187378)","57559381700; 57211999917; 59041130000; 58023227100; 57407142300; 57750482400; 58739979700; 7405453271; 36442463200; 56197228100; 57222187378","Polygonal Approximation Learning for Convex Object Segmentation in Biomedical Images with Bounding Box Supervision","2024","IEEE Journal of Biomedical and Health Informatics","28","8","","4522","4533","11","0","10.1109/JBHI.2023.3341699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180309620&doi=10.1109%2fJBHI.2023.3341699&partnerID=40&md5=cadb113a49e750624b7d19918644bbd8","Zhejiang University, College of Computer Science and Technology, Hangzhou, 310027, China; Zhejiang University, School of Public Health, Hangzhou, 310027, China; Zhejiang Univerisity, School of Software Technology, Hangzhou, 310027, China; University of Notre Dame, Department of Computer Science and Engineering, Notre Dame, 46556, IN, United States; Shanghai University, School of Computer Engineering and Science, Shanghai, 200444, China; Gachon University, College of Future Industry, Seongnam-si, 1342, South Korea; Zhejiang University, Second Affiliated Hospital School of Medicine, School of Public Health, Hangzhou, 310058, China; Zhejiang University, Zhejiang University-University of Edinburgh Institute, Zhejiang University School of Medicine, Haining, 310058, China","Zheng W., Zhejiang University, College of Computer Science and Technology, Hangzhou, 310027, China; Chen J., Zhejiang University, College of Computer Science and Technology, Hangzhou, 310027, China; Zhang K., Zhejiang University, School of Public Health, Hangzhou, 310027, China; Yan J., Zhejiang University, College of Computer Science and Technology, Hangzhou, 310027, China; Wang J., Zhejiang University, College of Computer Science and Technology, Hangzhou, 310027, China; Cheng Y., Zhejiang Univerisity, School of Software Technology, Hangzhou, 310027, China; Du B., Zhejiang University, College of Computer Science and Technology, Hangzhou, 310027, China; Chen D.Z., University of Notre Dame, Department of Computer Science and Engineering, Notre Dame, 46556, IN, United States; Gao H., Shanghai University, School of Computer Engineering and Science, Shanghai, 200444, China, Gachon University, College of Future Industry, Seongnam-si, 1342, South Korea; Wu J., Zhejiang University, Second Affiliated Hospital School of Medicine, School of Public Health, Hangzhou, 310058, China; Xu H., Zhejiang University, Zhejiang University-University of Edinburgh Institute, Zhejiang University School of Medicine, Haining, 310058, China","As a common and critical medical image analysis task, deep learning based biomedical image segmentation is hindered by the dependence on costly fine-grained annotations. To alleviate this data dependence, in this article, a novel approach, called Polygonal Approximation Learning (PAL), is proposed for convex object instance segmentation with only bounding-box supervision. The key idea behind PAL is that the detection model for convex objects already contains the necessary information for segmenting them since their convex hulls, which can be generated approximately by the intersection of bounding boxes, are equivalent to the masks representing the objects. To extract the essential information from the detection model, a repeated detection approach is employed on biomedical images where various rotation angles are applied and a dice loss with the projection of the rotated detection results is utilized as a supervised signal in training our segmentation model. In biomedical imaging tasks involving convex objects, such as nuclei instance segmentation, PAL outperforms the known models (e.g., BoxInst) that rely solely on box supervision. Furthermore, PAL achieves comparable performance with mask-supervised models including Mask R-CNN and Cascade Mask R-CNN. Interestingly, PAL also demonstrates remarkable performance on non-convex object instance segmentation tasks, for example, surgical instrument and organ instance segmentation.  © 2013 IEEE.","Biomedical object segmentation; nuclei segmentation; weakly-supervised segmentation","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Supervised Machine Learning; Biological systems; Image segmentation; Medical imaging; Object detection; Annotation; Biological system modeling; Biomedical imaging; Biomedical object segmentation; Biomedical objects; Instance segmentation; Nucleus segmentation; Objects segmentation; Shape; Supervised segmentation; Weakly-supervised segmentation; ablation study of predicting oval segmentation masks from detection models; ablation study on detection models; Article; artificial neural network; biomedical images; biomedical object segmentation; bounding box supervision; box supervised instance segmentation; computer vision; convex object instance segmentation; convolutional neural network; deep learning; human; image analysis; image segmentation; learning algorithm; mask supervised instance segmentation; medical image analysis task; minimum rotating angle ablation study; nuclei segmentation; polygonal approximation learning; segmentation algorithm; segmentation of non-convex objects; transformer-based detector; weakly supervised segmentation; algorithm; deep learning; image processing; procedures; supervised machine learning; Deep learning","","","","","","","Singer S.J., Nicolson G.L., The fluid mosaic model of the structure of cell membranes, Science, 175, 4023, pp. 720-731, (1972); Everingham M., Van Gool L., Williams C.K., Winn J., Zisserman A., The pascal visual object classes (VOC) challenge, Int. J. Comput. Vis., 88, pp. 303-338, (2010); Khoreva A., Benenson R., Hosang J., Hein M., Schiele B., Simple does it: Weakly supervised instance and semantic segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 876-885, (2017); Hsu C.-C., Hsu K.-J., Tsai C.-C., Lin Y.-Y., Chuang Y.-Y., Weakly supervised instance segmentation using the bounding box tightness prior, Proc. Adv. Neural Inf. Process. Syst., 32, pp. 6586-6597, (2019); Tian Z., Shen C., Wang X., Chen H., BoxInst: High-performance instance segmentation with box annotations, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 5443-5452, (2021); Qu H., Et al., Weakly supervised deep nuclei segmentation using partial points annotation in histopathology images, IEEE Trans. Med. Imag., 39, 11, pp. 3655-3666, (2020); Tian K., Et al., Weakly-supervised nucleus segmentation based on point annotations: A coarse-to-fine self-stimulated learning strategy, Proc. Med. Image Comput. Comput. Assist. Interv., pp. 299-308, (2020); Yoo I., Yoo D., Paeng K., PseudoEdgeNet: Nuclei segmentation only with point annotations, Proc. Med. Image Comput. Comput. Assist. Interv., pp. 731-739, (2019); Lee H., Jeong W.-K., Scribble2Label: Scribble-supervised cell segmentation via self-generating pseudo-labels with consistency, Proc. Med. Image Comput. Comput. Assist. Interv., pp. 14-23, (2020); Liang Y., Et al., Weakly supervised deep nuclei segmentation with sparsely annotated bounding boxes for DNA image cytometry, IEEE/ACM Trans. Comput. Biol. Bioinf., 20, 1, pp. 785-795, (2023); Ren S., He K., Girshick R., Sun J., Faster R-CNN: Towards real-time object detection with region proposal networks, Proc. Adv. Neural Inf. Process. Syst., 28, pp. 91-99, (2015); Girshick R., Donahue J., Darrell T., Malik J., Rich feature hierarchies for accurate object detection and semantic segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 580-587, (2014); Van de Sande K.E.A., Uijlings J.R.R., Gevers T., Smeulders A.W.M., Segmentation as selective search for object recognition, Proc. IEEE Int. Conf. Comput. Vis., pp. 1879-1886, (2011); Girshick R., Fast R-CNN, Proc. IEEE Int. Conf. Comput. Vis., pp. 1440-1448, (2015); He K., Gkioxari G., Dollar P., Girshick R., Mask R-CNN, Proc. IEEE Int. Conf. Comput. Vis., pp. 2961-2969, (2017); Redmon J., Divvala S., Girshick R., Farhadi A., You only look once: Unified, real-time object detection, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 779-788, (2016); Liu W., Et al., SSD: Single shot multibox detector, Proc. 14th Eur. Conf. Comput. Vis., pp. 21-37, (2016); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, Proc. IEEE Int. Conf. Comput. Vis., pp. 2980-2988, (2017); Carion N., Massa F., Synnaeve G., Usunier N., Kirillov A., Zagoruyko S., End-to-end object detection with transformers, Proc. Eur. Conf. Comput. Vis., 2020, pp. 213-229; Sun Z., Cao S., Yang Y., Kitani K.M., Rethinking transformer-based set prediction for object detection, Proc. IEEE/CVF Int. Conf. Comput. Vis., 2021, pp. 3611-3620; Zhu X., Su W., Lu L., Li B., Wang X., Dai J., Deformable transformers for end-to-end object detection, Proc. Int. Conf. Learn. Representations, pp. 3-7, (2021); Liu S., Et al., DAB-DETR: Dynamic anchor boxes are better queries for DETR, (2022); Li F., Zhang H., Liu S., Guo J., Ni L.M., Zhang L., DN-DETR: Accelerate DETR training by introducing query denoising, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 13619-13627, (2022); Zhang H., Et al., DINO: DETR with improved DeNoising anchor boxes for end-to-end object detection; Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 3431-3440, (2015); Liu W., Rabinovich A., Berg A.C., ParseNet: Looking wider to see better, (2015); Lin T.-Y., Dollar P., Girshick R., He K., Hariharan B., Belongie S., Feature pyramid networks for object detection, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 2117-2125, (2017); Liu S., Qi L., Qin H., Shi J., Jia J., Path aggregation network for instance segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 8759-8768, (2018); Dai J., He K., Sun J., Instance-aware semantic segmentation via multi-task network cascades, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 3150-3158, (2016); Chen L.-C., Hermans A., Papandreou G., Schroff F., Wang P., Adam H., MaskLab: Instance segmentation by refining object detection with semantic and direction features, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 4013-4022, (2018); Chen X., Girshick R., He K., Dollar P., TensorMask: A foundation for dense object segmentation, Proc. IEEE/CVF Int. Conf. Comput. Vis., pp. 2061-2069, (2019); Rother C., Kolmogorov V., Blake A., GrabCut’ interactive foreground extraction using iterated graph cuts, ACM Trans. Graph., 23, 3, pp. 309-314, (2004); Otsu N., A threshold selection method from gray-level histograms, IEEE Trans. Syst., Man, Cybern., 9, 1, pp. 62-66, (1979); Cai Z., Vasconcelos N., Cascade R-CNN: High quality object detection and instance segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 43, 5, pp. 1483-1498, (2021); Caicedo J.C., Et al., Nucleus segmentation across imaging experiments: The 2018 data science bowl, Nature Methods, 16, pp. 1247-1253, (2019); Codella N.C.F., Et al., Skin lesion analysis toward melanoma detection: A challenge at the 2017 international symposium on biomedical imaging (ISBI), hosted by the international skin imaging collaboration (ISIC), Proc. IEEE 15th Int. Symp. Biomed. Imag., pp. 168-172, (2018); Yoon J., Et al., Surgical scene segmentation using semantic image synthesis with a virtual surgery environment, Proc. Med. Image Comput. Comput. Assist. Interv., 2022, pp. 551-561; Lin T.-Y., Et al., Microsoft COCO: Common objects in context, Proc. Eur. Conf. Comput. Vis., pp. 740-755, (2014); Paszke A., Et al., PyTorch: An imperative style, high-performance deep learning library, Proc. Adv. Neural Inf. Process. Syst., 32, pp. 8024-8035, (2019); Chen K., Et al., MMDetection: Open MMLab detection toolbox and benchmark, (2019); Falcon W., Et al., PyTorch lightning, (2019); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 770-778, (2016); Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L., ImageNet: A large-scale hierarchical image database, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 248-255, (2009); Tian Z., Shen C., Chen H., Conditional convolutions for instance segmentation, Proc. 16th Eur. Conf. Comput. Vis., pp. 282-298, (2020)","H. Gao; Shanghai University, School of Computer Engineering and Science, Shanghai, 200444, China; email: gaohonghao@shu.edu.cn; H. Xu; Zhejiang University, Zhejiang University-University of Edinburgh Institute, Zhejiang University School of Medicine, Haining, 310058, China; email: einstein@zju.edu.cn","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21682194","","ITIBF","38090818","English","IEEE J. Biomedical Health Informat.","Article","Final","","Scopus","2-s2.0-85180309620"
"Zhang Y.; Liu M.; Yu F.; Zeng T.; Wang Y.","Zhang, Yuqiang (57226780797); Liu, Min (55783125200); Yu, Fuhao (57221219160); Zeng, Tieyong (25423412800); Wang, Yaonan (55998880600)","57226780797; 55783125200; 57221219160; 25423412800; 55998880600","An O-Shape Neural Network with Attention Modules to Detect Junctions in Biomedical Images Without Segmentation","2022","IEEE Journal of Biomedical and Health Informatics","26","2","","774","785","11","10","10.1109/JBHI.2021.3094187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112591760&doi=10.1109%2fJBHI.2021.3094187&partnerID=40&md5=63439a1285baa9d48b15aa31b0daaa7a","College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China; Department of Mathematics, The Chinese University of Hong Kong, Hong Kong, 999077, Hong Kong; National Engineering Laboratory for Robot Visual Perception and Control Technology, Hunan University, Changsha, 410082, China","Zhang Y., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China, National Engineering Laboratory for Robot Visual Perception and Control Technology, Hunan University, Changsha, 410082, China; Liu M., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China, National Engineering Laboratory for Robot Visual Perception and Control Technology, Hunan University, Changsha, 410082, China; Yu F., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China, National Engineering Laboratory for Robot Visual Perception and Control Technology, Hunan University, Changsha, 410082, China; Zeng T., Department of Mathematics, The Chinese University of Hong Kong, Hong Kong, 999077, Hong Kong; Wang Y., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China, National Engineering Laboratory for Robot Visual Perception and Control Technology, Hunan University, Changsha, 410082, China","Junction plays an important role in biomedical research such as retinal biometric identification, retinal image registration, eye-related disease diagnosis and neuron reconstruction. However, junction detection in original biomedical images is extremely challenging. For example, retinal images contain many tiny blood vessels with complicated structures and low contrast, which makes it challenging to detect junctions. In this paper, we propose an O-shape Network architecture with Attention modules (Attention O-Net), which includes Junction Detection Branch (JDB) and Local Enhancement Branch (LEB) to detect junctions in biomedical images without segmentation. In JDB, the heatmap indicating the probabilities of junctions is estimated and followed by choosing the positions with the local highest value as the junctions, whereas it is challenging to detect junctions when the images contain weak filament signals. Therefore, LEB is constructed to enhance the thin branch foreground and make the network pay more attention to the regions with low contrast, which is helpful to alleviate the imbalance of the foreground between thin and thick branches and to detect the junctions of the thin branch. Furthermore, attention modules are utilized to introduce the feature maps of LEB to JDB, which can establish a complementary relationship and further integrate local features and contextual information between these two branches. The proposed method achieves the highest average F1-scores of 0.82, 0.73 and 0.94 in two retinal datasets and one neuron dataset, respectively. The experimental results confirm that Attention O-Net outperforms other state-of-the-art detection methods, and is helpful for retinal biometric identification.  © 2013 IEEE.","Biomedical images; deep learning; junction detection","Algorithms; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Retina; Anthropometry; Biometrics; Blood vessels; Diagnosis; Image segmentation; Network architecture; Neural networks; Ophthalmology; Biomedical research; Biometric identifications; Complementary relationship; Complicated structures; Contextual information; Junction detection; Neuron reconstruction; Retinal image registrations; accuracy; algorithm; Article; artificial neural network; attention; B scan; biometry; deep learning; entropy; feature extraction; human; image analysis; image enhancement; image reconstruction; image segmentation; learning algorithm; machine learning; mathematical model; nerve cell network; normal distribution; optical coherence tomography; retina blood vessel; retina disease; retina image; signal noise ratio; training; algorithm; diagnostic imaging; image processing; procedures; retina; Image enhancement","","","ImageJ","","National Natural Science Foundation of China, NSFC, (61771189, 62073126); Natural Science Foundation of Hunan Province, (2020JJ2008)","Manuscript received March 20, 2021; revised June 2, 2021; accepted June 27, 2021. Date of publication July 1, 2021; date of current version February 4, 2022. This work was supported in part by the National Natural Science Foundation of China under Grants 62073126 and 61771189 and in part by the Hunan Provincial Natural Science Foundation of China under Grant 2020JJ2008. (Corresponding author: Min Liu.) Yuqiang Zhang, Min Liu, Fuhao Yu, and Yaonan Wang are with the College of Electrical and Information Engineering, Hunan University, Changsha 410082, China, and also with the National Engineering Laboratory for Robot Visual Perception and Control Technology, Hunan University, Changsha 410082, China (e-mail: yqzhang@hnu.edu.cn; liu_min@hnu.edu.cn; yufuhao@hnu.edu.cn; yaonan@hnu.edu.cn).","Shi J., Et al., Multimodal neuroimaging feature learning with multimodal stacked deep polynomial networks for diagnosis of Alzheimer's disease, IEEE J. Biomed. Health. Informat., 22, 1, pp. 173-183, (2018); Fu H., Cheng J., Xu Y., Wong D.W.K., Liu J., Cao X., Joint optic disc and cup segmentation based on multi-label deep network and polar transformation, IEEE Trans. Med. Imag., 37, 7, pp. 1597-1605, (2018); Lu Y., Liu A.A., Chen M., Nie W.Z., Su Y.T., Sequential saliency guided deep neural network for jointMitosis identification and localization in time-lapse phase contrast microscopy images, IEEE J. Biomed.Health. Informat., 24, 5, pp. 1367-1378, (2020); Zhao T., Et al., Automated reconstruction of neuronal morphology based on local geometrical and global structural models, Neuroinformatics, 9, 2-3, pp. 247-261, (2011); Li Q., Wu X., Liu T., Differentiable neural architecture search for optimal spatial/temporal brain function network decomposition, Med. Image Anal., 69, (2021); Zhao T., Yin Z., Wang J., Gao D., Chen Y., Mao Y., Bronchus segmentation and classification by neural networks and linear programming, Proc.Med. Image Comput. Comput.-Assist. Intervent., pp. 230-239, (2019); Li K., Qi X., Luo Y., Yao Z., Zhou X., Sun M., Accurate retinal vessel segmentation in color fundus images via fully attention-based networks, IEEE J. Biomed. Health. Informat., 25, 6, pp. 2071-2081, (2021); De J., Et al., A graph-theoretical approach for tracing filamentary structures in neuronal and retinal images, IEEE Trans. Med. Imag., 35, 1, pp. 257-272, (2016); Patton N., Et al., Retinal image analysis: Concepts, applications and potential, Prog. Retin. Eye Res., 25, 1, pp. 99-127, (2006); Grosso A., Et al., Hypertensive retinopathy revisited: Some answers, more questions, Br. J. Ophthalmol., 89, 12, pp. 1646-1654, (2005); Frost S., Et al., Retinal vascular biomarkers for early detection and monitoring of Alzheimer's disease, Transl. Psychiatry, 3, 2, (2013); Maetal Y., ROSE:Aretinal oct-angiography vessel segmentation dataset and new model, IEEE Trans. Med. Imag., 40, 3, pp. 928-939, (2021); Qu H., Wang J., Li B., Yu M., Probabilistic model for Robust affine and non-rigid point set matching, IEEE Trans. Pattern Anal.Mach. Intell., 39, 2, pp. 371-384, (2017); Zheng Y., Et al., Landmark matching based retinal image alignment by enforcing sparsity in correspondence matrix, Med. Image Anal., 18, 6, pp. 903-913, (2014); Hernandez-Matas C., Zabulis X., Argyros A., REMPE: Registration of retinal images through eye modelling and pose estimation, IEEE J. Biomed. Health. Informat., 24, 12, pp. 3362-3373, (2020); Farzin H., Abrishami-Moghaddam H., Moin M.-S., A novel retinal identification system, EURASIP J. Adv. Signal Process., 2008, pp. 1-10, (2008); Rubaiyat A.H.M., Aich S., Toma T.T., Mallik A.R., Al-Islam R., Fast normalized cross-correlation based retinal recognition, Proc. Int. Conf. Comput. Informat. Technol. Dhaka, pp. 358-361, (2014); Aleem S., Sheng B., Li P., Yang P., Feng D.D., Fast and accurate retinal identification system: Using retinal blood vasculature landmarks, IEEE Trans. Ind. Informat., 15, 7, pp. 4099-4110, (2019); Peng H., Et al., Automatic tracing of ultra-volumes of neuronal images, Nat. Methods, 14, 4, pp. 332-333, (2017); Zhou Z., Liu X., Long B., Peng H., TReMAP: Automatic 3D neuron reconstruction based on tracing, reverse mapping and assembling of 2D projections, Neuroinformatics, 14, 1, pp. 1-10, (2015); Xie J., Zhao T., Lee T., Myers E., Peng H., Anisotropic path searching for automatic neuron reconstruction, Med. Image Anal., 15, 5, pp. 680-689, (2011); Liu M., Chen W., Wang C., Peng H., A multiscale ray-shootingmodel for termination detection of tree-like structures in biomedical images, IEEE Trans. Med. Imag., 38, 8, pp. 1923-1934, (2019); Shen L., Liu M., Wang C., Guo C., Meijering E., Wang Y., Efficient 3D junction detection in biomedical images based on a circular sampling model and reverse mapping, IEEE J. Biomed. Health. Informat., 25, 5, pp. 1612-1623, (2021); Srinidhi C.L., Rath P., Sivaswamy J., A vessel keypoint detector for junction classification, Proc. IEEE Int. Symp. Biomed. Imag., pp. 882-885, (2017); Morales S., Et al., Retinal network characterization through fundus image processing: Significant point identification on vessel centerline, Signal Process, 59, pp. 50-64, (2017); Shen L., Et al., Efficient critical point detection for curvilinear structures using a ring-like ray-shootingmodel, IEEE Trans. Instrum.Meas., 70, pp. 1-11, (2021); Azzopardi G., Petkov N., Automatic detection of vascular bifurcations in segmented retinal images using trainable COSFIRE filters, Pattern Recogn. Lett., 34, 8, pp. 922-933, (2013); Radojevic M., Smal I., Meijering E., Fuzzy-logic based detection and characterization of junctions and terminations in fluorescence microscopy images of neurons, Neuroinformatics, 14, 2, pp. 201-219, (2016); Abbasi-Sureshjani S., Smit-Ockeloen I., Bekkers E., Dashtbozorg B., Romeny B.T.H., Automatic detection of vascular bifurcations and crossings in retinal images using orientation scores, Proc. IEEE Int. Symp. Biomed. Imag., pp. 189-192, (2016); Uslu F., Bharath A.A., A multi-task network to detect junctions in retinal vasculature, Proc. Med. Image Comput. Comput.-Assist. Intervent., pp. 92-100, (2018); Chen W., Et al., Spherical-patches extraction for deep-learning based critical points detection in 3D neuron microscopy images, IEEE Trans. Med. Imag., 40, 2, pp. 527-538, (2021); Zhao H., Sun Y., Li H., Retinal vascular junction detection and classification via deep neural networks, Comput. Methods Programs Biomed., 183, (2020); Pratt H., Et al., Automatic detection and distinction of retinal vessel bifurcations and crossings in colour fundus photography, J. Imag., 4, 1, pp. 4-17, (2018); Tan Y., Et al., DeepBranch: Deep neural networks for branch point detection in biomedical images, IEEE Trans. Med. Imag., 39, 4, pp. 1195-1205, (2020); Hervella A.S., Rouco J., Novo J., Penedo M.G., Ortega M., Deep multi-instance heatmap regression for the detection of retinal vessel crossings and bifurcations in eye fundus images, Comput. Methods Programs Biomed., 186, (2020); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, Proc. Med. Image Comput. Comput.-Assist. Intervent, pp. 234-241, (2015); Redmon J., Divvala S., Girshick R., Farhadi A., You only look once: Unified, real-time object detection, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 779-788, (2016); Valanarasu J.M.J., Sindagi V.A., Hacihaliloglu I., Patel V.M., KiUNet: Overcomplete Convolutional Architectures for Biomedical Image and Volumetric Segmentation, (2020); Yasarla R., Valanarasu J.M.J., Patel V.M., Exploring overcomplete representations for single image deraining using CNNs, IEEE J. Sel. Topics Signal Process., 15, 2, pp. 229-239, (2021); Falk T., Et al., U-Net: Deep learning for cell counting, detection, and morphometry, Nat. Methods, 16, pp. 67-70, (2019); Cao H., Et al., A two-stage convolutional neural networks for lung nodule detection, IEEE J. Biomed. Health. Informat., 24, 7, pp. 2006-2015, (2020); Kassim Y.M., Et al., Clustering-Based dual deep learning architecture for detecting red blood cells in Malaria diagnostic smears, IEEE J. Biomed. Health. Informat., 25, 5, pp. 1735-1746, (2021); Artacho B., Savakis A., UniPose: Unified human pose estimation in single images and videos, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 7033-7042, (2020); Chu X., Ouyang W., Li H., Wang X., Structured feature learning for pose estimation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 4715-4723, (2016); Toshev A., Szegedy C., DeepPose: Human pose estimation via deep neural networks, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1653-1660, (2014); Farha Y.A., Gall J., MS-TCN: Multi-stage temporal convolutional network for action segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 3570-3579, (2019); Sun K., Xiao B., Liu D., Wang J., Deep high-resolution representation learning for human pose estimation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 5686-5696, (2019); Chu X., Et al., Multi-context attention for human pose estimation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 5669-5678, (2017); Chollet F., Xception: Deep learning with depthwise separable convolutions, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1251-1258, (2017); Staal J., Abramoff M.D., Niemeijer M., Viergever M.A., Van Ginneken B., Ridge-based vessel segmentation in color images of the retina, IEEE Trans. Med. Imag., 23, 4, pp. 501-509, (2004); Peng H., Meijering E., Ascoli G., From DIADEM to BigNeuron, Neuroinformatics, 13, 3, pp. 259-260, (2015); Peng H., Et al., Virtual finger boosts three-dimensional imaging and microsurgery as well as terabyte volume image visualization and analysis, Nat. Commun., 5, 1, pp. 1-13, (2014); Guo C., Et al., SA-UNet: Spatial attention U-Net for retinal vessel segmentation, Proc. 25th Int. Conf. Pattern Recogn, pp. 1236-1242, (2021); Xiao H., Peng H., APP2:Automatic tracing of 3Dneuronmorphology based on hierarchical pruning of a gray-weighted image distance-tree, Bioinformatics, 29, 11, pp. 1448-1454, (2013); Jerman T., Pernus F., Likar B., Spiclin Z., Enhancement of vascular structures in 3D and 2D angiographic images, IEEE Trans. Med. Imag., 35, 9, pp. 2107-2118, (2016); Yang B., Chen W., Luo H., Tan Y., Liu M., Wang Y., Neuron image segmentation via learning deep features and enhancing weak neuronal structures, IEEE J. Biomed. Health. Informat., 25, 5, pp. 1634-1645, (2021); Sadikoglu F., Uzelaltinbulat S., Biometric retina identification based on neural network, Procedia Comput. Sci., 102, pp. 26-33, (2016)","M. Liu; College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China; email: liu_min@hnu.edu.cn","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21682194","","ITIBF","34197332","English","IEEE J. Biomedical Health Informat.","Article","Final","","Scopus","2-s2.0-85112591760"
"Aggarwal S.; Juneja S.; Rashid J.; Gupta D.; Gupta S.; Kim J.","Aggarwal, Sonam (57224361738); Juneja, Sapna (57210408722); Rashid, Junaid (57203222981); Gupta, Deepali (57208714508); Gupta, Sheifali (57072019200); Kim, Jungeun (56600264800)","57224361738; 57210408722; 57203222981; 57208714508; 57072019200; 56600264800","Protein Subcellular Localization Prediction by Concatenation of Convolutional Blocks for Deep Features Extraction From Microscopic Images","2023","IEEE Access","11","","","1057","1073","16","4","10.1109/ACCESS.2022.3232564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146250862&doi=10.1109%2fACCESS.2022.3232564&partnerID=40&md5=c07546cb43a08edb371f50dd60478f85","Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, Chandigarh, 140401, India; Kiet Group of Institutions, Department of Computer Science, Ghaziabad, 201206, India; Kongju National University, Department of Computer Science and Engineering, Cheonan, 31080, South Korea; Kongju National University, Department of Software, Cheonan, 31080, South Korea","Aggarwal S., Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, Chandigarh, 140401, India; Juneja S., Kiet Group of Institutions, Department of Computer Science, Ghaziabad, 201206, India; Rashid J., Kongju National University, Department of Computer Science and Engineering, Cheonan, 31080, South Korea; Gupta D., Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, Chandigarh, 140401, India; Gupta S., Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, Chandigarh, 140401, India; Kim J., Kongju National University, Department of Computer Science and Engineering, Cheonan, 31080, South Korea, Kongju National University, Department of Software, Cheonan, 31080, South Korea","Understanding where proteins are located within the cells is essential for proteomics research. Knowledge of protein subcellular location aids in early disease detection and drug targeting treatments. Incorrect localization of proteins can interfere with the functioning of cells and leads to illnesses like cancer. Technological advances have enabled computational methods to detect protein's subcellular location in living organisms. The advent of high-quality microscopy has led to the development of image-based prediction algorithms for protein subcellular localization. Confocal microscopy, which is used by the Human Protein Atlas (HPA), is a great tool for locating proteins. HPA database comprises millions of images which have been procured using confocal microscopy and are annotated with single as well as multi-labels. However, the multi-instance nature of the classification task and the low quality of the images make image-based prediction an extremely difficult problem. There are probably just a few algorithms for automatically predicting protein localization, and most of them are limited to single-label classification. Therefore, it is important to develop a satisfactory automatic multi-label HPA recognition system. The aim of this research is to design a model based on deep learning for automatic recognition system for classifying multi-label HPA. Specifically, a novel Convolutional Neural Network design for classifying protein distribution across 28 subcellular compartments has been presented in this paper. Extensive experiments have been done on the proposed model to achieve the best results for multilabel classification. With the proposed CNN framework as F1-score of 0.77 was achieved which outperformed the latest approaches.  © 2013 IEEE.","biomedical image analysis; convolutional neural network; Deep learning; protein subcellular localization prediction; proteomics","Bioinformatics; Cell engineering; Convolution; Deep neural networks; Diseases; Extraction; Feature extraction; Forecasting; Image processing; Location; Molecular biology; Biomedical image analysis; Convolutional neural network; Deep learning; Features extraction; Location awareness; Protein engineering; Protein subcellular localization prediction; Proteomics; Proteins","","","","","Ministry of Education, MOE; Ministry of SMEs and Startups, MSS, (S3033853)","This work was supported in part by the Technology Development Program of MSS under Grant S3033853; and in part by the National University Development Project by the Ministry of Education, in 2022.","Nanni L., Lumini A., Brahnam S., Local binary patterns variants as texture descriptors for medical image analysis, Artif. Intell. Med., 49, 2, pp. 117-125, (2010); Murphy R.F., Velliste V.M.B.M., Towards a systematics for protein subcellular location: Quantitative description of protein localization patterns and automated analysis of fluorescence microscope images, Proc. ISMB, 8, pp. 251-259, (2000); Glory E., Murphy R.F., Automated subcellular location determination and high-throughput microscopy, Develop. Cell, 12, 1, pp. 7-16, (2007); Tahir M., Khan A., Majid A., Protein subcellular localization of fluorescence imagery using spatial and transform domain features, Bioin-formatics, 28, 1, pp. 91-97, (2012); Lin C.-C., Tsai Y.-S., Lin Y.-S., Chiu T.-Y., Hsiung C.-C., Lee M.-I., Simpson J.C., Hsu C.-N., Boosting multiclass learning with repeating codes and weak detectors for protein subcellular localization, Bioin-formatics, 23, 24, pp. 3374-3381, (2007); Boland M.V., Murphy R.F., A neural network classifier capable of recognizing the patterns of all major subcellular structures in fluorescence microscope images of HeLa cells, Bioinformatics, 17, 12, pp. 1213-1223, (2001); Srinivasa G., Merryman T., Chebira A., Kovacevic J., Mintos A., Adaptive multiresolution techniques for subcellular protein location classification, Proc. IEEE Int. Conf. Acoust. Speed Signal Process., 5, (2006); Chebira A., Barbotin Y., Jackson C., Merryman T., Srinivasa G., Murphy R.F., Kovaevi J., Amultiresolution approach to automated classification of protein subcellular location images, BMC Bioinf., 8, 1, pp. 1-10, (2007); Murphy R.F., Automated proteome-wide determination of subcellular location using high throughput microscopy, Proc. 5th IEEE Int. Symp. Biomed. Imag., From Nano Macro, pp. 308-311, (2008); Uhlen M., Oksvold P., Fagerberg L., Lundberg E., Jonasson K., Forsberg M., Zwahlen M., Kampf C., Wester K., Hober S., Wernerus H., Bjorling L., Ponten F., Towards a knowledge-based human protein atlas, Nature Biotechnol., 28, 12, pp. 1248-1250, (2010); Thul P.J., Et al., A subcellular map of the human proteome, Science, 356, 6340, (2017); Handfield L.-F., Strome B., Chong Y.T., Moses A.M., Local statistics allow quantification of cell-to-cell variability from high-throughput microscope images, Bioinformatics, 31, 6, pp. 940-947, (2015); Boland M.V., Markey M.K., Murphy R.F., Automated recognition of patterns characteristic of subcellular structures in fluorescence microscopy images, Cytometry, 33, 3, pp. 366-375, (1998); Conrad C., Erffe H., Warnat P., Daigle N., Lorch T., Ellenberg J., Pepperkok R., Eils R., Automatic identification of subcellular phenotypes on human cell arrays, Genome Res., 14, 6, pp. 1130-1136, (2004); Zaidi S.S.A., Ansari M.S., Aslam A., Kanwal N., Asghar M., Lee B., A survey of modern deep learning based object detection models, Digit. Signal Process., 126, (2022); Mo Y., Wu Y., Yang X., Liu F., Liao Y., Review the state-ofthe-art technologies of semantic segmentation based on deep learning, Neurocomputing, 493, pp. 626-646, (2022); Stefanini M., Cornia M., Baraldi L., Cascianelli S., Fiameni G., Cucchiara R., From show to tell: A survey on deep learning-based image captioning, IEEE Trans. Pattern Anal. Mach. Intell., 45, 1, pp. 539-559, (2023); Davuluri R., Rengaswamy R., Identification of Alzheimer's disease using various deep learning techniques_A review, Intelligent Manufacturing and Energy Sustainability, pp. 485-498, (2022); Zemouri R., Zerhouni N., Racoceanu D., Deep learning in the biomedical applications: Recent and future status, Appl. Sci., 9, 8, (2019); Dash S., Acharya B.R., Mittal M., Abraham A., Kelemen A., Deep Learning Techniques for Biomedical and Health Informatics, (2020); Park Y., Kellis M., Deep learning for regulatory genomics, Nature Biotechnol., 33, 8, pp. 825-826, (2015); Zhuang L., Lipkova J., Chen R., Mahmood F., Deep learningbased integration of histology, radiology, and genomics for improved survival prediction in glioma patients, Proc. SPIE, 12039, (2022); Wang Y., Zhang G., Liu X., Xi Y., Wang P., Zhang Y., Li X., Abstract 5045: Genomics and pathology based deep learning to predict cancers of unknown primary, Cancer Res., 82, 12, (2022); Ede J.M., Deep learning in electron microscopy, Mach. Learn., Sci. Technol., 2, 1, (2021); Liu Z., Jin L., Chen J., Fang Q., Ablameyko S., Yin Z., Xu Y., A survey on applications of deep learning in microscopy image analysis, Comput. Biol. Med., 134, (2021); Chen X., Velliste M., Murphy R.F., Automated interpretation of subcellular patterns in fluorescence microscope images for location proteomics, Cytometry A, 69 A, 7, pp. 631-640, (2006); Su R., He L., Liu T., Liu X., Wei L., Protein subcellular localization based on deep image features and criterion learning strategy, Briefings Bioinf., 22, 4, (2020); Liu Z., Wang Z., Du B., Multi-marginal contrastive learning for multilabel subcellular protein localization, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 20626-20635, (2022); Kraus O.Z., Grys B.T., Ba J., Chong Y., Frey B.J., Boone C., Andrews B.J., Automated analysis of high-content microscopy data with deep learning, Mol. Syst. Biol., 13, 4, (2017); Parnamaa T., Parts L., Accurate classification of protein subcellular localization from high-throughput microscopy images using deep learning, G3, Genes, Genomes, Genet., 7, 5, pp. 1385-1392, (2017); Xiang S., Liang Q., Hu Y., Tang P., Coppola G., Zhang D., Sun W., AMC-Net: Asymmetric and multi-scale convolutional neural network for multi-label HPA classification, Comput. Methods Programs Biomed., 178, pp. 275-287, (2019); Sullivan D.P., Winsnes C.F., Akesson L., Hjelmare M., Wiking M., Schutten R., Campbell L., Leifsson H., Rhodes S., Nordgren A., Smith K., Revaz B., Finnbogason B., Szantner A., Lundberg E., Deep learning is combined with massive-scale citizen science to improve large-scale image classification, Nature Biotechnol., 36, 9, pp. 820-828, (2018); Liimatainen K., Valkonen M., Latonen L., Ruusuvuori P., Cell organelle classification with fully convolutional neural networks, (2018); Liimatainen K., Huttunen R., Latonen L., Ruusuvuori P., Convolutional neural network-based artificial intelligence for classification of protein localization patterns, Biomolecules, 11, 2, pp. 1-15, (2021); Li Z., Togo R., Ogawa T., Haseyama M., Classification of subcellular protein patterns in human cells with transfer learning, Proc. IEEE 1st Global Conf. Life Sci. Technol. (LifeTech), pp. 273-274, (2019); Shwetha T.R., Thomas S.A., Kamath V., N.K.B, Hybrid Xception model for human protein atlas image classification, Proc. IEEE 16th India Council Int. Conf. (INDICON), pp. 2019-2022, (2019); Human Protein Atlas Image Classification; Liang G., Hong H., Xie W., Zheng L., Combining convolutional neural network with recursive neural network for blood cell image classification, IEEE Access, 6, pp. 36188-36197, (2018); Gao Z., Wang L., Zhou L., Zhang J., HEp-2 cell image classification with deep convolutional neural networks, IEEE J. Biomed. Health Informat., 21, 2, pp. 416-428, (2017); Aggarwal S., Gupta S., Kannan R., Ahuja R., Gupta D., Juneja S., Belhaouari S.B., A convolutional neural network-based framework for classification of protein localization using confocal microscopy images, IEEE Access, 10, pp. 83591-83611, (2022)","J. Rashid; Kongju National University, Department of Computer Science and Engineering, Cheonan, 31080, South Korea; email: junaid.rashid@kongju.ac.kr; J. Kim; Kongju National University, Department of Computer Science and Engineering, Cheonan, 31080, South Korea; email: jekim@kongju.ac.kr","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85146250862"
"Yi D.; Baltov P.; Hua Y.; Philip S.; Sharma P.K.","Yi, Dewei (57189461703); Baltov, Petar (58608894300); Hua, Yining (57206481017); Philip, Sam (12797452800); Sharma, Pradip Kumar (57191076911)","57189461703; 58608894300; 57206481017; 12797452800; 57191076911","Compound Scaling Encoder-Decoder (CoSED) Network for Diabetic Retinopathy Related Bio-Marker Detection","2024","IEEE Journal of Biomedical and Health Informatics","28","4","","1959","1970","11","4","10.1109/JBHI.2023.3313785","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171797427&doi=10.1109%2fJBHI.2023.3313785&partnerID=40&md5=e3fc6d0995809233411e3d70f0087e39","University of Aberdeen, Department of Computing Science, Aberdeen, AB24 3UE, United Kingdom; Nhs Grampian, Department of Diabetes and Endocrinology, Aberdeen, AB25 2ZN, United Kingdom","Yi D., University of Aberdeen, Department of Computing Science, Aberdeen, AB24 3UE, United Kingdom; Baltov P., University of Aberdeen, Department of Computing Science, Aberdeen, AB24 3UE, United Kingdom; Hua Y., University of Aberdeen, Department of Computing Science, Aberdeen, AB24 3UE, United Kingdom; Philip S., Nhs Grampian, Department of Diabetes and Endocrinology, Aberdeen, AB25 2ZN, United Kingdom; Sharma P.K., University of Aberdeen, Department of Computing Science, Aberdeen, AB24 3UE, United Kingdom","Biomedical image segmentation plays an important role in Diabetic Retinopathy (DR)-related biomarker detection. DR is an ocular disease that affects the retina in people with diabetes and could lead to visual impairment if management measures are not taken in a timely manner. In DR screening programs, the presence and severity of DR are identified and classified based on various microvascular lesions detected by qualified ophthalmic screeners. Such a detection process is time-consuming and error-prone, given the small size of the microvascular lesions and the volume of images, especially with the increasing prevalence of diabetes. Automated image processing using deep learning methods is recognized as a promising approach to support diabetic retinopathy screening. In this article, we propose a novel compound scaling encoder-decoder network architecture to improve the accuracy and running efficiency of microvascular lesion segmentation. In the encoder phase, we develop a lightweight encoder to speed up the training process, where the encoder network is scaled up in depth, width, and resolution dimensions. In the decoder phase, an attention mechanism is introduced to yield higher accuracy. Specifically, we employ Concurrent Spatial and Channel Squeeze and Channel Excitation (scSE) blocks to fully utilise both spatial and channel-wise information. Additionally, a compound loss function is incorporated with transfer learning to handle the problem of imbalanced data and further improve performance. To assess performance, our method is evaluated on two large-scale lesion segmentation datasets: DDR and FGADR datasets. Experimental results demonstrate the superiority of our method compared to other competent methods.  © 2013 IEEE.","attention mechanism; compound scaling; Diabetic retinopathy; fundus image; lesion segmentation; retinal screening","Blood vessels; Channel coding; Decoding; Deep learning; Diagnosis; Eye protection; Large dataset; Medical imaging; Network architecture; Ophthalmology; Signal encoding; biological marker; Attention mechanisms; Biomedical imaging; Compound; Compound scaling; Decoding; Diabetic retinopathy; Fundus image; Images segmentations; Lesion; Lesion segmentations; Retina; Retinal screening; Scalings; Article; artificial neural network; compound scaling encoder decoder network; controlled study; deep learning; diabetic retinopathy; event related potential; human; image processing; image segmentation; learning algorithm; machine learning; mathematical model; nerve cell network; network analysis; prevalence; quality control; refraction index; training; transfer of learning; visual impairment; Image segmentation","","","","","","","Niu Y., Gu L., Zhao Y., Lu F., Explainable diabetic retinopathy detection and retinal image generation, IEEE J. Biomed. Health Inform., 26, 1, pp. 44-55, (2022); Eladawi N., Et al., Early diabetic retinopathy diagnosis based on local retinal blood vessel analysis in optical coherence tomography angiography (OCTA) images, Med. Phys., 45, 10, pp. 4582-4599, (2018); Ophthalmoscopy D., Levels E., International clinical diabetic retinopathy disease severity scale detailed table, Ophthalmology, (2002); Zhou Y., Wang B., Huang L., Cui S., Shao L., A benchmark for studying diabetic retinopathy: Segmentation, grading, and transferability, IEEE Trans. Med. Imag., 40, 3, pp. 818-828, (2021); Li T., Gao Y., Wang K., Guo S., Liu H., Kang H., Diagnostic assessment of deep learning algorithms for diabetic retinopathy screening, Inf. Sci., 501, pp. 511-522, (2019); Williams G.A., Et al., Single-field fundus photography for diabetic retinopathy screening: A report by the american academy of ophthalmology, Ophthalmology, 111, 5, pp. 1055-1062, (2004); Chakravarty A., Sivaswamy J., RACE-net:Arecurrent neural network for biomedical image segmentation, IEEE J. Biomed. Health Inform., 23, 3, pp. 1151-1162, (2019); Stitt A.W., Et al., The progress in understanding and treatment of diabetic retinopathy, Prog. Retinal Eye Res., 51, pp. 156-186, (2016); Akram M.U., Khalid S., Khan S.A., Identification and classification of microaneurysms for early detection of diabetic retinopathy, Pattern. Recognit., 46, 1, pp. 107-116, (2013); Taraprasad D., Et al., Recently updated global diabetic retinopathy screening guidelines: Commonalities, differences, and future possibilities, Eye, 35, 10, pp. 2685-2698, (2021); Alyoubi W.L., Shalash W.M., Abulkhair A.F., Diabetic retinopathy detection through deep learning techniques: A review, Inform. Med. Unlocked, 20, (2020); Asiri N., Hussain M., Adel F.A., Alzaidi N., Deep learning based computer-aided diagnosis systems for diabetic retinopathy: A survey, Artif. Intell. Med., 99, (2019); Litjens G., Et al., A survey on deep learning in medical image analysis, Med. Image Anal., 42, pp. 60-88, (2017); Stolte S., Fang R., A survey on medical image analysis in diabetic retinopathy, Med. Image Anal., 64, (2020); Sambyal N., Saini P., Syal R., Gupta V., Modified u-net architecture for semantic segmentation of diabetic retinopathy images, Biocybernetics Biomed. Eng., 40, 3, pp. 1094-1109, (2020); Ahmed U., Lin J.C.-W., Srivastava G., Towards early diagnosis and intervention: An ensemble voting model for precise vital sign prediction in respiratory disease, IEEE J. Biomed. Health Inform.; Ullah F., Srivastava G., Xiao H., Ullah S., Lin J.C.-W., Zhao Y., A scalable federated learning approach for collaborative smart healthcare systems with intermittent clients using medical imaging, IEEE J. Biomed. Health Inform.; Selvaraju R.R., Cogswell M., Das A., Vedantam R., Parikh D., Batra D., Grad-CAM: Visual explanations from deep networks via gradient-based localization, Int. J. Comput. Vis., 128, 2, pp. 336-359, (2020); Meng Q., Hashimoto Y., Satoh S., How to extract more information with less burden: Fundus image classification and retinal disease localization with ophthalmologist intervention, IEEE J. Biomed. Health Inform., 24, 12, pp. 3351-3361, (2020); Chen L.-C., Zhu Y., Papandreou G., Schroff F., Adam H., Encoderdecoder with atrous separable convolution for semantic image segmentation, Proc. Eur. Conf. Comp. Vis., pp. 801-818, (2018); Li X., Chen H., Qi X., Dou Q., Fu C.-W., Heng P.-A., H-denseunet: Hybrid densely connected unet for liver and tumor segmentation from CT volumes, IEEE Trans. Med. Imag., 37, 12, pp. 2663-2674, (2018); Huang G., Liu Z., Maaten L.V.D., Weinberger K.Q., Densely connected convolutional networks, Proc. IEEE Conf. Comput. Vis. Pattern. Recognit., pp. 4700-4708, (2017); Zhao H., Et al., Sc2Net: A novel segmentation-based classification network for detection of COVID-19 in chest x-ray images, IEEE J. Biomed. Health Inform., 26, 8, pp. 4032-4043, (2022); Ren J., Et al., A novel intelligent computational approach to model epidemiological trends and assess the impact of non-pharmacological interventions for COVID-19, IEEE J. Biomed. Health Inform., 24, 12, pp. 3551-3563, (2020); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, Proc. Int. Conf. Med. Image Comput. Comput. Assist. Int., pp. 234-241, (2015); Suri J.S., Et al., Systematic review of artificial intelligence in acute respiratory distress syndrome for COVID-19 lung patients: A biomedical imaging perspective, IEEE J. Biomed. Health Inform., 25, 11, pp. 4128-4139, (2021); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., Unet: A nested u-net architecture for medical image segmentation, Proc. Deep Learn. Med. Image Anal. Multimodal Learn. Clin. Decis. Support, pp. 3-11, (2018); Huang Y., Et al., Gpipe: Efficient training of giant neural networks using pipeline parallelism, Proc. Adv. Neural Inf. Process. Syst., 32, pp. 103-112, (2019); Tan M., Le Q., Efficientnet: Rethinking model scaling for convolutional neural networks, Proc. Int. Conf. Mach. Learn., pp. 6105-6114, (2019); Tan M., Et al., Mnasnet: Platform-aware neural architecture search for mobile, Proc. IEEE Conf. Comput. Vis. Pattern. Recognit., pp. 2820-2828, (2019); Sandler M., Howard A., Zhu M., Zhmoginov A., Chen L.-C., Mobilenetv2: Inverted residuals and linear bottlenecks, Proc. IEEE Conf. Comput. Vis. Pattern. Recognit., pp. 4510-4520, (2018); Hu J., Shen L., Sun G., Squeeze-and-excitation networks, Proc. IEEE Conf. Comput. Vis. Pattern. Recognit., pp. 7132-7141, (2018); Tan M., Le Q., Efficientnetv2: Smaller models and faster training, Proc. Int. Conf. Mach. Learn., pp. 10096-10106, (2021); He A., Li T., Li N., Wang K., Fu H., CABnet: Category attention block for imbalanced diabetic retinopathy grading, IEEE Trans. Med. Imag., 40, 1, pp. 143-153, (2021); Roy A.G., Navab N., Wachinger C., Recalibrating fully convolutional networks with spatial and channel 'squeeze and excitation' blocks, IEEE Trans. Med. Imag., 38, 2, pp. 540-549, (2019); Milletari F., Navab N., Ahmadi S.-A., V-Net: Fully convolutional neural networks for volumetric medical image segmentation, Proc. IEEE Int. Conf. 3D Vis., pp. 565-571, (2016); Yeung M., Sala E., Schonlieb C.-B., Rundo L., Unified focal loss: Generalising dice and cross entropy-based losses to handle class imbalanced medical image segmentation, Comput. Med. Imaging. Graph., 95, (2022); Dai L., Et al., A deep learning system for detecting diabetic retinopathy across the disease spectrum, Nature Commun., 12, 1, pp. 1-11, (2021); Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L., Imagenet: A large-scale hierarchical image database, Proc. IEEE Conf. Comput. Vis. Pattern. Recognit., pp. 248-255, (2009); Fang Z., Et al., A novel multi-stage residual feature fusion network for detection of covid-19 in chest x-ray images, IEEE Trans. Mol. Biol. Multiscale Commun., 8, 1, pp. 17-27, (2022); Minaee S., Boykov Y.Y., Porikli F., Plaza A.J., Kehtarnavaz N., Terzopoulos D., Image segmentation using deep learning: A survey, IEEE Trans. Pattern Anal. Mach. Intell., 44, 7, pp. 3523-3542, (2022); Ahmed U., Lin J.C.-W., Srivastava G., Graph attention-based curriculum learning formental healthcare classification, IEEE J. Biomed. Health Inform.","D. Yi; University of Aberdeen, Department of Computing Science, Aberdeen, AB24 3UE, United Kingdom; email: dewei.yi@abdn.ac.uk","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21682194","","ITIBF","37695962","English","IEEE J. Biomedical Health Informat.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85171797427"
"Song H.; Wang Y.; Zeng S.; Guo X.; Li Z.","Song, Haojie (57844924600); Wang, Yuefei (57192436981); Zeng, Shijie (57723196300); Guo, Xiaoyan (59289170900); Li, Zheheng (57844408200)","57844924600; 57192436981; 57723196300; 59289170900; 57844408200","OAU-net: Outlined Attention U-net for biomedical image segmentation","2023","Biomedical Signal Processing and Control","79","","104038","","","","17","10.1016/j.bspc.2022.104038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135930269&doi=10.1016%2fj.bspc.2022.104038&partnerID=40&md5=7f92b6650e927c165c5385eef100507f","College of Computer Science, Chengdu University, 2025 Chengluo Rd., Sichuan, Chengdu, 610106, China","Song H., College of Computer Science, Chengdu University, 2025 Chengluo Rd., Sichuan, Chengdu, 610106, China; Wang Y., College of Computer Science, Chengdu University, 2025 Chengluo Rd., Sichuan, Chengdu, 610106, China; Zeng S., College of Computer Science, Chengdu University, 2025 Chengluo Rd., Sichuan, Chengdu, 610106, China; Guo X., College of Computer Science, Chengdu University, 2025 Chengluo Rd., Sichuan, Chengdu, 610106, China; Li Z., College of Computer Science, Chengdu University, 2025 Chengluo Rd., Sichuan, Chengdu, 610106, China","In this paper, we propose an Outlined Attention U-network (OAU-net) with bypass branching strategy to solve biomedical image segmentation tasks, which is capable of sensing shallow and deep features. Unlike previous studies, we use residual convolution and res2convolution as encoders. In particular, the outline filter and attention module are embedded in the skip connection part, respectively. Shallow features will enhance the edge information after being processed by the outline filter. Meanwhile, in the depths of the network, to better realize feature fusion, our attention module will simultaneously emphasize the independence between feature map channels (channel attention module) and each position information (spatial attention module), that is, the hybrid domain attention module. Finally, we conducted ablation experiments and comparative experiments according to three public data sets (pulmonary CT lesions, Kaggle 2018 data science bowl, skin lesions), and analyzed them with classical evaluation indexes. Experimental results show that our proposed method improves segmentation accuracy effectively. Our code is public at https://github.com/YF-W/OAU-net. © 2022 Elsevier Ltd","Biomedical image segmentation; Bypass branching strategy; Hybrid attention module; Outlined filter kernel","Computerized tomography; Biomedical image segmentation; Bypass branching strategy; Edge information; Feature map; Features fusions; Hybrid attention module; Hybrid domain; Outlined filter kernel; Position information; Spatial attention; Article; convolution algorithm; deep learning; deep neural network; diagnostic imaging; edge detection; feature extraction; human; image processing; image segmentation; machine learning; outlined attention U network; receptive field; skin defect; visual attention; Image segmentation","","","","","","","Hansen S., Kuttner S., Kampffmeyer M., Et al., Unsupervised supervoxel-based lung tumor segmentation across patient scans in hybrid PET/MRI, Expert Syst. Appl., 167, (2021); Islam M.R., Nahiduzzaman M., Complex features extraction with deep learning model for the detection of COVID19 from CT scan images using ensemble based machine learning approach, Expert Syst. Appl., (2022); Du W., Shen H., Zhang G., Et al., Interactive defect segmentation in X-Ray images based on deep learning, Expert Syst. Appl., 198, (2022); Le N.Q., Khanh, Et al., DeepETC: a deep convolutional neural network architecture for investigating and classifying electron transport chain's complexes, Neurocomputing., 375, pp. 71-79, (2020); Sua J.N., Et al., Incorporating convolutional neural networks and sequence graph transform for identifying multilabel protein Lysine PTM sites, Chemomet. Intell. Lab. Syst., 206, (2020); Arridge S.R., Optical tomography in medical imaging, Inverse Prob., 15, 2, pp. 41-93, (1999); Ciresan D., Giusti A., Gambardella L., Et al., Deep neural networks segment neuronal membranes in electron microscopy images, Adv. Neural Inform. Process. Syst., 25, (2012); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3431-3440, (2015); Ronneberger O., Fischer P., U-net B.T., Convolutional networks for biomedical image segmentation, International Conference on Medical image computing and computer-assisted intervention, pp. 234-241, (2015); Hinton G.E., Srivastava N., Krizhevsky A., Et al., Improving neural networks by preventing co-adaptation of feature detectors, Comput. Sci., 3, 4, pp. 212-223, (2012); Yu F., Koltun V., Funkhouser T., Dilated residual networks, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 472-480, (2017); Ioffe S., Szegedy C., Batch normalization: Accelerating deep network training by reducing internal covariate shift, International conference on machine learning, PMLR., pp. 448-456, (2015); Qian N., On the momentum term in gradient descent learning algorithms, Neural Networks., 12, 1, pp. 145-151, (1999); He K., Zhang X., Ren S., Et al., Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Badrinarayanan V., Kendall A., Cipolla R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, pp. 2481-2495, (2017); pp. 652-662; Hu J., Shen L., Sun G., Squeeze-and-excitation networks, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 7132-7141, (2018); Woo S., Park J., Lee J.Y., Et al., Cbam: Convolutional block attention module, Proceedings of the European conference on computer vision (ECCV), pp. 3-19, (2018); Wang X., Girshick R., Gupta A., Et al., Non-local neural networks, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 7794-7803, (2018); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Et al., Unet++: Redesigning skip connections to exploit multiscale features in image segmentation, IEEE Trans. Med. Imaging, 39, 6, pp. 1856-1867, (2019); Chen J., Lu Y., Yu Q., Et al., (2021); Vaswani A., Shazeer N., Parmar N., Et al., Attention is all you need, Adv. Neural Inform. Process. Syst., 30, (2017); Lin G., Milan A., Shen C., Et al., Refinenet: Multi-path refinement networks for high-resolution semantic segmentation, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1925-1934, (2017); Ibtehaz N., Rahman M.S., MultiResUNet: Rethinking the U-Net architecture for multimodal biomedical image segmentation, Neural Networks., 121, pp. 74-87, (2020); Zhao H., Shi J., Qi X., Et al., Pyramid scene parsing network, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2881-2890, (2017); Chen L.C., Papandreou G., Kokkinos I., Et al., (2014); Chen L.C., Papandreou G., Kokkinos I., Et al., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs, IEEE Trans. Pattern Anal. Mach. Intell., 40, 4, pp. 834-848, (2017); Chen L.C., Papandreou G., Schroff F., Et al., (2017); Saad M.N., Muda Z., Ashaari N.S., Et al., pp. 46-51, (2014); Zuo W., Wang K., Zhang D., Et al., Combination of polar edge detection and active contour model for automated tongue segmentation, Third International Conference on Image and Graphics (ICIG'04), pp. 270-273, (2004); Zunair H., Hamza A.B., Sharp U-Net: Depthwise convolutional network for biomedical image segmentation, Comput. Biol. Med., 136, (2021); Mnih V., Heess N., Graves A., (2014); Wang F., Jiang M., Qian C., Et al., Residual attention network for image classification, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3156-3164, (2017); Fu J., Liu J., Tian H., Et al., Dual attention network for scene segmentation, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 3146-3154, (2019); Cheng J., Tian S., Yu L., Et al., Fully convolutional attention network for biomedical image segmentation, Artif. Intell. Med., 107, (2020)","","","Elsevier Ltd","","","","","","17468094","","","","English","Biomed. Signal Process. Control","Article","Final","","Scopus","2-s2.0-85135930269"
"Zhang Z.; Sun M.","Zhang, Zhaoguan (58666974900); Sun, Muxin (58668351200)","58666974900; 58668351200","Research on Biomedical Image Segmentation Method Based on Full Convolutional Neural Network","2023","2023 IEEE International Conference on Sensors, Electronics and Computer Engineering, ICSECE 2023","","","","1541","1545","4","0","10.1109/ICSECE58870.2023.10263584","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175075238&doi=10.1109%2fICSECE58870.2023.10263584&partnerID=40&md5=ddd1c3daef2cf152b0990fb520088087","The First Hospital of Jilin University, The Department of Laboratory Medicine, Changchun, 130000, China","Zhang Z., The First Hospital of Jilin University, The Department of Laboratory Medicine, Changchun, 130000, China; Sun M., The First Hospital of Jilin University, The Department of Laboratory Medicine, Changchun, 130000, China","With the continuous progress of deep learning technology, the application of artificial intelligence in the field of smart medical care has been deepened, and many new artificial intelligence algorithms have been applied to the process of medical diagnosis. At present, computed tomography (CT) is the most commonly used method to examine liver tumors, and tumor resection, intervention and radiation are the main treatment methods. Accurately knowing the size, number and location of tumors before surgery can make a scientific and reasonable surgical plan, which is a necessary condition for successful surgery. Product neural network can learn the features that describe the essence of images, and these features can be better used for classification or reconstruction after nonlinear mapping, so as to deal with different medical tasks. Therefore, this paper conducts segmentation research on cell data set and blood vessel data set. Experiments show that, compared with U-Net and RU Net models, this method only uses nearly 2/3 of the training parameters and achieves better segmentation evaluation performance. Among them, Dice coefficient increases by 0.56% and 1.46%, and Jacob coefficient increases by 0.91% and 1.92%. Therefore, compared with U-Net and RU Net models, This method has higher segmentation performance and better generalization performance.  © 2023 IEEE.","Biomedical science; Full Convolutional Neural Network; Image segmentation","Blood vessels; Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Medical imaging; Surgery; Tumors; Artificial intelligence algorithms; Biomedical image segmentation; Biomedical science; Convolutional neural network; Data set; Full convolutional neural network; Images segmentations; Learning technology; Net model; Segmentation methods; Image segmentation","","","","","","","Kist A.M., Dllinger M., Efficient Biomedical Image Segmentation onEdgeTPUs at Point of Care, Ieee Access, 44, 3, (2020); Ibtehaz N., Rahman M.S., MultiResUNet : Rethinking the U-Netarchitecture for multimodal biomedical image segmentation, NeuralNetworks, 24, 10, (2019); Lu F., Fu C., Zhang G., Et al., Convolution neural network based onfusion parallel multiscale features for segmenting fractures incoal-rock images, Journal of Electronic Imaging, 29, 2, (2020); Hu X., Yang H., DRU-net: A novel U-net for biomedical imagesegmentation, Iet Image Processing, 14, 1, (2020); Li Y.X., Pu Y.Y., Xu D., Et al., Image aesthetic quality evaluation usingconvolution neural network embedded learning, OptoelectronicsLetters, 121, 6, (2017); Jiang Y., Tan N., Peng T., Et al., Retinal Vessels Segmentation Based onDilated Multi-Scale Convolutional Neural Network, Ieee Access, 66, 13, (2019); Shao M., Zhang G., Zuo W., Et al., Target Attack on Biomedical ImageSegmentation Model based on Multi-scale Gradients, InformationSciences, 60, 35, (2020); Weng W., Zhu X., INet: Convolutional Networks for BiomedicalImage Segmentation, Ieee Access, 55, 14, (2021); Wang X., Gu L., Wang Z., Computer Medical Image SegmentationBased on Neural Network, Ieee Access, 47, 4, (2020); Peng D., Xiong S., Peng W., Et al., LCP-Net: A local context-perceptiondeep neural network for medical image segmentation, Expert Systemswith Applications, 70, 6, (2020)","M. Sun; The First Hospital of Jilin University, The Department of Laboratory Medicine, Changchun, 130000, China; email: sunmuxin0323@163.com","","Institute of Electrical and Electronics Engineers Inc.","","2023 IEEE International Conference on Sensors, Electronics and Computer Engineering, ICSECE 2023","18 August 2023 through 20 August 2023","Jinzhou","193096","","979-835031373-4","","","English","IEEE Int. Conf. Sensors, Electron. Comput. Eng., ICSECE","Conference paper","Final","","Scopus","2-s2.0-85175075238"
"Lee J.Y.; Lee Y.S.; Tae J.H.; Chang I.H.; Kim T.-H.; Myung S.C.; Nguyen T.T.; Lee J.H.; Choi J.; Kim J.H.; Kim J.W.; Choi S.Y.","Lee, Ju Young (59202047900); Lee, Yong Seong (36068330000); Tae, Jong Hyun (56678417400); Chang, In Ho (57203614272); Kim, Tae-Hyoung (57212837594); Myung, Soon Chul (7005796823); Nguyen, Tuan Thanh (57214889585); Lee, Jae Hyeok (57195838934); Choi, Joongwon (57208742789); Kim, Jung Hoon (57207437054); Kim, Jin Wook (57207437351); Choi, Se Young (57209856147)","59202047900; 36068330000; 56678417400; 57203614272; 57212837594; 7005796823; 57214889585; 57195838934; 57208742789; 57207437054; 57207437351; 57209856147","Selection of Convolutional Neural Network Model for Bladder Tumor Classification of Cystoscopy Images and Comparison with Humans","2024","Journal of Endourology","","","","","","","0","10.1089/end.2024.0250","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197385681&doi=10.1089%2fend.2024.0250&partnerID=40&md5=baf48212e3fed8e0edade970e9d0f0eb","DEEPNOID Inc., Seoul, South Korea; Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang University College of Medicine, Gyeonggi-do, South Korea; Department of Urology, Chung-Ang University Hospital, Chung-Ang University College of Medicine, Seoul, South Korea; Department of Urology, Cho Ray Hospital, University of Medicine and Pharmacy, Ho Chi Minh City, Viet Nam","Lee J.Y., DEEPNOID Inc., Seoul, South Korea; Lee Y.S., Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang University College of Medicine, Gyeonggi-do, South Korea; Tae J.H., Department of Urology, Chung-Ang University Hospital, Chung-Ang University College of Medicine, Seoul, South Korea; Chang I.H., Department of Urology, Chung-Ang University Hospital, Chung-Ang University College of Medicine, Seoul, South Korea; Kim T.-H., Department of Urology, Chung-Ang University Hospital, Chung-Ang University College of Medicine, Seoul, South Korea; Myung S.C., Department of Urology, Chung-Ang University Hospital, Chung-Ang University College of Medicine, Seoul, South Korea; Nguyen T.T., Department of Urology, Cho Ray Hospital, University of Medicine and Pharmacy, Ho Chi Minh City, Viet Nam; Lee J.H., DEEPNOID Inc., Seoul, South Korea; Choi J., Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang University College of Medicine, Gyeonggi-do, South Korea; Kim J.H., Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang University College of Medicine, Gyeonggi-do, South Korea; Kim J.W., Department of Urology, Chung-Ang University Gwangmyeong Hospital, Chung-Ang University College of Medicine, Gyeonggi-do, South Korea; Choi S.Y., Department of Urology, Chung-Ang University Hospital, Chung-Ang University College of Medicine, Seoul, South Korea","Purpose: An investigation of various convolutional neural network (CNN)-based deep learning algorithms was conducted to select the appropriate artificial intelligence (AI) model for calculating the diagnostic performance of bladder tumor classification on cystoscopy images, with the performance of the selected model to be compared against that of medical students and urologists. Methods: A total of 3,731 cystoscopic images that contained 2,191 tumor images were obtained from 543 bladder tumor cases and 219 normal cases were evaluated. A total of 17 CNN models were trained for tumor classification with various hyperparameters. The diagnostic performance of the selected AI model was compared with the results obtained from urologists and medical students by using the receiver operating characteristic (ROC) curve graph and metrics. Results: EfficientNetB0 was selected as the appropriate AI model. In the test results, EfficientNetB0 achieved a balanced accuracy of 81%, sensitivity of 88%, specificity of 74%, and an area under the curve (AUC) of 92%. In contrast, human-derived diagnostic statistics for the test data showed an average balanced accuracy of 75%, sensitivity of 94%, and specificity of 55%. Specifically, urologists had an average balanced accuracy of 91%, sensitivity of 95%, and specificity of 88%, while medical students had an average balanced accuracy of 69%, sensitivity of 94%, and specificity of 44%. Conclusions: Among the various AI models, we suggest that EfficientNetB0 is an appropriate AI classification model for determining the presence of bladder tumors in cystoscopic images. EfficientNetB0 showed the highest performance among several models and showed high accuracy and specificity compared to medical students. This AI technology will be helpful for less experienced urologists or nonurologists in making diagnoses. Image-based deep learning classifies bladder cancer using cystoscopy images and shows promise for generalized applications in biomedical image analysis and clinical decision making. Copyright 2024, Mary Ann Liebert, Inc., publishers.","artificial intelligence; bladder cancer; convolutional neural network; cystoscopy; deep learning","","","","","","National Research Foundation of Korea, NRF; Ministry of Science, ICT and Future Planning, MSIP, (NRF-2022R1F1A1076502); Ministry of Science, ICT and Future Planning, MSIP; Korean Neurological Association, KNA, (KUOS 21-06); Korean Neurological Association, KNA","This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT & Future Planning (NRF-2022R1F1A1076502) and by the Research Foundation Grant funded by the Korean Urological Association (KUOS 21-06).","Saginala K, Barsouk A, Aluru JS, Et al., Epidemiology of bladder cancer, Med Sci (Basel), 8, 1, (2020); Cheng X, Liu X, Liu X, Et al., Metabolomics of non-muscle invasive bladder cancer: Biomarkers for early detection of bladder cancer, Front Oncol, 8, (2018); Zhu CZ, Ting HN, Ng KH, Et al., A review on the accuracy of bladder cancer detection methods, J Cancer, 10, 17, pp. 4038-4044, (2019); Russo GI, Sholklapper TN, Cocci A, Et al., Performance of Narrow Band Imaging (NBI) and Photodynamic Diagnosis (PDD) fluorescence imaging compared to White Light Cystoscopy (WLC) in detecting non-muscle invasive bladder cancer: A systematic review and lesion-level diagnostic meta-analysis, Cancers (Basel), 13, 17, (2021); Ikeda A, Nosato H, Kochi Y, Et al., Cystoscopic imaging for bladder cancer detection based on stepwise organic transfer learning with a pretrained convolutional neural network, J Endourol, 35, 7, pp. 1030-1035, (2021); Yamashita R, Nishio M, Do RKG, Et al., Convolutional neural networks: An overview and application in radiology, Insights Imaging, 9, 4, pp. 611-629, (2018); Alzubaidi L, Zhang J, Humaidi AJ, Et al., Review of deep learning: Concepts, CNN architectures, challenges, applications, future directions, J Big Data, 8, 1, (2021); Powers R, Goldszmidt M, Cohen I, Short term performance forecasting in enterprise systems, Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining, pp. 801-807, (2005); Zoph B, Le QV, Neural architecture search with reinforcement learning, (2016); Tan M, Le Q, Efficientnet: Rethinking model scaling for convolutional neural networks, International conference on machine learning, pp. 6105-6114, (2019); Brabec J, Komarek T, Franc V, Et al., On model evaluation under non-constant class imbalance, Computational Science-ICCS 2020: 20th International Conference, pp. 74-87, (2020); Simundic A-M, Diagnostic accuracy—part 1: Basic concepts: Sensitivity and specificity, ROC analysis, STARD Statement, Point of Care, 11, 1, pp. 6-8, (2012); Aridas CK, Karlos S, Kanas VG, Et al., Uncertainty based under-sampling for learning naive bayes classifiers under imbalanced data sets, IEEE Access, 8, pp. 2122-2133, (2020); Hashemi SMR, Hassanpour H, Kozegar E, Et al., Cystoscopic image classification based on combining MLP and GA, Int J Nonlinear Anal Appl, 11, 1, pp. 93-105, (2020); Hashemi SMR, Hassanpour H, Kozegar E, Et al., Cystoscopy image classification using deep convolutional neural networks, Int J Nonlinear Anal Appl, 10, 1, pp. 193-215, (2019); Kozegar E, Cystoscopic image classification by an ensemble of VGG-nets, Int J Nonlinear Anal Appl, 12, 1, pp. 693-700, (2021); Grossfeld GD, Litwin MS, Wolf JS, Et al., Evaluation of asymptomatic microscopic hematuria in adults: The American Urological Association best practice policy-part I: Definition, detection, prevalence, and etiology, Urology, 57, 4, pp. 599-603, (2001); Barocas DA, Boorjian SA, Alvarez RD, Et al., Microhematuria: AUA/SUFU guideline, J Urol, 204, 4, pp. 778-786, (2020); David SA, Patil D, Alemozaffar M, Et al., Urologist use of cystoscopy for patients presenting with hematuria in the United States, Urology, 100, pp. 20-26, (2017); McCombie SP, Bangash HK, Kuan M, Et al., Delays in the diagnosis and initial treatment of bladder cancer in Western Australia, BJU Int, 120, pp. 28-34, (2017); Lee CT, Madii R, Daignault S, Et al., Cystectomy delay more than 3 months from initial bladder cancer diagnosis results in decreased disease specific and overall survival, J Urol, 175, 4, pp. 1262-1267, (2006); Gao J, Tian DW, Zhou DS, Et al., Flexible cystoscopy can improve anxiety and subjective feelings of bladder cancer patients during follow-up, Wideochir Inne Tech Maloinwazyjne, 16, 2, pp. 397-402, (2021); van der Aa MN, Steyerberg EW, Bangma C, Et al., Cystoscopy revisited as the gold standard for detecting bladder cancer recurrence: Diagnostic review bias in the randomized, prospective CEFUB trial, J Urol, 183, 1, pp. 76-80, (2010); Palou J, Brausi M, Catto JWF, Management of patients with normal cystoscopy but positive cytology or urine markers, Eur Urol Oncol, 3, 4, pp. 548-554, (2020); Marques G, Agarwal D, de la Torre Diez I, Automated medical diagnosis of COVID-19 through EfficientNet convolutional neural network, Appl Soft Comput, 96, (2020); Yoo JY, Kang SY, Park JS, Et al., Deep learning for anatomical interpretation of video bronchoscopy images, Sci Rep, 11, 1, (2021); Park T, Gu P, Kim CH, Et al., Artificial intelligence in urologic oncology: The actual clinical practice results of IBM Watson for Oncology in South Korea, Prostate Int, 11, 4, pp. 218-221, (2023)","S.Y. Choi; Department of Urology, Chung-Ang University Hospital, Chung-Ang University College of Medicine, Seoul, 102, Heukseok-ro, Dongjak-gu, 06973, South Korea; email: urosyc@cau.ac.kr","","Mary Ann Liebert Inc.","","","","","","08927790","","JENDE","38877795","English","J. Endourol.","Article","Article in press","","Scopus","2-s2.0-85197385681"
"Samprovalaki M.; Chatzipapadopoulou A.; Moschovis G.; Charalampakos F.; Kaliosis P.; Pavlopoulos J.; Androutsopoulos I.","Samprovalaki, Marina (59281954400); Chatzipapadopoulou, Anna (59281432800); Moschovis, Georgios (57866890500); Charalampakos, Foivos (57232257500); Kaliosis, Panagiotis (58665010800); Pavlopoulos, John (25654146700); Androutsopoulos, Ion (6506068227)","59281954400; 59281432800; 57866890500; 57232257500; 58665010800; 25654146700; 6506068227","AUEB NLP Group at ImageCLEFmedical Caption 2024","2024","CEUR Workshop Proceedings","3740","","","1729","1745","16","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201578472&partnerID=40&md5=6aa8863378db2fa81e7c8a00d481a064","Department of Informatics, Athens University of Economics and Business, 76, Patission Street, Athens, GR-104 34, Greece; Archimedes Unit, Athena Research Center, 1, Artemidos Street, Athens, GR-151 25, Greece","Samprovalaki M., Department of Informatics, Athens University of Economics and Business, 76, Patission Street, Athens, GR-104 34, Greece; Chatzipapadopoulou A., Department of Informatics, Athens University of Economics and Business, 76, Patission Street, Athens, GR-104 34, Greece; Moschovis G., Department of Informatics, Athens University of Economics and Business, 76, Patission Street, Athens, GR-104 34, Greece, Archimedes Unit, Athena Research Center, 1, Artemidos Street, Athens, GR-151 25, Greece; Charalampakos F., Department of Informatics, Athens University of Economics and Business, 76, Patission Street, Athens, GR-104 34, Greece; Kaliosis P., Department of Informatics, Athens University of Economics and Business, 76, Patission Street, Athens, GR-104 34, Greece; Pavlopoulos J., Department of Informatics, Athens University of Economics and Business, 76, Patission Street, Athens, GR-104 34, Greece, Archimedes Unit, Athena Research Center, 1, Artemidos Street, Athens, GR-151 25, Greece; Androutsopoulos I., Department of Informatics, Athens University of Economics and Business, 76, Patission Street, Athens, GR-104 34, Greece, Archimedes Unit, Athena Research Center, 1, Artemidos Street, Athens, GR-151 25, Greece","This article describes the approaches that the AUEB NLP Group experimented with during its participation in the 8th edition of the ImageCLEFmedical Caption evaluation campaign, including both Concept Detection and Caption Prediction tasks. The objective of Concept Detection is to automatically categorize biomedical images into a set of one or more concepts. In contrast, the Caption Prediction task focuses on generating a precise and meaningful diagnostic caption that describes the medical conditions depicted in the image. Building on our prior research for the Concept Detection task, we utilized a diverse set of Convolutional Neural Network (CNN) encoders, followed by a Feed-Forward Neural Network. Additionally, we implemented two versions of the retrieval-based k-NN algorithm: a version that assigned concepts based on statistical frequency and a weighted version that took into account the order of the retrieved neighbors. Both models used the CNN image encoders to improve their retrieval capabilities. Regarding the Caption Prediction task, we fine-tuned the InstructBLIP model to generate initial captions and then enhanced it by employing rephrasing techniques with further pre-trained models. We also used synthesizing techniques that incorporated information from similar neighboring images in the training set to refine these captions. Additionally, we employed “Distance from Median Maximum Concept Similarity” (DMMCS), a novel guided-decoding approach that drives the model's behaviour throughout the decoding process, aiming to integrate information from the predicted concepts of Concept Detection. We explored the application of DMMCS to all of our developed systems. Our group ranked 2nd in Concept Detection and 4th in Caption Prediction. © 2024 Copyright for this paper by its authors.","Biomedical Images; Caption Generation; Computer Vision; Convolutional Neural Networks; Deep Learning; Generative Models; Multi-Label Classification; Natural Language Processing; Transformers","Deep neural networks; Feedforward neural networks; Generative adversarial networks; Image coding; Image enhancement; Network coding; Biomedical images; Caption generation; Convolutional neural network; Deep learning; Generative model; Language processing; Multi-label classifications; Natural language processing; Natural languages; Transformer; Convolutional neural networks","","","","","","","Ionescu B., Muller H., Dragulinescu A., Ruckert J., Ben Abacha A., Garcia Seco de Herrera A., Bloch L., Brungel R., Idrissi-Yaghir A., Schafer H., Schmidt C. S., Pakull T. M. G., Damm H., Bracke B., Friedrich C. M., Andrei A., Prokopchuk Y., Karpenka D., Radzhabov A., Kovalev V., Macaire C., Schwab D., Lecouteux B., Esperanca-Rodier E., Yim W., Fu Y., Sun Z., Yetisgen M., Xia F., Hicks S. A., Riegler M. A., Thambawita V., Storas A., Halvorsen P., Heinrich M., Kiesel J., Potthast M., Stein B., Overview of ImageCLEF 2024: Multimedia retrieval in medical applications, Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the 15th International Conference of the CLEF Association (CLEF 2024), (2024); Ruckert J., Ben Abacha A., Seco de Herrera A. G., Bloch L., Brungel R., Idrissi-Yaghir A., Schafer H., Bracke B., Damm H., Pakull T. M. G., Schmidt C. S., Muller H., Friedrich C. M., Overview of ImageCLEFmedical 2024 - Caption Prediction and Concept Detection, CLEF2024 Working Notes, CEUR Workshop Proceedings, (2024); Pavlopoulos J., Kougia V., Androutsopoulos I., Papamichail D., Diagnostic Captioning: A Survey, Knowledge and Information Systems, 64, pp. 1-32, (2022); Shin H.-C., Roberts K., Lu L., Demner-Fushman D., Yao J., Summers R. M., Learning to Read Chest X-Rays: Recurrent Neural Cascade Model for Automated Image Annotation, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2497-2506, (2016); Moschovis G., Medical image captioning based on Deep Architectures, (2022); Pavlopoulos J., Kougia V., Androutsopoulos I., A Survey on Biomedical Image Captioning, Proceedings of the Second Workshop on Shortcomings in Vision and Language, pp. 26-36, (2019); Kaliosis P., Pavlopoulos J., Charalampakos F., Moschovis G., Androutsopoulos I., A data-driven guided decoding mechanism for diagnostic captioning, Findings of the Association for Computational Linguistics: ACL 2024; Zhao W. X., Zhou K., Li J., Tang T., Wang X., Hou Y., Min Y., Zhang B., Zhang J., Dong Z., Du Y., Yang C., Chen Y., Chen Z., Jiang J., Ren R., Li Y., Tang X., Liu Z., Liu P., Nie J.-Y., Wen J.-R., A Survey of Large Language Models, (2023); Dai W., Li J., Li D., Tiong A. M. H., Zhao J., Wang W., Li B., Fung P. N., Hoi S., InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning, Advances in Neural Information Processing Systems, 36, (2024); Pelka O., Koitka S., Ruckert J., Nensa F., Friedrich C., Radiology Objects in COntext (ROCO): A Multimodal Image Dataset: 7th Joint International Workshop, CVII-STENT 2018 and Third International Workshop, LABELS 2018, Held in Conjunction with MICCAI 2018, pp. 180-189, (2018); Chung H. W., Hou L., Longpre S., Zoph B., Tay Y., Fedus W., Li Y., Wang X., Dehghani M., Brahma S., Et al., Scaling Instruction-Finetuned Language Models, Journal of Machine Learning Research, 25, pp. 1-53, (2024); Li Y., Liang X., Hu Z., Xing E., Knowledge-Driven Encode, Retrieve, Paraphrase for Medical Image Report Generation, AAAI Conference on Artificial Intelligence, (2019); Vernikos G., Brazinskas A., Adamek J., Mallinson J., Severyn A., Malmi E., Small Language Models Improve Giants by Rewriting Their Outputs, Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 2703-2718, (2024); Lu Q., Dou D., Nguyen T., ClinicalT5: A Generative Language Model for Clinical Text, Findings of the Association for Computational Linguistics: EMNLP 2022, 2022, pp. 5436-5443; Dosovitskiy A., Beyer L., Kolesnikov A., Weissenborn D., Zhai X., Unterthiner T., Dehghani M., Minderer M., Heigold G., Gelly S., Uszkoreit J., Houlsby N., An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, International Conference on Learning Representations, (2021); Athanasiadis I., Moschovis G., Tuoma A., Weakly-Supervised Semantic Segmentation via Transformer Explainability, ML Reproducibility Challenge 2021, (2022); Moschovis G., Fransen E., NeuralDynamicsLab at ImageCLEF Medical 2022, CLEF2022 Working Notes, CEUR Workshop Proceedings, (2022); Kougia V., Pavlopoulos J., Androutsopoulos I., AUEB NLP Group at ImageCLEFmed Caption 2019, Working Notes of CLEF 2019 - Conference and Labs of the Evaluation Forum, 2380, (2019); Karatzas B., Pavlopoulos J., Kougia V., Androutsopoulos I., AUEB NLP Group at ImageCLEFmed Caption 2020, Working Notes of CLEF 2020 - Conference and Labs of the Evaluation Forum, Thessaloniki, Greece, September 22-25, volume 2696 of CEUR Workshop Proceedings, (2020); Charalampakos F., Karatzas V., Kougia V., Pavlopoulos J., Androutsopoulos I., AUEB NLP Group at ImageCLEFmed Caption Tasks 2021, Proceedings of the Working Notes of CLEF 2021 - Conference and Labs of the Evaluation Forum, 2936, pp. 1184-1200, (2021); Charalampakos F., Zachariadis G., Pavlopoulos J., Karatzas V., Trakas C., Androutsopoulos I., AUEB NLP Group at ImageCLEFmedical Caption 2022, CLEF2022 Working Notes, CEUR Workshop Proceedings, pp. 1355-1373, (2022); Kaliosis P., Moschovis G., Charalampakos F., Pavlopoulos J., Androutsopoulos I., AUEB NLP Group at ImageCLEFmedical Caption 2023, CLEF2023 Working Notes, CEUR Workshop Proceedings, (2023); Bodenreider O., The Unified Medical Language System (UMLS): integrating biomedical terminology, Nucleic acids research, 32, pp. D267-D270, (2004); Ruckert J., Bloch L., Brungel R., Idrissi-Yaghir A., Schafer H., Schmidt C. S., Koitka S., Pelka O., Abacha A. B., de Herrera A. G. S., Muller H., Horn P. A., Nensa F., Friedrich C. M., ROCOv2: Radiology Objects in COntext Version 2, an Updated Multimodal Image Dataset, Scientific Data, (2024); Radenovic F., Tolias G., Chum O., Fine-Tuning CNN Image Retrieval with No Human Annotation, IEEE Transactions on Pattern Analysis and Machine Intelligence, 41, pp. 1655-1668, (2019); Kingma D. P., Ba J. L., Adam: A Method for Stochastic Optimization, 3rd International Conference on Learning Representations, ICLR 2015, (2015); Chiang T.-H., Lo H.-Y., Lin S.-D., A Ranking-based KNN Approach for Multi-Label Classification, Proceedings of the Asian Conference on Machine Learning, 25, pp. 81-96, (2012); Eiben A., Smith J. E., Introduction to Evolutionary Computing, (2015); Wei J., Bosma M., Zhao V., Guu K., Yu A. W., Lester B., Du N., Dai A. M., Le Q. V., Finetuned Language Models Are Zero-Shot Learners, International Conference on Learning Representations, (2021); Li J., Li D., Savarese S., Hoi S. C. H., BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models, International Conference on Machine Learning, (2023); Gao Y., Xiong Y., Gao X., Jia K., Pan J., Bi Y., Dai Y., Sun J., Wang M., Wang H., Retrieval-Augmented Generation for Large Language Models: A Survey, (2024); Lewis P., Perez E., Piktus A., Petroni F., Karpukhin V., Goyal N., Kuttler H., Lewis M., Yih W.-t., Rocktaschel T., Riedel S., Kiela D., Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Neural Information Processing Systems, (2020); Huang Y., Huang J., A Survey on Retrieval-Augmented Text Generation for Large Language Models, (2024); Raffel C., Shazeer N. M., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P. J., Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, Journal of machine learning research, 21, (2019); Kaliosis P., Exploring Uni-modal, Multi-modal and Few-Shot Deep Learning Methods for Diagnostic Captioning, (2023); Zhang T., Kishore V., Wu F., Weinberger K. Q., Artzi Y., BERTScore: Evaluating text generation with BERT, International Conference on Learning Representations, (2019); Lin C.-Y., ROUGE: A Package for Automatic Evaluation of Summaries, Text Summarization Branches Out, pp. 74-81, (2004); Papineni K., Roukos S., Ward T., Zhu W.-J., BLEU: a Method for Automatic Evaluation of Machine Translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Sellam T., Das D., Parikh A., BLEURT: Learning Robust Metrics for Text Generation, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7881-7892, (2020); Banerjee S., Lavie A., METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments, Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pp. 65-72, (2005); Ouyang L., Wu J., Jiang X., Almeida D., Wainwright C. L., Mishkin P., Zhang C., Agarwal S., Slama K., Ray A., Schulman J., Hilton J., Kelton F., Miller L. E., Simens M., Askell A., Welinder P., Christiano P., Leike J., Lowe R. J., Training language models to follow instructions with human feedback, Neural Information Processing Systems, (2022); Lewis P., Perez E., Piktus A., Petroni F., Karpukhin V., Goyal N., Kuttler H., Lewis M., Yih W.-t., Rocktaschel T., Riedel S., Kiela D., Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Advances in Neural Information Processing Systems, 33, pp. 9459-9474, (2020)","M. Samprovalaki; Department of Informatics, Athens University of Economics and Business, Athens, 76, Patission Street, GR-104 34, Greece; email: mar.samprovalaki@aueb.gr; A. Chatzipapadopoulou; Department of Informatics, Athens University of Economics and Business, Athens, 76, Patission Street, GR-104 34, Greece; email: annachatzipap@gmail.com; G. Moschovis; Department of Informatics, Athens University of Economics and Business, Athens, 76, Patission Street, GR-104 34, Greece; email: geomos@aueb.gr; P. Kaliosis; Department of Informatics, Athens University of Economics and Business, Athens, 76, Patission Street, GR-104 34, Greece; email: pkaliosis@aueb.gr","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS","","25th Working Notes of the Conference and Labs of the Evaluation Forum, CLEF 2024","9 September 2024 through 12 September 2024","Grenoble","201493","16130073","","","","English","CEUR Workshop Proc.","Conference paper","Final","","Scopus","2-s2.0-85201578472"
"Khouy M.; Jabrane Y.; Ameur M.; Hajjam El Hassani A.","Khouy, Mohammed (58627999800); Jabrane, Younes (22937642900); Ameur, Mustapha (57201741115); Hajjam El Hassani, Amir (26429325600)","58627999800; 22937642900; 57201741115; 26429325600","Medical Image Segmentation Using Automatic Optimized U-Net Architecture Based on Genetic Algorithm","2023","Journal of Personalized Medicine","13","9","1298","","","","3","10.3390/jpm13091298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172868048&doi=10.3390%2fjpm13091298&partnerID=40&md5=184c8c0c9e72dc997378cc1d81d92615","MSC Laboratory, Cadi Ayyad University, Marrakech, 40000, Morocco; Nanomedicine Imagery & Therapeutics Laboratory, EA4662—Bourgogne-Franche-Comté University, University of Technologie of Belfort Montbéliard, Belfort, CEDEX, 90010, France","Khouy M., MSC Laboratory, Cadi Ayyad University, Marrakech, 40000, Morocco; Jabrane Y., MSC Laboratory, Cadi Ayyad University, Marrakech, 40000, Morocco; Ameur M., MSC Laboratory, Cadi Ayyad University, Marrakech, 40000, Morocco; Hajjam El Hassani A., Nanomedicine Imagery & Therapeutics Laboratory, EA4662—Bourgogne-Franche-Comté University, University of Technologie of Belfort Montbéliard, Belfort, CEDEX, 90010, France","Image segmentation is a crucial aspect of clinical decision making in medicine, and as such, it has greatly enhanced the sustainability of medical care. Consequently, biomedical image segmentation has become a prominent research area in the field of computer vision. With the advent of deep learning, many manual design-based methods have been proposed and have shown promising results in achieving state-of-the-art performance in biomedical image segmentation. However, these methods often require significant expert knowledge and have an enormous number of parameters, necessitating substantial computational resources. Thus, this paper proposes a new approach called GA-UNet, which employs genetic algorithms to automatically design a U-shape convolution neural network with good performance while minimizing the complexity of its architecture-based parameters, thereby addressing the above challenges. The proposed GA-UNet is evaluated on three datasets: lung image segmentation, cell nuclei segmentation in microscope images (DSB 2018), and liver image segmentation. Interestingly, our experimental results demonstrate that the proposed method achieves competitive performance with a smaller architecture and fewer parameters than the original U-Net model. It achieves an accuracy of 98.78% for lung image segmentation, 95.96% for cell nuclei segmentation in microscope images (DSB 2018), and 98.58% for liver image segmentation by using merely 0.24%, 0.48%, and 0.67% of the number of parameters in the original U-Net architecture for the lung image segmentation dataset, the DSB 2018 dataset, and the liver image segmentation dataset, respectively. This reduction in complexity makes our proposed approach, GA-UNet, a more viable option for deployment in resource-limited environments or real-world implementations that demand more efficient and faster inference times. © 2023 by the authors.","convolutional neural networks (CNNs); genetic algorithms (GAs); medical image segmentation; U-Net","article; cell nucleus; convolutional neural network; genetic algorithm; image segmentation; liver; lung; microscope image; resource limited setting","","","","","","","Liu X., Song L., Liu S., Zhang Y., A Review of Deep-Learning-Based Medical Image Segmentation Methods, Sustainability, 13, (2021); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., Van Der Laak J.A., Van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Med. Image Anal, 42, pp. 60-88, (2017); Suri J.S., Farag A.A., Wang Y., Guo Q., Zhu Y., Medical image segmentation based on deformable models and its applications, Deformable Models: Theory and Biomaterial Applications, pp. 209-260, (2007); Ramesh N., Yoo J.H., Sethi I., Thresholding based on histogram approximation, IEE Proc. Vis. Image Signal Process, 142, pp. 271-279, (1995); Boykov Y.Y., Jolly M.P., Interactive graph cuts for optimal boundary & region segmentation of objects in ND images, Proceedings of the Eighth IEEE International Conference on Computer Vision (ICCV), 1, pp. 105-112, (2001); Sharma N., Ray A.K., Computer aided segmentation of medical images based on hybridized approach of edge and region based techniques, International Conference on Mathematical Biology, (2006); Greenspan H., Van Ginneken B., Summers R.M., Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique, IEEE Trans. Med. Imaging, 35, pp. 1153-1159, (2016); Lecun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc. IEEE, 86, pp. 2278-2324, (1998); Alom M.Z., Hasan M., Yakopcic C., Taha T.M., Asari V.K., Recurrent residual convolutional neural network based on u-net (r2u-net) for medical image segmentation, arXiv, (2018); Abedalla A., Abdullah M., Al-Ayyoub M., Benkhelifa E., Chest X-ray pneumothorax segmentation using U-Net with EfficientNet and ResNet architectures, PeerJ. Comput. Sci, 7, (2021); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Ronneberger O., Fischer P., Brox T., U-Net: Convolutional Networks for Biomedical Image Segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Zhou Z., Rahman Siddiquee M.M., Tajbakhsh N., Liang J., Unet++: A nested u-net architecture for medical image segmentation, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 3-11, (2018); Oktay O., Schlemper J., Folgoc L.L., Lee M., Heinrich M., Misawa K., Mori K., McDonagh S., Hammerla N.Y., Kainz B., Et al., Attention U-Net: Learning where to look for the pancreas, arXiv, (2018); Ibtehaz N., Rahman M.S., MultiResUNet: Rethinking the U-Net architecture for multimodal biomedical image segmentation, Neural Netw, 121, pp. 74-87, (2020); Siddique N., Paheding S., Elkin C.P., Devabhaktuni V., U-Net and its variants for medical image segmentation: A review of theory and applications, IEEE Access, 9, pp. 82031-82057, (2021); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Wei J., Zhu G., Fan Z., Liu J., Rong Y., Mo J., Li W., Chen X., Genetic U-Net: Automatically designed deep networks for retinal vessel segmentation using a genetic algorithm, IEEE Trans. Med. Imaging, 41, pp. 292-307, (2021); (2017); (2018); (2021); Alom M.Z., Yakopcic C., Taha T.M., Asari V.K., Nuclei Segmentation with Recurrent Residual Convolutional Neural Networks Based U-Net (R2U-Net), Proceedings of the NAECON 2018—IEEE National Aerospace and Electronics Conference, pp. 228-233, (2018); Lau S.L., Chong E.K., Yang X., Wang X., Automated pavement crack segmentation using u-net-based convolutional neural network, IEEE Access, 8, pp. 114892-114899, (2020); Azad R., Asadi-Aghbolaghi M., Fathy M., Escalera S., Bi-directional ConvLSTM U-Net with densley connected convolutions, Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops, pp. 406-415; Jalali Y., Fateh M., Rezvani M., Abolghasemi V., Anisi M.H., ResBCDU-Net: A deep learning framework for lung CT image segmentation, Sensors, 21, (2021); Arora R., Basu A., Mianjy P., Mukherjee A., Understanding deep neural networks with rectified linear units, arXiv, (2016); Milletari F., Navab N., Ahmadi S.A., V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation, Proceedings of the 2016 Fourth International Conference on 3D Vision (3DV), pp. 565-571, (2016); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation, Proceedings of the Medical Image Computing and Computer-Assisted Intervention–MICCAI 2016: 19th International Conference, Proceedings, Part II 19, pp. 424-432, (2016); Ozsahin I., Sekeroglu B., Musa M.S., Mustapha M.T., Ozsahin D.U., Review on diagnosis of COVID-19 from chest CT images using artificial intelligence, Comput. Math. Methods Med, 2020, (2020); Parcham E., Fateh M., HybridBranchNet: A novel structure for branch hybrid convolutional neural networks architecture, Neural Netw, 165, pp. 77-93, (2023); Fateh A., Fateh M., Abolghasemi V., Multilingual handwritten numeral recognition using a robust deep network joint with transfer learning, Inf. Sci, 581, pp. 479-494, (2021); Holland J.H., Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence, (1992); Ameur M., Habba M., Jabrane Y., A comparative study of nature inspired optimization algorithms on multilevel thresholding image segmentation, Multimed. Tools Appl, 78, pp. 34353-34372, (2019); Liu P., El Basha M.D., Li Y., Xiao Y., Sanelli P.C., Fang R., Deep evolutionary networks with expedited genetic algorithms for medical image denoising, Med. Image Anal, 54, pp. 306-315, (2019); Nagarajan G., Minu R., Muthukumar B., Vedanarayanan V., Sundarsingh S., Hybrid genetic algorithm for medical image feature extraction and selection, Procedia Comput. Sci, 85, pp. 455-462, (2016); Mohamed Ben Ali Y., Edge-based segmentation using robust evolutionary algorithm applied to medical images, J. Signal. Process. Syst, 54, pp. 231-238, (2009); Sun Y., Xue B., Zhang M., Yen G.G., Lv J., Automatically designing CNN architectures using the genetic algorithm for image classification, IEEE Trans. Cybern, 50, pp. 3840-3854, (2020); Clevert D.A., Unterthiner T., Hochreiter S., Fast and accurate deep network learning by exponential linear units (elus), arXiv, (2015); Maas A.L., Hannun A.Y., Ng A.Y., Rectifier nonlinearities improve neural network acoustic models, Proceedings of the ICML Workshop on Deep Learning for Audio, Speech and Language Processing; Duchi J., Hazan E., Singer Y., Adaptive Subgradient Methods for Online Learning and Stochastic Optimization, J. Mach. Learn. Res, 12, pp. 2121-2159, (2011); Kingma D.P., Ba J., Adam: A method for stochastic optimization, arXiv, (2014); Jadon S., A Survey of Loss Functions for Semantic Segmentation, Proceedings of the 2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB), pp. 1-7, (2020); Dice L.R., Measures of the amount of ecologic association between species, Ecology, 26, pp. 297-302, (1945); Jaccard P., The distribution of the flora in the alpine zone, New Phytol, 11, pp. 37-50, (1912)","A. Hajjam El Hassani; Nanomedicine Imagery & Therapeutics Laboratory, EA4662—Bourgogne-Franche-Comté University, University of Technologie of Belfort Montbéliard, Belfort, CEDEX, 90010, France; email: amir.hajjam-el-hassani@utbm.fr","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","20754426","","","","English","J. Pers. Med.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85172868048"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Communications in Computer and Information Science","1963 CCIS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178637916&partnerID=40&md5=586fffd2441e9387dc354a41897227bc","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","18650929","978-981998137-3","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85178637916"
"Aydın M.; Kiraz B.; Eren F.; Uysalh Y.; Morova B.; Can Ozcan S.; Acilan C.; Kiraz A.","Aydın, Musa (56369220000); Kiraz, Berna (36959472600); Eren, Furkan (57226398182); Uysalh, Yiğit (57460004300); Morova, Berna (57195804504); Can Ozcan, Selahattin (57460004400); Acilan, Ceyda (16240700600); Kiraz, Alper (58903933900)","56369220000; 36959472600; 57226398182; 57460004300; 57195804504; 57460004400; 16240700600; 58903933900","A Deep Learning Model for Automated Segmentation of Fluorescence Cell images","2022","Journal of Physics: Conference Series","2191","1","012003","","","","5","10.1088/1742-6596/2191/1/012003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124988437&doi=10.1088%2f1742-6596%2f2191%2f1%2f012003&partnerID=40&md5=964ead13f966850d6125924ff08691aa","Department of Computer Engineering, Fatih Sultan Mehmet Vakif University, Istanbul, Turkey; Optofl Inc., Istanbul, Turkey; Department of Physics, Koc University, Istanbul, Turkey; Koc University Research Center for Translational Medicine (KUTTAM), Istanbul, 34450, Turkey; School of Medicine, Koc University, Istanbul, 34450, Turkey; Department of Electrical and Electronics Engineering, Koc University, Istanbul, Turkey","Aydın M., Department of Computer Engineering, Fatih Sultan Mehmet Vakif University, Istanbul, Turkey; Kiraz B., Department of Computer Engineering, Fatih Sultan Mehmet Vakif University, Istanbul, Turkey, Optofl Inc., Istanbul, Turkey; Eren F., Optofl Inc., Istanbul, Turkey; Uysalh Y., Optofl Inc., Istanbul, Turkey, Department of Physics, Koc University, Istanbul, Turkey; Morova B., Department of Physics, Koc University, Istanbul, Turkey; Can Ozcan S., Koc University Research Center for Translational Medicine (KUTTAM), Istanbul, 34450, Turkey; Acilan C., Koc University Research Center for Translational Medicine (KUTTAM), Istanbul, 34450, Turkey, School of Medicine, Koc University, Istanbul, 34450, Turkey; Kiraz A., Optofl Inc., Istanbul, Turkey, Department of Physics, Koc University, Istanbul, Turkey, Koc University Research Center for Translational Medicine (KUTTAM), Istanbul, 34450, Turkey, Department of Electrical and Electronics Engineering, Koc University, Istanbul, Turkey","Deep learning techniques bring together key advantages in biomedical image segmentation. They speed up the process, increase the reproducibility, and reduce the workload in segmentation and classifcation. Deep learning techniques can be used for analysing cell concentration, cell viability, as well as the size and form of each cell. In this study, we develop a deep learning model for automated segmentation of fuorescence cell images, and apply it to fuorescence images recorded with a home-built epi-fuorescence microscope. A deep neural network model based on U-Net architecture was built using a publicly available dataset of cell nuclei images [1]. A model accuracy of 97.3% was reached at the end of model training. Fluorescence cell images acquired with our home-built microscope were then segmented using the developed model. 141 of 151 cells in 5 images were successfully segmented, revealing a segmentation success rate of 93.4%. This deep learning model can be extended to the analysis of diferent cell types and cell viability.  © 2021 Published under licence by IOP Publishing Ltd.","","Cells; Cytology; Deep neural networks; Fluorescence; Image segmentation; Automated segmentation; Biomedical image segmentation; Cell images; Cell viability; Fluorescence cell; Home-built; Learning models; Learning techniques; Reproducibilities; Speed up; Learning algorithms","","","","","KOSGEB; TÜBA; TÜBİTAK, (7190434); Türkiye Bilimler Akademisi","We acknowledge financial supports from TÜBİTAK (Project No: 7190434) and KOSGEB. A. Kiraz acknowledges partial support from the Turkish Academy of Sciences (TÜBA).","Cell nuclei data set; Hollandi R., Szkalisity A., Toth T., Tasnadi E., Molnar C., Mathe B., Grexa I., Molnar J., Balind A., Gorbe M., Et al., nucleaizer: A parameter-free deep learning framework for nucleus segmentation using image style transfer, Cell Systems, 10, 5, pp. 453-458, (2020); Habibzadeh M., Jannesari M., Rezaei Z., Baharvand H., Totonchi M., Automatic white blood cell classifcation using pre-trained deep learning models: Resnet and inception Tenth international conference on machine vision (ICMV 2017) 10696 International Society for Optics and Photonics, (2018); Delgado-Ortet M., Molina A., Alferez S., Rodellar J., Merino A., A deep learning approach for segmentation of red blood cell images and malaria detection, Entropy, 22, 6, (2020); Mookiah M. R. K., Hogg S., MacGillivray T. J., Prathiba V., Pradeepa R., Mohan V., Anjana R. M., Doney A. S., Palmer C. N., Trucco E., A review of machine learning methods for retinal blood vessel segmentation and artery/vein classifcation Medical Image Analysis, (2020); Havaei M., Davy A., Warde-Farley D., Biard A., Courville A., Bengio Y., Pal C., Jodoin P.-M., Larochelle H., Brain tumor segmentation with deep neural networks, Medical image analysis, 35, 18 31, (2017); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation International Conference on Medical image computing and computer-assisted intervention, 234, (2015); Livne M., Rieger J., Aydin O. U., Taha A. A., Akay E. M., Kossen T., Sobesky J., Kelleher J. D., Hildebrand K., Frey D., Et al., A u-net deep learning framework for high performance vessel segmentation in patients with cerebrovascular disease, Frontiers in neuroscience, 13, (2019); Ehsani S. P., Mousavi H. S., Khalaj B. H., Iterative histogram matching algorithm for chromosome image enhancement based on statistical moments 2012, 9th IEEE International Symposium on Biomedical Imaging (ISBI) IEEE, 214, (2012); Liu Z., Retinal vessel segmentation based on fully convolutional networks, (2019)","","","IOP Publishing Ltd","","A Life in Mathematical Physics: Conference in Honour of Tekin Dereli, DERELI-FS 2021","26 November 2021 through 28 November 2021","Virtual, Online","177155","17426588","","","","English","J. Phys. Conf. Ser.","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85124988437"
"Navaneethakrishnan M.; Anand M.V.; Vasavi G.; Rani V.V.","Navaneethakrishnan, M. (57219354649); Anand, M. Vijay (57751198900); Vasavi, G. (57201994187); Rani, V. Vasudha (57209498941)","57219354649; 57751198900; 57201994187; 57209498941","Deep Fuzzy SegNet-based lung nodule segmentation and optimized deep learning for lung cancer detection","2023","Pattern Analysis and Applications","26","3","","1143","1159","16","8","10.1007/s10044-023-01135-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148643156&doi=10.1007%2fs10044-023-01135-1&partnerID=40&md5=3ae0ca1d2b5223f2110b7e7edbc2668f","Department of Computer Science and Engineering, St. Joseph College of Engineering, Chennai, India; Department of Computer Science and Engineering, Saveetha Engineering College, Chennai, India; Department of Computer Science and Engineering, BV Raju Institute of Technology, Telangana, Narsapur, India; Department of Computer Science and Engineering, GMR Institute of Technology, AndhraPradesh, Rajam, India","Navaneethakrishnan M., Department of Computer Science and Engineering, St. Joseph College of Engineering, Chennai, India; Anand M.V., Department of Computer Science and Engineering, Saveetha Engineering College, Chennai, India; Vasavi G., Department of Computer Science and Engineering, BV Raju Institute of Technology, Telangana, Narsapur, India; Rani V.V., Department of Computer Science and Engineering, GMR Institute of Technology, AndhraPradesh, Rajam, India","Globally, lung cancer has a high fatality rate and is a lethal disease. Since lung cancer affects both men and women, it requires extra consideration when evaluating various diseases. Furthermore, early detection is even more important in order to increase the survival percentage of affected patients. There are many methods for detecting lung cancer, but it can be difficult to locate the affected area due to low visibility of the tumor section and imaging failure rates. Due to poor image quality, which distorts the segmentation process, the standard strategies failed to increase the accuracy rate. In order to diagnose lung cancer disease, this research created an approach known as Bat Deer Hunting Optimization Algorithm-based Deep Convolutional Neural Network (BDHOA-based DCNN). Here, Computed Tomography pictures are used to predict the presence of lung cancer. The Bat Algorithm (BA) and Deer Hunting Optimization Algorithm have been integrated into the newly developed BDHOA algorithm (DHOA). To execute the lung cancer detection and classification, the lung lobe and nodule region is segmented from the lung picture. With accuracy, sensitivity, and specificity scores of 0.9243, 0.9421, and 0.8915, the suggested approach performed better. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Biomedical image processing; DEEP fuzzy clustering; Deep learning; DEER hunting optimization algorithm; Lung cancer; Lung nodule segmentation","","","","","","","","Saba T., Sameh A., Khan F., Shad S.A., Sharif M., Lung nodule detection based on ensemble of hand crafted and deep features, J Med Syst, 43, 12, pp. 1-12, (2019); Maqbali B.A., Hybrid wolf pack algorithm and particle swarm optimization algorithm for breast cancer diagnosis, Multimed Res, 4, 3, pp. 9-16, (2021); Khan R., Artificial bee colony-based general adversarial network for liver cancer detection using CT images, Multimed Res, 3, 4, pp. 1-11, (2020); Doll R., Hill A.B., Smoking and carcinoma of the lung, Br Med J, 2, 4682, (1950); Naik A., Edla D.R., Lung nodule classification on computed tomography images using deep learning, Wireless Pers Commun, 116, 1, pp. 655-690, (2021); Guadagni S., Fiorentini G., De Simone M., Masedu F., Zoras O., Mackay A.R., Sarti D., Papasotiriou I., Apostolou P., Catarci M., Clementi M., Ricevuto E., Bruera G., Precision oncotherapy based on liquid biopsies in multidisciplinary treatment of unresectable recurrent rectal cancer: a retrospective cohort study, J Cancer Res Clin Oncol, 146, 1, pp. 205-219, (2016); Catarci M., Berlanda M., Grassi G.B., Masedu F., Guadagni S., Pancreatic enzyme supplementation after gastrectomy for gastric cancer: a randomized controlled trial, Gastric Cancer, 21, 3, pp. 542-551, (2018); Gopal A., Hybrid classifier: brain tumor classification and segmentation using genetic-based grey wolf optimization, Multimed Res, 3, 2, pp. 1-10, (2020); Fernandis J.R., ALOA: ant lion optimization algorithm-based deep learning for breast cancer classification, Multimed Res, 4, 1, pp. 32-43, (2021); Messay T., Hardie R.C., Rogers S.K., A new computationally efficient CAD system for pulmonary nodule detection in CT imagery, Med Image Anal, 14, 3, pp. 390-406, (2010); Bajaj S., Predictive models for various diseases including corona virus disease (covid-19) using different machine learning algorithms, IJEAMA, 131, I, (2021); Gu Y., Lu X., Zhang B., Zhao Y., Yu D., Gao L., Cui G., Wu L., Zhou T., Automatic lung nodule detection using multi-scale dot nodule-enhancement filter and weighted support vector machines in chest computed tomography, PLoS ONE, 14, 1, (2019); Li Q., Recent progress in computer-aided diagnosis of lung nodules on thin-section CT, Comput Med Imaging Graph, 31, 4-5, pp. 248-257, (2007); Dai S., Lu K., Dong J., Zhang Y., Chen Y., A novel approach of lung segmentation on chest CT images using graph cuts, Neurocomputing, 168, pp. 799-807, (2015); Rajan Baby Y., Ramayyan Sumathy V.K., Kernel-based Bayesian clustering of computed tomography images for lung nodule segmentation, IET Image Proc, 14, 5, pp. 890-900, (2020); Suji R.J., Bhadouria S.S., Dhar J., Godfrey W.W., Optical flow methods for lung nodule segmentation on LIDC-IDRI images, J Digit Imaging, 33, 5, pp. 1306-1324, (2020); Bajaj S., Artificial intelligence for disease prediction and monitoring using association rule mining for major disease like corona-virus in India, Int J Adv Res Sci Eng, 10, 3, (2021); Muthazhagan B., Ravi T., Rajinigirinath D., An enhanced computer-assisted lung cancer detection method using content based image retrieval and data mining techniques, J Ambient Intell Humaniz Comput, (2020); Gokulkumari G., Classification of brain tumor using manta ray foraging optimization-based DeepCNN classifier, Multimed Res, 3, 4, pp. 32-42, (2020); Ganeshan R., Skin cancer detection with optimized neural network via hybrid algorithm, Multimedia Research, 3, 2, pp. 27-34, (2020); Akter O., Moni M.A., Islam M.M., Julian M.W., Quinn A.H.M., Kamal, Lung cancer detection using enhanced segmentation accuracy, Appl Intell, 51, 6, pp. 3391-3404, (2020); Zhang J., Xia Y., Cui H., Zhang Y., Pulmonary nodule detection in medical images: a survey, Biomed Signal Process Control, 43, pp. 138-147, (2018); Veronica B.K., An effective neural network model for lung nodule detection in CT images with optimal fuzzy model, Multimedia Tools and Applications, pp. 1-21, (2020); Milletari F., Ahmadi S.A., Kroll C., Plate A., Rozanski V., Maiostre J., Levin J., Dietrich O., Ertl-Wagner B., Botzel K., Navab N., Hough-CNN: deep learning for segmentation of deep brain regions in MRI and ultrasound, Comput Vis Image Underst, 164, pp. 92-102, (2017); Wang S., Zhou M., Liu Z., Liu Z., Gu D., Zang Y., Dong D., Gevaert O., Tian J., Central focused convolutional neural networks: developing a data-driven model for lung nodule segmentation, Med Image Anal, 40, pp. 172-183, (2017); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, (2015); Ronneberger O., Fischer P., Brox T., (2015) U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, Cham, Pp, pp. 234-241, (2015); Hesamian M.H., Jia W., He X., Kennedy P.J., Atrous convolution for binary semantic segmentation of lung nodule”, ICASSP IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1015-1019, (2019); Jadhav J.N., Arunkumar B., Web page recommendation system using laplace correction dependent probability and chronological dragonfly-based clustering, Int J Eng Technol, 7, 3, pp. 290-302, (2018); Pedawi S., Alzubi A., Effects of E-government policy on the management of healthcare systems, Appl Bion Biomech, 2022, pp. 1-9, (2022); Astaraki M., Toma-Dasu I., Smedby O., Wang C., Normal appearance autoencoder for lung cancer detection and segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, Springer, Cham, pp. 249-256, (2019); Ozdemir O., Russell R.L., Berlin A.A., A 3D probabilistic deep learning system for detection and diagnosis of lung cancer using low-dose CT scans, IEEE Trans Med Imaging, 39, 5, pp. 1419-1429, (2019); Kavitha M.S., Shanthini J., Karthikeyan N., Volumetric analysis framework for accurate segmentation and classification (VAF-ASC) of lung tumor from CT images, Soft Comput, 24, pp. 18489-18497, (2020); Tu F., Yin S., Ouyang P., Tang S., Liu L., Wei S., Deep convolutional neural network architecture with reconfigurable computation patterns, IEEE Trans Very Larg Scale Integr Syst, 25, 8, pp. 2220-2233, (2017); Yang X.-S., A new metaheuristic bat-inspired algorithm, Nature inspired cooperative strategies for optimization (NICSO 2010), pp. 65-74, (2010); Brammya G., Praveena S., Ninu Preetha N.S., Ramya R., Rajakumar B.R., Binu D., Deer hunting optimization algorithm: a new nature-inspired meta-heuristic paradigm, Comput J, (2019); Almotairi S., Kareem G., Aouf M., Almutairi B., Salem M.A.M., Liver tumor segmentation in CT scans using modified segnet, Sensors, 20, 5, (2020); Yeganejou M., Dick S., Improved deep fuzzy clustering for accurate and interpretable classifiers, 2019 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE), pp. 1-7, (2019); Zhong Z., Zheng L., Kang G., Li S., Yang Y., Random erasing data augmentation, Proceedings of the AAAI conference on artificial intelligence, 34, 7, pp. 13001-13008, (2020); (2021)","M. Navaneethakrishnan; Department of Computer Science and Engineering, St. Joseph College of Engineering, Chennai, India; email: mnksjce@gmail.com","","Springer Science and Business Media Deutschland GmbH","","","","","","14337541","","","","English","Pattern Anal. Appl.","Article","Final","","Scopus","2-s2.0-85148643156"
"Nanammal V.S.R.; Jayagopalan V.G.","Nanammal, Venkata Samy Raja (56586269000); Jayagopalan, Venu Gopalakrishnan (57696453800)","56586269000; 57696453800","A secured biomedical image processing scheme to detect pneumonia disease using dynamic learning principles","2022","Concurrent Engineering Research and Applications","30","3","","245","252","7","1","10.1177/1063293X221097447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130227794&doi=10.1177%2f1063293X221097447&partnerID=40&md5=431ba77a0b124ad8739c7d03a27c28e4","Department of ECE, Sathyabama Institute of Science and Technology, TN, Chennai, India; Department of ECE, Madha Engineering College, TN, Chennai, India","Nanammal V.S.R., Department of ECE, Sathyabama Institute of Science and Technology, TN, Chennai, India; Jayagopalan V.G., Department of ECE, Madha Engineering College, TN, Chennai, India","Now-a-days, the medical industry is growing a lot with the adaptation of latest technologies as well as the logical evaluation and security norms provides a robust platform to enhance the effectiveness of the industry at a drastic level. In this paper, a digital bio-medical image processing based Pneumonia disease identification system is introduced with enhanced security features. Due to improving the efficiency of the application, a well-known watermarking based security constraint is included to provide the protection to the respective hospital environment and patients as well. To avoid these issues, some sort of security aspects need to be followed so that this paper included watermarking based security to provide a rich level of protection to the images going to be tested. The main intention of this paper is to introduce a novel security enabled digital image processing scheme to identify the Pneumonic disease in earlier stages with respect to the proper classification principles. In this paper, a novel deep learning algorithm is introduced called enhanced Dynamic Learning Neural Network in which it is a hybrid algorithm with the combinations of conventional DLNN algorithm and the Support Vector Classification algorithm. This proposed approach effectively identifies the Pneumonia disease in earlier stages but the security inspection on the testing stage is so important to analyze the disease. The respective testing image is properly watermarked with the logo of the corresponding hospital; the image is processed otherwise the proposed approach skips the image to process. These kinds of security features emphasize the medical industry and boost up the levels more as well as the patients can get an appropriate error free care with the help of such technology. A proper Chest X-Ray based Kaggle dataset is considered to process the system as well as which contains 5856 Chest X-Ray images under two different categories such as Pneumonia and Normal. With respect to processing these images and identifying the Pneumonia disease effectively as well as the proposed watermarking enabled security features provide a good impact in the medical field protection system. The resulting section provides the proper proof to the effectiveness of the proposed approach and its prediction efficiency. © The Author(s) 2022.","deep learning; enhanced dynamic learning neural network; pneumonia; security; support vector classification; watermarking","Deep learning; Efficiency; Hospitals; Image classification; Image watermarking; Learning algorithms; Learning systems; Medical imaging; Network security; Security systems; Support vector machines; Watermarking; Deep learning; Dynamic learning; Enhanced dynamic learning neural network; Latest technology; Learning neural networks; Medical industries; Pneumonia; Security; Security features; Support vector classification; Image enhancement","","","","","","","Bhatti U.A., Yu Z., Li J., Et al., Hybrid watermarking algorithm using clifford algebra with arnold scrambling and chaotic encryption, IEEE Access, 8, pp. 76386-76389, (2020); Bushra Abdulla N.T., Navas K.A., High security watermarking techniques for digital rights management: A review, pp. 162-166, (2020); Cao X., Zhou Y., Guo J.-M., Guest editorial introduction to special section on modern reversible data hiding and watermarking, IEEE Transactions on Circuits and Systems for Video Technology, 30, 8, pp. 2297-2299, (2020); Ernawan F., Ariatmanto D., Musa Z., Et al., An improved robust watermarking scheme using flexible scaling factor, pp. 266-269, (2020); Kamili A., Hurrah N.N., Parah S.A., Et al., DWFCAT: Dual watermarking framework for industrial image authentication and tamper localization, IEEE Transactions on Industrial Informatics, 17, 7, pp. 5108-5117, (2021); Nunez-Ramirez D., Cedillo-Hernandez M., Nakano-Miyatake M., Et al., Efficient management of ultrasound images using digital watermarking, IEEE Latin America Transactions, 18, 8, pp. 1398-1406, (2020); Ramkumar G., Manikandan M., Uncompressed digital video watermarking using stationary wavelet transform, pp. 1252-1258, (2014); Ramkumar G., Parkavi P., Ramya K., Et al., A survey on sar images using image processing techniques, pp. 1097-1100, (2020); Ramkumar G., Anitha G., Suresh Kumar M., Et al., An effectual underwater image enhancement using deep learning algorithm, pp. 1507-1511, (2021); Ren N., Zhu C., Tong D., Et al., Commutative encryption and watermarking algorithm based on feature invariants for secure vector map, IEEE Access, 8, pp. 221481-221493, (2020); Rosiyadi D., Heri P., Horng S.J., Et al., Security attack on secret sharing based watermarking using fractional fourier transform and singular value decomposition, (2020); Vybornova Y., Method for Image Copyright Protection Based on Construction of Highly Robust Watermarks, pp. 1-4, (2020)","","","SAGE Publications Ltd","","","","","","1063293X","","CRAPE","","English","Concurrent Eng Res Appl","Article","Final","","Scopus","2-s2.0-85130227794"
"Çiğ H.; Güllüoğlu M.T.; Er M.B.; Kuran U.; Kuran E.C.","Çiğ, Harun (57200138132); Güllüoğlu, Mehmet Tahir (6603160891); Er, Mehmet Bilal (57200138180); Kuran, Umut (57200140755); Kuran, Emre Can (57226394399)","57200138132; 6603160891; 57200138180; 57200140755; 57226394399","Enhanced Disease Detection Using Contrast Limited Adaptive Histogram Equalization and Multi-Objective Cuckoo Search in Deep Learning","2023","Traitement du Signal","40","3","","915","925","10","4","10.18280/ts.400308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166331049&doi=10.18280%2fts.400308&partnerID=40&md5=b8b773a898167f7271dcea6056e57f92","Department of Computer Engineering, Harran University, Şanlıurfa, 63050, Turkey; Department of Electrical and Electronics Engineering, Harran University, Şanlıurfa, 63050, Turkey; Department of Software Engineering, Bandirma University, Bandırma, 10250, Turkey","Çiğ H., Department of Computer Engineering, Harran University, Şanlıurfa, 63050, Turkey; Güllüoğlu M.T., Department of Electrical and Electronics Engineering, Harran University, Şanlıurfa, 63050, Turkey; Er M.B., Department of Computer Engineering, Harran University, Şanlıurfa, 63050, Turkey; Kuran U., Department of Computer Engineering, Harran University, Şanlıurfa, 63050, Turkey; Kuran E.C., Department of Software Engineering, Bandirma University, Bandırma, 10250, Turkey","Delayed diagnosis of numerous diseases often results in postponed treatment, adversely affecting patient outcomes. By analyzing biological signals and patient photographs, critical information about an individual's health or the severity of a medical condition can be obtained for various diseases. Signals from Electroencephalography (EEG), Electrocardiography (ECG), and Electrooculography (EOG) can be used to predict and diagnose disorders related to the brain, heart, eyes, muscles, and nervous system. Additionally, biomedical images acquired through X-ray, ultrasound, and magnetic resonance imaging can be utilized for disease diagnosis and detection with the help of image processing techniques, artificial intelligence, and deep learning methods. In this study, we propose a novel approach that combines the Contrast Limited Adaptive Histogram Equalization (CLAHE) algorithm and Multi-Objective Cuckoo Search (MOCS) with Convolutional neural networks (CNNs) to achieve highly accurate disease classification using chest X-ray images. Our method begins by applying a contrast enhancement strategy, specifically, the CLAHE algorithm, with MOCS for optimal parameter selection to attain the highest classification performance. Subsequently, contrast-enhanced images are fed into the CNNs to further improve image quality and classification accuracy. Our approach is employed to categorize three types of chest X-ray images, namely, unhealthy, normal (healthy), and pneumonia. To assess the performance of our proposed method, we utilize the widely-used ""COVID-19 Radiography"" dataset. Experimental results yield an accuracy rate of 99.16%, a precision rate of 99.20%, and a sensitivity rate of 98.99%. These findings demonstrate that our proposed model outperforms existing techniques in the literature and can be effectively employed for disease detection and classification. © 2023 Lavoisier. All rights reserved.","Convolutional neural network (CNN); hybrid CNN; multi-objective cuckoo search algorithm optimization (MOCS)","Biomedical signal processing; Convolution; Convolutional neural networks; Deep learning; Electrocardiography; Electrophysiology; Equalizers; Graphic methods; Image enhancement; Learning algorithms; Learning systems; Medical imaging; Multiobjective optimization; Patient treatment; Adaptive histograms; Algorithms optimizations; Convolutional neural network; Cuckoo search algorithms; Disease detection; Hybrid convolutional neural network; Multi objective; Multi-objective cuckoo search algorithm optimization; Electroencephalography","","","","","","","Pathak Y., Shukla P.K., Tiwari A., Stalin S., Singh S., Deep transfer learning based classification model for COVID-19 disease, IRBM, 43, 2, pp. 87-92, (2022); Ahmed H.M., Abdullah B.W., Overview of deep learning models for identification Covid-19, Materials Today. Proceedings, (2021); Wu X., Chen C., Zhong M., Wang J., Shi J., COVID-AL: The diagnosis of COVID-19 with deep active learning, Medical Image Analysis, 68, (2021); Alakus T.B., Turkoglu I., Comparison of deep learning approaches to predict COVID-19 infection, Chaos, Solitons & Fractals, 140, (2020); Zhou T., Lu H., Yang Z., Qiu S., Huo B., Dong Y., The ensemble deep learning model for novel COVID-19 on CT images, Applied Soft Computing, 98, (2021); Ding X., Xu J., Zhou J., Long Q., Chest CT findings of COVID-19 pneumonia by duration of symptoms, European Journal of Radiology, 127, (2020); Bhattacharya S., Maddikunta P.K.R., Pham Q.V., Gadekallu T.R., Chowdhary C.L., Alazab M., Piran M.J., Deep learning and medical image processing for coronavirus (COVID-19) pandemic: A survey, Sustainable Cities and Society, 65, (2021); Panwar H., Gupta P.K., Siddiqui M.K., Morales-Menendez R., Bhardwaj P., Singh V., A deep learning and grad-CAM based color visualization approach for fast detection of COVID-19 cases using chest X-ray and CT-Scan images, Chaos, Solitons & Fractals, 140, (2020); Brogna B., Bignardi E., Brogna C., Alberigo M., Grappone M., Megliola A., Salvatore P., Fontanella G., Mazza E.M., Musto L., Typical CT findings of COVID-19 pneumonia in patients presenting with repetitive negative RT-PCR, Radiography, 27, 2, pp. 743-747, (2021); Islam M.Z., Islam M.M., Asraf A., A combined deep CNN-LSTM network for the detection of novel coronavirus (COVID-19) using X-ray images, Informatics in Medicine Unlocked, 20, (2020); Pan Y., Li X., Yang G., Fan J., Tang Y., Zhao J., Long X., Guo S., Zhao Z., Liu Y., Hu H., Xue H., Li Y., Serological immunochromatographic approach in diagnosis with SARS-CoV-2 infected COVID-19 patients, Journal of Infection, 81, 1, pp. e28-e32, (2020); Wang S., Kang B., Ma J., Zeng X., Xiao M., Guo J., Cai M., Yang J., Li Y., Meng X., Xu B., A deep learning algorithm using CT images to screen for corona virus disease (COVID-19), European Radiology, 31, pp. 6096-6104, (2021); Hertel R., Benlamri R., COV-SNET: A deep learning model for X-ray-based COVID-19 classification, Informatics in Medicine Unlocked, 24, (2021); Qin C., Yao D., Shi Y., Song Z., Computer-aided detection in chest radiography based on artificial intelligence: A survey, Biomedical Engineering Online, 17, 1, pp. 1-23, (2018); Jalali S.M.J., Ahmadian M., Ahmadian S., Khosravi A., Alazab M., Nahavandi S., An oppositional-Cauchy based GSK evolutionary algorithm with a novel deep ensemble reinforcement learning strategy for COVID-19 diagnosis, Applied Soft Computing, 111, (2021); Kuran U., Kuran E.C., Parameter selection for CLAHE using multi-objective cuckoo search algorithm for image contrast enhancement, Intelligent Systems with Applications, 12, (2021); Narin A., Kaya C., Pamuk Z., Automatic detection of coronavirus disease (covid-19) using x-ray images and deep convolutional neural networks, Pattern Analysis and Applications, 24, pp. 1207-1220, (2021); Apostolopoulos I.D., Mpesiana T.A., Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks, Physical and Engineering Sciences in Medicine, 43, pp. 635-640, (2020); Minaee S., Kafieh R., Sonka M., Yazdani S., Soufi G.J., Deep-COVID: Predicting COVID-19 from chest X-ray images using deep transfer learning, Medical Image Analysis, 65, (2020); Kumar S., Mishra S., Singh S.K., Deep transfer learning-based COVID-19 prediction using chest X-rays, Journal of Health Management, 23, 4, pp. 730-746, (2021); Ai T., Yang Z., Hou H., Zhan C., Chen C., Lv W., Tao Q., Sun Z., Xia L., Correlation of chest CT and RT-PCR testing for coronavirus disease 2019 (COVID-19) in China: A report of 1014 cases, Radiology, 296, 2, pp. E32-E40, (2020); Chung M., Bernheim A., Mei X., Zhang N., Huang M., Zeng X., Cui J., Xu W., Yang Y., Fayad Z.A., Jacobi A., Li K., Li S., Shan H., CT imaging features of 2019 novel coronavirus (2019-nCoV), Radiology, 295, 1, pp. 202-207, (2020); Khan A.I., Shah J.L., Bhat M.M., CoroNet: A deep neural network for detection and diagnosis of COVID-19 from chest x-ray images, Computer Methods and Programs in Biomedicine, 196, (2020); Ismael A.M., Sengur A., Deep learning approaches for COVID-19 detection based on chest X-ray images, Expert Systems with Applications, 164, (2021); Ardakani A.A., Kanafi A.R., Acharya U.R., Khadem N., Mohammadi A., Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: Results of 10 convolutional neural networks, Computers in Biology and Medicine, 121, (2020); Oh Y., Park S., Ye J.C., Deep learning COVID-19 features on CXR using limited training data sets, IEEE Transactions on Medical Imaging, 39, 8, pp. 2688-2700, (2020); Li J., Wang Y., Wang S., Wang J., Liu J., Jin Q., Sun L., Multiscale attention guided network for COVID-19 diagnosis using chest X-ray images, IEEE Journal of Biomedical and Health Informatics, 25, 5, pp. 1336-1346, (2021); Dilshad S., Singh N., Atif M., Hanif A., Yaqub N., Farooq W.A., Ahmad H., Chu Y.M., Masood M.T., Automated image classification of chest X-rays of COVID-19 using deep transfer learning, Results in Physics, 28, (2021); Yoo S.H., Geng H., Chiu T.L., Yu S.K., Cho D.C., Heo J., Choi M.S., Choi I.H., Van C.C., Nhung N.V., Min B.J., Lee H., Deep learning-based decision-tree classifier for COVID-19 diagnosis from chest X-ray imaging, Frontiers in Medicine, 7, (2020); Aminu M., Ahmad N.A., Noor M.H.M., Covid-19 detection via deep neural network and occlusion sensitivity maps, Alexandria Engineering Journal, 60, 5, pp. 4829-4855, (2021); Ohata E.F., Bezerra G.M., das Chagas J.V.S., Neto A.V.L., Albuquerque A.B., De Albuquerque V.H.C., Reboucas Filho P.P., Automatic detection of COVID-19 infection using chest X-ray images through transfer learning, IEEE/CAA Journal of Automatica Sinica, 8, 1, pp. 239-248, (2020); Haksoro E.I., Setiawan A., Pengenalan jamur yang dapat dikonsumsi menggunakan metode transfer learning pada convolutional neural network, Jurnal Eltikom: Jurnal Teknik Elektro, Teknologi Informasi dan Komputer, 5, 2, pp. 81-91, (2021); Acharya U.K., Kumar S., Genetic algorithm based adaptive histogram equalization (GAAHE) technique for medical image enhancement, Optik, 230, (2021); Oloyede M.O., Onumanyi A.J., Bello-Salau H., Djouani K., Kurien A., Exploratory analysis of different metaheuristic optimization methods for medical image enhancement, IEEE Access, 10, pp. 28014-28036, (2022); Ghosh S.K., Ghosh A., ENResNet: A novel residual neural network for chest X-ray enhancement based COVID-19 detection, Biomedical Signal Processing and Control, 72, (2022); Siracusano G., La Corte A., Gaeta M., Cicero G., Chiappini M., Finocchio G., Pipeline for advanced contrast enhancement (PACE) of chest x-ray in evaluating COVID-19 patients by combining bidimensional empirical mode decomposition and contrast limited adaptive histogram equalization (CLAHE), Sustainability, 12, 20, (2020); Yang X.S., Deb S., Multiobjective cuckoo search for design optimization, Computers & Operations Research, 40, 6, pp. 1616-1624, (2013); Pizer S.M., Amburn E.P., Austin J.D., Cromartie R., Geselowitz A., Greer T., Romeny B.H., Zimmerman J.B., Zuiderveld K., Adaptive histogram equalization and its variations, Computer Vision, Graphics, And Image Processing, 39, 3, pp. 355-368, (1987); Yang X.S., Deb S., Cuckoo Search via Lévy flights, 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC), pp. 210-214, (2009); Gonzalez R.C., Woods R.E., Masters B.R., Digital image processing, third edition, Journal of Biomedical Optics, 14, 2, (2009); Patel O., Maravi Y.P., Sharma S., A comparative study of histogram equalization based image enhancement techniques for brightness preservation and contrast enhancement, An International Journal (SIPIJ), (2013); Immerkaer J., Fast noise variance estimation, Computer Vision and Image Understanding, 64, 2, pp. 300-302, (1996); Fu Y., Aldrich C., Flotation froth image recognition with convolutional neural networks, Minerals Engineering, 132, pp. 183-190, (2019); Gulcu A., Zeki K.U.S., Konvolüsyonel sinir ağlarında hiper-parametre optimizasyonu yöntemlerinin incelenmesi, Gazi University Journal of Science Part C: Design and Technology, 7, 2, pp. 503-522, (2019); Ciresan D.C., Meier U., Masci J., Gambardella L.M., Schmidhuber J., Flexible, high performance convolutional neural networks for image classification, Twenty-Second International Joint Conference on Artificial Intelligence, (2011); ER M.B., Akciğer seslerinin derin öğrenme ile siniflandirilmasi, Gazi University Journal of Science Part C: Design and Technology, 8, 4, pp. 830-844, (2020); Chowdhury M.E., Rahman T., Khandakar A., Mazhar R., Kadir M.A., Mahbub Z.B., Islam K.R., Khan M.S., Iqbal A., Emadi N.A., Reaz M.B.I., Islam M.T., Can ai help in screening viral and COVID-19 pneumonia?, IEEE Access, 8, pp. 132665-132676, (2020); Rahman T., Khandakar A., Qiblawey Y., Tahir A., Kiranyaz S., Kashem S.B.A., Islam M.T., Maadeed S.A., Zughaier S.M., Khan M.S., Chowdhury M.E.H., Exploring the effect of image enhancement techniques on COVID-19 detection using chest X-ray images, Computers in Biology and Medicine, 132, (2021); Fjodorova N., Vracko M., Novic M., Roncaglioni A., Benfenati E., New public QSAR model for carcinogenicity, Chemistry Central Journal, 4, pp. 1-15, (2010); Aslan M.F., Unlersen M.F., Sabanci K., Durdu A., CNN-based transfer learning-BiLSTM network: A novel approach for COVID-19 infection detection, Applied Soft Computing, 98, (2021); Turkoglu M., COVIDetectioNet: COVID-19 diagnosis system based on X-ray images using features selected from pre-learned deep features ensemble, Applied Intelligence, 51, 3, pp. 1213-1226, (2021); Arifin F., Artanto H., Nurhasanah T.S.G., Fast COVID-19 detection of chest X-ray images using single shot detection mobilenet convolutional neural networks, Journal of Southwest Jiaotong University, 56, 2, (2021); Progga N.I., Hossain M.S., Andersson K., A deep transfer learning approach to diagnose covid-19 using x-ray images, 2020 IEEE International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE), pp. 177-182, (2020); Chowdhury N.K., Rahman M.M., Kabir M.A., PDCOVIDNet: A parallel-dilated convolutional neural network architecture for detecting COVID-19 from chest X-ray images, Health Information Science and Systems, 8, 1, (2020)","H. Çiğ; Department of Computer Engineering, Harran University, Şanlıurfa, 63050, Turkey; email: haruncig@harran.edu.tr","","International Information and Engineering Technology Association","","","","","","07650019","","","","English","Trait. Signal","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85166331049"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14451 LNCS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178583888&partnerID=40&md5=007ceaaaf0db55b4cc3502c42b9f5b5c","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","03029743","978-981998072-7","","","English","Lect. Notes Comput. Sci.","Conference review","Final","","Scopus","2-s2.0-85178583888"
"Hamdi M.; Senan E.M.; Jadhav M.E.; Olayah F.; Awaji B.; Alalayah K.M.","Hamdi, Mohammed (57201749980); Senan, Ebrahim Mohammed (57222957501); Jadhav, Mukti E. (57201156883); Olayah, Fekry (39161803000); Awaji, Bakri (57219144774); Alalayah, Khaled M. (57190568317)","57201749980; 57222957501; 57201156883; 39161803000; 57219144774; 57190568317","Hybrid Models Based on Fusion Features of a CNN and Handcrafted Features for Accurate Histopathological Image Analysis for Diagnosing Malignant Lymphomas","2023","Diagnostics","13","13","2258","","","","2","10.3390/diagnostics13132258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164710227&doi=10.3390%2fdiagnostics13132258&partnerID=40&md5=7dfc2ae8a8d9cce7cb9467623c2261ff","Department of Computer Science, Faculty of Computer Science and Information System, Najran University, Najran, 66462, Saudi Arabia; Department of Artificial Intelligence, Faculty of Computer Science and Information Technology, Alrazi University, Sana’a, Yemen; Shri Shivaji Science & Arts College, Chikhli Dist, Buldana, 443201, India; Department of Information System, Faculty Computer Science and Information System, Najran University, Najran, 66462, Saudi Arabia; Department of Computer Science, Faculty of Science and Arts, Najran University, Najran, Sharurah, 66462, Saudi Arabia","Hamdi M., Department of Computer Science, Faculty of Computer Science and Information System, Najran University, Najran, 66462, Saudi Arabia; Senan E.M., Department of Artificial Intelligence, Faculty of Computer Science and Information Technology, Alrazi University, Sana’a, Yemen; Jadhav M.E., Shri Shivaji Science & Arts College, Chikhli Dist, Buldana, 443201, India; Olayah F., Department of Information System, Faculty Computer Science and Information System, Najran University, Najran, 66462, Saudi Arabia; Awaji B., Department of Computer Science, Faculty of Computer Science and Information System, Najran University, Najran, 66462, Saudi Arabia; Alalayah K.M., Department of Computer Science, Faculty of Science and Arts, Najran University, Najran, Sharurah, 66462, Saudi Arabia","Malignant lymphoma is one of the most severe types of disease that leads to death as a result of exposure of lymphocytes to malignant tumors. The transformation of cells from indolent B-cell lymphoma to B-cell lymphoma (DBCL) is life-threatening. Biopsies taken from the patient are the gold standard for lymphoma analysis. Glass slides under a microscope are converted into whole slide images (WSI) to be analyzed by AI techniques through biomedical image processing. Because of the multiplicity of types of malignant lymphomas, manual diagnosis by pathologists is difficult, tedious, and subject to disagreement among physicians. The importance of artificial intelligence (AI) in the early diagnosis of malignant lymphoma is significant and has revolutionized the field of oncology. The use of AI in the early diagnosis of malignant lymphoma offers numerous benefits, including improved accuracy, faster diagnosis, and risk stratification. This study developed several strategies based on hybrid systems to analyze histopathological images of malignant lymphomas. For all proposed models, the images and extraction of malignant lymphocytes were optimized by the gradient vector flow (GVF) algorithm. The first strategy for diagnosing malignant lymphoma images relied on a hybrid system between three types of deep learning (DL) networks, XGBoost algorithms, and decision tree (DT) algorithms based on the GVF algorithm. The second strategy for diagnosing malignant lymphoma images was based on fusing the features of the MobileNet-VGG16, VGG16-AlexNet, and MobileNet-AlexNet models and classifying them by XGBoost and DT algorithms based on the ant colony optimization (ACO) algorithm. The color, shape, and texture features, which are called handcrafted features, were extracted by four traditional feature extraction algorithms. Because of the similarity in the biological characteristics of early-stage malignant lymphomas, the features of the fused MobileNet-VGG16, VGG16-AlexNet, and MobileNet-AlexNet models were combined with the handcrafted features and classified by the XGBoost and DT algorithms based on the ACO algorithm. We concluded that the performance of the two networks XGBoost and DT, with fused features between DL networks and handcrafted, achieved the best performance. The XGBoost network based on the fused features of MobileNet-VGG16 and handcrafted features resulted in an AUC of 99.43%, accuracy of 99.8%, precision of 99.77%, sensitivity of 99.7%, and specificity of 99.8%. This highlights the significant role of AI in the early diagnosis of malignant lymphoma, offering improved accuracy, expedited diagnosis, and enhanced risk stratification. This study highlights leveraging AI techniques and biomedical image processing; the analysis of whole slide images (WSI) converted from biopsies allows for improved accuracy, faster diagnosis, and risk stratification. The developed strategies based on hybrid systems, combining deep learning networks, XGBoost and decision tree algorithms, demonstrated promising results in diagnosing malignant lymphoma images. Furthermore, the fusion of handcrafted features with features extracted from DL networks enhanced the performance of the classification models. © 2023 by the authors.","ACO; deep learning; DT; fusion features; GVF; malignant lymphoma; XGBoost","alexnet; ant colony optimization; Article; artificial intelligence; biopsy; cancer classification; cancer diagnosis; cancer staging; classifier; controlled study; convolutional neural network; decision tree; deep learning; diagnostic accuracy; diagnostic test accuracy study; discrete wavelet transform; early cancer; early diagnosis; evaluation study; feature extraction; feature extraction algorithm; gradient vector flow algorithm; gray level cooccurrence matrix; handcrafted feature; histopathology; human; human tissue; image analysis; image processing; local binary pattern; lymphocyte; lymphoma; machine learning; mobilenet; radiomics; risk assessment; segmentation algorithm; sensitivity and specificity; XGBoost algorithm","","","","","Najran University, NU; Deanship of Scientific Research, University of Jordan, DSR, (NU/DRP/SERC/12/17)","Funding text 1: The authors are thankful to the Deanship of Scientific Research at Najran University for funding this work, under the General Research Funding program (grant code NU/DRP/SERC/12/17). ; Funding text 2: This research has been funded by the Deanship of Scientific Research at Najran University, Kingdom of Saudi Arabia, through grant code NU/DRP/SERC/12/17.","Stefaniuk P., Szymczyk A., Podhorecka M., The neutrophil to lymphocyte and lymphocyte to monocyte ratios as new prognostic factors in hematological malignancies—A narrative review, Cancer Manag. Res, 12, (2020); Kobayashi H., Asada N., Egusa Y., Ikeda T., Sakamoto M., Abe M., Maeda Y., Transformation to diffuse large B-cell lymphoma with germinal center B-cell like subtype and discordant light chain expression in a patient with Waldenström macroglobulinemia/lymphoplasmacytic lymphoma, Int. J. Hematol, 114, pp. 401-407, (2021); Zmigrodzka M., Witkowska-Pilaszewicz O., Pingwara R., Pawlak A., Winnicka A., Canine B Cell Lymphoma- and Leukemia-Derived Extracellular Vesicles Moderate Differentiation and Cytokine Production of T and B Cells In Vitro, Int. J. Mol. Sci, 23, (2022); Kanas G., Ge W., Quek R.G., Keeven K., Nersesyan K., Arnason J.E., Epidemiology of diffuse large B-cell lymphoma (DLBCL) and follicular lymphoma (FL) in the United States and Western Europe: Population-level projections for 2020–2025, Leuk. Lymphoma, 63, pp. 54-63, (2022); King R.L., Gupta A., Kurtin P.J., Ding W., Call T.G., Rabe K.G., Parikh S.A., Chronic lymphocytic leukemia (CLL) with Reed–Sternberg-like cells vs. Classic Hodgkin lymphoma transformation of CLL: Does this distinction matter?, Blood Cancer J, 12, (2022); Beitinjaneh A., Kaufman A., Wang Y., Jain P., Srour S.A., Wang M., Is There Still a Role for Transplant for Patients with Mantle Cell Lymphoma (MCL) in the Era of CAR-T Cell Therapy?, Curr. Treat. Options Oncol, 23, pp. 1614-1625, (2022); Ng K.W.L., Beatty J.A., Tse M.P.Y., Giuliano A., Nasal Lymphoma with Low Mitotic Index in Three Cats Treated with Chlorambucil and Prednisolone, Vet. Sci, 9, (2022); Lisson C.S., Lisson C.G., Mezger M.F., Wolf D., Schmidt S.A., Thaiss W.M., Tausch E., Beer A.J., Stilgenbauer S., Beer M., Et al., Deep Neural Networks and Machine Learning Radiomics Modelling for Prediction of Relapse in Mantle Cell Lymphoma, Cancers, 14, (2022); Wang C.-W., Khalil M.-A., Lin Y.-J., Lee Y.-C., Huang T.-W., Chao T.-K., Deep Learning Using Endobronchial-Ultrasound-Guided Transbronchial Needle Aspiration Image to Improve the Overall Diagnostic Yield of Sampling Mediastinal Lymphadenopathy, Diagnostics, 12, (2022); Caldonazzi N., Rizzo P.C., Eccher A., Girolami I., Fanelli G.N., Naccarato A.G., Bonizzi G., Fusco N., d'Amati G., Scarpa A., Et al., Value of Artificial Intelligence in Evaluating Lymph Node Metastases, Cancers, 15, (2023); Irshaid L., Bleiberg J., Weinberger E., Garritano J., Shallis R.M., Patsenker J., Xu M.L., Histopathologic and machine deep learning criteria to predict lymphoma transformation in bone marrow biopsies, Arch. Pathol. Lab. Med, 146, pp. 182-193, (2022); Xia W., Hu B., Li H., Shi W., Tang Y., Yu Y., Li Y., Deep learning for automatic differential diagnosis of primary central nervous system lymphoma and glioblastoma: Multi-parametric magnetic resonance imaging based convolutional neural network model, J. Magn. Reson. Imaging, 54, pp. 880-887, (2021); Savas I., Classifying Lymphoma Subtypes using CNN and CNN LSTM Mixed Model, (2021); Miyoshi H., Sato K., Kabeya Y., Yonezawa S., Nakano H., Takeuchi Y., Ohshima K., Deep learning shows the capability of high-level computer-aided diagnosis in malignant lymphoma, Lab. Investig, 100, pp. 1300-1310, (2020); Li D., Bledsoe J.R., Zeng Y., Liu W., Hu Y., Bi K., Li S., A deep learning diagnostic platform for diffuse large B-cell lymphoma with high accuracy across multiple hospitals, Nat. Commun, 11, (2020); Syrykh C., Abreu A., Amara N., Siegfried A., Maisongrosse V., Frenois F.X., Brousset P., Accurate diagnosis of lymphoma on whole-slide histopathology images using deep learning, NPJ Digit. Med, 3, (2020); Zhang X., Zhang K., Jiang M., Yang L., Research on the classification of lymphoma pathological images based on deep residual neural network, Technol. Health Care, 29, pp. 335-344, (2021); Reena M.R., Ameer P.M., A content-based image retrieval system for the diagnosis of lymphoma using blood micrographs: An incorporation of deep learning with a traditional learning approach, Comput. Biol. Med, 145, (2022); Zahra H.N., Anshori I., Nadila H., Utami H.M., Chandra J.A., Kurniawan M.R., Husain O., Classification of Lymphoma, Benign Lesions, and Carcinoma Using Convolutional Neural Network, Proceedings of the 4th International Conference on Life Sciences and Biotechnology (ICOLIB), pp. 175-192, (2022); Zhang F., Yang S., Guo S., Xia X., Lymphoma recognition based on CNN models, Proceedings of the Second IYSF Academic Symposium on Artificial Intelligence and Computer Engineering, pp. 602-607; Swiderska-Chadaj Z., Hebeda K., van den Brand M., Litjens G., Predicting MYC translocation in HE specimens of diffuse large B-cell lymphoma through deep learning, Proceedings of the Medical Imaging 2020: Digital Pathology, pp. 238-244; Sheng B., Zhou M., Hu M., Li Q., Sun L., Wen Y., A blood cell dataset for lymphoma classification using faster R-CNN, Biotechnol. Biotechnol. Equip, 34, pp. 413-420, (2020); Mohlman J.S., Leventhal S.D., Hansen T., Kohan J., Pascucci V., Salama M.E., Improving augmented human intelligence to distinguish Burkitt lymphoma from diffuse large B-cell lymphoma cases, Am. J. Clin. Pathol, 153, pp. 743-759, (2020); Gaidano V., Tenace V., Santoro N., Varvello S., Cignetti A., Prato G., Saglio G., De Rosa G., Geuna M., A Clinically Applicable Approach to the Classification of B-Cell Non-Hodgkin Lymphomas with Flow Cytometry and Machine Learning, Cancers, 12, (2020); Farinha F., Ioannidis N., Artifact Removal and FOXP3+ Biomarker Segmentation for Follicular Lymphomas; Zijtregtop E.A.M., Winterswijk L.A., Beishuizen T.P.A., Zwaan C.M., Nievelstein R.A.J., Meyer-Wentrup F.A.G., Beishuizen A., Machine Learning Logistic Regression Model for Early Decision Making in Referral of Children with Cervical Lymphadenopathy Suspected of Lymphoma, Cancers, 15, (2023); Yang Y., Zheng B., Li Y., Li Y., Ma X., Computer-aided diagnostic models to classify lymph node metastasis and lymphoma involvement in enlarged cervical lymph nodes using PET/CT, Med. Phys, 50, pp. 152-162, (2023); Hashimoto N., Takagi Y., Masuda H., Miyoshi H., Kohno K., Nagaishi M., Takeuchi I., Case-based similar image retrieval for weakly annotated large histopathological images of malignant lymphoma using deep metric learning, Med. Image Anal, 85, (2023); Shankar K., Dutta A.K., Kumar S., Joshi G.P., Doo I.C., Chaotic Sparrow Search Algorithm with Deep Transfer Learning Enabled Breast Cancer Classification on Histopathological Images, Cancers, 14, (2022); Ahmed I.A., Senan E.M., Shatnawi H.S.A., Alkhraisha Z.M., Al-Azzam M.M.A., Multi-Models of Analyzing Dermoscopy Images for Early Detection of Multi-Class Skin Lesions Based on Fused Features, Processes, 11, (2023); Chang J., Gao X., Yang Y., Wang N., Object-Oriented Building Contour Optimization Methodology for Image Classification Results via Generalized Gradient Vector Flow Snake Model, Remote Sens, 13, (2021); Olayah F., Senan E.M., Ahmed I.A., Awaji B., AI Techniques of Dermoscopy Image Analysis for the Early Detection of Skin Lesions Based on Combined CNN Features, Diagnostics, 13, (2023); Ahmed I.A., Senan E.M., Shatnawi H.S.A., Alkhraisha Z.M., Al-Azzam M.M.A., Multi-Techniques for Analyzing X-ray Images for Early Detection and Differentiation of Pneumonia and Tuberculosis Based on Hybrid Features, Diagnostics, 13, (2023); Ansari S., Navin A.H., Babazadeh Sangar A., Vaez Gharamaleki J., Danishvar S., Acute Leukemia Diagnosis Based on Images of Lymphocytes and Monocytes Using Type-II Fuzzy Deep Network, Electronics, 12, (2023); Al-Mekhlafi Z.G., Senan E.M., Mohammed B.A., Alazmi M., Alayba A.M., Alreshidi A., Alshahrani M., Diagnosis of Histopathological Images to Distinguish Types of Malignant Lymphomas Using Hybrid Techniques Based on Fusion Features, Electronics, 11, (2022); Ansari S., Navin A.H., Sangar A.B., Gharamaleki J.V., Danishvar S., A Customized Efficient Deep Learning Model for the Diagnosis of Acute Leukemia Cells Based on Lymphocyte and Monocyte Images, Electronics, 12, (2023); Mohammed B.A., Senan E.M., Alshammari T.S., Alreshidi A., Alayba A.M., Alazmi M., Alsagri A.N., Hybrid Techniques of Analyzing MRI Images for Early Diagnosis of Brain Tumours Based on Hybrid Features, Processes, 11, (2023); Ahmed I.A., Senan E.M., Rassem T.H., Ali M.A.H., Shatnawi H.S.A., Alwazer S.M., Alshahrani M., Eye Tracking-Based Diagnosis and Early Detection of Autism Spectrum Disorder Using Machine Learning and Deep Learning Techniques, Electronics, 11, (2022); Mohammed B.A., Senan E.M., Al-Mekhlafi Z.G., Alazmi M., Alayba A.M., Alanazi A.A., Alreshidi A., Alshahrani M., Hybrid Techniques for Diagnosis with WSIs for Early Detection of Cervical Cancer Based on Fusion Features, Appl. Sci, 12, (2022); Li S., Wei Y., Liu X., Zhu H., Yu Z., A New Fast Ant Colony Optimization Algorithm: The Saltatory Evolution Ant Colony Optimization Algorithm, Mathematics, 10, (2022); Paleczek A., Grochala D., Rydosz A., Artificial Breath Classification Using XGBoost Algorithm for Diabetes Detection, Sensors, 21, (2021); Zhao L., Lee S., Jeong S.-P., Decision Tree Application to Classification Problems with Boosting Algorithm, Electronics, 10, (2021); Fati S.M., Senan E.M., Javed Y., Early Diagnosis of Oral Squamous Cell Carcinoma Based on Histopathological Images Using Deep and Hybrid Learning Approaches, Diagnostics, 12, (2022); Berganzo-Besga I., Orengo H.A., Lumbreras F., Carrero-Pazos M., Fonte J., Vilas-Estevez B., Hybrid MSRM-Based Deep Learning and Multitemporal Sentinel 2-Based Machine Learning Algorithm Detects Near 10k Archaeological Tumuli in North-Western Iberia, Remote Sens, 13, (2021); Khan I.U., Afzal S., Lee J.W., Human Activity Recognition via Hybrid Deep Learning Based Model, Sensors, 22, (2022); Alkinani M.H., Khan W.Z., Arshad Q., Raza M., HSDDD: A Hybrid Scheme for the Detection of Distracted Driving through Fusion of Deep Learning and Handcrafted Features, Sensors, 22, (2022)","M. Hamdi; Department of Computer Science, Faculty of Computer Science and Information System, Najran University, Najran, 66462, Saudi Arabia; email: mahamdi@nu.edu.sa; E.M. Senan; Department of Artificial Intelligence, Faculty of Computer Science and Information Technology, Alrazi University, Sana’a, Yemen; email: senan1710@gmail.com","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","20754418","","","","English","Diagn.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85164710227"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Communications in Computer and Information Science","1969 CCIS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178557826&partnerID=40&md5=c23286954f90d2afc18b7ed624564f69","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","18650929","978-981998183-0","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85178557826"
"Arvidsson M.; Rashed S.K.; Aits S.","Arvidsson, Malou (58001558500); Rashed, Salma Kazemi (57188972941); Aits, Sonja (23468829600)","58001558500; 57188972941; 23468829600","An annotated high-content fluorescence microscopy dataset with Hoechst 33342-stained nuclei and manually labelled outlines","2023","Data in Brief","46","","108769","","","","1","10.1016/j.dib.2022.108769","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143768599&doi=10.1016%2fj.dib.2022.108769&partnerID=40&md5=813b6ef950ef5bba6ced06a44fdbc79e","Cell Death, Lysosomes and Artificial Intelligence Group, Faculty of Medicine and AI Lund, Lund University, Sweden","Arvidsson M., Cell Death, Lysosomes and Artificial Intelligence Group, Faculty of Medicine and AI Lund, Lund University, Sweden; Rashed S.K., Cell Death, Lysosomes and Artificial Intelligence Group, Faculty of Medicine and AI Lund, Lund University, Sweden; Aits S., Cell Death, Lysosomes and Artificial Intelligence Group, Faculty of Medicine and AI Lund, Lund University, Sweden","Automated detection of cell nuclei in fluorescence microscopy images is a key task in bioimage analysis. It is essential for most types of microscopy-based high-throughput drug and genomic screening and is often required in smaller scale experiments as well. To develop and evaluate algorithms and neural networks that perform instance or semantic segmentation for detecting nuclei, high quality annotated data is essential. Here we present a benchmarking dataset of fluorescence microscopy images with Hoechst 33342-stained nuclei together with annotations of nuclei, nuclear fragments and micronuclei. Images were randomly selected from an RNA interference screen with a modified U2OS osteosarcoma cell line, acquired on a Thermo Fischer CX7 high-content imaging system at 20x magnification. Labelling was performed by a single annotator and reviewed by a biomedical expert. The dataset, called Aitslab-bioimaging1, contains 50 images showing over 2000 labelled nuclear objects in total, which is sufficiently large to train well-performing neural networks for instance or semantic segmentation. The dataset is split into training, development and test set for user convenience. © 2022","Biomedical image analysis; Computer vision; Deep learning training and evaluation; Fluorescence microscopy; High-content screening; Instance segmentation","Cell culture; Computer vision; Deep learning; Fluorescence; Image analysis; Large dataset; Medical imaging; Quality control; Semantic Segmentation; Semantics; Statistical tests; Automated detection; Biomedical image analysis; Deep learning training and evaluation; Fluorescence microscopy images; High-content; High-content screening; Hoechst; Instance segmentation; Neural-networks; Semantic segmentation; Fluorescence microscopy","","","","","Fabrikant Einar Willumsen's Memorial Fund; Längmanska Cultural Fund; National Bioinformatics Infrastructure Sweden; Sigurd & Elsa Golje's Memorial Fund; Swedish Research Council for Sustainable Development; Thora and Viggo Grove's Memorial Fund; Kræftens Bekæmpelse, DCS; Svenska Forskningsrådet Formas, (2019-01554); Crafoordska Stiftelsen; Lunds Universitet; Hjärnfonden; Knut och Alice Wallenbergs Stiftelse, (2018-05973); Vetenskapsrådet, VR, (2016-02003); Kungliga Fysiografiska Sällskapet i Lund; Thorsten och Elsa Segerfalks Stiftelse; Science for Life Laboratory, SciLifeLab","Funding text 1: We are grateful for financial support from Lund University, LINXS, the Danish Cancer Society, the Swedish Research Council (grant no. 2016-02003), the SciLifeLab/Knut and Alice Wallenberg Foundation National COVID-19 Research Program, the Swedish Research Council for Sustainable Development ( FORMAS , grant no. 2019-01554 ), the Segerfalk Foundation, the Swedish Brain Foundation, the Crafoord Foundation, the Längmanska Cultural Fund, the Sigurd & Elsa Golje's Memorial Fund, the Thora and Viggo Grove's Memorial Fund, the Fabrikant Einar Willumsen's Memorial Fund and the Royal Physiographic Society. We are also grateful for the Bioinformatics Long-term Support (WABI) from the National Bioinformatics Infrastructure Sweden at SciLifeLab (financed by the Knut and Alice Wallenberg Foundation), which enabled the secondment of Dr. Oskolkov to our group. ; Funding text 2: The data handling was enabled by resources provided by the Swedish National Infrastructure for Computing (SNIC), partially funded by the Swedish Research Council through grant agreement no. 2018-05973.","Caicedo J.C., Roth J., Goodman A., Becker T., Karhohs K.W., Broisin M., Molnar C., McQuin C., Singh S., Theis F.J., Carpenter A.E., Evaluation of deep learning strategies for nucleus segmentation in fluorescence images, Cytomet. A, 95, 9, pp. 952-965, (2019); Mahbod A., Schaefer G., Low C., Dorffner G., Ecker R., Ellinger I., Investigating the impact of the bit depth of fluorescence-stained images on the performance of deep learning-based nuclei instance segmentation, Diagnostics (Basel), 11, 6, (2021); Mahbod A., Schaefer G., Bancher B., Low C., Dorffner G., Ecker R., Ellinger I., CryoNuSeg: A dataset for nuclei instance segmentation of cryosectioned H&E-stained histological images, Comput. Biol. Med., 132, (2021)","S. Aits; Cell Death, Lysosomes and Artificial Intelligence Group, Faculty of Medicine and AI Lund, Lund University, Sweden; email: sonja.aits@med.lu.se","","Elsevier Inc.","","","","","","23523409","","","","English","Data Brief","Data paper","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85143768599"
"Balasubramanian K.; Ramya K.; Gayathri Devi K.","Balasubramanian, Kishore (57188969156); Ramya, K. (57733230300); Gayathri Devi, K. (56574176700)","57188969156; 57733230300; 56574176700","Improved swarm optimization of deep features for glaucoma classification using SEGSO and VGGNet","2022","Biomedical Signal Processing and Control","77","","103845","","","","5","10.1016/j.bspc.2022.103845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131408028&doi=10.1016%2fj.bspc.2022.103845&partnerID=40&md5=a24d8d07273f53bcbe4313d2938230cf","Dr Mahalingam College of Engineering and Technology, Pollachi, India; P A College of Engineering and Technology, Pollachi, India; Dr NGP Institute of Technology, Coimbatore, India","Balasubramanian K., Dr Mahalingam College of Engineering and Technology, Pollachi, India; Ramya K., P A College of Engineering and Technology, Pollachi, India; Gayathri Devi K., Dr NGP Institute of Technology, Coimbatore, India","Efficient classification of glaucoma from fundus images remains crucial and a challenging task as the retinal anatomical structure is so complex in nature with varying contrast and boundaries. As a result, there is a chance that expert systems will misclassify the data. As a way to reduce the misclassification rate, a methodology wherein a deep learning approach integrated with an evolutionary algorithm is proposed. First, the relevant features are extracted using a pre-trained ImageNet model, the VGGNet. The features extorted are subsequently filtered using statistically enhanced Glow-worm Swarm Optimization (SEGSO). The algorithm identifies the most important and relevant features, while excluding those that are noisy or highly correlated. The efficiency of this fully automated system is evaluated on public and private retinal fundus image databases (totally 18,879 images) and the experiments demonstrated a high accuracy of 99.6% with less computational complexity, better sensitivity and specificity. SEGSO algorithm selected comparatively lesser features than the similar algorithms and when, employed with VGGNet outperform several other convolutional network models. The proposed method is robust against salt-pepper noise and achieved an accuracy of 97.2% when applied on degraded images. Feature extraction using Convolutional Neural Network and SEGSO feature optimization could prove to be a good combination to be used for other biomedical image classification processes. © 2022 Elsevier Ltd","Classification; CNN; Deep learning; Fundus image; Glaucoma; Swarm intelligence","Automation; Classification (of information); Convolution; Deep learning; Evolutionary algorithms; Image classification; Image enhancement; Ophthalmology; Swarm intelligence; Anatomical structures; CNN; Deep learning; Fundus image; Highly-correlated; Important features; Learning approach; Misclassification rates; Relevant features; Swarm optimization; anatomical concepts; Article; cancer classification; comparative study; controlled study; convolutional neural network; data availability; deep learning; diagnostic test accuracy study; evolutionary algorithm; expert system; eye fundus; feature extraction; feature selection; genetic algorithm; glaucoma; image processing; nonhuman; particle swarm optimization; pattern recognition; sensitivity and specificity; Complex networks","","","","","","","Haleem M.S., Han L., van Hemert J., Li B., Automatic extraction of retinal features from colour retinal images for glaucoma diagnosis: a review, Computer. Med. Imag. Graph., 37, 7-8, pp. 581-596, (2013); Joshi G.D., Sivaswamy J., Krishnadas S.R., Optic disk and cup segmentation from monocular color retinal images for glaucoma assessment, IEEE Trans. Med. Imaging, 30, 6, pp. 1192-1205, (2011); Kanse S.S., Yadav D.M., Retinal fundus image for glaucoma detection: a review and study, J. Intell. Syst., 28, 1, pp. 43-56, (2019); Geetha A., Santhi D., Prakash N.B., Hemalakshmi G.R., Sumithra M., (2020); Jonas J.B., Budde W.M., Panda-Jonas S., Ophthalmoscopic evaluation of the optic nerve head, Surv. Ophthalmol., 43, 4, pp. 293-320, (1999); Yousefi S., Goldbaum M.H., Balasubramanian M., Jung T.P., Weinreb R.N., Medeiros F.A., Zangwill L.M., Liebmann J.M., Girkin C.A., Bowd C., Glaucoma progression detection using structural retinal nerve fiber layer measurements and functional visual field points, IEEE Trans. Bio-Med. Eng., 61, 4, pp. 1143-1154, (2014); Roberti G., Manni G., Riva I., Hollo G., Quaranta L., Agnifili L., Figus M., Giammaria S., Rastelli D., Oddone F., Bhattacharya S., Detection of central visual field defects in early glaucomatous eyes: comparison of humphrey and octopus perimetry, PLoS ONE, 12, 10, (2017); Kim S.J., Cho K.J., Oh S., Liu B., Development of machine learning models for diagnosis of glaucoma, PLoS ONE, 12, 5, (2017); Murtagh P., Greene G., O'Brien C., Current applications of machine learning in the screening and diagnosis of glaucoma: a systematic review and Meta-analysis, Int. J. Ophthalmol., 13, 1, pp. 149-162, (2020); Thompson A.C., Jammal A.A., Medeiros F.A., A review of deep learning for screening, diagnosis, and detection of glaucoma progression, Transl. Vis. Sci. Technol., 9, 2, (2020); Nguyen L.D., Lin D., Lin Z., Cao J., Deep CNNs for microscopic image classification by exploiting transfer learning and feature concatenation, In 2018 IEEE International Symposium on Circuits and Systems, pp. 1-5, (2018); Shin H.C., Roth H.R., Gao M., Lu L., Xu Z., Nogues I., Yao J., Mollura D., Summers R.M., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning, IEEE Trans. Med. Imaging, 35, 5, pp. 1285-1298, (2016); Khan S., Islam N., Jan Z., Din I.U., Rodrigues J.J., A novel deep learning based framework for the detection and classification of breast cancer using transfer learning, Pattern Recognit. Lett., 125, pp. 1-6, (2019); Li L., Xu M., Liu H., Li Y., Wang X., Jiang L., Wang Z., Fan X., Wang N., A large-scale database and a CNN Model for attention-based glaucoma detection, IEEE Trans. Med. Imaging, 39, 2, pp. 413-424, (2020); Serener A., Serte S., Transfer learning for early and advanced glaucoma detection with convolutional neural networks, Med. Technol. Congr. (TIPTEKNO), 2019, pp. 1-4, (2019); Christopher M., Belghith A., Bowd C., Proudfoot J.A., Goldbaum M.H., Weinreb R.N., Girkin C.A., Liebmann J.M., Zangwill L.M., Performance of deep learning architectures and transfer learning for detecting glaucomatous optic neuropathy in fundus photographs, Sci. Rep., 8, 1, (2018); Singh L.K., Garg H., (2020); Nalepa J., Mrukwa G., Kawulok M., (2018); Chen X., Xu Y., Wong D., Wong T., Liu J., Glaucoma detection based on deep convolutional neural network, 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 715-718, (2015); Alghamdi H.S., Tang H.L., (2016); Abbas Q., Glaucoma-deep: detection of glaucoma eye disease on retinal fundus images using deep learning, Int. J. Adv. Comput. Sci. Appl., 8, 6, pp. 41-45, (2017); Orlando J., Prokofyeva E., Fresno M.D., Blaschko M.B., pp. 10160-10, (2017); Sevastopolsky A., Optic disc and cup segmentation methods for glaucoma detection with modification of U-Net convolutional neural network, Pattern Recognit Image Anal., 27, 3, pp. 618-624, (2017); Juneja M., Singh S., Agarwal N., Bali S., Gupta S., Thakur N., Jindal P., Automated detection of Glaucoma using deep learning convolution network (G-net), Multimedia Tools Appl., 79, pp. 15531-15553, (2019); Gheisari S., Shariflou S., Phu J., Kennedy P.J., Agar A., Kalloniatis M., Golzan S.M., A combined convolutional and recurrent neural network for enhanced glaucoma detection, Sci. Rep., 11, 1, (2021); Raghavendra U., Fujita H., Bhandary S., Gudigar A., Tan J., Acharya U., Deep convolution neural network for accurate diagnosis of glaucoma using digital fundus images, Inf. Sci., 441, pp. 41-49, (2018); Bajwa M.N., Malik M.I., Siddiqui S.A., Dengel A., Shafait F., Neumeier W., Ahmed S., Two-stage framework for optic disc localization and glaucoma classification in retinal fundus images using deep learning, BMC Med. Inf. Decis. Making, 19, 1, (2019); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S.E., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., pp. 1-9, (2015); Sivaswamy J., Krishnadas S.R., Joshi G.D., Jain M., Tabish A.U., pp. 53-56, (2014); Diaz-Pinto A., Morales S., Naranjo V., Kohler T., Mossi J.M., Navea A., CNNs for automatic glaucoma assessment using fundus images: an extensive validation, Biomed. Eng. Online, 18, 1, (2019); Zhang Z., Yin F.S., Liu J., Wong W.K., Tan N.M., Lee B.H., Cheng J., Wong T., (2010); Li L., Xu M., Wang X., Jiang L., Liu H., pp. 10563-10572, (2019); Shorten C., Khoshgoftaar T., A survey on image data augmentation for deep learning, J. Big Data, 6, pp. 1-48, (2019); Chen L.C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., DeepLab: semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs, IEEE Trans. Pattern Anal. Mach. Intell., 40, 4, pp. 834-848, (2018); Simonyan K., Zisserman A., (2015); Bengio Y., Courville A., Vincent P., Representation learning: a review and new perspectives, IEEE Trans. Pattern Anal. Mach. Intell., 35, 8, pp. 1798-1828, (2013); Krishnanand K.N., Ghose D., Glow-worm swarm optimization: a new method for optimizing multi-modal functions, Int. J. Comput. Intell. Stud., 1, 1, pp. 93-119, (2009); Balasubramanian K., Ananthamoorthy N.P., Improved adaptive neuro-fuzzy inference system based on modified glowworm swarm and differential evolution optimization algorithm for medical diagnosis, Neural Comput. Appl., 33, 13, pp. 7649-7660, (2021); Guyon I., Weston J., Barnhill S., Vapnik V., Gene selection for cancer classification using support vector machines, Mach. Learn., 46, pp. 389-422, (2004); Kim S., Margin-maximised redundancy-minimised SVM-RFE for diagnostic classification of mammograms, Int. J. Data Min. Bioinform., 10, 4, pp. 374-390, (2014); Granitto P.M., Furlanello C., Biasioli F., Gasperi F., Recursive feature elimination with random forest for ptrms analysis of agroindustrial products, Chemomet. Intell. Labor. Syst., 83, 2, pp. 83-90, (2006); Chang C., Lin C.; Baratloo A., Hosseini M., Negida A., El Ashal G., Part 1: simple definition and calculation of accuracy, sensitivity and specificity, Emergency (Tehran, Iran), 3, 2, pp. 48-49, (2015); Liu H., Setiono R., A probabilistic approach to feature selection: A filter solution, pp. 319-327, (1996); Sikonja M., Kononenko I., pp. 296-304; Niwas S.I., Lin W., Bai X., Kwoh C.K., Sng C.C., Aquino M.C., Chew P.T.K., Reliable feature selection for automated angle closure glaucoma mechanism detection, J. Med. Syst., 39, 3, (2015); Bengio Y., Practical Recommendations for Gradient-Based Training of Deep Architectures, (2012); Radiuk P., Impact of training set batch size on the performance of convolutional neural networks for diverse datasets, Inform. Technol. Manage. Sci., 20, pp. 20-24, (2017); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Elangovan P., Nath M.K., Glaucoma assessment from color fundus images using convolutional neural network, Int. J. Imaging Syst. Technol., 31, 2, pp. 955-971, (2021); Ajitha S., pp. 5449-5458, (2020); Guo F., Mai Y., Zhao X., Duan X., Fan Z., Zou B., Xie B., Yanbao: a mobile app using the measurement of clinical parameters for glaucoma screening, IEEE Access, 6, pp. 77414-77428, (2018); Ajitha S., Akkara J.D., Judy M.V., Identification of glaucoma from fundus images using deep learning techniques, Indian J. Ophthalmol., 69, 10, pp. 2702-2709, (2021); pp. 2563-2579, (2022); Sreng S., Maneerat N., Hamamoto K., Win K.Y., Deep learning for optic disc segmentation and glaucoma diagnosis on retinal images, Appl. Sci., 10, (2020); Islam M.T., Mashfu S.T., Faisal A., Siam S.C., Naheen I.T., Khan R., Deep learning-based glaucoma detection with cropped optic cup and disc and blood vessel segmentation, IEEE Access, 10, pp. 2828-2841, (2022); Ovreiu S., Paraschiv E., Ovreiu E.; Bao Y., Wang J., Li T., Wang L., Xu J., Ye J., Qian D., (2021)","K. Balasubramanian; Dr Mahalingam College of Engineering and Technology, Pollachi, India; email: kishoreb.phd2018@gmail.com","","Elsevier Ltd","","","","","","17468094","","","","English","Biomed. Signal Process. Control","Article","Final","","Scopus","2-s2.0-85131408028"
"Hasan M.E.; Wagler A.","Hasan, Md Easin (57223897299); Wagler, Amy (37062272800)","57223897299; 37062272800","A novel deep learning graph attention network for Alzheimer's disease image segmentation","2024","Healthcare Analytics","5","","100310","","","","1","10.1016/j.health.2024.100310","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185316951&doi=10.1016%2fj.health.2024.100310&partnerID=40&md5=ac69f48e82dc50e1e87a9324d385860f","Department of Mathematical Sciences, The University of Texas at El Paso, 500 W. University Ave., El Paso, 79968, TX, United States; Department of Public Health Sciences, The University of Texas at El Paso, 500 W. University Ave., El Paso, 79968, TX, United States","Hasan M.E., Department of Mathematical Sciences, The University of Texas at El Paso, 500 W. University Ave., El Paso, 79968, TX, United States; Wagler A., Department of Public Health Sciences, The University of Texas at El Paso, 500 W. University Ave., El Paso, 79968, TX, United States","Neuronal cell segmentation identifies and separates individual neurons in an image, typically to study their properties or analyze their organization in the nervous system. This is significant because neurological problems and diseases can only be treated effectively when the structure and function of neurons are understood. The proposed method is based on convolutional neural networks (CNNs) and graph attention networks (GATs) for segmenting biomedical images. A contracting path built upon a couple of convolution layers and max pooling is included in the architecture to capture context. After that, the GATs are applied to the captured context. In GATs, each node in the graph is associated with a vector of hidden features, and the model calculates attention coefficients between pairs of nodes. These attention coefficients are learned during training and can be used to weigh the contribution of each node's features to the representation of the graph. An expanding path that utilizes the outputs generated by GATs paves the way for exact segmentation. The dataset comprises 606 microscopic images, mainly categorized into different cell types (astrocytes, cortex, and SHSY5Y). By implementing our proposed U-GAT algorithm, we obtained the highest accuracy of 86.5% and an F1 score of 0.719 compared to the CNN, U-Net, SegResNet, SegNet VGG16, and GAT benchmarking algorithms. This proposed method could help researchers in the biotech industry develop novel drugs since a more accurate deep-learning method is essential for segmenting complex images like neuronal images. © 2024 The Authors","Convolutional neural networks; Deep learning; Graph attention networks; Image segmentation; Neuronal cells; U-Net","accuracy; Alzheimer disease; Article; attention network; benchmarking; cells by body anatomy; convolutional neural network; deep learning; human; image segmentation; imaging algorithm; nerve cell; process development; research gap","","","","","","","Mesfin F.B., Al-Dhahir M.A., Gliomas, (2017); Verkhratsky A., Olabarria M., Noristani H.N., Yeh C.-Y., Rodriguez J.J., Astrocytes in Alzheimer's disease, Neurotherapeutics, 7, 4, pp. 399-412, (2010); Sadigh-Eteghad S., Sabermarouf B., Majdi A., Talebi M., Farhoudi M., Mahmoudi J., Amyloid-beta: a crucial factor in Alzheimer's disease, Med. Princ. Pract., 24, 1, pp. 1-10, (2015); Clinic M., Alzheimer's disease, (2023); Edlund C., Jackson T.R., Khalid N., Bevan N., Dale T., Dengel A., Ahmed S., Trygg J., Sjogren R., LIVECell—A large-scale dataset for label-free live cell segmentation, Nat. Methods, 18, 9, pp. 1038-1045, (2021); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation,, pp. 3431-3440, (2015); Gonzalez S.R., Zemmoura I., Tauber C., 3D brain tumor segmentation and survival prediction using ensembles of convolutional neural networks, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 241-254, (2021); Groza V., Tuchinov B., Amelina E., Pavlovskiy E., Tolstokulakov N., Amelin M., Golushko S., Letyagin A., Brain tumor segmentation and associated uncertainty evaluation using multi-sequences MRI mixture data preprocessing, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 148-157, (2021); Iantsen A., Jaouen V., Visvikis D., Hatt M., Squeeze-and-excitation normalization for brain tumor segmentation, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 366-373, (2021); Asgharzadeh-Bonab A., Kalbkhani H., Azarfardian S., An Alzheimer's disease classification method using fusion of features from brain magnetic resonance image transforms and deep convolutional networks, Healthc. Anal., 4, (2023); Shaikh S., Phophalia A., A deep random forest approach for multimodal brain tumor segmentation, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 133-147, (2021); Velickovic P., Cucurull G., Casanova A., Romero A., Lio P., Bengio Y., Graph attention networks, Stat, 1050, (2017); Badrinarayanan V., Kendall A., Cipolla R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, 12, pp. 2481-2495, (2017); Liu X., Bonner E.R., Jiang Z., Roth H.R., Anwar S.M., Packer R.J., Bornhorst M., Linguraru M.G., Automatic segmentation of rare pediatric brain tumors using knowledge transfer from adult data, 2023 IEEE 20th International Symposium on Biomedical Imaging, ISBI, pp. 1-4, (2023); Pandya A., Oguine O.C., Bhargava H., Zade S., Enhanced 3D brain tumor segmentation using assorted precision training, BOHR Int. J. Internet Things Artif. Intell. Mach. Learn., 1, 1, pp. 79-84, (2022); Zhao J., Xing Z., Chen Z., Wan L., Han T., Fu H., Zhu L., Uncertainty-aware multi-dimensional mutual learning for brain and brain tumor segmentation, IEEE J. Biomed. Health Inf., (2023); Choi Y., Al-Masni M.A., Jung K.-J., Yoo R.-E., Lee S.-Y., Kim D.-H., A single stage knowledge distillation network for brain tumor segmentation on limited MR image modalities, Comput. Methods Programs Biomed., (2023); Doganay F.E., Sahin O., Ozer S., Chen C.H., Deep learning based 3D brain tumor segmentation with multispectral MRI, Computational Intelligence and Image Processing in Medical Applications, pp. 119-133, (2022); Liu X., Bonner E.R., Jiang Z., Roth H.R., Packer R., Bornhorst M., Linguraru M.G., From adult to pediatric: deep learning-based automatic segmentation of rare pediatric brain tumors, Medical Imaging 2023: Computer-Aided Diagnosis, 12465, pp. 15-19, (2023); Daimary D., Bora M.B., Amitab K., Kandar D., Brain tumor segmentation from MRI images using hybrid convolutional neural networks, Procedia Comput. Sci., 167, pp. 2419-2428, (2020); Maruyama T., Hayashi N., Sato Y., Ogura T., Uehara M., Ogura A., Watanabe H., Kitoh Y., Initiative A.D.N., Simultaneous brain structure segmentation in magnetic resonance images using deep convolutional neural networks, Radiol. Phys. Technol., 14, pp. 358-365, (2021); Nalini N., Et al., Classification and segmentation of brain MRI images using deep learning, 2021 2nd Global Conference for Advancement in Technology, GCAT, pp. 1-7, (2021); Alkassar S., Abdullah M.A., Jebur B.A., Automatic brain tumour segmentation using fully convolution network and transfer learning, 2019 2nd International Conference on Electrical, Communication, Computer, Power and Control Engineering, ICECCPCE, pp. 188-192, (2019); Tarasiewicz T., Kawulok M., Nalepa J., Lightweight u-nets for brain tumor segmentation, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 3-14, (2021); Su Z.-J., Chang T.-C., Tai Y.-L., Chang S.-J., Chen C.-C., Attention u-net with dimension-hybridized fast data density functional theory for automatic brain tumor image segmentation, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 81-92, (2021); Zhao C., Zhao Z., Zeng Q., Feng Y., MVP U-net: Multi-view pointwise U-net for brain tumor segmentation, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 93-103, (2021); Zsamboki R., Takacs P., Deak-Karancsi B., Glioma segmentation with 3D U-Net backed with energy-based post-processing, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 104-117, (2021); Walsh J., Othmani A., Jain M., Dev S., Using U-net network for efficient brain tumor segmentation in MRI images, Healthc. Anal., 2, (2022); Awasthi N., Pardasani R., Gupta S., Multi-threshold attention u-net (mtau) based model for multimodal brain tumor segmentation in mri scans, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 168-178, (2021); Ali M.J., Akram M.T., Saleem H., Raza B., Shahid A.R., Glioma segmentation using ensemble of 2D/3D U-nets and survival prediction using multiple features fusion, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 189-199, (2021); Parmar B., Parikh M., Brain tumor segmentation and survival prediction using patch based modified 3D U-net, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 398-409, (2021); Savadikar C., Kulhalli R., Garware B., Brain tumour segmentation using probabilistic u-net, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 255-264, (2021); McHugh H., Talou G.M., Wang A., 2D Dense-UNet: a clinically valid approach to automated glioma segmentation, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 69-80, (2021); Kaewrak K., Soraghan J., Di Caterina G., Grose D., TwoPath U-net for automatic brain tumor segmentation from multimodal MRI data, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 300-309, (2021); Colman J., Zhang L., Duan W., Ye X., DR-unet104 for multimodal MRI brain tumor segmentation, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 410-419, (2021); Bommineni V.L., PieceNet: A redundant UNet ensemble, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries: 6th International Workshop, BrainLes 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Revised Selected Papers, Part II 6, pp. 331-341, (2021); Pendse M., Thangarasa V., Chiley V., Holmdahl R., Hestness J., DeCoste D., Memory efficient 3d u-net with reversible mobile inverted bottlenecks for brain tumor segmentation, International MICCAI Brainlesion Workshop, pp. 388-397, (2020); Hu J., Cao L., Li T., Dong S., Li P., GAT-LI: a graph attention network based learning and interpreting method for functional brain network classification, BMC Bioinform., 22, 1, pp. 1-20, (2021); Zhou W., Xia Z., Dou P., Su T., Hu H., Double attention based on graph attention network for image multi-label classification, ACM Trans. Multimedia Comput. Commun. Appl., 19, 1, pp. 1-23, (2023); Yang F., Zhang H., Tao S., Semi-supervised classification via full-graph attention neural networks, Neurocomputing, 476, pp. 63-74, (2022); Dong Y., Liu Q., Du B., Zhang L., Weighted feature fusion of convolutional neural network and graph attention network for hyperspectral image classification, IEEE Trans. Image Process., 31, pp. 1559-1572, (2022); Billones C.D., Demetria O.J.L.D., Hostallero D.E.D., Naval P.C., DemNet: a convolutional neural network for the detection of Alzheimer's disease and mild cognitive impairment, 2016 IEEE Region 10 Conference, TENCON, pp. 3724-3727, (2016); Goodfellow I., Bengio Y., Courville A., Deep Learning, (2016); Bacciu D., Errica F., Micheli A., Podda M., A gentle introduction to deep learning for graphs, Neural Netw., 129, pp. 203-221, (2019); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Adv. Neural Inf. Process. Syst., 30, (2017)","M.E. Hasan; Department of Mathematical Sciences, The University of Texas at El Paso, El Paso, 500 W. University Ave., 79968, United States; email: mhasan8@miners.utep.edu","","Elsevier Inc.","","","","","","27724425","","","","English","Healthc. Anal.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85185316951"
"Habib G.; Qureshi S.","Habib, Gousia (57221589277); Qureshi, Shaima (26325864200)","57221589277; 26325864200","Compressed lightweight deep learning models for resource-constrained Internet of things devices in the healthcare sector","2023","Expert Systems","","","","","","","2","10.1111/exsy.13269","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150632978&doi=10.1111%2fexsy.13269&partnerID=40&md5=98df5bbde753379f963657f0054f5de0","Department of Computer Science and Engineering, National Institute of Technology Srinagar, Srinagar, India","Habib G., Department of Computer Science and Engineering, National Institute of Technology Srinagar, Srinagar, India; Qureshi S., Department of Computer Science and Engineering, National Institute of Technology Srinagar, Srinagar, India","The performance of convolutional neural networks (CNNs) in image classification and object detection has been remarkable, even though they contain millions and billions of parameters. This over-parameterization of CNN makes them both memory-intensive and computationally complex and exhaustive. This greatly hinders the application of CNNs in resource-constrained environments such as Internet of things (IoT) and edge devices. This poses a critical challenge for CNNs in deploying these powerful computer vision tools to mobile devices, which needs immediate attention. In this study, we have proposed a novel technique based on non-convex optimization, max-norm regularization. The max-norm will structurally prune the number of parameters without compromising the model's performance. The proximal gradient descent algorithm is used for network optimization while using this non-convex regularizer. The max-norm is combined with the channel pruning to achieve more sparse CNN networks. Later, the pruned network can be easily deployed in the resource-constrained application environment. The proposed technique is tested on several benchmark datasets for validation. In addition, in this study, the sparsified CNNs are used for biomedical image analysis using the BRAIN MRI dataset. This sparsely trained CNN model can later serve as the best lightweight model applicable in the IoT healthcare sector for detecting and classifying three types of brain tumours, one of the most life-threatening diseases whose early detection can save the costly lives of human beings. This is the first paper to propose the novel max-norm regularizer to enforce sparse learning through CNNs. The paper provides a detailed analysis of convex and non-convex regularizers before presenting the proposed novel max-norm regularizer. Finally, the paper compares the proposed max-norm regularizer with existing regularization methods using state-of-the-art CNN models. © 2023 John Wiley & Sons Ltd.","CNN; FLOPS; infinity norm; max-norm; NLP; regularization; VGG-19; weight pruning","Convex optimization; Convolutional neural networks; Deep learning; Gradient methods; Health care; Magnetic resonance imaging; Object detection; Convolutional neural network; FLOPS; Healthcare sectors; Infinity norm; Max-norms; Neural network model; Regularisation; Regularizer; VGG-19; Weight pruning; Internet of things","","","","","","","Abouelnaga Y., Ali O.S., Rady H., Moustafa M., CIFAR-10: KNN-based ensemble of classifiers. In 2016 international conference on computational science and computational intelligence (CSCI) (pp. 1192–1195). IEEE, (2016); Alvarez J.M., Salzmann M., Learning the number of neurons in deep networks, Advances in neural information processing systems, 29, (2016); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs, IEEE Transactions on Pattern Analysis and Machine Intelligence, 40, 4, pp. 834-848, (2017); Collins M.D., Kohli P., Memory bounded deep convolutional networks, arXiv preprint arXiv:1412.1442, (2014); Denil M., Shakibi B., Dinh L., Ranzato M., De Freitas N., Predicting parameters in deep learning. In Advances in neural information processing systems, 26, (2013); Fan J., Li R., Variable selection via nonconcave penalized likelihood and its oracle properties, Journal of the American Statistical Association, 96, 456, pp. 1348-1360, (2001); Fan J., Peng H., Nonconcave penalized likelihood with a diverging number of parameters, The Annals of Statistics, 32, 3, pp. 928-961, (2004); Friedman J., Hastie T., Tibshirani R., A note on the group lasso and a sparse group lasso, arXiv preprint arXiv:1001.0736, (2010); Glorot X., Bordes A., Bengio Y., Deep sparse rectifier neural networks, Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS) 2011, 15, pp. 315-323, (2011); Goodfellow I., Bengio Y., Courville A., Deep learning, (2016); Habib G., Qureshi S., Biomedical image classification using cnn by exploiting deep domain transfer learning, International Journal of Computing and Digital Systems, 10, pp. 2-11, (2020); Habib G., Qureshi S., Comparative analysis of lbp variants with the introduction of new radial and circumferential derivatives, International Journal of Computing and Digital System, (2021); Habib G., Qureshi S., Optimization and acceleration of convolutional neural networks: A survey, Journal of King Saud University-Computer and Information Sciences, 34, 7, pp. 4244-4268, (2022); Han S., Pool J., Tran J., Dally W., Learning both weights and connections for efficient neural network. In Advances in neural information processing systems,, 28, (2015); Hassibi B., Stork D., Second order derivatives for network pruning: Optimal brain surgeon. In Advances in neural information processing systems, vol. 5, (1992); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770–778), (2016); Huang G., Sun Y., Liu Z., Sedra D., Weinberger K.Q., Deep networks with stochastic depth, European conference on computer vision, pp. 646-661, (2016); Huang J., Rathod V., Sun C., Zhu M., Korattikara A., Fathi A., Fischer I., Wojna Z., Song Y., Guadarrama S., Murphy K., Speed/accuracy trade-offs for modern convolutional object detectors. In Proceedings of the IEEE conference on computer vision and pattern recognition, (pp. 7310–7311), (2017); James G., Witten D., Hastie T., Tibshirani R., An introduction to statistical learning, 112, (2013); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, 25, (2012); Lebedev V., Lempitsky V., Fast convnets using group-wise brain damage. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2554–2564), (2016); LeCun Y., Denker J., Solla S., Optimal brain damage. In Advances in neural information processing systems, 2, (1989); Liu Z., Li J., Shen Z., Huang G., Yan S., Zhang C., Learning efficient convolutional networks through network slimming. In Proceedings of the IEEE international conference on computer vision (pp. 2736–2744), (2017); Ma R., Miao J., Niu L., Zhang P., Transformed l<sub>1</sub> regularization for learning sparse deep neural networks, Neural Networks, 119, pp. 286-298, (2019); Mao N., Ye W., Et al., Group variable selection via a combination of L<sub>q</sub> norm and correlation-based penalty, Advances in Pure Mathematics, 7, 1, pp. 51-65, (2017); Marjanovic G., Solo V., On l<sub>q</sub> optimization and matrix completion, IEEE Transactions on Signal Processing, 60, 11, pp. 5714-5724, (2012); Nie F., Wang H., Huang H., Ding C., Adaptive loss minimization for semi-supervised elastic embedding. In Twenty-third international joint conference on artificial intelligence, (2013); Pandit M.K., Banday S.A., Naaz R., Chishti M.A., Automatic detection of covid-19 from chest radiographs using deep learning, Radiography, 27, 2, pp. 483-489, (2021); Parkhi O.M., Vedaldi A., Zisserman A., Deep face recognition, (2015); Rezaeezade A., Batina L., Regularizers to the rescue: Fighting overfitting in deeplearning-based side-channel analysis, (2022); Scardapane S., Comminiello D., Hussain A., Uncini A., Group sparse regularization for deep neural networks, Neurocomputing, 241, pp. 81-89, (2017); Simon N., Friedman J., Hastie T., Tibshirani R., A sparse-group lasso, Journal of Computational and Graphical Statistics, 22, 2, pp. 231-245, (2013); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: A simple way to prevent neural networks from overfitting, The Journal of Machine Learning Research, 15, 1, pp. 1929-1958, (2014); Wen W., Wu C., Wang Y., Chen Y., Li H., Learning structured sparsity in deep neural networks. In Advances in neural information processing systems, vol. 29, (2016); Wen W., Xu C., Wu C., Wang Y., Chen Y., Li H., Coordinating filters for faster deep neural networks. In Proceedings of the IEEE international conference on computer vision (pp. 658–666), (2017); Wu T., Shao J., Gu X., Ng M.K., Zeng T., Two-stage image segmentation based on nonconvex l<sub>2</sub> – l<sub>p</sub> approximation and thresholding, Applied Mathematics and Computation, 403, (2021); Yin P., Zhang S., Lyu J., Osher S., Qi Y., Xin J., Binaryrelax: A relaxation approach for training deep neural networks with quantized weights, SIAM Journal on Imaging Sciences, 11, 4, pp. 2205-2223, (2018); Yoon J., Hwang S.J., Combined group and exclusive sparsity for deep neural networks. In International conference on machine learning (pp. 3958–3966). PMLR, (2017); Zhang S., Xin J., Minimization of transformed L<sub>1</sub> penalty: Theory, difference of convex function algorithm, and robust application in compressed sensing, Mathematical Programming, 169, 1, pp. 307-336, (2018); Zhou H., Alvarez J.M., Porikli F., Less is more: Towards compact cnns, European conference on computer vision, pp. 662-677, (2016)","G. Habib; Department of Computer Science and Engineering, National Institute of Technology Srinagar, Srinagar, 190006, India; email: gousiahabib_01phd19@nitsri.net","","John Wiley and Sons Inc","","","","","","02664720","","EXSYE","","English","Expert Syst","Article","Article in press","","Scopus","2-s2.0-85150632978"
"Maqsood S.; Damaševičius R.; Maskeliūnas R.","Maqsood, Sarmad (57212142651); Damaševičius, Robertas (6603451290); Maskeliūnas, Rytis (27467587600)","57212142651; 6603451290; 27467587600","TTCNN: A Breast Cancer Detection and Classification towards Computer-Aided Diagnosis Using Digital Mammography in Early Stages","2022","Applied Sciences (Switzerland)","12","7","3273","","","","78","10.3390/app12073273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127380874&doi=10.3390%2fapp12073273&partnerID=40&md5=853c3ce2c58f2fc4f4d87679354d58a6","Department of Software Engineering, Kaunas University of Technology, Kaunas, LT-51386, Lithuania; Department of Multimedia Engineering, Kaunas University of Technology, Kaunas, LT-51423, Lithuania","Maqsood S., Department of Software Engineering, Kaunas University of Technology, Kaunas, LT-51386, Lithuania; Damaševičius R., Department of Software Engineering, Kaunas University of Technology, Kaunas, LT-51386, Lithuania; Maskeliūnas R., Department of Multimedia Engineering, Kaunas University of Technology, Kaunas, LT-51423, Lithuania","Breast cancer is a major research area in the medical image analysis field; it is a dangerous disease and a major cause of death among women. Early and accurate diagnosis of breast cancer based on digital mammograms can enhance disease detection accuracy. Medical imagery must be detected, segmented, and classified for computer-aided diagnosis (CAD) systems to help the radiologists for accurate diagnosis of breast lesions. Therefore, an accurate breast cancer detection and classification approach is proposed for screening of mammograms. In this paper, we present a deep learning system that can identify breast cancer in mammogram screening images using an “end-to-end” training strategy that efficiently uses mammography images for computer-aided breast cancer recognition in the early stages. First, the proposed approach implements the modified contrast enhancement method in order to refine the detail of edges from the source mammogram images. Next, the transferable texture convolutional neural network (TTCNN) is presented to enhance the performance of classification and the energy layer is integrated in this work to extract the texture features from the convolutional layer. The proposed approach consists of only three layers of convolution and one energy layer, rather than the pooling layer. In the third stage, we analyzed the performance of TTCNN based on deep features of convolutional neural network models (InceptionResNet-V2, Inception-V3, VGG-16, VGG-19, GoogLeNet, ResNet-18, ResNet-50, and ResNet-101). The deep features are extracted by determining the best layers which enhance the classification accuracy. In the fourth stage, by using the convolutional sparse image decomposition approach, all the extracted feature vectors are fused and, finally, the best features are selected by using the entropy controlled firefly method. The proposed approach employed on DDSM, INbreast, and MIAS datasets and attained the average accuracy of 97.49%. Our proposed transferable texture CNN-based method for classifying screening mammograms has outperformed prior methods. These findings demonstrate that automatic deep learning algorithms can be easily trained to achieve high accuracy in diverse mammography images, and can offer great potential to improve clinical tools to minimize false positive and false negative screening mammography results. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","biomedical image processing; breast cancer detection; computer aided diagnosis; deep learning; digital mammograms","","","","","","","","Xian M., Zhang Y., Cheng H.D., Xu F., Zhang B., Automatic breast ultrasound image segmentation: A survey, Pattern Recognit, 79, pp. 340-355, (2018); Xu C., Gu Z., Liu J., Lin X., Wang C., Li J., Zhuang Z., Adenosquamous carcinoma of the breast: A population-based study, Breast Cancer, 28, pp. 848-858, (2021); Gardezi S.J.S., Elazab A., Lei B., Wang T., Breast cancer detection and diagnosis using mammographic data: Systematic review, J. Med. Internet Res, 21, (2019); Al-Antari M.A., Han S.M., Kim T.S., Evaluation of deep learning detection and classification towards computer-aided diagnosis of breast lesions in digital X-ray mammograms, Comput. Methods Programs Biomed, 196, (2020); Punitha S., Al-Turjman F., Stephan T., An automated breast cancer diagnosis using feature selection and parameter optimization in ANN, Comput. Electr. Eng, 90, (2021); Mao Y.J., Lim H.J., Ni M., Yan W.H., Wong D.W.C., Cheung J.C.W., Breast Tumour Classification Using Ultrasound Elastography with Machine Learning: A Systematic Scoping Review, Cancers, 14, (2022); Dhungel N., Carneiro G., Bradley A.P., A deep learning approach for the analysis of masses in mammograms with minimal user intervention, Med. Image Anal, 37, pp. 114-128, (2017); Al-Antari M.A., Al-Masni M.A., Choi M.T., Han S.M., Kim T.S., A fully integrated computer-aided diagnosis system for digital X-ray mammograms via deep learning detection, segmentation, and classification, Int. J. Med. Inform, 117, pp. 44-54, (2018); Byra M., Breast mass classification with transfer learning based on scaling of deep representations, Biomed. Signal Process. Control, 69, (2021); Assari Z., Mahloojifar A., Ahmadinejad N., Discrimination of benign and malignant solid breast masses using deep residual learning-based bimodal computer-aided diagnosis system, Biomed. Signal Process. Control, 73, (2022); Shen L., Margolies L.R., Rothstein J.H., Fluder E., McBride R., Sieh W., Deep learning to improve breast cancer detection on screening mammography, Sci. Rep, 9, (2019); Jansson D., Dieriks V.B., Rustenhoven J., Smyth L.C., Scotter E., Aalderink M., Dragunow M., Cardiac glycosides target barrier inflammation of the vasculature, meninges and choroid plexus, Commun. Biol, 4, (2021); Song B.I., A machine learning-based radiomics model for the prediction of axillary lymph-node metastasis in breast cancer, Breast Cancer, 28, pp. 664-671, (2021); Mukand N.H., Ko N.Y., Nabulsi N.A., Hubbard C.C., Chiu B.C.H., Hoskins K.F., Calip G.S., The association between physical health-related quality of life, physical functioning, and risk of contralateral breast cancer among older women, Breast Cancer, 29, pp. 287-295, (2021); Abdelrahman L., Ghamdi M.A., Collado-Mesa F., Abdel-Mottaleb M., Convolutional neural networks for breast cancer detection in mammography: A survey, Comput. Biol. Med, 131, (2021); Blakely T., Shaw C., Atkinson J., Cunningham R., Sarfati D., Social inequalities or inequities in cancer incidence? Repeated census-cancer cohort studies, New Zealand 1981–1986 to 2001–2004, Cancer Causes Control, 22, pp. 1307-1318, (2011); Lotter W., Diab A.R., Haslam B., Kim J.G., Grisot G., Wu E., Sorensen A.G., Robust breast cancer detection in mammography and digital breast tomosynthesis using an annotation-efficient deep learning approach, Nat. Med, 27, pp. 244-249, (2021); Dembrower K., Wahlin E., Liu Y., Salim M., Smith K., Lindholm P., Strand F., Effect of artificial intelligence-based triaging of breast cancer screening mammograms on cancer detection and radiologist workload: A retrospective simulation study, Lancet Digit. Health, 2, pp. 468-474, (2020); Chouhan N., Khan A., Shah J.Z., Hussnain M., Khan M.W., Deep convolutional neural network and emotional learning based breast cancer detection using digital mammography, Comput. Biol. Med, 132, (2021); Cancer Stat Facts: Female Breast Cancer; Pacifici S., Murphy A., Mediolateral Oblique View; Sadad T., Munir A., Saba T., Hussain A., Fuzzy c-means and region growing based classification of tumor from mammograms using hybrid texture feature, J. Comput. Sci, 29, pp. 34-45, (2018); Zeebaree D.Q., Abdulazeez A., Zebari D.A., Haron H., Hamed H.N.A., Multi-level fusion in ultrasound for cancer detection based on uniform LBP features, Comput. Mater. Contin, 66, pp. 3363-3382, (2021); Maqsood S., Damasevicius R., Shah F.M., Maskeliunas R., Detection of Macula and Recognition of Aged-Related Macular Degeneration in Retinal Fundus Images, Comput. Inform, 40, pp. 957-987, (2021); Chougrad H., Zouaki H., Alheyane O., Deep convolutional neural networks for breast cancer screening, Comput. Methods Programs Biomed, 157, pp. 19-30, (2018); Kooi T., Litjens G., Ginneken B.V., Gubern-Merida A., Sanchez C.I., Mann R., Karssemeijer N., Large scale deep learning for computer aided detection of mammographic lesions, Med. Image Anal, 35, pp. 303-312, (2017); Maqsood S., Javed U., Multi-modal medical image fusion based on two-scale image decomposition and sparse representation, Biomed. Signal Process. Control, 57, (2020); Muzammil S.R., Maqsood S., Haider S., Damasevicius R., CSID: A Novel Multimodal Image Fusion Algorithm for Enhanced Clinical Diagnosis, Diagnostics, 10, (2020); Maqsood S., Javed U., Riaz M.M., Muzammil M., Muhammad F., Kim S., Multiscale image matting based multi-focus image fusion technique, Electronics, 9, (2020); Jabeen K., Khan M.A., Alhaisoni M., Tariq U., Zhang Y.D., Hamza A., Mickus A., Damasevicius R., Breast Cancer Classification from Ultrasound Images Using Probability-Based Optimal Deep Learning Feature Fusion, Sensors, 22, (2022); Al-Masni M.A., Al-Antari M.A., Choi M.T., Han S.M., Kim T.S., Skin lesion segmentation in dermoscopy images via deep full resolution convolutional networks, Comput. Methods Programs Biomed, 162, pp. 221-231, (2018); Yassin N.I., Omran S., ElHouby E.M., Allam H., Machine learning techniques for breast cancer computer aided diagnosis using different image modalities: A systematic review, Comput. Methods Programs Biomed, 156, pp. 25-45, (2017); Wang D., Khosla A., Gargeya R., Irshad H., Beck A.H., Deep Learning for Identifying Metastatic Breast Cancer, (2016); Carneiro G., Nascimento J., Bradley A.P., Automated analysis of unregistered multi-view mammograms with deep learning, IEEE Trans. Med Imaging, 36, pp. 2355-2365, (2017); Sechopoulos I., Teuwen J., Mann R., Artificial intelligence for breast cancer detection in mammography and digital breast tomosynthesis: State of the art, Semin. Cancer Biol, 72, pp. 214-225, (2021); Al-Masni M.A., Al-Antari M.A., Park J.M., Gi G., Kim T.Y., Rivera P., Kim T.S., Simultaneous detection and classification of breast masses in digital mammograms via a deep learning YOLO-based CAD system, Comput. Methods Programs Biomed, 157, pp. 85-94, (2018); Rezaei Z., A review on image-based approaches for breast cancer detection, segmentation, and classification, Expert Syst. Appl, 182, (2021); Maqsood S., Damasevicius R., Maskeliunas R., Hemorrhage detection based on 3D CNN deep learning framework and feature fusion for evaluating retinal abnormality in diabetic patients, Sensors, 21, (2021); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Adv. Neural Inf. Process. Syst, 25, pp. 1097-1105, (2012); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778, (2016); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, (2014); Szegedy C., Ioffe S., Vanhoucke V., Alemi A.A., Inception-v4, inception-resnet and the impact of residual connections on learning, Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, (2017); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1-9, (2015); Huang G., Liu Z., Maaten L.V.D., Weinberger K.Q., Densely connected convolutional networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4700-4708, (2017); Muduli D., Dash R., Majhi B., Automated breast cancer detection in digital mammograms: A moth flame optimization based ELM approach, Biomed. Signal Process. Control, 59, (2020); Junior G.B., da Rocha S.V., de Almeida J.D., de Paiva A.C., Silva A.C., Gattass M., Breast cancer detection in mammography using spatial diversity, geostatistics, and concave geometry, Multimed. Tools Appl, 78, pp. 13005-13031, (2019); Ghosh S.K., Mitra A., Ghosh A., A novel intuitionistic fuzzy soft set entrenched mammogram segmentation under multigranulation approximation for breast cancer detection in early stages, Expert Syst. Appl, 169, (2021); Zheng J., Lin D., Gao Z., Wang S., He M., Fan J., Deep learning assisted efficient AdaBoost algorithm for breast cancer detection and early diagnosis, IEEE Access, 8, pp. 96946-96954, (2020); Harefa J., Alexander A., Pratiwi M., Comparison classifier: Support vector machine (SVM) and K-nearest neighbor (K-NN) in digital mammogram images, J. Inform. Dan Sist. Inf, 2, pp. 35-40, (2017); Samala R.K., Chan H.P., Hadjiiski L., Helvie M.A., Richter C.D., Cha K.H., Breast cancer diagnosis in digital breast tomosynthesis: Effects of training sample size on multi-stage transfer learning using deep neural nets, IEEE Trans. Med. Imaging, 38, pp. 686-696, (2019); Qi Q., Li Y., Wang J., Zheng H., Huang Y., Ding X., Rohde G.K., Label-efficient breast cancer histopathological image classification, IEEE J. Biomed. Health Inform, 23, pp. 2108-2116, (2018); Agarwal R., Diaz O., Llado X., Yap M.H., Marti R., Automatic mass detection in mammograms using deep convolutional neural networks, J. Med. Imaging, 6, (2019); Irfan R., Almazroi A.A., Rauf H.T., Damasevicius R., Nasr E.A., Abdelgawad A.E., Dilated Semantic Segmentation for Breast Ultrasonic Lesion Detection Using Parallel Feature Fusion, Diagnostics, 11, (2021); Rajinikanth V., Kadry S., Taniar D., Damasevicius R., Rauf H.T., Breast-Cancer Detection using Thermal Images with Marine-Predators-Algorithm Selected Features, Proceedings of the 2021 Seventh International conference on Bio Signals, Images, and Instrumentation (ICBSII), pp. 1-6, (2021); Kadry S., Damasevicius R., Taniar D., Rajinikanth V., Lawal I.A., Extraction of Tumour in Breast MRI using Joint Thresholding and Segmentation—A Study, Proceedings of the 2021 Seventh International conference on Bio Signals, Images, and Instrumentation (ICBSII), pp. 1-5, (2021); Heath M., Bowyer K., Kopans D., Moore R., Kegelmeyer W.P., The digital database for screening mammography, Proceedings of the 5th International Workshop on Digital Mammography, pp. 212-218, (2000); Moreira I.C., Amaral I., Domingues I., Cardoso A., Cardoso M.J., Cardoso J.S., INbreast: Toward a full-field digital mammographic database, Acad. Radiol, 19, pp. 236-248, (2012); Suckling J., Parker J., Dance D., Astley S., Hutt I., Boggis C., Ricketts I., Stamatakis E., Cerneaz N., Kok S., The mammographic images analysis society digital mammogram database, Exerpta Medica Int. Congr. Ser, 1069, pp. 375-378, (1994); Fan R., Li X., Lee S., Li T., Zhang H.L., Smart Image Enhancement Using CLAHE Based on an F-Shift Transformation during Decompression, Electronics, 9, (2020); Zebari D.A., Ibrahim D.A., Zeebaree D.Q., Mohammed M.A., Haron H., Zebari N.A., Damasevicius R., Maskeliunas R., Breast Cancer Detection Using Mammogram Images with Improved Multi-Fractal Dimension Approach and Feature Fusion, Appl. Sci, 11, (2021); Parsi A., Byrne D., Glavin M., Jones E., Heart rate variability feature selection method for automated prediction of sudden cardiac death, Biomed. Signal Process. Control, 65, (2021); Yang X.S., Firefly algorithms for multimodal optimization, International Symposium on Stochastic Algorithms, pp. 169-178, (2009); Zang H., Zhang S., Hapeshi K., A review of nature-inspired algorithms, J. Bionic Eng, 7, pp. 232-237, (2010); Mohanty F., Rup S., Dash B., Majhi B., Swamy M.N.S., Mammogram classification using contourlet features with forest optimization-based feature selection approach, Multimed. Tools Appl, 78, pp. 12805-12834, (2019); Xie W., Li Y., Ma Y., Breast mass classification in digital mammography based on extreme learning machine, Neurocomputing, 173, pp. 930-941, (2016); Mohanty F., Rup S., Dash B., Majhi B., Swamy M.N.S., An improved scheme for digital mammogram classification using weighted chaotic salp swarm algorithm-based kernel extreme learning machine, Appl. Soft Comput, 91, (2020); Zhang H., Wu R., Yuan T., Jiang Z., Huang S., Wu J., Ji D., DE-Ada: A novel model for breast mass classification using cross-modal pathological semantic mining and organic integration of multi-feature fusions, Inf. Sci, 539, pp. 461-486, (2020); Pezeshki H., Rastgarpour M., Sharifi A., Yazdani S., Extraction of spiculated parts of mammogram tumors to improve accuracy of classification, Multimed. Tools Appl, 78, pp. 19979-20003, (2019); Tatikonda K.C., Bhuma C.M., Samayamantula S.K., The analysis of digital mammograms using HOG and GLCM features, Proceedings of the 2018 9th International Conference on Computing, Communication and Networking Technologies (ICCCNT), pp. 1-7, (2018); Pashoutan S., Shokouhi S.B., Pashoutan M., Automatic breast tumor classification using a level set method and feature extraction in mammography, Proceedings of the 2017 24th National and 2nd International Iranian Conference on Biomedical Engineering (ICBME), pp. 1-6, (2017); Aleem J., Qureshi P.A.A.A., Babar N., Sultan A., Rehman A.U., Metastatic Choriocarcinoma of the Breast: A Rare Entity, Cureus, 14, (2022); Shaban M., Raza S.E.A., Hassan M., Jamshed A., Mushtaq S., Loya A., Rajpoot N., A digital score of tumour-associated stroma infiltrating lymphocytes predicts survival in head and neck squamous cell carcinoma, J. Pathol, 256, pp. 174-185, (2022)","R. Damaševičius; Department of Software Engineering, Kaunas University of Technology, Kaunas, LT-51386, Lithuania; email: robertas.damasevicius@ktu.lt","","MDPI","","","","","","20763417","","","","English","Appl. Sci.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85127380874"
"Güler M.; Namlı E.","Güler, Mustafa (58984022900); Namlı, Ersin (55499104800)","58984022900; 55499104800","Brain Tumor Detection with Deep Learning Methods’ Classifier Optimization Using Medical Images","2024","Applied Sciences (Switzerland)","14","2","642","","","","0","10.3390/app14020642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192528413&doi=10.3390%2fapp14020642&partnerID=40&md5=257d5f684d2698f674ea73f7946980ed","Department of Engineering Sciences, Faculty of Engineering, Istanbul University-Cerrahpaşa, Istanbul, 34320, Turkey; Department of Industrial Engineering, Faculty of Engineering, Istanbul University-Cerrahpaşa, Istanbul, 34320, Turkey","Güler M., Department of Engineering Sciences, Faculty of Engineering, Istanbul University-Cerrahpaşa, Istanbul, 34320, Turkey; Namlı E., Department of Industrial Engineering, Faculty of Engineering, Istanbul University-Cerrahpaşa, Istanbul, 34320, Turkey","It is known that, with the development of artificial intelligence science in recent years, it has started to be used in all areas of life. Due to the increase in diseases that threaten human life, such as epidemics and cancer, more attention has been paid to research in this field. Especially in the field of biomedical image processing, very successful results have been obtained in recent years with the use of deep learning methods. For this study, MR images are utilized to diagnose brain tumors. To assist doctors and radiologists in automatic brain tumor diagnosis and to overcome the need for manual diagnosis, a brain MR image automated classification system is being developed. The data used in the study are open access data obtained from the Kaggle library. This paper presents a novel approach for classifying brain MR images utilizing a dataset of 7022 MR images. To give an unbiased evaluation of the dataset, it is divided into a 40% test and 60% training set. Respectively, VGG, ResNet, DenseNet and SqueezeNet architectures are trained and used for feature extraction from brain MRI images. In order to classify the extracted features, machine learning methods (Support Vector Machines, K-Nearest Neighbors, Naive Bayes, Decision Tree, Linear Regression Analysis) are applied first, then an ensemble learning method is applied and the best validation method is selected. In addition, parameter optimization is applied to the trained CNN algorithms. In order to develop the proposed methods, the Python software program was used in the training and testing phases of the models, and the classification success rates were mutually evaluated. Among the results found, it can see that the ResNet architecture reached 100% accuracy. The data obtained as a result of the study were compared with the results of similar studies. In conclusion, the techniques and methods applied highlight their effectiveness in accurately classifying brain MRI images and their potential to improve diagnostic capabilities. © 2024 by the authors.","brain tumor; classification; convolutional neural networks; deep learning; image processing","","","","","","Istanbul University-Cerrahpaşa Scientific Research Projects Coordination Unit, (35916)","This study is derived from Mustafa G\u00FCler\u2019s PhD Thesis. This study was supported by Istanbul University-Cerrahpa\u015Fa Scientific Research Projects Coordination Unit. Project no: 35916.","Mathew A., Amudha P., Sivakumari S., Deep Learning Techniques: An Overview, International Conference on Advanced Machine Learning Technologies and Applications, pp. 599-608, (2020); Apostolopoulos I.D., Aznaouridis S.I., Tzani M.A., Extracting Possibly Representative COVID-19 Biomarkers from X-ray Images with Deep Learning Approach and Image Data Related to Pulmonary Diseases, J. Med. Biol. Eng, 40, pp. 462-469, (2020); Akgul A., Kaya V., Unver E., Karavas E., Baran A., Tuncer S., COVID-19 Detection on X-ray Images Using a Deep Learning Architecture, J. Eng. Res, 11, pp. 15-26, (2022); Younis A., Qiang L., Nyatega C.O., Adamu M.J., Kawuwa H.B., Brain Tumor Analysis Using Deep Learning and VGG-16 Ensembling Learning Approaches, Appl. Sci, 12, (2022); Gurkahraman K., Karakis R., Veri Büyütme Kullanarak Derin Öğrenme ile Beyin Tümörleri Sınıflandırması, Gazi Üniversitesi Mühendislik Mimar. Fakültesi Derg, 36, pp. 997-1011, (2021); Noreen N., Palaniappan S., Qayyum A., Ahmad I., Imran M., Shoaib M., A Deep Learning Model Based on Concatenation Approach for the Diagnosis of Brain Tumor, IEEE Access, 8, pp. 55135-55144, (2020); Kazdal S., Dogan B., Camurcu A.Y., Computer-Aided Detection of Brain Tumors Using Image Processing Techniques, Proceedings of the 2015 23rd Signal Processing and Communications Applications Conference (SIU), pp. 863-866; Ramteke R., Monali K.Y., Automatic Medical Image Classification and Abnormality Detection Using k-Nearest Neighborhood, Int. J Adv. Comput, 2, (2012); Aleid A., Alhussaini K., Alanazi R., Altwaimi M., Altwijri O., Saad A.S., Artificial Intelligence Approach for Early Detection of Brain Tumors Using MRI Images, Appl. Sci, 13, (2023); Sultan H.H., Salem N.M., Al-Atabany W., Multi-Classification of Brain Tumor Images Using Deep Neural Network, IEEE Access, 7, pp. 69215-69225, (2019); Demirhan A., Guler I., Automatic Segmentation of Tumors, Edema and Healthy Tissues in the Brain Using Neural Fuzzy Inference System, Proceedings of the Signal Processing and Communications Applications Conference (SIU), pp. 120-123; Sajjad M., Khan S., Muhammad K., Wu W., Ullah A., Baik S.W., Multi-Grade Brain Tumor Classification Using Deep CNN with Extensive Data Augmentation, J. Comput. Sci, 30, pp. 74-82, (2019); Divya S., Padma Suresh L., John A., A Deep Transfer Learning Framework for Multi Class Brain Tumor Classification Using MRI, Proceedings of the 2020 2nd International Conference on Advances in Computing, Communication Control and Networking (ICACCCN), pp. 283-290; Mercaldo F., Brunese L., Martinelli F., Santone A., Cesarelli M., Object Detection for Brain Cancer Detection and Localization, Appl. Sci, 13, (2023); Paul A., Chauhan P., Sharma H., Khosla K., Srivastava V., Kumar A., Classification of Brain Tumor Images Using Enhanced Deep Learning-based Methodologies, pp. 519-532, (2022); Rehman A., Naz S., Razzak M.I., Akram F., Imran M., A Deep Learning- Based Framework for Automatic Brain Tumors Classification Using Transfer Learning, Circuits Syst. Signal Process, 39, pp. 757-775, (2020); Eker A.G., Duru N., Deep Learning Applications in Medical Image Processing, Acta Infologica, 5, pp. 459-474, (2021); Arora A., Jayal A., Gupta M., Mittal P., Satapathy S.C., Brain Tumor Segmentation of MRI Images Using Processed Image Driven U-Net Architecture, Computers, 10, (2021); Anitha R., Raja D.S.S., Development of Computer-Aided Approach for Brain Tumor Detection Using Random Forest Classifier, Int. J. Imaging Syst. Technol, 28, pp. 48-53, (2017); Akkus Z., Ali I., Sedlar J., Agrawal J.P., Parney I.F., Giannini C., Erickson B.J., Predicting Deletion of Chromosomal Arms in Low-Grade Gliomas from MR Images Using Machine Intelligence, J. Digit. Imaging, 30, pp. 469-476, (2017); Hoffman M., Brain Structure and Its Parts, (2021); Dandil E., Machine Learning Based Brain Tumor Detection Method and Application with MR Images and MR Spectroscopy Data, Ph.D. Thesis, (2015); Tharwat A., Gaber T., Ibrahim A., Hassanien A.E., Linear Discriminant Analysis: A Detailed Tutorial, AI Commun, 30, pp. 169-190, (2017); Goodfellow I., Bengio Y., Courville A., DeepLearning, pp. 164-341, (2016); Guo Y., Liu Y., Oerlemans A., Lao S., Wu S., Lew M.S., Deep learning for visual understanding: A review, Neurocomputing, 187, pp. 27-48, (2016); Gu J., Wang Z., Kuen J., Ma L., Shahroudy A., Shuai B., Chen T., Recent advances in convolutional neural networks, Pattern Recognit, 77, pp. 354-377, (2018); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going Deeper with Convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1-9; Howard A.G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications, arXiv, (2017); Kumar R., Adding Binary Search Connections to Improve DenseNet Performance, Proceedings of the 5th International Conference on Next Generation Computing Technologies (NGCT-2019); Ozyurt F., Sert E., Avci D., An Expert System for Brain Tumor Detection: Fuzzy C- Means with Super Resolution and Convolutional Neural Network with Extreme Learning Machine, Med. Hypotheses, 134, (2020); Hong H., Pradhan B., Bui D.T., Xu C., Youssef A.M., Chen W., Comparison of Four Kernel Functions Used in Support Vector Machines for Landslide Susceptibility Mapping: A Case Study at Suichuan Area (China), Geomat. Nat. Hazards Risk, 8, pp. 544-569, (2017); Hellman M.E., The Nearest Neighbor Classification Rule with a Reject Option, IEEE Trans. Syst. Sci. Cybern, 6, pp. 179-185, (1970); Connelly L., Logistic Regressio, Medsurg. Nurs, 29, pp. 353-354, (2020); Bayes F.R.S., Essay Towards Solving a Problem in the Doctrine of Chances, Biometrica, 45, pp. 296-315, (1958); Yang Y., Temporal Data Mining via Unsupervised Ensemble Learning, (2016); Manikandan G., Karthikeyan B., Rajendiran P., Harish R., Prathyusha T., Sethu V., Breast Cancer Prediction Using Ensemble Techniques, Scopus Ijphrd Cit. Score, 10, (2019); Buber E., Sahingoz O.K., Image Processing with Machine Learning System and Setting Optimal Parameters, Proceedings of the International Artificial Intelligence and Data Processing Symposium, pp. 1-5; Tan M., Chen B., Pang R., Vasudevan V., Sandler M., Howard A., Le Q.V., Mnasnet: Platform-aware neural architecture search for mobile, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2820-2828; Duchi J., Hazan E., Singer Y., Adaptive subgradient methods for online learning and stochastic optimization, J. Mach. Learn. Res, 12, pp. 2121-2159, (2011); Bengio Y., Practical recommendations for gradient-based training of deep architectures, Neural Networks: Tricks of the Trade, pp. 437-478, (2012); Liu Y., Zhou Y., Wen S., Tang C., A Strategy on Selecting Performance Metrics for Classifier Evaluation, Int. J. Mob. Comput. Multimed. Commun, 6, pp. 20-35, (2014); Hossin M., Sulaiman M.N., A Review on Evaluation Metrics for Data Classification Evaluations, Int. J. Data Min. Knowl. Manag. Process, 5, pp. 1-11, (2015)","M. Güler; Department of Engineering Sciences, Faculty of Engineering, Istanbul University-Cerrahpaşa, Istanbul, 34320, Turkey; email: m.guler@iuc.edu.tr","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","20763417","","","","English","Appl. Sci.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85192528413"
"Rabie K.; Karthik C.; Chowdhury S.; Dutta P.K.","Rabie, Khaled (55884933100); Karthik, Chandran (57226546597); Chowdhury, Subrata (57200565797); Dutta, Pushan Kumar (7202355384)","55884933100; 57226546597; 57200565797; 7202355384","Deep learning in medical image processing and analysis","2023","Deep Learning in Medical Image Processing and Analysis","","","","1","358","357","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178972591&partnerID=40&md5=f0ab8a9c4f6734e6ac2cd3e208a91804","Department of Engineering at Manchester Metropolitan University, United Kingdom; Jyothi Engineering College, India; Sreenivasa Institute of Technology and Management Studies, Chittoor, Andhra Pradesh, India; Amity University Kolkata, India","Rabie K., Department of Engineering at Manchester Metropolitan University, United Kingdom; Karthik C., Jyothi Engineering College, India; Chowdhury S., Sreenivasa Institute of Technology and Management Studies, Chittoor, Andhra Pradesh, India; Dutta P.K., Amity University Kolkata, India","Medical images, in various formats, are used by clinicians to identify abnormalities or markers associated with certain conditions, such as cancers, diseases, abnormalities or other adverse health conditions. Deep learning algorithms use vast volumes of data to train the computer to recognise certain features in the images that are associated with the disease or condition that you wish to identify. Whilst analysing the images by eye can take a lot of time, deep learning algorithms have the benefit of reviewing medical images at a faster rate than a human can, which aids the clinician, speeding up diagnoses and freeing up clinicians' time for other duties. Deep Learning in Medical Image Processing and Analysis introduces the fundamentals of deep learning for biomedical image analysis for applications including ophthalmology, cancer detection and heart disease. The book considers the principles of multi-instance feature selection, swarm optimisation, parallel processing models, artificial neural networks, support vector machines, as well as their design and optimisation, in biomedical applications. Topics such as data security, patient confidentiality, effectiveness and reliability will also be discussed. Written by an international team of experts, this edited book covers principles and applications for industry and academic researchers, scientists, engineers, developers, and designers in the fields of machine learning, deep learning, AI, image processing, signal processing, computer science or related fields. It will also be of interest to standards bodies and regulators, and clinicians using deep learning models. © The Institution of Engineering and Technology 2023. All rights reserved.","","","","","","","","","","","","Institution of Engineering and Technology","","","","","","","978-183953794-3; 978-183953793-6","","","English","Deep Learn. in Med. Image Process. and Anal.","Book","Final","","Scopus","2-s2.0-85178972591"
"Shin M.; Seo M.; Lee K.; Yoon K.","Shin, Minwoo (57222380433); Seo, Minjee (58778680400); Lee, Kyunghyun (58945415900); Yoon, Kyungho (57208559577)","57222380433; 58778680400; 58945415900; 57208559577","Super-resolution techniques for biomedical applications and challenges","2024","Biomedical Engineering Letters","14","3","","465","496","31","0","10.1007/s13534-024-00365-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188073218&doi=10.1007%2fs13534-024-00365-4&partnerID=40&md5=306ec4d8fff655a7829bfe31c2deec94","School of Mathematics and Computing (Computational Science and Engineering), Yonsei University, 50 Yonsei-Ro, Seodaemun-Gu, Seoul, 03722, South Korea","Shin M., School of Mathematics and Computing (Computational Science and Engineering), Yonsei University, 50 Yonsei-Ro, Seodaemun-Gu, Seoul, 03722, South Korea; Seo M., School of Mathematics and Computing (Computational Science and Engineering), Yonsei University, 50 Yonsei-Ro, Seodaemun-Gu, Seoul, 03722, South Korea; Lee K., School of Mathematics and Computing (Computational Science and Engineering), Yonsei University, 50 Yonsei-Ro, Seodaemun-Gu, Seoul, 03722, South Korea; Yoon K., School of Mathematics and Computing (Computational Science and Engineering), Yonsei University, 50 Yonsei-Ro, Seodaemun-Gu, Seoul, 03722, South Korea","Super-resolution (SR) techniques have revolutionized the field of biomedical applications by detailing the structures at resolutions beyond the limits of imaging or measuring tools. These techniques have been applied in various biomedical applications, including microscopy, magnetic resonance imaging (MRI), computed tomography (CT), X-ray, electroencephalogram (EEG), ultrasound, etc. SR methods are categorized into two main types: traditional non-learning-based methods and modern learning-based approaches. In both applications, SR methodologies have been effectively utilized on biomedical images, enhancing the visualization of complex biological structures. Additionally, these methods have been employed on biomedical data, leading to improvements in computational precision and efficiency for biomedical simulations. The use of SR techniques has resulted in more detailed and accurate analyses in diagnostics and research, essential for early disease detection and treatment planning. However, challenges such as computational demands, data interpretation complexities, and the lack of unified high-quality data persist. The article emphasizes these issues, underscoring the need for ongoing development in SR technologies to further improve biomedical research and patient care outcomes. © Korean Society of Medical and Biological Engineering 2024.","Biomedical imaging; Biomedical simulation; CT; Deep learning; ECG; EEG; Elastography; Microscopy; MRI; MRS; PET; Spectrometry; Spectroscopy; Super-resolution; Thermography; Ultrasound; X-ray","Bioinformatics; Computational efficiency; Computerized tomography; Deep learning; Electroencephalography; Image enhancement; Medical applications; Medical imaging; Optical resolving power; Ultrasonic applications; bisoprolol fumarate; tracer; Biomedical applications; Biomedical imaging; Biomedical simulation; Computed tomography; Deep learning; Elastography; MRS; Resolution techniques; Superresolution; Thermography; artificial neural network; biomedical application; breast cancer; computer assisted tomography; convolutional neural network; deep learning; deep neural network; diagnostic procedure; elastography; electrocardiogram; electroencephalography; electromagnetic radiation; electromyography; electrophysiology; feature extraction; histology; human; image analysis; image processing; image quality; image reconstruction; image segmentation; learning algorithm; machine learning; mass spectrometry; medical technology; microbubble; microscopy; molecular imaging; morphology; myography; neuroimaging; neurologic disease; nuclear magnetic resonance imaging; nuclear magnetic resonance spectroscopy; particle image velocimetry; positron emission tomography; proteomics; Review; scanning electron microscopy; signal noise ratio; signal processing; single molecule force spectroscopy; stimulated emission depletion microscopy; structured illumination microscopy; super-resolution technique; thermography; three-dimensional imaging; transmission electron microscopy; ultrasound; viscoelasticity; X ray; Magnetic resonance imaging","","bisoprolol fumarate, 104344-23-2, 208523-18-6","","","National Research Foundation of Korea, NRF; Ministry of Science, ICT and Future Planning, MSIP, (RS-2023-00220762); Ministry of Science, ICT and Future Planning, MSIP; Yonsei University Research Fund, (2023-12-0018)","The work was supported in part by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) (No. RS-2023-00220762), and in part by the Yonsei University Research Fund (Post Doc. Researcher Supporting Program) of 2023 (Project No.: 2023-12-0018). ","Li Y., Sixou B., Peyrin F., A review of the deep learning methods for medical images super resolution problems, IRBM, 42, 2, pp. 120-133, (2021); Wang X., Yu K., Wu S., Gu J., Liu Y., Et al., ESRGAN: enhanced super-resolution generative adversarial networks, Computer vision—ECCV 2018 workshops, pp. 63-79, (2019); Nie W., BSD100, Set5, Set14, Urban100 Datasets.; Brain Tumor MRI Dataset; Breast Ultrasound Images Dataset; Chest Ct-Scan Images Dataset; Chest X-Ray Images; Alpaydin E., Machine learning, (2016); Li Z., Dewaraja Y.K., Fessler J.A., Training End-to-End unrolled iterative neural networks for SPECT image reconstruction, IEEE Trans Radiat Plasma Med Sci, 7, 4, pp. 410-420, (2023); He Z., Zhu Y.N., Chen Y., Chen Y., He Y., Et al., A deep unrolled neural network for real-time MRI-guided brain intervention, Nat Commun, 14, 1, (2023); Yan Q., Liu L., Mei L., Learning unrolling-based neural network for magnetic resonance imaging reconstruction, Image Analysis and processing—ICIAP, 21St International Conference, Lecce, Italy, May 23–27, 2022, pp. 124-136, (2022); Souza R., Frayne R., A hybrid frequency-domain/image-domain deep network for magnetic resonance image reconstruction, 32Nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI); 2019. P, pp. 257-264, (2019); Ye J.C., Han Y., Cha E., Deep convolutional framelets: A general deep learning framework for inverse problems, SIAM J Imaging Sci, 11, 2, pp. 991-1048, (2018); Ali H.M., High-Resolution Neuroimaging, Intechopen, Rijeka, Chap. 7, (2018); Chung H., Ye J.C., Score-based diffusion models for accelerated MRI, Med Image Anal, 80, (2022); Xiang T., Yurt M., Syed A.B., Setsompop K., Chaudhari A., DDM 2: Self-supervised diffusion MRI denoising with generative diffusion models, : The Eleventh International Conference on Learning Representations; 2023.; Zein M.E., Laz W.E., Laza M., Wazzan T., Kaakour I., Et al., A deep learning framework for denoising MRI images using autoencoders, 5Th International Conference on Bio-Engineering for Smart Technologies (Biosmart); 2023. P, pp. 1-4, (2023); Ben Yedder H., Cardoen B., Hamarneh G., Deep learning for biomedical image reconstruction: a survey, Artif Intell Rev, 54, 1, pp. 215-251, (2021); Kaur H., Rani J. MRI brain image enhancement using histogram equalization techniques, 2016 international conference on wireless communications, signal processing and networking (WiSPNET), pp. 770-773, (2016); Kalyani J., Chakraborty M., Contrast enhancement of MRI images using histogram equalization techniques, International Conference on Computer, Electrical & Communication Engineering (ICCECE, pp. 1-5, (2020); Zimmerman J., Pizer S., Staab E., Perry J., McCartney W., Et al., An evaluation of the effectiveness of adaptive histogram equalization for contrast enhancement, IEEE Trans Med Imaging, 7, 4, pp. 304-312, (1988); Anand S., Shantha R., Selva K., Sharpening enhancement of computed tomography (CT) images using hyperbolic secant square filter, Optik, 124, 15, pp. 2121-2124, (2013); Wang G., Ye J.C., De Man B., Deep learning for tomographic image reconstruction, Nat Mach Intell, 2, 12, pp. 737-748, (2020); Sarker I.H., Deep learning: A comprehensive overview on techniques, taxonomy, applications and research directions, SN Comput Sci, 2, 6, (2021); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: a simple way to prevent neural networks from overfitting, J Mach Learn Res, 15, 1, pp. 1929-1958, (2014); Livni R.S., Shalev-Shwartz O., Shamir, On the computational efficiency of training neural networks, Editors. Advances in Neural Information Processing Systems, 27, (2014); Abd-Elmoniem K., Youssef A.B., Kadah Y., Real-time speckle reduction and coherence enhancement in ultrasound imaging via nonlinear anisotropic diffusion, IEEE Trans Biomed Eng, 49, 9, pp. 997-1014, (2002); Burle B., Spieser L., Roger C., Casini L., Hasbroucq T., Et al., Spatial and temporal resolutions of EEG: Is it really black and white? a scalp current density view, Int J Psychophysiol, 97, 3, pp. 210-220, (2015); Shen K., Lu H., Baig S., Wang M.R., Improving lateral resolution and image quality of optical coherence tomography by the multi-frame superresolution technique for 3D tissue imaging, Biomed Opt Express, 8, 11, pp. 4887-4918, (2017); Bono S., Konishi S., Temperature gradient sensing mechanism using liquid crystal droplets with 0.1-mk-level detection accuracy and high spatial resolution, Sci Rep, 12, 1, (2022); Zhang J., Sun K., Yang J., Hu Y., Gu Y., Et al., A generalized dual-domain generative framework with hierarchical consistency for medical image reconstruction and synthesis, Commun Eng, 2, 1, (2023); Wen Y., Chen L., Deng Y., Zhou C., Rethinking pre-training on medical imaging, J Vis Commun Image Represent, 78, (2021); Huang S.C., Pareek A., Jensen M., Lungren M.P., Yeung S., Et al., Self-supervised learning for medical image classification: a systematic review and implementation guidelines, NPJ Digit Med, 6, 1, (2023); Ahmad W., Ali H., Shah Z., Azmat S., A new generative adversarial network for medical images super resolution, Sci Rep, 12, 1, (2022); Michailovich O., Tannenbaum A., Despeckling of medical ultrasound images, IEEE Trans Ultrason Ferroelectr Freq Control, 53, 1, pp. 64-78, (2006); Moinuddin M., Khan S., Alsaggaf A.U., Abdulaal M.J., Al-Saggaf U.M., Et al., Medical ultrasound image speckle reduction and resolution enhancement using texture compensated multi-resolution convolution neural network, Front Physiol, (2022); Niyas S., Pawan S., Anand Kumar M., Rajan J., Medical image segmentation with 3d convolutional neural networks: a survey, Neurocomputing, 493, pp. 397-413, (2022); de Leeuw M.L., den Bouter G., Ippolito T.P.A., O'Reilly T.P.A., Remis R.F., van Gijzen M.B., Et al., Deep learning-based single image super-resolution for low-field MR brain images, Sci Rep, 12, 1, (2022); Huang B., Xiao H., Liu W., Zhang Y., Wu H., Et al., MRI super-resolution via realistic downsampling with adversarial learning, Phys Med Biol, 66, 20, (2021); Jin C., Tanno R., Mertzanidou T., Panagiotaki E., Alexander D.C., Learning to downsample for segmentation of ultra-high resolution images, : International Conference on Learning Representations; 2022; Peled S., Yeshurun Y., Superresolution in MRI: application to human white matter fiber tract visualization by diffusion tensor imaging, Magn Reson Med, 45, 1, pp. 29-35, (2001); Greenspan H., Oz G., Kiryati N., Peled S., MRI inter-slice reconstruction using super-resolution, Magn Reson Imaging, 20, 5, pp. 437-446, (2002); Zhai Y., Yao D., A radial-basis function based surface Laplacian estimate for a realistic head model, Brain Topogr, 17, 1, pp. 55-62, (2004); Rousseau F., Glenn O.A., Iordanova B., Rodriguez-Carranza C., Vigneron D.B., Et al., Registration-based approach for reconstruction of high-resolution in utero fetal MR brain images, Acad Radiol, 13, 9, pp. 1072-1081, (2006); Dey N., Blanc-Feraud L., Zimmer C., Roux P., Kam Z., Et al., Richardson-Lucy algorithm with total variation regularization for 3D confocal microscope deconvolution, Microsc Res Tech, 69, 4, pp. 260-266, (2006); Joshi S.H., Marquina A., Osher S.J., Dinov I., Van Horn J.D., Et al., MRI resolution enhancement using total variation regularization, 2009 IEEE international symposium on biomedical imaging: from nano to macro, pp. 161-164, (2009); Akhtar P., Azhar F., A single image interpolation scheme for enhanced super resolution in bio-medical imaging, 2010 4Th International Conference on Bioinformatics and Biomedical Engineering, pp. 1-5, (2010); Tieng Q.M., Cowin G.J., Reutens D.C., Galloway G.J., Vegh V., MRI resolution enhancement: How useful are shifted images obtained by changing the demodulation frequency?, Magn Reson Med, 65, 3, pp. 664-672, (2011); Nallikuzhy J.J., Sharma L.N., Dandapat S., Projection based approach for super-resolution ECG, 2013 IEEE 1st international conference on condition assessment techniques in electrical systems (CATCON), pp. 270-274, (2013); Zhang H., Huang J., Ma J., Bian Z., Feng Q., Et al., Iterative reconstruction for X-ray computed tomography using prior-image induced nonlocal regularization, IEEE Trans Biomed Eng, 61, pp. 2367-2378, (2014); Nayak R., Harshavardhan S., Patra D., Morphology based iterative back-projection for super-resolution reconstruction of image, In: 2014 2Nd International Conference on Emerging Technology Trends in Electronics, Communication and Networking, pp. 1-6, (2014); Yu W., Zeng L., ℓ<sub>0</sub> gradient minimization based image reconstruction for limited-angle computed tomography, PLoS ONE, 10, 7, (2015); Abd-Almajeed A., Langevin F., Sub-pixel shifted acquisitions for super-resolution proton magnetic resonance spectroscopy (1h MRS) mapping, Magn Reson Imaging, 33, 4, pp. 448-458, (2015); Chan A.C.S., Ng H.C., Bogaraju S.C.V., So H.K.H., Lam E.Y., Et al., All-passive pixel super-resolution of time-stretch imaging, Sci Rep, 7, 1, (2017); Huang Y., Shao L., Frangi A.F., Simultaneous super-resolution and cross-modality synthesis of 3D medical images using weakly-supervised joint convolutional sparse coding, In,. IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society, Los Alamitos, CA. USA., pp. 5787-5796, (2017); Zhang J., Sun J., Chen Q., Li J., Zuo C., Adaptive pixel-super-resolved lensfree in-line digital holography for wide-field on-chip microscopy, Sci Rep, 7, 1, (2017); Song P., Trzasko J.D., Manduca A., Huang R., Kadirvel R., Et al., Improved super-resolution ultrasound microvessel imaging with spatiotemporal nonlocal means filtering and bipartite graph-based microbubble tracking, IEEE Trans Ultrason Ferroelectr Freq Control, 65, 2, pp. 149-167, (2018); Liu C., Wu X., Yu X., Tang Y., Zhang J., Et al., Fusing multi-scale information in convolution network for MR image super-resolution reconstruction, Biomed Eng Online, 17, 1, (2018); Bar-Zion A., Solomon O., Tremblay-Darveau C., Adam D., Eldar Y.C., SUSHI: Sparsity-based ultrasound super-resolution hemodynamic imaging, IEEE Trans Ultrason Ferroelectr Freq Control, 65, 12, pp. 2365-2380, (2018); Umehara K., Ota J., Ishida T., Application of super-resolution convolutional neural network for enhancing image resolution in chest CT, J Digit Imaging, 31, 4, pp. 441-450, (2018); Corley I.A., Huang Y., Deep EEG super-resolution: Upsampling EEG spatial resolution with generative adversarial networks, IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), pp. 100-103, (2018); Song T.A., Chowdhury S.R., Kim K., Gong K., Fakhri G.E., Et al., Super-resolution PET using a very deep convolutional neural network, . In: 2018 IEEE Nuclear Science Symposium and Medical Imaging Conference Proceedings (NSS/MIC), pp. 1-2, (2018); Xu J., Zhao Y., Li H., Zhang P., An image reconstruction model regularized by edge-preserving diffusion and smoothing for limited-angle computed tomography, Inverse Probl, (2019); Iqbal Z., Nguyen D., Hangel G., Motyka S., Bogner W., Et al., Super-resolution (1)H magnetic resonance spectroscopic imaging utilizing deep learning, Front Oncol, 9, (2019); Hatvani J., Basarab A., Tourneret J.Y., Gyongy M., Kouame D., A tensor factorization method for 3-D super resolution with application to dental CT, IEEE Trans Med, 38, 6, pp. 1524-1531, (2019); Kwon M., Han S., Kim K., Jun S.C., Super-resolution for improving EEG spatial resolution using deep convolutional neural network—feasibility study, Sensors, (2019); Song T.A., Yang F., Chowdhury S.R., Kim K., Johnson K.A., Et al., PET image deblurring and super-resolution with an MR-based joint entropy prior, IEEE Trans Comput, 5, 4, pp. 530-539, (2019); Salami P., Yousefi L., Far-field imaging beyond the diffraction limit using waves interference, J Lightwave Technol, 38, 8, pp. 2322-2327, (2020); Song T.A., Chowdhury S., Yang F., Dutta J., Super-resolution PET imaging using convolutional neural networks, IEEE Trans Comput, (2020); Song T.A., Chowdhury S.R., Yang F., Dutta J., PET image super-resolution using generative adversarial networks, Neural Netw, 125, pp. 83-91, (2020); Ayas S., Ekinci M., Microscopic image super resolution using deep convolutional neural networks, Multimedia Tools Appl, 79, 21, pp. 15397-15415, (2020); He L., Peng B., Yang T., Jiang J., An application of super-resolution generative adversary networks for quasi-static ultrasound strain elastography: A feasibility study, IEEE Access, 8, pp. 65769-65779, (2020); Lyu Q., Shan H., Wang G., MRI super-resolution with ensemble learning and complementary priors, IEEE Trans Comput, 6, pp. 615-624, (2020); Zhu Y., Zhou Z., Liao G., Yuan K., CSRGAN: Medical image super-resolution using a generative adversarial network, 2020 IEEE 17Th International Symposium on Biomedical Imaging Workshops, pp. 1-4, (2020); Chen R., Tang X., Zhao Y., Shen Z., Zhang M., Et al., Single-frame deep-learning super-resolution microscopy for intracellular dynamics imaging, Nat Commun, 14, 1, (2023); Shah Z.H., Muller M., Wang T.C., Scheidig P.M., Schneider A., Et al., Deep-learning based denoising and reconstruction of super-resolution structured illumination microscopy images, Photon Res, 9, 5, pp. B168-B181, (2021); van Sloun R.J.G., Solomon O., Bruce M., Khaing Z.Z., Wijkstra H., Et al., Super-resolution ultrasound localization microscopy through deep learning, IEEE Trans Med, 40, 3, pp. 829-839, (2021); Park S., Gach H.M., Kim S., Lee S.J., Motai Y., Autoencoder-inspired convolutional network-based super-resolution method in MRI, IEEE J Transl Eng Health Med, 9, pp. 1-13, (2021); Xia Y., Ravikumar N., Greenwood J.P., Neubauer S., Petersen S.E., Et al., Super-resolution of cardiac MR cine imaging using conditional GANs and unsupervised transfer learning, Med Image Anal, 71, (2021); Brown K.G., Waggener S.C., Redfern A.D., Hoyt K., Faster super-resolution ultrasound imaging with a deep learning model for tissue decluttering and contrast agent localization, Biomed Phys Eng Express, 7, 6, (2021); Parteka-Tojek Z., Zhu J.J., Lee B., Jodkowska K., Wang P., Et al., Super-resolution visualization of chromatin loop folding in human lymphoblastoid cells using interferometric photoactivated localization microscopy, Sci Rep, 12, 1, (2022); Shit S., Zimmermann J., Ezhov I., Paetzold J.C., Sanches A.F., Et al., SRflow: deep learning based super-resolution of 4D-flow MRI data, Front Artif Intell, (2022); Marini M., Bouzin M., Scodellaro R., D'Alfonso L., Sironi L., Et al., Quantitative active super-resolution thermal imaging: The melanoma case study, Biomol Concepts, 13, 1, pp. 242-255, (2022); Chi J., Sun Z., Wang H., Lyu P., Yu X., Et al., CT image super-resolution reconstruction based on global hybrid attention, Comput Biol Med, 150, (2022); Yu H., Wang S., Fan Y., Wang G., Li J., Et al., Large-factor micro-CT super-resolution of bone microstructure, Front Phys, (2022); Chemli Y., Tetrault M.A., Marin T., Normandin M.D., Bloch I., Et al., Super-resolution in brain positron emission tomography using a real-time motion capture system, Neuroimage, 272, (2023); Qiao C., Li D., Liu Y., Zhang S., Liu K., Et al., Rationalized deep learning super-resolution microscopy for sustained live imaging of rapid subcellular processes, Nat Biotechnol, 41, 3, pp. 367-377, (2023); Li S., Wang G., Modified kernel MLAA using autoencoder for PET-enabled dual-energy CT, Philos Trans R Soc, 379, 2204, (2021); Kozhinov A.N., Johnson A., Nagornov K.O., Stadlmeier M., Martin W.L., Et al., Super-resolution mass spectrometry enables rapid, accurate, and highly multiplexed proteomics at the MS2 level, Anal Chem, 95, 7, pp. 3712-3719, (2023); Liao T., Ren Z., Chai Z., Yuan M., Miao C., Et al., A super-resolution strategy for mass spectrometry imaging via transfer learning, Nat Mach Intell, 5, 6, pp. 656-668, (2023); Chen K., Choudhary A., Sandler S.E., Maffeo C., Ducati C., Et al., Super-resolution detection of DNA nanostructures using a nanopore, Adv Mater, 35, 12, (2023); Senalp F.M., Ceylan M., A new approach for super-resolution and classification applications on neonatal thermal images, Quant Infrared Thermogr J, (2023); Chen T.M., Tsai Y.H., Tseng H.H., Liu K.C., Chen J.Y., Et al., SRECG: ECG signal super-resolution framework for portable/wearable devices in cardiac arrhythmias classification, IEEE Trans Consum Electron, (2023); Shin M., Peng Z., Kim H.J., Yoo S.S., Yoon K., Multivariable-incorporating super-resolution residual network for transcranial focused ultrasound simulation, Comput Methods Programs Biomed, 237, (2023); Li H., Huang Y., Kuang C., Liu X., Method of super-resolution based on array detection and maximum-likelihood estimation, Appl Opt, 55, 35, pp. 9925-9931, (2016); Capel D., Super-resolution: maximum Likelihood and related approaches, pp. 81-136, (2004); Zhang Y., Tao M., Yang K., Deng Z., Video superresolution reconstruction using iterative back projection with critical-point filters based image matching, Adv Multimed, 2015, (2015); Mukamel E.A., Babcock H., Zhuang X., Statistical deconvolution for superresolution fluorescence microscopy, Biophys J, 102, 10, pp. 2391-2400, (2012); Zhao W., Zhao S., Li L., Huang X., Xing S., Et al., Sparse deconvolution improves the resolution of live-cell super-resolution fluorescence microscopy, Nat Biotechnol, 40, 4, pp. 606-617, (2022); Mahmoudzadeh A.P., Kashou N.H., Interpolation-based super-resolution reconstruction: effects of slice thickness, J Med Imaging, 1, 3, (2014); Patil V.H., Bormane D.S., Interpolation for super resolution imaging, Innovations and advanced techniques in computer and information sciences and engineering, pp. 483-489, (2007); Yu L., Cao S., He J., Sun B., Dai F., Single-image super-resolution based on regularization with stationary gradient fidelity, 10Th International Congress on Image and Signal Processing, Biomedical Engineering and Informatics (CISP-BMEI), pp. 1-5, (2017); Shi F., Cheng J., Wang L., Yap P.T., Shen D., Low-rank total variation for image super-resolution, Med Image Comput Assist Interv, 16, pp. 155-162, (2013); Heintzmann R., Huser T., Super-resolution structured illumination microscopy, Chem Rev, 117, 23, pp. 13890-13908, (2017); Scupakova K., Terzopoulos V., Jain S., Smeets D., Heeren R.M.A., A patch-based super resolution algorithm for improving image resolution in clinical mass spectrometry, Sci Rep, 9, 1, (2019); Prakash K., Diederich B., Heintzmann R., Schermelleh L., Super-resolution microscopy: a brief history and new avenues, Philos Trans R Soc, 380, 2220, (2022); Schermelleh L., Ferrand A., Huser T., Eggeling C., Sauer M., Et al., Super-resolution microscopy demystified, Nat Cell Biol, 21, 1, pp. 72-84, (2019); Katti G., Ara S.A., Shireen A., Magnetic resonance imaging (MRI)—a review, Int J Dent Clin, 3, 1, pp. 65-70, (2011); Gujar S.K., Maheshwari S., Bjorkman-Burtscher I., Sundgren P.C., Magnetic resonance spectroscopy, J Neuroophthalmol, 25, 3, pp. 217-226, (2005); Buonocore M.H., Maddock R.J., Magnetic resonance spectroscopy of the brain: a review of physical principles and technical methods, Rev Neurosci, 26, 6, pp. 609-632, (2015); Jog A., Carass A., Prince J.L., Self super-resolution for magnetic resonance images, Med Image Comput Comput Assist Interv, 9902, pp. 553-560, (2016); Rontgen W.C., On a new kind of rays, Science, 3, 59, pp. 227-231, (1896); Dai W.C., Wen Zhang H., Yu J., Jian H., Xu H., Chen H., Et al., CT imaging and differential diagnosis of COVID-19, Can Assoc Radiol J, 71, 2, pp. 195-200, (2020); Pisani P., Screening and early diagnosis of osteoporosis through X-ray and ultrasound based techniques, World J Radiol, 5, 11, (2013); Lee J.H., Kim Y.J., Kim K.G., Bone age estimation using deep learning and hand X-ray images, Biomed Eng Lett, 10, 3, pp. 323-331, (2020); Keall P., 4-dimensional computed tomography imaging and treatment planning, Semin Radiat Oncol, 14, 1, pp. 81-90, (2004); U.N.S.C. on the Effects of Atomic Radiation. Sources and effects of ionizing radiation, (2000); Sano Y., Mori T., Goto T., Hirano S., Funahashi K., Super-resolution method and its application to medical image processing, 2017 IEEE 6Th Global Conference on Consumer Electronics (GCCE), pp. 1-2, (2017); Yan Z., Li J., Lu Y., Yan H., Zhao Y., Super resolution in CT, Int J Imaging Syst Technol, 25, 1, pp. 92-101, (2015); Alauddin M.M., Positron emission tomography (PET) imaging with (18) F-based radiotracers, Am J Nucl Med Mol Imaging, 2, 1, pp. 55-76, (2011); Ito M., Hong S.J., Lee J.S., Positron emission tomography (PET) detectors with depth-of-interaction (DOI) capability, Biomed Eng Lett, 1, 2, pp. 70-81, (2011); Crisan G., Moldovean-Cioroianu N.S., Timaru D.G., Andries G., Cainap C., Et al., Radiopharmaceuticals for PET and SPECT imaging: a literature review over the last decade, Int J Mol Sci, 23, 9, (2022); Zhu A., Lee D., Shim H., Metabolic positron emission tomography imaging in cancer detection and therapy response, Semin Oncol, 38, 1, pp. 55-69, (2011); Shukla A.K., Kumar U., Positron emission tomography: An overview, J Med Phys, 31, 1, pp. 13-21, (2006); Ahn I.J., Kim J.H., Chang Y., Nam W.H., Ra J.B., Super-resolution reconstruction of 3D PET images using two respiratory-phase low-dose CT images, IEEE Trans Radiat Plasma Med Sci, 1, 1, pp. 46-55, (2017); Zhu Y., Spencer B.A., Xie Z., Leung E.K., Bayerlein R., Super-resolution reconstruction of γ -ray CT images for PET-enabled dual-energy CT imaging, Medical Imaging 2023: Physics of Medical Imaging. International Society for Optics and Photonics, (2023); Wells P.N.T., Liang H.D., Medical ultrasound: imaging of soft tissue strain and elasticity, J R Soc Interface, 8, 64, pp. 1521-1549, (2011); Ng A., Swanevelder J., Resolution in ultrasound imaging, CEACCP, 11, 5, pp. 186-192, (2011); Cox B., Beard P., Super-resolution ultrasound, Nature, 527, 7579, pp. 451-452, (2015); Errico C., Pierre J., Pezet S., Desailly Y., Lenkei Z., Et al., Ultrafast ultrasound localization microscopy for deep super-resolution vascular imaging, Nature, 527, 7579, pp. 499-502, (2015); Viessmann O.M., Eckersley R.J., Christensen-Jeffries K., Tang M.X., Dunsby C., Acoustic super-resolution with ultrasound and microbubbles, Phys Med Biol, 58, 18, pp. 6447-6458, (2013); Abbe E., Beiträge zur theorie des mikroskops und der mikroskopischen wahrnehmung, Arch Mikr Anat, 9, 1, pp. 413-468, (1873); Yu J., Lavery L., Kim K., Super-resolution ultrasound imaging method for microvasculature in vivo with a high temporal accuracy, Sci Rep, 8, 1, (2018); Mathon B., Clemenceau S., The Temporal Lobe, Handbook of Clinical Neurology, 187, pp. 531-556, (2022); Lerosey G., de Rosny J., Tourin A., Fink M., Focusing beyond the diffraction limit with far-field time reversal, Science, 315, 5815, pp. 1120-1122, (2007); Chen S., Moitra A. Algorithmic foundations for the diffraction limit, . In: Proceedings of the 53Rd Annual ACM SIGACT Symposium on Theory of Computing (Association for Computing Machinery, 2021, pp. 490-503; Kim M., Rho J., Metamaterials and imaging, Nano Converg, 2, 1, (2015); Zemzemi C., Zorgani A., Daunizeau L., Belabhar S., Souchon R., Et al., Super-resolution limit of shear-wave elastography, EPL, 129, 3, (2020); Krikler D.M., Historical aspects of electrocardiography, Cardiol Clin, 5, 3, pp. 349-355, (1987); Rundo F., Conoci S., Ortis A., Battiato S., An advanced bio-inspired PhotoPlethysmoGraphy (PPG) and ECG pattern recognition system for medical assessment, Sensors, (2018); Rashed-Al-Mahfuz M., Moni M.A., Lio' P., Islam S.M.S., Berkovsky S., Et al., Deep convolutional neural networks based ECG beats classification to diagnose cardiovascular conditions, Biomed Eng Lett, 11, 2, pp. 147-162, (2021); Rautaharju P.M., Surawicz B., Gettes L.S., Bailey J.J., Childers R., Et al., AHA/ACCF/HRS recommendations for the standardization and interpretation of the electrocardiogram: part IV: the ST segment, T and U waves, and the QT interval, J Am Coll Cardiol, 53, 11, pp. 982-991, (2009); Light G.A., Williams L.E., Minow F., Sprock J., Rissling A., Electroencephalography (EEG) and event-related potentials (ERPs) with human participants., 6, Chapter 6,, pp. 1-24, (2010); Biasiucci A., Franceschiello B., Murray M.M., Electroencephalography, Curr Biol, 29, 3, pp. R80-R85, (2019); Raez M.B.I., Hussain M.S., Mohd-Yasin F., Techniques of EMG signal analysis: detection, processing, classification and applications, Biol Proced Online, 8, pp. 11-35, (2006); Hu Y., Cheng Z., Fan X., Liang Z., Zhai X., Optimizing the quality of Fourier single-pixel imaging via generative adversarial network, Optik, 227, (2021); Wenwen M., Dongfeng S., Jian H., Kee Y., Yingjian W., Et al., Sparse Fourier single-pixel imaging, Opt Express, 27, 22, pp. 31490-31503, (2019); Srinivasan R., Nunez P.L., Tucker D.M., Silberstein R.B., Cadusch P.J., Spatial sampling and filtering of EEG with spline Laplacians to estimate cortical potentials, Brain Topogr, 8, 4, pp. 355-366, (1996); Michel C.M., Brunet D., EEG source imaging: a practical review of the analysis steps, Front Neurol, (2019); Somani S., Russak A.J., Richter F., Zhao S., Vaid A., Et al., Deep learning and the electrocardiogram: review of the current state-of-the-art, Europace, 23, 8, pp. 1179-1191, (2021); Xie L., Li Z., Zhou Y., He Y., Zhu J., Computational diagnostic techniques for electrocardiogram signal analysis, Sensors, (2020); Wang H., Zuo S., Cerezo-Sanchez M., Arekhloo N.G., Nazarpour K., Et al., Wearable super-resolution muscle–machine interfacing, Front Neurosci, (2022); Karhana S., Bhat M., Ninawe A., Dinda A.K., Biomedical imaging instrumentation, Primers in biomedical imaging devices and systems, pp. 185-212, (2022); Bond C., Santiago-Ruiz A.N., Tang Q., Lakadamyali M., Technological advances in super-resolution microscopy to study cellular processes, Mol Cell, 82, 2, pp. 315-332, (2022); Sun N., Jia Y., Bai S., Li Q., Dai L., Et al., The power of super-resolution microscopy in modern biomedical science, Adv Colloid Interface Sci, 314, (2023); Xu J., Ma H., Ma H., Jiang W., Mela C.A., Et al., Super-resolution imaging reveals the evolution of higher-order chromatin folding in early carcinogenesis, Nat Commun, 11, 1, (2020); Lelek M., Gyparaki M.T., Beliu G., Schueder F., Griffie J., Et al., Single-molecule localization microscopy, Nat Rev Methods Primers, 1, 1, (2021); Birk U.J., Super-resolution microscopy of chromatin, Genes (Basel), (2019); West J.A., Mito M., Kurosaka S., Takumi T., Tanegashima C., Et al., Structural, super-resolution microscopy analysis of paraspeckle nuclear body organization, J Cell Biol, 214, 7, pp. 817-830, (2016); Shim S.H., Super-resolution microscopy of genome organization, Genes Genom, 43, 3, pp. 281-287, (2021); Castells-Garcia A., Ed-daoui I., Gonzalez-Almela E., Vicario C., Ottestrom J., Et al., Super resolution microscopy reveals how elongating RNA polymerase II and nascent RNA interact with nucleosome clutches, Nucleic Acids Res, 50, 1, pp. 175-190, (2021); Gagnon L., Imaging the genome in 3D at super resolution, Microscopy Today, 28, 6, pp. 18-26, (2020); Reinhard S., Aufmkolk S., Sauer M., Doose S., Registration and visualization of correlative super-resolution microscopy data, Biophys J, 116, 11, pp. 2073-2078, (2019); Ballard D., Generalizing the Hough transform to detect arbitrary shapes, Pattern Recognit, 13, 2, pp. 111-122, (1981); Han K., Hua X., Vasani V., Kim G.A.R., Liu W., Et al., 3D super-resolution live-cell imaging with radial symmetry and Fourier light-field microscopy, Biomed Opt Express, 13, 11, pp. 5574-5584, (2022); Torres-Garcia E., Pinto-Camara R., Linares A., Martinez D., Abonza V., Et al., Extending resolution within a single imaging frame, Nat Commun, 13, 1, (2022); Shaked E., Dolui S., Michailovich O.V., Regularized Richardson-Lucy algorithm for reconstruction of Poissonian medical images, 2011 IEEE international symposium on biomedical imaging: from nano to macro, pp. 1754-1757, (2011); Lambert T.J., Waters J.C., Navigating challenges in the application of superresolution microscopy, J Cell Biol, 216, 1, pp. 53-63, (2016); Infante H.G., Warren J., Chalmers J., Dent G., Todoli J.L., Et al., Glossary of methods and terms used in analytical spectroscopy (IUPAC recommendations 2019), Pure Appl Chem, 93, 6, pp. 647-776, (2021); Miyamoto S., Hsu C.C., Hamm G., Darshi M., Diamond-Stanic M., Et al., Mass spectrometry imaging reveals elevated glomerular ATP/AMP in diabetes/obesity and identifies sphingomyelin as a possible mediator, EBioMedicine, 7, pp. 121-134, (2016); Buchberger A.R., DeLaney K., Johnson J., Li L., Mass spectrometry imaging: A review of emerging advancements and future insights, Anal Chem, 90, 1, pp. 240-265, (2017); Goodwin R.J.A., Takats Z., Bunch J., A critical and concise review of mass spectrometry applied to imaging in drug discovery, SLAS Discov, 25, 9, pp. 963-976, (2020); Qiu S., Cai Y., Yao H., Lin C., Xie Y., Et al., Small molecule metabolites: discovery of biomarkers and therapeutic targets, Signal Transduct Target Ther, 8, 1, (2023); Kovac J., Foundations of spectroscopy (Oxford chemistry primers no. 78) (Duckett, Simon; Gilbert, Bruce), J Chem Educ, 80, 9, (2003); Jia H., Wang Y., Xu S., Super-resolution force spectroscopy reveals ribosomal motion at sub-nucleotide steps, Chem Commun, 54, pp. 5883-5886, (2018); Usamentiaga R., Venegas P., Guerediaga J., Vega L., Molleda J., Et al., Infrared thermography for temperature measurement and non-destructive testing, Sensors, 14, 7, pp. 12305-12348, (2014); Rakhunde M.B., Gotarkar S., Choudhari S.G., Thermography as a breast cancer screening technique: a review article, Cureus, 14, 11, (2022); Marnissi M.A., Fathallah A., GAN-based vision Transformer for high-quality thermal image enhancement, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pp. 817-825, (2023); Dong C., Loy C.C., He K., Tang X., Learning a deep convolutional network for image super-resolution, Computer vision—ECCV 2014. Cham, pp. 184-199, (2014); Sun N., Li H., Super resolution reconstruction of images based on interpolation and full convolutional neural network and application in medical fields, IEEE Access, 7, pp. 186470-9, (2019); Kim J., Lee J.K., Lee K.M., Accurate image super-resolution using very deep convolutional networks, 2016 IEEE conference on computer vision and pattern recognition (CVPR), pp. 1646-1654, (2016); Kim J., Lee J.K., Lee K.M., Deeply-recursive convolutional network for image super-resolution, 2016 IEEE conference on computer vision and pattern recognition (CVPR), pp. 1637-1645, (2016); Tai Y., Yang J., Liu X., Image super-resolution via deep recursive residual network, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2790-2798, (2017); Lim B., Son S., Kim H., Nah S., Lee K.M., Enhanced deep residual networks for single image super-resolution, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, (2017); Ledig C., Theis L., Huszar F., Caballero J., Cunningham A., Et al., Photo-realistic single image super-resolution using a generative adversarial network, IEEE Conference on Computer Vision and Pattern Recognition (CVPR)., pp. 105-114, (2017); Zhang K., Hu H., Philbrick K., Conte G.M., Sobek J., Et al., SOUP-GAN: super-resolution MRI using generative adversarial networks, Tomography, 8, 2, pp. 905-919, (2022); Wang J., Chen Y., Wu Y., Shi J., Gee J., Enhanced generative adversarial network for 3D brain MRI super-resolution, . In: 2020 IEEE Winter Conference on Applications of Computer Vision (WACV), pp. 3616-3625, (2020); Sanchez I., Vilaplana V., Brain MRI super-resolution using 3D generative adversarial networks, Med Imaging Deep Learn, (2018); Mahapatra D., Bozorgtabar B., Garnavi R., Image super-resolution using progressive generative adversarial networks for medical image analysis, Comput Med Imaging Graph, 71, pp. 30-39, (2019); Ota J., Umehara K., Kershaw J., Kishimoto R., Hirano Y., Et al., Super-resolution generative adversarial networks with static T2*WI-based subject-specific learning to improve spatial difference sensitivity in fMRI activation, Sci Rep, 12, 1, (2022); Zhang H., Goodfellow I., Metaxas D., Odena A., Self-Attention Generative Adversarial Networks, (2019); Lu Z., Li J., Liu H., Huang C., Zhang L., Transformer for single image super-resolution, IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)., pp. 456-465, (2022); Chen X., Wang X., Zhou J., Qiao Y., Dong C., Activating more pixels in image super-resolution transformer, In,. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR, pp. 22367-22377, (2023)","K. Yoon; School of Mathematics and Computing (Computational Science and Engineering), Yonsei University, Seoul, 50 Yonsei-Ro, Seodaemun-Gu, 03722, South Korea; email: yoonkh@yonsei.ac.kr","","Springer Verlag","","","","","","20939868","","","","English","Biomed. Eng. Lett.","Review","Final","","Scopus","2-s2.0-85188073218"
"Choi S.J.; Kim D.K.; Kim B.S.; Cho M.; Jeong J.; Jo Y.H.; Song K.J.; Kim Y.J.; Kim S.","Choi, Seung Jae (58032704200); Kim, Dae Kon (57216822391); Kim, Byeong Soo (57365979400); Cho, Minwoo (56783471200); Jeong, Joo (39061606100); Jo, You Hwan (25822597600); Song, Kyoung Jun (57037616400); Kim, Yu Jin (56658847500); Kim, Sungwan (27169083000)","58032704200; 57216822391; 57365979400; 56783471200; 39061606100; 25822597600; 57037616400; 56658847500; 27169083000","Mask R-CNN based multiclass segmentation model for endotracheal intubation using video laryngoscope","2023","Digital Health","9","","","","","","4","10.1177/20552076231211547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176430215&doi=10.1177%2f20552076231211547&partnerID=40&md5=98a109508f241780296a9ddba0a8b5f8","Transdisciplinary Department of Medicine and Advanced Technology, Seoul National University Hospital, Seoul, South Korea; Department of Emergency Medicine, Seoul National University Bundang Hospital, Seongnam, South Korea; Department of Emergency Medicine, Seoul National University College of Medicine, Seoul, South Korea; Department of Biomedical Engineering, Seoul National University College of Medicine, Seoul, South Korea; Interdisciplinary Program in Bioengineering, Graduate School, Seoul National University, Seoul, South Korea; Department of Emergency Medicine, Seoul Metropolitan Government-Seoul National University Boramae Medical Center, Seoul, South Korea; Institute of Bioengineering, Seoul National University, Seoul, South Korea","Choi S.J., Transdisciplinary Department of Medicine and Advanced Technology, Seoul National University Hospital, Seoul, South Korea; Kim D.K., Department of Emergency Medicine, Seoul National University Bundang Hospital, Seongnam, South Korea, Department of Emergency Medicine, Seoul National University College of Medicine, Seoul, South Korea, Department of Biomedical Engineering, Seoul National University College of Medicine, Seoul, South Korea; Kim B.S., Interdisciplinary Program in Bioengineering, Graduate School, Seoul National University, Seoul, South Korea; Cho M., Transdisciplinary Department of Medicine and Advanced Technology, Seoul National University Hospital, Seoul, South Korea; Jeong J., Department of Emergency Medicine, Seoul National University Bundang Hospital, Seongnam, South Korea, Department of Emergency Medicine, Seoul National University College of Medicine, Seoul, South Korea; Jo Y.H., Department of Emergency Medicine, Seoul National University Bundang Hospital, Seongnam, South Korea, Department of Emergency Medicine, Seoul National University College of Medicine, Seoul, South Korea; Song K.J., Department of Emergency Medicine, Seoul National University College of Medicine, Seoul, South Korea, Department of Emergency Medicine, Seoul Metropolitan Government-Seoul National University Boramae Medical Center, Seoul, South Korea; Kim Y.J., Department of Emergency Medicine, Seoul National University Bundang Hospital, Seongnam, South Korea, Department of Emergency Medicine, Seoul National University College of Medicine, Seoul, South Korea; Kim S., Department of Biomedical Engineering, Seoul National University College of Medicine, Seoul, South Korea, Institute of Bioengineering, Seoul National University, Seoul, South Korea","Objective: Endotracheal intubation (ETI) is critical to secure the airway in emergent situations. Although artificial intelligence algorithms are frequently used to analyze medical images, their application to evaluating intraoral structures based on images captured during emergent ETI remains limited. The aim of this study is to develop an artificial intelligence model for segmenting structures in the oral cavity using video laryngoscope (VL) images. Methods: From 54 VL videos, clinicians manually labeled images that include motion blur, foggy vision, blood, mucus, and vomitus. Anatomical structures of interest included the tongue, epiglottis, vocal cord, and corniculate cartilage. EfficientNet-B5 with DeepLabv3+, EffecientNet-B5 with U-Net, and Configured Mask R-Convolution Neural Network (CNN) were used; EffecientNet-B5 was pretrained on ImageNet. Dice similarity coefficient (DSC) was used to measure the segmentation performance of the model. Accuracy, recall, specificity, and F1 score were used to evaluate the model's performance in targeting the structure from the value of the intersection over union between the ground truth and prediction mask. Results: The DSC of tongue, epiglottis, vocal cord, and corniculate cartilage obtained from the EfficientNet-B5 with DeepLabv3+, EfficientNet-B5 with U-Net, and Configured Mask R-CNN model were 0.3351/0.7675/0.766/0.6539, 0.0/0.7581/0.7395/0.6906, and 0.1167/0.7677/0.7207/0.57, respectively. Furthermore, the processing speeds (frames per second) of the three models stood at 3, 24, and 32, respectively. Conclusions: The algorithm developed in this study can assist medical providers performing ETI in emergent situations. © The Author(s) 2023.","Biomedical image processing; convolutional neural networks; deep learning; image segmentation; intubation","","","","","","National Research Foundation of Korea, NRF, (2021R1C1C101035213)","The authors disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by the National Research Foundation of Korea (grant number 2021R1C1C101035213) and AI Institute at Seoul National University. ","Peters J., Van Wageningen B., Hendriks I., Et al., First-pass intubation success rate during rapid sequence induction of prehospital anaesthesia by physicians versus paramedics, Eur J Emerg Med, 22, pp. 391-394, (2015); Hurford W.E., Techniques for endotracheal intubation, Int Anesthesiol Clin, 38, pp. 1-28, (2000); Matava C., Pankiv E., Raisbeck S., Et al., A convolutional neural network for real time classification, identification, and labelling of vocal cord and tracheal using laryngoscopy and bronchoscopy video, J Med Syst, 44, (2020); Biro P., Hofmann P., Gage D., Et al., Automated tracheal intubation in an airway manikin using a robotic endoscope: a proof of concept study, Anaesthesia, 75, pp. 881-886, (2020); Levitan R.M., Heitz J.W., Sweeney M., Et al., The complexities of tracheal intubation with direct laryngoscopy and alternative intubation devices, Ann Emerg Med, 57, pp. 240-247, (2011); Paolini J.-B., Donati F., Drolet P., Review article: video-laryngoscopy: another tool for difficult intubation or a new paradigm in airway management?, Can J Anesth, 60, pp. 184-191, (2013); Carlson J.N., Das S., De la Torre F., Et al., A novel artificial intelligence system for endotracheal intubation, Prehosp Emerg Care, 20, pp. 667-671, (2016); Ronneberger O., Fischer P., Brox T.; Ding H., Cen Q., Si X., Et al., Automatic glottis segmentation for laryngeal endoscopic images based on U-Net, Biomed Signal Process Control, 71, (2022); He K., Gkioxari G., Dollar P., Et al.; Chin C.-L., Chang C.-L., Liu Y.-C., Et al., Automatic segmentation and indicators measurement of the vocal folds and glottal in laryngeal endoscopy images using mask R-CNN, Biomed Eng Appl Basis Commun, 33, (2021); Vaswani A., Shazeer N., Parmar N., Et al., Attention is all you need, Adv Neural Inf Process Syst, 30, pp. 5998-6008, (2017); Dosovitskiy A., Beyer L., Kolesnikov A., Et al., (2020); Pan X., Bai W., Ma M., Et al., RANT: a cascade reverse attention segmentation framework with hybrid transformer for laryngeal endoscope images, Biomed Signal Process Control, 78, (2022); Ren J., Jing X., Wang J., Et al., Automatic recognition of laryngoscopic images using a deep-learning technique, Laryngoscope, 130, (2020); Laves M.-H., Bicker J., Kahrs L.A., Et al., A dataset of laryngeal endoscopic images with comparative study on convolution neural network-based semantic segmentation, Int J Comput Assist Radiol Surg, 14, pp. 483-492, (2019); Vasconcelos Pereira A., Simoes A.V., Rego L., Et al., New technologies in airway management: a review, Medicine (Baltimore), 101, (2022); Chen L.-C., Zhu Y., Papandreou G., Et al.; Tan M., Le Q.; Luo G., Yang Q., Chen T., Et al., An optimized two-stage cascaded deep neural network for adrenal segmentation on CT images, Comput Biol Med, 136, (2021); Chen J., Lu Y., Yu Q., Et al.; Uhm K.-H., Jung S.-W., Choi M.H., Et al., Deep learning for end-to-end kidney cancer diagnosis on multi-phase abdominal computed tomography, NPJ Precis Oncol, 5, (2021); Azam M.A., Sampieri C., Ioppi A., Et al., Deep learning applied to white light and narrow band imaging videolaryngoscopy: toward real-time laryngeal cancer detection, Laryngoscope, 132, pp. 1798-1806, (2022); Nogueira-Rodriguez A., Dominguez-Carbajales R., Campos-Tato F., Et al., Real-time polyp detection model using convolutional neural networks, Neural Comput Appl, 34, pp. 10375-10396, (2022); Li Y.; Zlocha M., Dou Q., Glocker B.; Vuola A.O., Akram S.U., Kannala J.; Vyshnav M.T., Sowmya V., Gopalakrishnan E.A., Et al.; Jin J., Zhang Q., Dong B., Et al., Automatic detection of early gastric cancer in endoscopy based on Mask region-based convolutional neural networks (Mask R-CNN)(with video), Front Oncol, 12, (2022); Alfonso-Francia G., Pedraza-Ortega J.C., Badillo-Fernandez M., Et al., Performance evaluation of different object detection models for the segmentation of optical cups and discs, Diagnostics, 12, (2022); Alzahrani N., Al-Baity H.H., Object recognition system for the visually impaired: a deep learning approach using Arabic annotation, Electronics, 12, (2023); Goodfellow I., Pouget-Abadie J., Mirza M., Et al., Generative adversarial networks, Commun ACM, 63, pp. 139-144, (2020)","Y.J. Kim; Department of Emergency Medicine, Seoul National University Bundang Hospital, Seongnam, South Korea; email: myda02@gmail.com; S. Kim; Department of Biomedical Engineering, Seoul National University College of Medicine, Seoul, South Korea; email: sungwan@snu.ac.kr","","SAGE Publications Inc.","","","","","","20552076","","","","English","Digit. Health","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85176430215"
"Parihar S.; Kukker A.; Dhar S.; Amitabh V.; Singh V.; Krishna V.","Parihar, Sushma (57211908398); Kukker, Amit (57200143782); Dhar, Supriyo (58765446700); Amitabh, Varun (58765639800); Singh, Varun (58830446400); Krishna, Vamsi (59267164900)","57211908398; 57200143782; 58765446700; 58765639800; 58830446400; 59267164900","Biomedical Image Classification using Deep Reinforcement Learning","2024","2024 4th International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies, ICAECT 2024","","","","","","","0","10.1109/ICAECT60202.2024.10468733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190115796&doi=10.1109%2fICAECT60202.2024.10468733&partnerID=40&md5=c62b01c01c27c8eb54bdf91b6d5b771f","Symbiosis International (Deemed University), Symbiosis Institute of Technology, Pune, India; Chandigarh University, Punjab, India","Parihar S., Symbiosis International (Deemed University), Symbiosis Institute of Technology, Pune, India; Kukker A., Chandigarh University, Punjab, India; Dhar S., Symbiosis International (Deemed University), Symbiosis Institute of Technology, Pune, India; Amitabh V., Symbiosis International (Deemed University), Symbiosis Institute of Technology, Pune, India; Singh V., Symbiosis International (Deemed University), Symbiosis Institute of Technology, Pune, India; Krishna V., Symbiosis International (Deemed University), Symbiosis Institute of Technology, Pune, India","The amalgamated tool of two renowned tools deep learning and reinforcement learning is a powerful representation for deep neural networks that improves the basic reinforcement learning framework. With the use of deep learning's representational power, it learns from the agent's activities on how to increase the expected reward. Recent work has shown a lot of success of deep reinforcement learning in different domains such as video games, robotics, finance, medical and computer vision. In this project, various DRL models and methods for planning medical image analysis are discussed. This study covers the fundamentals of reinforcement learning. DRL algorithms can address the problems with limited and inconsistent annotated medical imaging data, which has been a major obstacle to the implementation of deep learning models in clinical settings. DRL algorithms support these models for the reward function, interactions between agents, and the environment. There has been an extensive amount of research being done in this area, and it has the potential to enhance the utilisation of deep learning in medical imaging.  © 2024 IEEE.","Convolutional neural network; Deep learning; Machine learning; Reinforcement learning","Computer games; Convolutional neural networks; Deep neural networks; Image classification; Learning systems; Medical imaging; Medical problems; Agent activities; Biomedical images; Convolutional neural network; Deep learning; Images classification; Learn+; Learning frameworks; Machine-learning; Power; Reinforcement learnings; Reinforcement learning","","","","","","","Huang S.-C., Et al., Self-supervised learning for medical image classification: a systematic review and implementation guidelines, (2022); Kevin Zhou S., Et al., Deep reinforcement learning in medical imaging: A literature review, (2021); Treloar N.J., Fedorec H.A.J., Ingalls B., Barnes C.P., Et al., deep reinforcement learning (DRL) to control microbial co-cultures in bioreactors, (2020); Liu Z., Yao C., Yu H., Wu T., Et al., deep reinforcement learning (DRL) for the detection of lung cancer, (2018); Tian Z., Si X., Zheng Y., Chen Z., Li X., Multi-step medical image segmentation based on reinforcement learning, Journal of Ambient Intelligence and Humanized Computing, (2020); Alansary A., Oktay O., Li Y., Folgoc L.L., Hou B., Vaillant G., Rueckert D., Evaluating Reinforcement Learning Agents for Anatomical Landmark Detection, Medical Image Analysis, (2019); Shen C., Gonzalez Y., Chen L., Jiang S.B., Jia X., Intelligent Parameter Tuning in Optimization-Based Iterative CT Reconstruction via Deep Reinforcement Learning, IEEE Transactions on Medical Imaging, 37, 6, pp. 1430-1439, (2018); Li K., Zhang T., Wang R., Deep Reinforcement Learning for Multiobjective Optimization, IEEE Transactions on Cybernetics, 51, 6, pp. 3103-3114, (2021); Mahmud M., Kaiser M.S., Hussain A., Vassanelli S., Applications of Deep Learning and Reinforcement Learning to Biological Data, IEEE Transactions on Neural Networks and Learning Systems, 29, 6, pp. 2063-2079, (2018); Litjens G., Kooi T., Ehteshami Bejnordi B., Arindra Adiyoso Setio A., Ciompi F., Ghafoorian M., Van Der Laak M.W.J.A., Van Ginneken B., Sanchez C.I., A Survey on Deep Learning in Medical Image Analysis; Niraula D., Jamaluddin J., Matuszak M.M., Naqa El Issam Haken Ten R.K., Quantum deep reinforcement learning for clinical decision support in oncology: application to adaptive radiotherapy; Hu M., Zhang J., Matkovic L., Liu T., Reinforcement learning in medical image analysis: Concepts, applications, challenges, and future directions, Journal of Applied Clinical Medical Physics; Mnih V., Heess N., Graves A., Recurrent models of visual attention, Neural Information Processing Systems, pp. 2204-2212, (2014); Zheng Yu., Li Y., Deep Reinforcement Learning for Cost-Effective Medical Diagnosis, (2023); Rao Y., Lu J., Zhou J., Attention-aware deep reinforcement learning for video face recognition, IEEE International Conference on Computer Vision, pp. 3931-3940, (2017); Mueed Hafiz A., Image Classification by Reinforcement Learning With Two-State Q-Learning; Hashmi A., Barukab O., Dementia Classification Using Deep Reinforcement Learning for Early Diagnosis, Appl. Sci., 13, 3, (2023); Nawaz H., Maqsood M., Afzal S., Aadil F., Mehmood I., Rho S., A Deep Feature-Based Real-Time System for Alzheimer Disease Stage Detection, Multimed. Tools Appl., 80, pp. 35789-35807, (2021); Basher A., Kim B.C., Lee K.H., Jung H.Y., Volumetric Feature-Based Alzheimer's Disease Diagnosis From sMRI Data Using a Convolutional Neural Network and a Deep Neural Network, IEEE Access, 9, pp. 29870-29882, (2021); Li H., Habes M., Wolk D.A., Fan Y., A Deep Learning Model for Early Prediction of Alzheimer's Disease Dementia Based on Hippocampal Magnetic Resonance Imaging Data","S. Parihar; Symbiosis International (Deemed University), Symbiosis Institute of Technology, Pune, India; email: sushmap@sitpune.edu.in","","Institute of Electrical and Electronics Engineers Inc.","","4th International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies, ICAECT 2024","11 January 2024 through 12 January 2024","Bhilai","198331","","979-835034367-0","","","English","Int. Conf. Adv. Electr., Comput., Commun. Sustain. Technol., ICAECT","Conference paper","Final","","Scopus","2-s2.0-85190115796"
"Manoharan T.; Velvizhi R.; Juluru T.K.; Kamal S.; Mallick S.; Puliyanjalil E.","Manoharan, Thiyagarajan (58995607200); Velvizhi, Ramalingam (57210977000); Juluru, Tarun Kumar (57218311197); Kamal, Shoaib (57188986928); Mallick, Shrabani (56366477500); Puliyanjalil, Ezudheen (58892168300)","58995607200; 57210977000; 57218311197; 57188986928; 56366477500; 58892168300","Biomedical image classification using seagull optimization with deep learning for colon and lung cancer diagnosis","2024","Indonesian Journal of Electrical Engineering and Computer Science","35","3","","1670","1679","9","0","10.11591/ijeecs.v35.i3.pp1670-1679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197930832&doi=10.11591%2fijeecs.v35.i3.pp1670-1679&partnerID=40&md5=e3c3c8ff19fafe4934af0c4c72184408","Computer Science and Engineering, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Department of Computer Science and Engineering, Sathyabama Institute of Science and Technology, (Deemed to be University), Chennai, India; Department of Electrical and Computer Engineering, Kakatiya Institute of Technology and Science, Warangal, India; Department of Electrical and Computer Engineering, Dr. B. R. Ambedkar Institute of Technology, Port Blair, India; Department of Computer Science and Engineering, Dr. B. R. Ambedkar Institute of Technology, Port Blair, India; Government Engineering College Thrissur, Thrissur Engineering College P O, Thrissur, India","Manoharan T., Computer Science and Engineering, Vel Tech Rangarajan Dr. Sagunthala R&D Institute of Science and Technology, Chennai, India; Velvizhi R., Department of Computer Science and Engineering, Sathyabama Institute of Science and Technology, (Deemed to be University), Chennai, India; Juluru T.K., Department of Electrical and Computer Engineering, Kakatiya Institute of Technology and Science, Warangal, India; Kamal S., Department of Electrical and Computer Engineering, Dr. B. R. Ambedkar Institute of Technology, Port Blair, India; Mallick S., Department of Computer Science and Engineering, Dr. B. R. Ambedkar Institute of Technology, Port Blair, India; Puliyanjalil E., Government Engineering College Thrissur, Thrissur Engineering College P O, Thrissur, India","Traditional health care relies on biomedical image categorization to identify and treat various medical conditions. In machine learning and medical imaging, biomedical image classification for colon and lung cancer diagnosis is significant. The work focuses on building novel models and algorithms to accurately detect and categorize tumorous lesions using computer tomography (CT) scans and histopathology slides. These systems use image processing, deep learning (DL), and convolutional neural networks (CNN) to assist medical professionals diagnose cancer sooner and improve patient outcomes. Biomedical image classification using seagull optimization with deep learning (BIC-SGODL) addresses colon and lung cancer diagnosis. The BIC-SGODL method improves cancer diagnosis using hyperparameter optimized DL model. BIC-SGODL utilizes DenseNet to learn complicated features. The convolutional long short-term memory (CLSTM) standard captures spatiotemporal information in sequential picture data. Finally, the SGO method adjusts hyperparameters to improve model performance and generalization. BIC-SGODL performs well with biomedical image dataset simulations. Thus, medical picture cancer diagnosis may be automated using BIC-SGODL. © 2024 Institute of Advanced Engineering and Science. All rights reserved.","Deep learning; Magnetic resonance imaging; Medical imaging; Seagull optimization algorithm; X-ray","","","","","","","","Chehade A. H., Abdallah N., Marion J. M., Oueidat M., Chauvet P., Lung and colon cancer classification using medical imaging: a feature engineering approach, Physical and Engineering Sciences in Medicine, 45, 3, pp. 729-746, (2022); Togacar M., Disease type detection in lung and colon cancer images using the complement approach of inefficient sets, Computers in Biology and Medicine, 137, (2021); Pacal I., Karaboga D., Basturk A., Akay B., Nalbantoglu U., A comprehensive review of deep learning in colon cancer, Computers in Biology and Medicine, 126, (2020); Attallah O., Aslan M. F., Sabanci K., A framework for lung and colon cancer diagnosis via lightweight deep learning models and transformation methods, Diagnostics, 12, 12, (2022); Fahami M. A., Roshanzamir M., Izadi N. H., Keyvani V., Alizadehsani R., Detection of effective genes in colon cancer: a machine learning approach, Informatics in Medicine Unlocked, 24, (2021); Raju M. S. S. N., Rao B. S., Lung and colon cancer classification using hybrid principle component analysis network-extreme learning machine, Concurrency and Computation: Practice and Experience, 35, 1, (2023); Talukder M. A., Islam M. M., Uddin M. A., Akhter A., Hasan K. F., Moni M. A., Machine learning-based lung and colon cancer detection using deep feature extraction and ensemble learning, Expert Systems with Applications, 205, (2022); Reis H. C., Turk V., Transfer learning approach and nucleus segmentation with MedCLNet colon cancer database, Journal of Digital Imaging, 36, 1, pp. 306-325, (2023); Kumar N., Sharma M., Singh V. P., Madan C., Mehandia S., An empirical study of handcrafted and dense feature extraction techniques for lung and colon cancer classification from histopathological images, Biomedical Signal Processing and Control, 75, (2022); Masud M., Sikder N., Al Nahid A., Bairagi A. K., Alzain M. A., A machine learning approach to diagnosing lung and colon cancer using a deep learning‐based classification framework, Sensors (Switzerland), 21, 3, (2021); Ijaz M., Et al., DS<sup>2</sup>LC<sup>3</sup>Net: a decision support system for lung colon cancer classification using fusion of deep neural networks and normal distribution based gray wolf optimization, ACM Transactions on Asian and Low-Resource Language Information Processing, (2023); Bakht A. B., Javed S., Almarzouqi H., Khandoker A., Werghi N., Colorectal cancer tissue classification using semi-supervised hypergraph convolutional network, Proceedings - International Symposium on Biomedical Imaging, 2021, pp. 1306-1309, (2021); Ragab M., Abdushkour H. A., Nahhas A. F., Aljedaibi W. H., Deer hunting optimization with deep learning model for lung cancer classification, Computers, Materials and Continua, 73, 1, pp. 533-546, (2022); Ullah N., De Falco I., Sannino G., A novel deep learning approach for colon and lung cancer classification using histopathological images, 2023 IEEE 19th International Conference on e-Science (e-Science), pp. 1-10, (2023); Ibrahim D. M., Elshennawy N. M., Sarhan A. M., Deep-chest: multi-classification deep learning model for diagnosing COVID-19, pneumonia, and lung cancer chest diseases, Computers in Biology and Medicine, 132, (2021); Mohalder R. D., Ali F. B., Paul L., Talukder K. H., Deep learning-based colon cancer tumor prediction using histopathological images, Proceedings of 2022 25th International Conference on Computer and Information Technology, ICCIT 2022, 2022, pp. 629-634; Kadirappa R., Deivalakshmi S., Pandeeswari R., Ko S. B., DeepHistoNet: a robust deep-learning model for the classification of hepatocellular, lung, and colon carcinoma, Microscopy Research and Technique, 87, 2, pp. 229-256, (2024); Sakai H., Et al., Primary lung cancer presenting with metastasis to the colon: a case report, World Journal of Surgical Oncology, 10, pp. 1-5, (2012); Hadiyoso S., Aulia S., Irawati I. D., Diagnosis of lung and colon cancer based on clinical pathology images using convolutional neural network and CLAHE framework, International Journal of Applied Science and Engineering, 20, 1, pp. 1-7, (2023); Chehade A. H., Abdallah N., Marion J.-M., Oueidat M., Chauvet P., Lung and colon cancer classification using medical imaging: a feature engineering approach, Physical and Engineering Sciences in Medicine, 45, 3, pp. 729-746; Bao W., Et al., An improved DenseNet model to classify the damage caused by cotton aphid, Computers and Electronics in Agriculture, 203, (2022); Zhang B., Zou G., Qin D., Ni Q., Mao H., Li M., RCL-learning: ResNet and convolutional long short-term memory-based spatiotemporal air pollutant concentration prediction model, Expert Systems with Applications, 207, (2022); Ewees A. A., Mostafa R. R., Ghoniem R. M., Gaheen M. A., Improved seagull optimization algorithm using Lévy flight and mutation operator for feature selection, Neural Computing and Applications, 34, 10, pp. 7437-7472, (2022); Maranhao A., Lung and colon cancer histopathological images, Kaggle.com, (2020); Obayya M., Arasi M. A., Alruwais N., Alsini R., Mohamed A., Yaseen I., Biomedical image analysis for colon and lung cancer detection using tuna swarm algorithm with deep learning model, IEEE Access, 11, pp. 94705-94712, (2023)","E. Puliyanjalil; Government Engineering College Thrissur, Thrissur Engineering College P O, Thrissur, Kerala, 680009, India; email: ezudheenpuliyanjalil@gmail.com","","Institute of Advanced Engineering and Science","","","","","","25024752","","","","English","Indones. J. Electrical Eng. Comput. Sci.","Article","Final","","Scopus","2-s2.0-85197930832"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14447 LNCS","","","","","3459","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182011176&partnerID=40&md5=895edbcfa16594160d146efaa02e87d0","","","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","","","","","","","","Luo B.; Cheng L.; Wu Z.-G.; Li H.; Li C.","Springer Science and Business Media Deutschland GmbH","","30th International Conference on Neural Information Processing, ICONIP 2023","20 November 2023 through 23 November 2023","Changsha","304439","03029743","978-981998078-9","","","English","Lect. Notes Comput. Sci.","Conference review","Final","","Scopus","2-s2.0-85182011176"
"Ajai A.K.; Anitha A.","Ajai, Ajni K. (57191488323); Anitha, A. (57211773955)","57191488323; 57211773955","Clustering based lung lobe segmentation and optimization based lung cancer classification using CT images","2022","Biomedical Signal Processing and Control","78","","103986","","","","11","10.1016/j.bspc.2022.103986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134694723&doi=10.1016%2fj.bspc.2022.103986&partnerID=40&md5=34c52ed65431eba6e3d0a5b112132750","Department of Computer Science and Engineering, Noorul Islam Centre for Higher Education, India","Ajai A.K., Department of Computer Science and Engineering, Noorul Islam Centre for Higher Education, India; Anitha A., Department of Computer Science and Engineering, Noorul Islam Centre for Higher Education, India","A serious condition with a high death and morbidity rate worldwide is lung cancer. To increase the likelihood that a person will survive, early diagnosis is urgently required. Various existing approaches are modeled to detect lung cancer, but low visibility of tumor region and the negative rates of images still result a complex task to recognize infected regions. Also, the traditional methods failed to enhance the accuracy of the lung cancer classification. Hence, this research developed a method named Shuffled Social Sky Optimizer-based Multi-Object Rectified Attention Network (SSSO-based MORAN) to effectively classify lung cancer disease. The proposed SSSO algorithm is the integration of the Shuffled Shepherd Optimization Algorithm (SSOA) and social ski-driver (SSD) algorithm, respectively. The input computed tomography (CT) image is supplied to the pre-processing phase, where the Gaussian filtering is employed to pre-process the image, and thereby the Region of Interest (ROI) is acquired from the input image. Then, the lung lobes are segmented using the proposed Deep Renyi entropy fuzzy clustering (DREFC). With the segmented lung lobes, the nodule region is identified from the lung image, and the process of cancer classification is done based on features. The features considered for the lung cancer classification are Local Gabor XOR Pattern (LGXP), Gray-Level Co-occurrence Matrix (GLCM) features, Global Binary Pattern (GBP), Tetrolet transform, and statistical features. The proposed algorithm effectively showed higher performance of accuracy, Mean Absolute Error (MAE), sensitivity, and specificity of 0.896, 0.104, 0.8969, and 0.845, respectively. © 2022","Biomedical image processing; Deep learning; Diagnosis system; Lung cancer; Lung lobe segmentation","Biological organs; Classification (of information); Computer aided diagnosis; Computerized tomography; Deep learning; Image classification; Image segmentation; Local binary pattern; Cancer classification; Clusterings; Computed tomography images; Condition; Deep learning; Diagnose system; Early diagnosis; Lung Cancer; Lung lobe segmentations; Optimisations; Article; attention network; cancer classification; clustering algorithm; comparative study; computer assisted tomography; contrast enhancement; deep renyi entropy fuzzy clustering; diagnostic accuracy; feasibility study; feature extraction; fuzzy c means clustering; fuzzy clustering; global binary pattern; gray level co occurrence matrix; human; human tissue; image processing; image segmentation; kernel method; local gabor xor pattern; lung cancer; lung lobe; lung nodule; lung parenchyma; mean absolute error; multi object rectified attention network; recurrent neural network; sensitivity and specificity; shuffled shepherd optimization algorithm; shuffled social sky optimizer; social ski driver algorithm; tetrolet transform; Diseases","","","","","","","Togacar M., Ergen B., Comert Z., Detection of lung cancer on chest CT images using minimum redundancy maximum relevance feature selection method with convolutional neural networks, Biocybernet. Biomed. Eng., 40, 1, pp. 23-39, (2020); Guo Y., Shang X., Li Z., Identification of cancer subtypes by integrating multiple types of transcriptomics data with deep learning in breast cancer, Neurocomputing, 324, pp. 20-30, (2019); [Asuntha A., Srinivasan A., (2020); Roy T.S., Sirohi N., Patle A., (2015); Ozdemir O., Russell R.L., Berlin A.A., A 3D probabilistic deep learning system for detection and diagnosis of lung cancer using low-dose CT scans, IEEE Trans. Med. Imaging, 39, 5, pp. 1419-1429, (2019); Khan S.A., Nazir M., Khan M.A., Saba T., Javed K., Rehman A., Akram T., Awais M., Lungs nodule detection framework from computed tomography images using support vector machine, Microsc. Res. Tech., 82, 8, pp. 1256-1266, (2019); Khan M.A., Rubab S., Kashif A., Sharif M.I., Muhammad N., Shah J.H., Zhang Y.D., Satapathy S.C., Lungs cancer classification from CT images: an integrated design of contrast based classical features fusion and selection, Pattern Recogn. Lett., 129, pp. 77-85, (2020); Caterina Ledda, Emanuele Cannizzaro, Piero Lovreglio, Ermanno Vitale, Angela Stufano, Angelo Montana, Giovanni Li Volti, Venerando Rapisarda, Exposure to Toxic Heavy Metals Can Influence Homocysteine Metabolism?, Antioxidants, 9, 1, (2019); Shakeel P.M., Burhanuddin M.A., Desa M.I., (2020); Digennaro M., Sambiasi D., Tommasi S., Pilato B., Diotaiuti S., Kardhashi A., Trojano G., Tufaro A., Paradiso A.V., Hereditary and non-hereditary branches of family eligible for BRCA test: cancers in other sites, Hereditary Cancer in Clinical Practice, 15, 1, pp. 1-5, (2017); Maria Angela Caponio, Addati T., Popescu O., Petroni S., Rubini V., Centrone M., Trojano G., Simone G., P16 INK4a protein expression in endocervical, endometrial and metastatic adenocarcinomas of extra-uterine origin: Diagnostic and clinical considerations, Cancer Biomark., 14, 2, pp. 169-175, (2014); National Lung Screening Trial Research Team, Reduced lung-cancer mortality with low-dose computed tomographic screening, N. Engl. J. Med., 365, 5, pp. 395-409, (2011); Paing M.P., Hamamoto K., Tungjitkusolmun S., Pintavirooj C., Automatic detection and staging of lung tumors using locational features and double-staged classifications, Appl. Sci., 9, 11, (2019); Gokulkumari G., Classification of Brain Tumor using Manta Ray Foraging Optimization-based DeepCNN Classifier, Multimedia Res., 3, 4, pp. 32-42, (2020); Khan R., Artificial bee colony-based general adversarial network for liver cancer detection using CT images, Multimedia Res., 3, 4, pp. 1-11, (2020); Manikandan T., Challenges in lung cancer detection using computer-aided diagnosis (CAD) systems–a key for survival of patients, Arch. General Int. Med., 1, 1, (2016); Manogaran G., Shakeel P.M., Hassanein A.S., Kumar P.M., Babu G.C., Machine learning approach-based gamma distribution for brain tumor detection and data sample imbalance analysis, IEEE Access, 7, pp. 12-19, (2018); Vinolin V., Breast cancer detection by optimal classification using GWO algorithm, Multimedia Res., 2, 2, pp. 10-18, (2019); Ganeshan R., (2020); Chen C.H., Chang C.K., Tu C.Y., Liao W.C., Wu B.R., Chou K.T., Chiou Y.R., Yang S.N., Zhang G., Huang T.C., Radiomic features analysis in computed tomography images of lung nodule classification, PLoS ONE, 13, 2, (2018); Chabat F., Yang G.Z., Hansell D.M., “Obstructive lung diseases: texture classification for differentiation at CT, Radiology”, 228, 3, pp. 871-877, (2003); Vourlaki I., Balas C., Livanos G., Vardoulakis M., Giakos G., Zervakis M., Bootstrap clustering approaches for organization of data: Application in improving grade separability in cervical neoplasia, Biomed. Signal Process. Control, 49, pp. 263-273, (2019); Borlea I.-D., Precup R.-E., Borlea A.-B., Iercan D., A unified form of fuzzy c-means and k-means algorithms and its partitional implementation, Knowl.-Based Syst., 214, (2021); Taher F., Sammouda R., “Lung cancer detection by using artificial neural network and fuzzy clustering methods,” In the proceeding of IEEE GCC Conference and Exhibition (GCC), (2011); Kuruvilla J., Gunavathi K., Lung cancer classification using fuzzy logic for CT images, Int. J. Med. Eng. Inf., 7, 3, pp. 233-249, (2015); Lynch C.M., van Berkel V.H., Frieboes H.B., Application of unsupervised analysis techniques to lung cancer patient data, PLoS ONE, 12, 9, (2017); Wang H., Zhou Z., Li Y., Chen Z., Lu P., Wang W., Liu W., Yu L., Comparison of machine learning methods for classifying mediastinal lymph node metastasis of non-small cell lung cancer from 18 F-FDG PET/CT images, EJNMMI Res., 7, 1, (2017); Sivakumar S., Chandrasekar C., (2013); Bandyopadhyay S.K., Edge detection from CT images of lung, Int. J. Eng. Sci. Adv. Technol., 2, 1, pp. 34-37, (2012); Masood A., Sheng B., Yang P., Li P., Li H., Kim J., Feng D.D., Automated decision support system for lung cancer detection and classification via enhanced RFCN with multilayer fusion RPN, IEEE Trans. Ind. Inf., 16, 12, pp. 7791-7801, (2020); Jiang J., Hu Y.C., Liu C.J., Halpenny D., Hellmann M.D., Deasy J.O., Mageras G., Veeraraghavan H., Multiple resolution residually connected feature streams for automatic lung tumor segmentation from CT images, IEEE Trans. Med. Imaging, 38, 1, pp. 134-144, (2018); Jena S.R., George S.T., Morphological feature extraction and KNG-CNN classification of CT images for early lung cancer detection, Int. J. Imaging Syst. Technol., 30, 4, pp. 1324-1336, (2020); 33, pp. 10737-10750, (2021); Feng Q., Chen L., Chen C.P., Guo L., Deep fuzzy clustering—A representation learning approach, IEEE Trans. Fuzzy Syst., 28, 7, pp. 1420-1433, (2020); 99, (2020); Chicco G., Sumaili Akilimali J., Renyi entropy-based classification of daily electrical load patterns, IET Gener. Transm. Distrib., 4, 6, pp. 736-745, (2010); Zheng Y., Qin Z., Shao L., Hou X., A novel objective image quality metric for image fusion based on Renyi entropy, Inf. Technol, 7, 6, pp. 930-935, (2008); Kannana P., Shantha Selva Kumari R., VLSI architecture for LGXP texture for facerecognition, J. Intell. Fuzzy Syst., 27, 5, pp. 2635-2647, (2014); Zulpe N., Pawar V., GLCM textural features for brain tumor classification, Int. J. Comput. Sci. Issues (IJCSI), 9, 3, (2012); Kar A., Bhattacharjee D., Basu D.K., Nasipuri M., Kundu M., (2013); Praveena K.S., A classical hierarchy method for bone X-Ray image classification using SVM, Int. Res. J. Eng. Technol., 4, 8, pp. 991-993, (2017); Meena K.B., Tyagi V., A copy-move image forgery detection technique based on tetrolet transform, J. Inform. Secur. Appl., 52, (2020); Luo C., Jin L., Sun Z., Moran: a multi-object rectified attention network for scene text recognition, Pattern Recogn., 90, pp. 109-118, (2019); (2020); Tharwat A., Gabel T., (2019); (2021)","A.K. Ajai; Department of Computer Science and Engineering, Noorul Islam Centre for Higher Education, India; email: ajnikajai@gmail.com","","Elsevier Ltd","","","","","","17468094","","","","English","Biomed. Signal Process. Control","Article","Final","","Scopus","2-s2.0-85134694723"
"McConnell N.; Ndipenoch N.; Cao Y.; Miron A.; Li Y.","McConnell, Niccolò (57472609800); Ndipenoch, Nchongmaje (58064883400); Cao, Yu (58730971100); Miron, Alina (57214473917); Li, Yongmin (56717319800)","57472609800; 58064883400; 58730971100; 57214473917; 56717319800","Exploring advanced architectural variations of nnUNet","2023","Neurocomputing","560","","126837","","","","4","10.1016/j.neucom.2023.126837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173447520&doi=10.1016%2fj.neucom.2023.126837&partnerID=40&md5=fd1e645613616dfe30af7bdec3983364","Department of Computer Science, Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom; Institute of Health Informatics, University College London, Euston Road, London, NW1 2DA, United Kingdom","McConnell N., Department of Computer Science, Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom, Institute of Health Informatics, University College London, Euston Road, London, NW1 2DA, United Kingdom; Ndipenoch N., Department of Computer Science, Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom; Cao Y., Department of Computer Science, Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom; Miron A., Department of Computer Science, Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom; Li Y., Department of Computer Science, Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom","The nnUNet is a state-of-the-art deep learning based segmentation framework which automatically and systematically configures the entire network training pipeline. We extend the network architecture component of the nnUNet framework by newly integrating mechanisms from advanced U-Net variations including residual, dense, and inception blocks as well as three forms of the attention mechanism. We propose the following extensions to nnUNet, namely Residual-nnUNet, Dense-nnUNet, Inception-nnUNet, Spatial-Single-Attention-nnUNet, Spatial- Multi-Attention-nnUNet, and Channel-Spatial-Attention-nnUNet. Furthermore, within Channel-Spatial- Attention-nnUNet we integrate our newly proposed variation of the channel-attention mechanism. We demonstrate that use of the nnUNet allows for consistent and transparent comparison of U-Net architectural modifications, while maintaining network architecture as the sole independent variable across experiments with respect to a dataset. The proposed variants are evaluated on eight medical imaging datasets consisting of 20 anatomical regions which is the largest collection of datasets on which attention U-Net variants have been compared in a single work. Our results suggest that attention variants are effective at improving performance when applied to tumour segmentation tasks consisting of two or more target anatomical regions, and that segmentation performance is influenced by use of the deep supervision architectural feature. © 2023 Elsevier B.V.","Attention; Biomedical image segmentation; Dense; Inception; nnUnet; Residual","Deep learning; Image segmentation; Medical imaging; Anatomical regions; Attention; Attention mechanisms; Biomedical image segmentation; Dense; Inception; Nnunet; Residual; Spatial attention; State of the art; Article; artificial neural network; automation; deep learning; image analysis; image processing; information processing; mathematical model; segmentation algorithm; Network architecture","","","","","","","of Radiology (ESR) communications@ myesr. org E.S., Medical imaging in personalised medicine: A white paper of the research committee of the European society of radiology (ESR), Insights into Imaging, 6, pp. 141-155, (2015); Liu L., Cheng J., Quan Q., Wu F.-X., Wang Y.-P., Wang J., A survey on U-shaped networks in medical image segmentations, Neurocomputing, 409, pp. 244-258, (2020); Haque I.R.I., Neubert J., Deep learning approaches to biomedical image segmentation, Inform. Med. Unlocked, 18, (2020); Lock F.K., Carrieri D., Factors affecting the UK junior doctor workforce retention crisis: An integrative review, BMJ open, 12, 3, (2022); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., Van Der Laak J.A., Van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Med. Image Anal., 42, pp. 60-88, (2017); Zhang Y., Chung A., Deep supervision with additional labels for retinal vessel segmentation task, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 83-91, (2018); Leopold H.A., Orchard J., Zelek J.S., Lakshminarayanan V., PixelBNN: Augmenting the PixelCNN with batch normalization and the presentation of a fast architecture for retinal vessel segmentation, J. Imaging, 5, 2, (2019); Dai W., Dong N., Wang Z., Liang X., Zhang H., Xing E.P., Scan: Structure correcting adversarial network for organ segmentation in chest x-rays, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 263-273, (2018); Giacomello E., Loiacono D., Mainardi L., Brain MRI tumor segmentation with adversarial networks, 2020 International Joint Conference on Neural Networks, IJCNN, pp. 1-8, (2020); Wang S., Yi L., Chen Q., Meng Z., Dong H., He Z., Edge-aware fully convolutional network with CRF-RNN layer for hippocampus segmentation, 2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference, ITAIC, pp. 803-806, (2019); Christ P.F., Ettlinger F., Grun F., Elshaera M.E.A., Lipkova J., Schlecht S., Ahmaddy F., Tatavarty S., Bickel M., Bilic P., Et al., Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks, (2017); Jin D., Xu Z., Harrison A.P., Mollura D.J., White matter hyperintensity segmentation from T1 and FLAIR images using fully convolutional neural networks enhanced with residual connections, 2018 IEEE 15th International Symposium on Biomedical Imaging, ISBI 2018, pp. 1060-1064, (2018); Ibtehaz N., Rahman M.S., MultiResUNet: Rethinking the U-net architecture for multimodal biomedical image segmentation, Neural Netw., 121, pp. 74-87, (2020); Jin Q., Meng Z., Sun C., Cui H., Su R., RA-UNet: A hybrid deep attention-aware network to extract liver and tumor in CT scans, Front. Bioeng. Biotechnol., (2020); Isensee F., Jaeger P.F., Kohl S.A., Petersen J., Maier-Hein K.H., nnU-Net: A self-configuring method for deep learning-based biomedical image segmentation, Nat. Methods, 18, 2, pp. 203-211, (2021); Isensee F., Jager P.F., Full P.M., Vollmuth P., Maier-Hein K.H., Nnu-net for brain tumor segmentation, International MICCAI Brainlesion Workshop, pp. 118-132, (2020); Bakas S., Reyes M., Jakab A., Bauer S., Rempfler M., Crimi A., Shinohara R.T., Berger C., Ha S.M., Rozycki M., Et al., Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge, (2018); Menze B.H., Jakab A., Bauer S., Kalpathy-Cramer J., Farahani K., Kirby J., Burren Y., Porz N., Slotboom J., Wiest R., Et al., The multimodal brain tumor image segmentation benchmark (BRATS), IEEE Trans. Med. Imaging, 34, 10, pp. 1993-2024, (2014); Luu H.M., Park S.-H., Extending nn-unet for brain tumor segmentation, (2021); McConnell N., Miron A., Wang Z., Li Y., Integrating residual, dense, and inception blocks into the nnUNet, 2022 IEEE 35th International Symposium on Computer-Based Medical Systems, CBMS, pp. 217-222, (2022); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, pp. 770-778, (2016); Russakovsky O., Deng J., Su H., Krause J., Satheesh S., Ma S., Huang Z., Karpathy A., Khosla A., Bernstein M., Et al., Imagenet large scale visual recognition challenge, Int. J. Comput. Vis., 115, 3, pp. 211-252, (2015); Khanna A., Londhe N.D., Gupta S., Semwal A., A deep residual U-Net convolutional neural network for automated lung segmentation in computed tomography images, Biocybern. Biomed. Eng., 40, 3, pp. 1314-1327, (2020); Cheng H., Zhu Y., Pan H., Modified U-Net block network for lung nodule detection, 2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference, ITAIC, pp. 599-605, (2019); Kermi A., Mahmoudi I., Khadir M.T., Deep convolutional neural networks using U-Net for automatic brain tumor segmentation in multimodal MRI volumes, International MICCAI Brainlesion Workshop, pp. 37-48, (2018); Guerrero R., Qin C., Oktay O., Bowles C., Chen L., Joules R., Wolz R., Valdes-Hernandez M.D.C., Dickie D.A., Wardlaw J., Et al., White matter hyperintensity and stroke lesion segmentation and differentiation using convolutional neural networks, NeuroImage: Clin., 17, pp. 918-934, (2018); Huang G., Liu Z., Van Der Maaten L., Weinberger K.Q., pp. 4700-4708, (2017); Li X., Chen H., Qi X., Dou Q., Fu C.-W., Heng P.-A., H-DenseUNet: Hybrid densely connected UNet for liver and tumor segmentation from CT volumes, IEEE Trans. Med. Imaging, 37, 12, pp. 2663-2674, (2018); Bilic P., Christ P.F., Vorontsov E., Chlebus G., Chen H., Dou Q., Fu C.-W., Han X., Heng P.-A., Hesser J., Et al., The liver tumor segmentation benchmark (lits), (2019); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, pp. 1-9, (2015); Chen W., Liu B., Peng S., Sun J., Qiao X., S3D-UNet: Separable 3D U-Net for brain tumor segmentation, International MICCAI Brainlesion Workshop, pp. 358-368, (2018); Li H., Li A., Wang M., A novel end-to-end brain tumor segmentation method using improved fully convolutional networks, Comput. Biol. Med., 108, pp. 150-160, (2019); Rad R.M., Saeedi P., Au J., Havelock J., Trophectoderm segmentation in human embryo images via inceptioned U-Net, Med. Image Anal., 62, (2020); Dolz J., Ben Ayed I., Desrosiers C., Dense multi-path U-Net for ischemic stroke lesion segmentation in multiple image modalities, International MICCAI Brainlesion Workshop, pp. 271-282, (2018); Meng C., Sun K., Guan S., Wang Q., Zong R., Liu L., Multiscale dense convolutional neural network for DSA cerebrovascular segmentation, Neurocomputing, 373, pp. 123-134, (2020); Chen L., Bentley P., Mori K., Misawa K., Fujiwara M., Rueckert D., Drinet for medical image segmentation, IEEE Trans. Med. Imaging, 37, 11, pp. 2453-2462, (2018); Zhang Z., Wu C., Coleman S., Kerr D., DENSE-INception U-net for medical image segmentation, Comput. Methods Programs Biomed., 192, (2020); Oktay O., Schlemper J., Folgoc L.L., Lee M., Heinrich M., Misawa K., Mori K., McDonagh S., Hammerla N.Y., Kainz B., Et al., Attention u-net: Learning where to look for the pancreas, (2018); Huang A., Jiang L., Zhang J., Wang Q., Attention-VGG16-UNet: A novel deep learning approach for automatic segmentation of the median nerve in ultrasound images, Quantit. Imaging Medi. Surg., 12, 6, (2022); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, (2014); Maji D., Sigedar P., Singh M., Attention Res-UNet with guided decoder for semantic segmentation of brain tumors, Biomed. Signal Process. Control, 71, (2022); Lee C.-Y., Xie S., Gallagher P., Zhang Z., Tu Z., Deeply-supervised nets, Artificial Intelligence and Statistics, pp. 562-570, (2015); Wu J., Zhou S., Zuo S., Chen Y., Sun W., Luo J., Duan J., Wang H., Wang D., U-Net combined with multi-scale attention mechanism for liver segmentation in CT images, BMC Med. Inform. Decis. Mak., 21, 1, pp. 1-12, (2021); Amer A., Lambrou T., Ye X., MDA-Unet: A multi-scale dilated attention U-net for medical image segmentation, Appl. Sci., 12, 7, (2022); Woo S., Park J., Lee J.-Y., Kweon I.S., Cbam: Convolutional block attention module, pp. 3-19, (2018); Wang Z., Zou Y., Liu P.X., Hybrid dilation and attention residual U-Net for medical image segmentation, Comput. Biol. Med., 134, (2021); Wu P., Wang Z., Zheng B., Li H., Alsaadi F.E., Zeng N., AGGN: Attention-based glioma grading network with multi-scale feature extraction and multi-modal information fusion, Comput. Biol. Med., 152, (2023); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Hochreiter S., The vanishing gradient problem during learning recurrent neural nets and problem solutions, Int. J. Uncertain. Fuzziness Knowl.-Based Syst., 6, pp. 107-116, (1998); Simpson A.L., Antonelli M., Bakas S., Bilello M., Farahani K., Van Ginneken B., Kopp-Schneider A., Landman B.A., Litjens G., Menze B., Et al., A large annotated medical image dataset for the development and evaluation of segmentation algorithms, (2019); Antonelli M., Reinke A., Bakas S., Farahani K., Landman B.A., Litjens G., Menze B., Ronneberger O., Summers R.M., van Ginneken B., Et al., The medical segmentation decathlon, (2021); Payette K., de Dumast P., Kebiri H., Ezhov I., Paetzold J.C., Shit S., Iqbal A., Khan R., Kottke R., Grehten P., Et al., An automatic multi-tissue human fetal brain segmentation benchmark using the fetal tissue annotation dataset, Sci. Data, 8, 1, pp. 1-14, (2021); Nolden M., Zelzer S., Seitel A., Wald D., Muller M., Franz A.M., Maleike D., Fangerau M., Baumhauer M., Maier-Hein L., Et al., The medical imaging interaction toolkit: Challenges and advances, Int. J. Comput. Assist. Radiol. Surg., 8, 4, pp. 607-620, (2013); Taha A.A., Hanbury A., Metrics for evaluating 3D medical image segmentation: Analysis, selection, and tool, BMC Med. Imaging, 15, (2015); Dosovitskiy A., Beyer L., Kolesnikov A., Weissenborn D., Zhai X., Unterthiner T., Dehghani M., Minderer M., Heigold G., Gelly S., Et al., An image is worth 16x16 words: Transformers for image recognition at scale, (2020)","N. McConnell; Institute of Health Informatics, University College London, London, Euston Road, NW1 2DA, United Kingdom; email: niccolo.mcconnell.17@ucl.ac.uk","","Elsevier B.V.","","","","","","09252312","","NRCGE","","English","Neurocomputing","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85173447520"
"Chen H.; Gao J.; Zhao D.; Wang H.; Song H.; Su Q.","Chen, Hongyang (57935194000); Gao, Jingyang (55995325700); Zhao, Di (56701350400); Wang, Hongzhi (57193402519); Song, Hong (7404037613); Su, Qinghua (50362000500)","57935194000; 55995325700; 56701350400; 57193402519; 7404037613; 50362000500","Review of the research progress in deep learning and biomedical image analysis till 2020; [深度学习与生物医学图像分析2020年综述]","2021","Journal of Image and Graphics","26","3","","475","486","11","17","10.11834/jig.200351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104664544&doi=10.11834%2fjig.200351&partnerID=40&md5=c4631c28d4b66b831314279da402a26f","Beijing University of Chemical Technology, Beijing, 100029, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100080, China; East China Normal University, Shanghai, 200062, China; Beijing Institute of Technology, Beijing, 100081, China; Beijing Wuzi University, Beijing, 101125, China","Chen H., Beijing University of Chemical Technology, Beijing, 100029, China; Gao J., Beijing University of Chemical Technology, Beijing, 100029, China; Zhao D., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100080, China; Wang H., East China Normal University, Shanghai, 200062, China; Song H., Beijing Institute of Technology, Beijing, 100081, China; Su Q., Beijing Wuzi University, Beijing, 101125, China","Medical big data mainly include electronic health record data, such as medical imaging data and genetic information data, among which medical imaging data takes up the most of medical data currently. One of the problems that researchers in computer science are greatly concerned about is how to apply medical big data in clinical practice.Artificial intelligence (AI) provides a good way to address this problem. AI algorithms, particularly deep learning, have demonstrated remarkable progress in image-recognition tasks. Historically, in radiology practice, trained physicians visually assess medical images for the detection, characterization, and monitoring of diseases. AI methods excel at automatically recognizing complex patterns in imaging data and providing quantitative, rather than qualitative, assessments of radiographic characteristics. Methods ranging from convolutional neural networks to variational autoencoders have found myriad applications in the medical image analysis field, propelling it forward at a rapid pace. In this review, by combining recent work and the latest research progress of big data analysis of medical images until 2020, we have summarized the theory, main process, and evaluation results of multiple deep learning algorithms in some fields of medical image analysis, including magnetic resonance imaging (MRI), pathology imaging, ultrasound imaging, electrical signals, digital radiography, molybdenum target, and diabetic eye imaging, using deep learning. MRI is one of the main research areas of medical image analysis. The existing research literature includes Alzheimer's disease MRI, Parkinson's disease MRI, brain tumor MRI, prostate cancer MRI, and cardiac MRI. MRI is also divided into two-dimensional and three-dimensional image analysis, especially for three-dimensional data, where insufficient data volume leads to problems such as overfitting, large calculations, and slow training. Medical ultrasound (also known as diagnostic sonography or ultrasonography) is a diagnostic imaging technique or therapeutic application of ultrasound. It is used to create an image of internal body structures such as tendons, muscles, joints, blood vessels, and internal organs. It aims to find the source of a disease or to exclude pathology. The practice of examining pregnant women using ultrasound is called obstetric ultrasonography and was an early development and application of clinical ultrasonography. Ultrasonography uses sound waves with higher frequencies than those audible to humans (>20 000 Hz). Ultrasonic images, also known as sonograms, are made by sending ultrasound pulses into the tissue using a probe. The ultrasound pulses echo off tissues with different reflection properties and are recorded and displayed as an image. Many different types of images can be formed. The most common is a B-mode image (brightness), which displays the acoustic impedance of a two-dimensional cross-section of a tissue. Other types can display blood flow, tissue motion over time, the location of blood, the presence of specific molecules, the stiffness of a tissue, or the anatomy of a three-dimensional region. Pathology is the gold standard for diagnosing some diseases, especially digital image of pathology.We specifically discuss AI combined with digital pathology images for diagnosis. Electroencephalography (EEG) is an electrophysiological monitoring method to record the electrical activity of the brain. It is typically noninvasive, with the electrodes placed along the scalp. However, invasive electrodes are sometimes used, for example in electrocorticography, sometimes called intracranial EEG. EEG is most often used to diagnose epilepsy, which causes abnormalities in EEG readings. It is also used to diagnose sleep disorders, depth of anesthesia, coma, encephalopathies, and brain death. EEG used to be a first-line method of diagnosis for tumors, stroke, and other focal brain disorders, but its use has decreased with the advent of high-resolution anatomical imaging techniques such as MRI and computed tomography (CT). Despite limited spatial resolution, EEG continues to be a valuable tool for research and diagnosis. It is one of the few mobile techniques available and offers millisecond-range temporal resolution, which is not possible with CT, positron emission tomography (PET), or MRI. Electrocardiography(ECG or EKG) is the process of producing an electrocardiogram. It is a graph of voltage versus time of the electrical activity of the heart using electrodes placed on the skin. These electrodes detect small electrical changes that are a consequence of cardiac muscle depolarization followed by repolarization during each cardiac cycle (heartbeat). Changes in the normal ECG pattern occur in numerous cardiac abnormalities, including cardiac rhythm disturbances (e.g., atrial fibrillation and ventricular tachycardia), inadequate coronary artery blood flow (e.g., myocardial ischemia and myocardial infarction), and electrolyte disturbances (e.g., hypokalemia and hyperkalemia).We analyzed the advantages and disadvantages of existing algorithms and the important and difficult points in the field of medical imaging, and introduced the application of intelligent imaging and deep learning in the field of big data analysis and early disease diagnosis. The current algorithms in the field of medical imaging have made considerable progress, but there is still a lot of room for development. We also focus on the optimization and improvement of different algorithms in different sub-fields under a variety of segmentation and classification indicators (e.g., Dice, IoU, accuracy and recall rate), and we look forward to the future development hotspots in this field. Deep learning has developed rapidly in the field of medical imaging and has broad prospects for development. It plays an important role in the early diagnosis of diseases. It can effectively improve the work efficiency of doctors and reduce their burden. Moreover, it has important theoretical research and practical application value. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.","Deep learning; Magnetic resonance imaging(MRI); Pathology; Review; Target segmentation; Ultrasound","","","","","","","","Cai L, Gao J Y, Zhao D., A review of the application of deep learning in medical image classification and segmentation, Annals of Translational Medicine, 8, 11, (2020); Chen L, Cui Y T, Song H, Huang B X, Yang J, Zhao D, Xia B., Femoral head segmentation based on improved fully convolutional neural network for ultrasound images, Signal, Image and Video Processing, 14, 5, pp. 1043-1051, (2020); Chen S W, Liu Y J, Liu D, Su C, Zhao D, Qian L X, Zhang P H., Alex model and adaptive contrast enhancement based ultrasound imaging classification, Computer Science, 46, 6A, pp. 146-152, (2019); Gao Q, Gao J Y, Zhao D., GNNI U-Net: precise segmentation neural network of left ventricular contours for MRI images based on group normalization and nearest interpolation, Computer Science, 47, 8, pp. 213-220, (2020); Guo X J, Zeng C, Sun S Y, Zhao D, Hua Z Q., QRS complex detection algorithm based on 1-D CNN, Computer Engineering and Design, 41, 9, pp. 2469-2475, (2020); Guo Z H, Zhou J Q, Zhao D., Thyroid nodule ultrasonic imaging segmentation based on a deep learning model and data augmentation, Proceedings of the 4th IEEE Information Technology, Networking, Electronic and Automation Control Conference, pp. 549-554, (2020); Li L W, Xiong M, Qian L X, Zhao D, Chen J J, Chi X B., Bultrasound imaging diagnosis of fatty liver based on adaptive contrast enhancement and deep CNN, Computer Application Research, 35, pp. 402-404, (2018); Lyu H M, Zhao D, Chi X B., Deep learning for early diagnosis of Alzheimer's disease based on intensive AlexNet, Computer Science, 44, 6A, pp. 50-53, (2017); Su Q H, Fu J C, Gu H, Zhang S S, Li Y F, Jiang F Z, Bai H L, Zhao D., Parallel algorithm design for assisted diagnosis of prostate cancer, Computer Science, 46, 11A, pp. 524-527, (2019); Su Q H, Zhang S S, Cai L, Gu H, Li Y F, Yu G H, Jiang F Z, Bai H L, Zhao D., Prostate diagnostic model based on 3D classification network, China Digital Medicine, 14, 3, pp. 18-21, (2019); Sun Z Y, Shi X L, Zhu Y W, Zhang S S, Guo J F, Zhao D., Mammary molybdenum target screening based on deep convolutional neural network, China Digital Medicine, 14, 3, pp. 62-65, (2019); Wang H Z, Zhao D, Yang L Q, Xia T, Zhou X Y, Miao Z Y., An approach for training data enrichment and batch labeling in AI+MRI aided diagnosis, Chinese Journal of Magnetic Resonance, 35, 4, pp. 447-456, (2018); Wang J X, Gao D, Zhao D, Zhou L X, Geng Z J, Zong H Q, Cao H Z, Xie Z W., Study on the aging of resting functional connections in vermis of nornal human brain, Hebei Medical Jounary, 41, 20, pp. 3052-3056, (2019); Wei X N, Xing J Q, Wang Z Y, Wang Y S, Shi J, Zhao D, Wang H Z., Magnetic resonance image segmentation of articular synovium based on improved U-Net, Journal of Computer Applications, 40, 11, pp. 3340-3345, (2020); Yan S L, Lin Y X, Li H X, Zhao D, Chi X B., Diabetic retinopathy detection based on multiple transfer learning, China Digital Medicine, 14, 3, pp. 26-30, (2019); Yang T, Zhang S S, Jiang F Z, Li Y F, Yu G H, Zhao D., Brachial plexus ultrasound image optimization based on deep learning and adaptive contrast enhancement, Computer Science, 46, 11A, pp. 236-240, (2019); Yang Y, Yan L F, Zhang X, Han Y, Nan H Y, Hu Y C, Hu B, Yan S L, Zhang J, Cheng D L, Ge X W, Cui G B, Zhao D, Wang W., Glioma grading on conventional MR images: a deep learning study with transfer learning, Front Neurosci, 12, (2018); Yao T C, Xiao L, Zhao D, Sun Y Z., GPU computing based fast discrete wavelet transform for l1-regularized SPIRiT reconstruction, The Imaging Science Journal, 66, 7, pp. 393-408, (2018); Yao T C, Zhao D, Chi X B., Study on early warning of Alzheimer's disease based on multiple GPU and convolutional neural network, (2017); Zhang J H, Han X, Zhao H W, Zhao D, Wang N, Zhao T, He G N, Zhu X R, Zhang Y, Han J Y, Huang D L., Personalized prediction model for seizure-free epilepsy with levetiracetam therapy: a retrospective data analysis using support vector machine, British Journal of Clinical Pharmacology, 84, 11, pp. 2615-2624, (2018); Zhang Q L, Chi X B, Zhao D., Early diagnosis of parkinson's disease based on deep learning, Computer Systems and Applications, 27, 9, pp. 1-9, (2018); Zhang Q L, Zhao D, Chi X B., Review for deep learning based on medical lmaging diagnosis, Computer Science, 44, 11A, pp. 1-7, (2017); Zhang Z Z, Gao J Y, Lyu G, Zhao D., Pathological image classification of gastric cancer based on depth learning, Computer Science, 45, 11A, pp. 263-268, (2018); Zhang Z Z, Gao J Y, Zhao D., MIFNet: pathological image segmentation method for stomach cancer based on multi-scale input and feature fusion, Journal of Computer Applications, 39, S2, pp. 107-113, (2019)","J. Gao; Beijing University of Chemical Technology, Beijing, 100029, China; email: gaojy@mail.buct.edu.cn; D. Zhao; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100080, China; email: zhaodi@escience.cn","","Editorial and Publishing Board of JIG","","","","","","10068961","","","","Chinese","J. Image and Graphics","Review","Final","","Scopus","2-s2.0-85104664544"
"Gadosey P.K.; Li Y.; Agyekum E.A.; Zhang T.; Liu Z.; Yamak P.T.; Essaf F.","Gadosey, Pius Kwao (57201334954); Li, Yujian (26642995500); Agyekum, Enock Adjei (57215589307); Zhang, Ting (57198705645); Liu, Zhaoying (55672356900); Yamak, Peter T. (57208780170); Essaf, Firdaous (57212878980)","57201334954; 26642995500; 57215589307; 57198705645; 55672356900; 57208780170; 57212878980","SD-UNET: Stripping down U-net for segmentation of biomedical images on platforms with low computational budgets","2020","Diagnostics","10","2","110","","","","60","10.3390/diagnostics10020110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081253571&doi=10.3390%2fdiagnostics10020110&partnerID=40&md5=a971286937330d8ec35aa6a56c47e524","Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; School of Artificial Intelligence, Guilin University of Electronic Technology, Guilin, 541004, China; College of Life Science and Bioengineering, Beijing University of Technology, Beijing, 100124, China","Gadosey P.K., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; Li Y., School of Artificial Intelligence, Guilin University of Electronic Technology, Guilin, 541004, China; Agyekum E.A., College of Life Science and Bioengineering, Beijing University of Technology, Beijing, 100124, China; Zhang T., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; Liu Z., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; Yamak P.T., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; Essaf F., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China","During image segmentation tasks in computer vision, achieving high accuracy performance while requiring fewer computations and faster inference is a big challenge. This is especially important in medical imaging tasks but one metric is usually compromised for the other. To address this problem, this paper presents an extremely fast, small and computationally effective deep neural network called Stripped-Down UNet (SD-UNet), designed for the segmentation of biomedical data on devices with limited computational resources. By making use of depthwise separable convolutions in the entire network, we design a lightweight deep convolutional neural network architecture inspired by the widely adapted U-Net model. In order to recover the expected performance degradation in the process, we introduce a weight standardization algorithm with the group normalization method. We demonstrate that SD-UNet has three major advantages including: (i) smaller model size (23x smaller than U-Net); (ii) 8x fewer parameters; and (iii) faster inference time with a computational complexity lower than 8M floating point operations (FLOPs). Experiments on the benchmark dataset of the Internatioanl Symposium on Biomedical Imaging (ISBI) challenge for segmentation of neuronal structures in electron microscopic (EM) stacks and the Medical Segmentation Decathlon (MSD) challenge brain tumor segmentation (BRATs) dataset show that the proposed model achieves comparable and sometimes better results compared to the current state-of-the-art. © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","Biomedical image segmentation; Computer vision; Depthwise separable convolutions; Group normalization; Weight standardization","algorithm; Article; brain tumor; computer vision; convolutional neural network; deep learning; deep neural network; diagnostic imaging; electron microscopy; image analysis; image segmentation; nerve cell; stripped down unet; structure analysis; u net; weight","","","","","Chaoyang Postdoctoral Foundation of Beijing, (2019zz-35); National Natural Science Foundation of China, NSFC, (61806013, 61876010, 61906005)","Funding: This work was supported by the National Natural Science Foundation of China (61876010, 61806013, 61906005); Chaoyang Postdoctoral Foundation of Beijing (2019zz-35). Conflicts of Interest: The authors declare no conflict of interest. The funders had no role in the design of the Conflicts of Interest: The authors declare no conflict of interest. The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, or in the decision to publish the results.","Wismuller A., Vietze F., Behrends J., Meyer-Baese A., Reiser M., Ritter H., Fully automated biomedical image segmentation by self-organized model adaptation, Neural Netw, 17, pp. 1327-1344, (2004); Chen C., Ozolek J.A., Wang W., Rohde G., A general system for automatic biomedical image segmentation using intensity neighborhoods, Int. J. Biomed. Imaging, 2011, pp. 1-12, (2011); Aganj I., Harisinghani M.G., Weissleder R., Fischl B., Unsupervised medical image segmentation based on the local center of mass, Sci. Rep., 8, (2018); Hesamian M.H., Jia W., He X., Kennedy P., Deep learning techniques for medical image segmentation: Achievements and challenges, J. Digit. Imaging, 32, pp. 582-596, (2019); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Adv. Neural Inf. Process., pp. 1097-11059, (2012); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1-9, (2015); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, pp. 1-14; Davis J.W., Sharma V., Simultaneous detection and segmentation of pedestrians using top-down and bottom-up processing, Proceedings of the 2007 IEEE Conference on Computer Vision and Pattern Recognition Processing, pp. 1-8, (2007); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, Form. Asp. Compon. Softw., 9351, pp. 234-241, (2015); Shelhamer E., Long J., Darrell T., Fully convolutional networks for semantic segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, pp. 640-651, (2017); Badrinarayanan V., Badrinarayanan V., Cipolla R., SegNet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, pp. 2481-2495, (2017); Hu R., Dollar P., He K., Darrell T., Girshick R., Learning to Segment Every Thing 2017; Simonyan K., Zisserman A., Two-Stream Convolutional Networks for Action Recognition in Videos; Ehsani K., Bagherinezhad H., Redmon J., Mottaghi R., Farhadi A., Who let the dogs out? Modeling dog behavior from visual data, Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4051-4060, (2018); Iqbal U., Milan A., Gall J., PoseTrack: Joint multi-person pose estimation and tracking, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2011-2020, (2011); Kehl W., Tombari F., Ilic S., Navab N., Real-time 3D model tracking in color and depth on a single CPU core, Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 465-473, (2017); Girshick R., Donahue J., Darrell T., Malik J., Malik J., Rich feature hierarchies for accurate object detection and semantic segmentation, Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 580-587, (2014); Li J., Wu Y., Zhao J., Guan L., Ye C., Yang T., Pedestrian detection with dilated convolution, region proposal network and boosted decision trees, Proceedings of the 2017 International Joint Conference on Neural Networks (IJCNN), pp. 4052-4057, (2017); Sun W., Wang R., Fully convolutional networks for semantic segmentation of very high resolution remotely sensed images combined with DSM, IEEE Geosci. Remote. Sens. Lett., 15, pp. 474-478, (2018); Roth H.R., Shen C., Oda H., Oda M., Hayashi Y., Misawa K., Mori K., Deep learning and its application to medical image segmentation, Med Imaging Technol, 36, pp. 63-71, (2018); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., van der Laak J.A., van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Med Image Anal, 42, pp. 60-88, (2017); Yao W., Zeng Z., Lian C., Tang H., Pixel-wise regression using U-Net and its application on pansharpening, Neurocomputing, 312, pp. 364-371, (2018); Iglovikov V., Shvets A., TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation 2018; Russakovsky O., Deng J., Su H., Krause J., Satheesh S., Ma S., Huang Z., Karpathy A., Khosla A., Bernstein M., Et al., ImageNet large scale visual recognition challenge, Int. J. Comput. Vis., 115, pp. 211-252, (2015); Oktay O., Schlemper J., Le Folgoc L., Lee M.C.H., Heinrich M., Misawa K., Mori K., McDonagh S., Hammerla N.Y., Kainz B., Et al., Attention U-Net: Learning Where to Look for the Pancreas 2018; Denil M., Shakibi B., Dinh L., Ranzato M., de Freitas N., Predicting Parameters in Deep Learning; LeCun Y., Denker J.S., Solla S.A., Optimal brain damage, Adv. Neural Inf. Process. Syst., 2, pp. 598-605, (1990); Hassibi B., Stork D.G., Second Order Derivaties for Network Prunning: Optimal Brain Surgeon; Alvarez J.M., Salzmann M., Compression-Aware Training of Deep Networks 2017; Han S., Mao H., Dally W.J., Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization, and Huffman Coding; Howard A.G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications; Zhang X., Zhou X., Lin M., Sun J., ShuffleNet: An extremely efficient convolutional neural network for mobile devices, Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition 2018, pp. 6848-6856, (2018); Qin Z., Zhang Z., Chen X., Peng Y., FD-MobileNet: Improved MobileNet with A Fast Downsampling Strategy, (2018); Sifre L., Rigid-Motion Scattering for Image Classification, (2014); Chollet F., Xception: Deep learning with depthwise separable convolutions, Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1800-1807, (2017); Ioffe S., Szegedy C., Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift; Wu Y., He K., Group normalization, Formal Asp. Compon. Softw., pp. 3-19, (2018); Qiao S., Wang H., Liu C., Shen W., Yuille A., Weight Standardization; Srivastava N., Hinton A., Sutskever K.I., Salakhutdinov R., Dropout: A simple way to prevent neural networks from overfitting, J. Mach. Learn. Res., 15, pp. 1929-1958, (2017); Arganda-Carreras I., Turaga S.C., Berger D.R., Ciresan D., Giusti A., Gambardella L.M., Schmidhuber J., Laptev D., Dwivedi S., Buhmann J.M., Et al., Crowdsourcing the creation of image segmentation algorithms for connectomics, Front. Neuroanat., 9, (2015); Cardona A., Saalfeld S., Preibisch S., Schmid B., Cheng A., Pulokas J., Tomancak P., Hartenstein V., An integrated micro- And macroarchitectural analysis of the Drosophila brain by computer-assisted serial section electron microscopy, PLoS Boil, 8, (2010); Simpson A., Antonelli M., Bakas S., Bilello M., Farahani K., van Ginneken B., Kopp-Schneider A., Landman B.A., Litjens G., Menze B., Et al., A Large Annotated Medical Image Dataset for the Development and Evaluation of Segmentation Algorithms; Bakas S., Reyes M., Jakab A., Bauer S., Rempfler M., Cromo A., Shinohara R.T., Berger C., Ha S.M., Rozycki M., Et al., Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge; Bakas S., Akbari H., Sotiras A., Bilello M., Rozycki M., Kirby J., Freymann J.B., Farahani K., Davatzikos C., Advancing the Cancer Genome Atlas glioma MRI collections with expert segmentation labels and radiomic features, Sci. Data, 4, (2017); Menze B.H., Jakab A., Bauer S., Kalpathy-Cramer J., Farahani K., Kirby J., Burren Y., Porz N., Slotboom J., Wiest R., Et al., The multimodal brain tumor image segmentation benchmark (BRATS), IEEE Trans. Med Imaging, 34, pp. 1993-2024, (2015); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization","P.K. Gadosey; Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; email: kwaogad@emails.bjut.edu.cn","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","20754418","","","","English","Diagn.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85081253571"
"Zahia S.; Sierra-Sosa D.; Garcia-Zapirain B.; Elmaghraby A.","Zahia, Sofia (57201091335); Sierra-Sosa, Daniel (37076014100); Garcia-Zapirain, Begonya (35732954700); Elmaghraby, Adel (7004230200)","57201091335; 37076014100; 35732954700; 7004230200","Tissue classification and segmentation of pressure injuries using convolutional neural networks","2018","Computer Methods and Programs in Biomedicine","159","","","51","58","7","60","10.1016/j.cmpb.2018.02.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043369305&doi=10.1016%2fj.cmpb.2018.02.018&partnerID=40&md5=aab242960976e1122e2b5ddd9e25baca","Department of Computer Engineering and Computer Science, Duthie Center for Engineering, University of Louisville, Louisville, 40292, KY, United States; eVida research laboratory, University of Deusto, Bilbao, 48007, Spain","Zahia S., Department of Computer Engineering and Computer Science, Duthie Center for Engineering, University of Louisville, Louisville, 40292, KY, United States, eVida research laboratory, University of Deusto, Bilbao, 48007, Spain; Sierra-Sosa D., Department of Computer Engineering and Computer Science, Duthie Center for Engineering, University of Louisville, Louisville, 40292, KY, United States; Garcia-Zapirain B., eVida research laboratory, University of Deusto, Bilbao, 48007, Spain; Elmaghraby A., Department of Computer Engineering and Computer Science, Duthie Center for Engineering, University of Louisville, Louisville, 40292, KY, United States","Background and Objectives: This paper presents a new approach for automatic tissue classification in pressure injuries. These wounds are localized skin damages which need frequent diagnosis and treatment. Therefore, a reliable and accurate systems for segmentation and tissue type identification are needed in order to achieve better treatment results. Methods: Our proposed system is based on a Convolutional Neural Network (CNN) devoted to performing optimized segmentation of the different tissue types present in pressure injuries (granulation, slough, and necrotic tissues). A preprocessing step removes the flash light and creates a set of 5x5 sub-images which are used as input for the CNN network. The network output will classify every sub-image of the validation set into one of the three classes studied. Results: The metrics used to evaluate our approach show an overall average classification accuracy of 92.01%, an average total weighted Dice Similarity Coefficient of 91.38%, and an average precision per class of 97.31% for granulation tissue, 96.59% for necrotic tissue, and 77.90% for slough tissue. Conclusions: Our system has been proven to make recognition of complicated structures in biomedical images feasible. © 2018 Elsevier B.V.","Convolutional neural networks; Deep learning; Image segmentation; Pressure injuries; Tissue type classification","Algorithms; Databases, Factual; Humans; Image Processing, Computer-Assisted; Models, Anatomic; Models, Statistical; Necrosis; Neural Networks (Computer); Pressure Ulcer; Reproducibility of Results; Sensitivity and Specificity; Tomography, X-Ray Computed; Wound Healing; Wounds and Injuries; Convolution; Deep learning; Granulation; Image segmentation; Neural networks; Tissue engineering; Classification accuracy; Complicated structures; Convolutional neural network; Convolutional Neural Networks (CNN); Optimized segmentation; Similarity coefficients; Tissue classification; Tissue types; Article; automated pattern recognition; clinical evaluation; constants and coefficients; controlled study; convolutional neural network; decubitus; dice similarity coefficient; granulation tissue; image analysis; image processing; image segmentation; machine learning; measurement accuracy; measurement precision; pathological tissue; sensitivity and specificity; slough tissue; tissue characterization; tissue injury; tissue necrosis; validation process; algorithm; anatomic model; artificial neural network; decubitus; diagnostic imaging; factual database; human; injury; necrosis; reproducibility; statistical model; wound healing; x-ray computed tomography; Tissue","","","","","Department of Electricial and Computer Engineering, Boston University, (IT905-16); University of Louisville, UL","Funding text 1: This project has been funded by the University of Louisville Computer Engineering and Computer Science Department. The authors would like to thank the Igurko Hospital in Bilbao, Spain, for the images provided in order to carry out this work. Acknowledgment to Basque country government that partially funded this project with IT905-16 grant.; Funding text 2: This project has been funded by the University of Louisville Computer Engineering and Computer Science Department. The authors would like to thank the Igurko Hospital in Bilbao, Spain, for the images provided in order to carry out this work. Acknowledgment to Basque country government that partially funded this project with IT905-16 grant.   ","Tubaishat A., Papanikolaou P., Anthony D., Habiballah L., Pressure ulcers prevalence in the acute care setting: a systematic review, 2000–2015, Clin. Nurs Res., (2017); Ortiz D.P., Sierra-Sosa D., Zapirain B.G., Pressure ulcer image segmentation technique through synthetic frequencies generation and contrast variation using toroidal geometry, Biomed. Eng. Online, 16, 1, (2017); Leachtenauer J., Kell S., Turner B., Newcomer C., Lyder C., Alwan M., A non-contact imaging-based approach to detecting stage i pressure ulcers, Engineering in Medicine and Biology Society, 2006. EMBS’06. 28th Annual International Conference of the IEEE (pp. 6380–6383), (2006); Guadagnin R., Neves R.D.S., Santana L.A., Guilhem D.B., An image mining based approach to detect pressure ulcer stage, Pattern Recognit. Image Anal., 24, 2, pp. 292-296, (2014); Hansen G.L., Sparrow E.M., Kokate J.Y., Leland K.J., Iaizzo P.A., Wound status evaluation using color image processing, IEEE Trans. Med. Imaging, 16, 1, pp. 78-86, (1997); Mankar N.B., Nagdeve U., Comparison of different imaging techniques used for chronic wounds, IJRET, 2, 7, pp. 68-70, (2013); Mukherjee R., Manohar D.D., Das D.K., Achar A., Mitra A., Chakraborty C., Automated tissue classification framework for reproducible chronic wound assessment, BioMed. Res. Int., (2014); Bedo M.V.N., Santos L.F.D., Oliveira W.D., Blanco G., Traina A.J.M., Frade M.A., Junior C.T., Color and texture influence on computer-aided diagnosis of dermatological ulcers, In Computer-Based Medical Systems (CBMS), 2015 IEEE 28th International Symposium on (pp. 109–114), (2015); Veredas F.J., Luque-Baena R.M., Martin-Santos F.J., Morilla-Herrera J.C., Morente L., Wound image evaluation with machine learning, Neurocomputing, 164, pp. 112-122, (2015); Arroyo J.L.G., Zapirain B.G., Zorrilla A.M., Blue-white veil and dark-red patch of pigment pattern recognition in dermoscopic images using machine-learning techniques, In Signal Processing and Information Technology (ISSPIT), 2011 IEEE International Symposium on (pp. 196–201), (2011); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., Sanchez C.I., (2017); Krizhevsky A., Sutskever I., Hinton G., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Simonyan K., Zisserman A., (2014); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., (2014); He K., Zhang X., Ren S., Sun J., (2015); Wang C., Yan X., Smith M., Kochhar K., Rubin M., Warren S.M., Lee H., A unified framework for automatic wound segmentation and analysis with deep convolutional neural networks, In Engineering in Medicine and Biology Society (EMBC), 2015 37th Annual International Conference of the IEEE (pp. 2415–2418), (2015); Kawahara J., Hamarneh G., Multi-resolution-tract CNN with hybrid pretrained and skin-lesion trained layers, In International Workshop on Machine Learning in Medical Imaging (pp. 164–171), (2016); Esteva A., Kuprel B., Novoa R.A., Ko J., Swetter S.M., Blau H.M., Thrun S., Dermatologist-level classification of skin cancer with deep neural networks, Nature, 542, 7639, pp. 115-118, (2017); Fu H., Xu Y., Lin S., Wong D.W.K., Liu J., Deepvessel: retinal vessel segmentation via deep learning and conditional random field, In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 132–139), (2016); Fu H., Xu Y., Wong D.W.K., Liu J., Retinal vessel segmentation via deep learning network and fully-connected conditional random fields, Biomedical Imaging (ISBI), 2016 IEEE 13th International Symposium on (pp. 698–701), (2016); Maninis K.K., Pont-Tuset J., Arbelaez P., Van Gool L., Deep retinal image understanding, International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 140–148), (2016); Wu A., Xu Z., Gao M., Buty M., Mollura D.J., Deep vessel tracking: a generalized probabilistic approach via deep learning, Biomedical Imaging (ISBI), 2016 IEEE 13th International Symposium on (pp. 1363–1367), (2016); Zilly J., Buhmann J.M., Mahapatra D., Glaucoma detection using entropy sampling and ensemble learning for automatic optic cup and disc segmentation, Comput. Med. Imaging Graph., 55, pp. 28-41, (2017); Gao X., Lin S., Wong T.Y., Automatic feature learning to grade nuclear cataracts based on deep learning, IEEE Trans. Biomed. Eng., 62, 11, pp. 2693-2701, (2015); Birenbaum A., Greenspan H., Longitudinal multiple sclerosis lesion segmentation using multi-view convolutional neural networks, International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis (pp. 58–67), (2016); Brosch T., Tang L.Y., Yoo Y., Li D.K., Traboulsee A., Tam R., Deep 3d convolutional encoder networks with shortcuts for multiscale feature integration applied to multiple sclerosis lesion segmentation, IEEE Trans. Med. Imaging, 35, 5, pp. 1229-1239, (2016); Ghafoorian M., Karssemeijer N., Heskes T., van Uden I., Sanchez C., Litjens G., de Leeuw F.E., van Ginneken B., Marchiori E., Platel B., (2016); Ghafoorian M., Karssemeijer N., Heskes T., van Uder I.W.M., de Leeuw F.E., Marchiori E., Platel B., Non-uniform patch sampling with deep convolutional neural networks for white matter hyperintensity segmentation, Biomedical Imaging (ISBI), 2016 IEEE 13th International Symposium on (pp. 1414–1417), (2016); Havaei M., Davy A., Warde-Farley D., Biard A., Courville A., Bengio Y., Larochelle H., Brain tumor segmentation with deep neural networks, Med. Image Anal., 35, pp. 18-31, (2017); Havaei M., Guizard N., Chapados N., Bengio Y., HeMIS: hetero-modal image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 469–477), (2016); Kamnitsas K., Ledig C., Newcombe V.F., Simpson J.P., Kane A.D., Menon D.K., Glocker B., Efficient multi-scale 3d CNN with fully connected CRF for accurate brain lesion segmentation, Med. Image Anal., 36, pp. 61-78, (2017); Zhang W., Li R., Deng H., Wang L., Lin W., Ji S., Shen D., Deep convolutional neural networks for multi-modality isointense infant brain image segmentation, NeuroImage, 108, pp. 214-224, (2015); Chen H., Dou Q., Yu L., Heng P.A., (2016); Moeskops P., Viergever M.A., Mendrik A.M., de Vries L.S., Benders M.J., Isgum I., Automatic segmentation of MR brain images with a convolutional neural network, IEEE Trans. Med. Imaging, 35, 5, pp. 1252-1261, (2016); Stollenga M.F., Byeon W., Liwicki M., Schmidhuber J., Parallel multi-dimensional lstm, with application to fast biomedical volumetric image segmentation, Advances in Neural Information Processing Systems (pp. 2998–3006), (2015); Andermatt S., Pezold S., Cattin P., Multi-dimensional gated recurrent units for the segmentation of biomedical 3d-data, International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis (pp. 142–151), (2016); Guadagnin R., Neves R.D.S., Santana L.A., Guilhem D.B., An image mining based approach to detect pressure ulcer stage, Pattern Recognit. Image Anal., 24, 2, pp. 292-296, (2014); Bovik A.C., Handbook of Image and Video Processing, (2010); Raja N., Rajinikanth V., Latha K., Otsu based optimal multilevel image thresholding using firefly algorithm, Modell. Simul. Eng., 2014, (2014); Murphy J., (2016); Rickard H.E., Tourassi G.D., Elmaghraby A.S., Self-organizing maps for masking mammography images, Information Technology Applications in Biomedicine, 2003. 4th International IEEE EMBS Special Topic Conference on (pp. 302–305), (2003); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., Sanchez C.I., (2017)","D. Sierra-Sosa; Department of Computer Engineering and Computer Science, Duthie Center for Engineering, University of Louisville, Louisville, 40292, United States; email: d.sierrasosa@louisville.edu","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","29650318","English","Comput. Methods Programs Biomed.","Article","Final","","Scopus","2-s2.0-85043369305"
"Shrivastava A.; Chakkaravathy M.; Shah M.A.","Shrivastava, Anurag (58035982500); Chakkaravathy, Midhun (58175875900); Shah, Mohd Asif (58090397100)","58035982500; 58175875900; 58090397100","A Comprehensive Analysis of Machine Learning Techniques in Biomedical Image Processing Using Convolutional Neural Network","2022","Proceedings of 5th International Conference on Contemporary Computing and Informatics, IC3I 2022","","","","1363","1369","6","20","10.1109/IC3I56241.2022.10072911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152086993&doi=10.1109%2fIC3I56241.2022.10072911&partnerID=40&md5=910d2a83febf45b399f1ab034c9fc34b","Lincoln University College (LUC), Electronics and Communication Engineering, Malaysia; Lincoln University College (LUC), Faculty of Computer Science and Multimedia, Malaysia; Faculty of Kebri Dehar University, Somali, Ethiopia","Shrivastava A., Lincoln University College (LUC), Electronics and Communication Engineering, Malaysia; Chakkaravathy M., Lincoln University College (LUC), Faculty of Computer Science and Multimedia, Malaysia; Shah M.A., Faculty of Kebri Dehar University, Somali, Ethiopia","Deep learning is a branch of machine learning that has grown by leaps and bounds since it was first used in computer vision. The 'Olympics' of computer vision, ImageNet Classification, was won by a system that used deep learning and convolutional neural networks in December 2012. Because of how important it is in the field, this competition is sometimes called the 'Olympics' of computer vision. (CNN). Since then, people in many different fields, such as medical image analysis, have looked into deep learning. We are going to look into whether or not it would be possible to use deep learning algorithms to analyse medical images. This poll asked people what they thought about the four following topics related to machine learning: 1) How it is now used in computer vision, 2) How machine learning has changed before and after deep learning, 3) What role ML models play in deep learning, and 4) How deep learning can be used to analyse medical photos. Before the invention of deep learning, most machine learning systems relied on inputs called 'features.' This type of machine learning is called feature-based ML by some (also known as feature-based ML). Studying photographic data can be used to learn through deep learning without the need to separate objects or pull out features. The main difference between the two was this. This was pretty clear when we looked at MLs made before and after deep learning became very popular. This part, along with the model's huge scope, makes deep learning work well. Even though the term 'deep learning' is still new, a study on the topic found that photo-input deep-learning algorithms have been available in the field of machine learning for a long time. Even though 'deep learning' is a term that has only been around for a short time, this was seen. Even though the idea of 'deep learning' is still in its early stages, discoveries like this one have been made. Even before the term 'deep learning' was invented, machine learning techniques that used pictures as input were already showing promise for solving a wide range of medical image interpretation problems. Even before the term 'deep learning' was made up, this was the case. One of these jobs is to Figure out how lesions are different from other organs and tissues. To solve the problem, an approach to machine learning that is based on images was used. In the next few decades, it is expected that deep learning will completely replace all of the traditional ways that medical images are currently interpreted. This is because applying deep learning and other machine learning techniques to the study of picture data could make medical image analysis much better. 'Deep learning,' which is the process of teaching computers to 'learn' from images, is one of the most promising and quickly growing areas of medical image analysis. Traditional ways of figuring out what a medical image means are likely to be replaced in the next few decades by machine learning that works from pictures.  © 2022 IEEE.","Analysis of medical images; CNN - Convolutional neural network; Deep and Machine learning; Medical image","Computer vision; Convolution; Deep neural networks; Image analysis; Learning algorithms; Learning systems; Medical imaging; Analyse of medical image; CNN - convolutional neural network; Convolutional neural network; Deep and machine learning; Feature-based; Machine learning techniques; Machine-learning; Medical image; Medical image analysis; Olympics; Convolutional neural networks","","","","","","","Swamy K.V., Divya B., Skin Disease Classification using Machine Learning Algorithms, 2021 2nd International Conference on Communication, Computing and Industry 4.0 (C2I4), pp. 1-5, (2021); Agrawal N., Aurelia S., Corroboration of skin Diseases: Melanoma, Vitiligo & Vascular Tumor using Transfer Learning, 2021 7th International Conference on Electrical Energy Systems (ICEES), pp. 590-592, (2021); Bates M., The Role of the Skin Microbiome in Health and Disease, Ieee Pulse, 13, 4, pp. 8-13, (2022); Borade S., Kalbande D., Survey paper based critical reviews for Cosmetic Skin Diseases, 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), pp. 580-585, (2021); Iqbal M.A., Saleh A., Darwito H.A., Implementation of the Introduction of Skin Diseases Based on Augmented Reality, 2020 International Electronics Symposium (IES), pp. 406-410, (2020); Ozdemr Z., Keles H.Y., Tanriover O.O., Skin Disease Classification using Few-Shot Meta-Transfer Learning, 2022 30th Signal Processing and Communications Applications Conference (SIU), pp. 1-4, (2022); Shaik R., Bodhapati S.K., Uddandam A., Krupal L., Sengupta J., A Deep Learning Model that Diagnosis Skin Diseases and Recommends Medication, 2022 1st International Conference on the Paradigm Shifts in Communication, Embedded Systems, Machine Learning and Signal Processing (PCEMS), pp. 7-10, (2022); Li L.-F., Wang X., Hu W.-J., Xiong N.N., Du Y.-X., Li B.-S., Deep Learning in Skin Disease Image Recognition: A Review, Ieee Access, 8, 2020, pp. 208264-208280; Lilien L., Gupta A., Yang Z., Opportunistic networks for emergency applications and their standard implementation framework, Ieee Intl. Performance, Computing, and Communications Conference (IPCCC 2007), 1, (2007); Awasekar D., An Enhanced Skin Disease Vitiligo and Ringworm Recognition Android Application Using Image Analysis, 2021 Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV), pp. 1445-1449, (2021); Vincent L., Jayasingh J.R., Comparison of Psoriasis Disease Detection and Classification Through Various Image Processing Techniques-A Review, 2022 6th International Conference on Devices, Circuits and Systems (ICDCS), pp. 122-124, (2022); Patil D.D., Singh A.K., Shrivastava A., Bairagi D., IOT Sensor-Based Smart Agriculture Using Agro-robot, IoT Based Smart Applications, pp. 345-361, (2023); Borole Y.D., Shrivastava A., Niranjanamurthy M., Diagnosis of COVID-19 Using Low-Energy IoT-Enabled System, IoT Based Smart Applications, 375, (2022); Saxena M.C., Banu F., Shrivastava A., Thyagaraj M., Upadhyay S., Comprehensive analysis of energy efficient secure routing protocol over sensor network, Materials Today: Proceedings, (2022); Haripriya D., Kumar K., Shrivastava A., Al-Khafaji H.M.R., Moyal V., Singh S.K., Energy-Efficient UART Design on FPGA Using Dynamic Voltage Scaling for Green Communication in Industrial Sector, Wireless Communications and Mobile Computing, (2022); Shrivastava A., Rizwan A., Kumar N.S., Saravanakumar R., Dhanoa I.S., Bhambri P., Singh B.K., VLSI implementation of green computing control unit on Zynq FPGA for green communication, Wireless Communications and Mobile Computing, 2021, (2021); Rana A., Sharma S., Mechanism of sphingosine-1-phosphate induced cardioprotection against I/R injury in diabetic rat heart: Possible involvement of glycogen synthase kinase 3β and mitochondrial permeability transition pore, Clinical and Experimental Pharmacology and Physiology, 43, 2, pp. 166-173, (2016); Walia H., Rana A., Kansal V., A Naive Bayes Approach for working on Gurmukhi Word Sense Disambiguation, 2017 6th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), pp. 432-435, (2017); Raghavendra M.S., Chawla P., Rana A., A Survey of Optimization Algorithms for Fog Computing Service Placement, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), pp. 259-262, (2020); Sharma S., Mishra V.M., Development of Sleep Apnea Device by detection of blood pressure and heart rate measurement, Int J Syst Assur Eng Manag, 12, pp. 145-153, (2021)","A. Shrivastava; Lincoln University College (LUC), Electronics and Communication Engineering, Malaysia; email: pdf.ashrivastava@lincoln.edu.my","","Institute of Electrical and Electronics Engineers Inc.","IEEE UP Section","5th International Conference on Contemporary Computing and Informatics, IC3I 2022","14 December 2022 through 16 December 2022","Uttar Pradesh","187464","","979-835039826-7","","","English","Proc. Int. Conf. Contemp. Comput. Informatics, IC3I","Conference paper","Final","","Scopus","2-s2.0-85152086993"
"Heena A.; Biradar N.; Maroof N.M.","Heena, Ayesha (57215537131); Biradar, Nagashettappa (56267698900); Maroof, Najmuddin M. (57215192261)","57215537131; 56267698900; 57215192261","Machine Learning Based Detection and Classification of Heart Abnormalities","2022","Lecture Notes in Networks and Systems","300 LNNS","","","15","22","7","2","10.1007/978-3-030-84760-9_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115630582&doi=10.1007%2f978-3-030-84760-9_2&partnerID=40&md5=777633047b8d07d3bf869a22a39ab80a","Department of Electronics and Communication Engineering, BKIT Bhalki Karnataka/VTU Belagavi, Belagavi, Karnataka, India; Department of Electronics and Communication Engineering, KBN College of Engineering Kalaburagi Karnataka/VTU Belagavi, Belagavi, Karnataka, India","Heena A., Department of Electronics and Communication Engineering, BKIT Bhalki Karnataka/VTU Belagavi, Belagavi, Karnataka, India; Biradar N., Department of Electronics and Communication Engineering, BKIT Bhalki Karnataka/VTU Belagavi, Belagavi, Karnataka, India; Maroof N.M., Department of Electronics and Communication Engineering, KBN College of Engineering Kalaburagi Karnataka/VTU Belagavi, Belagavi, Karnataka, India","Various types of heart abnormalities require various parameters of consideration for effective detection, analysis, processing and classification of heart abnormalities. Like any other disease, prevention is the key to avoid heart diseases. Heart abnormalities are very common not only in India but all over the world, but with better understanding of different symptoms of heart problems, proper diagnosis and prognosis is possible, so that early and optimal treatment is initiated. Particularly in these Pandemic situations of COVID 19 which led to more stress and as a consequence many heart related issues. Deep learning is also vastly employed technique in recent researches for classification of heart images and biomedical images in general. Neural network and support vector machine (SVM) algorithms are also frequently used in classification because of higher accuracy in results. The use of machine learning resulted in improved accuracy and reduced variability in comparison to manual quantification of echocardiographic parameters. A hybrid algorithm (Image enhancement and denoising both carried out in preprocessing task) is developed in this article which can efficiently and effectively classify the heart abnormalities by detecting whether the image is normal or abnormal, if abnormal whether mild stage or critical stage. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Classification; Detection; Gradient modulation; Intensity preservation dynamic histogram equalization; Luminance modulation; Neural network; Support vector machine algorithm","","","","","","BKIT Bhalki; KBN College of Engineering; VTU Belagavi and family","The author would like to thank Almighty God, Dr. Nagashettappa Biradar, KBN College of Engineering, BKIT Bhalki, VTU Belagavi and family.","Heena A., Biradar N., Maroof N.M., Machine learning based biomedical image processing for echocardiographic images, MTAP J; Ling Z.G., Liang Y., Wang Y.N., Shen H., Lu X., Adaptive extended piecewise histogram equalisation for dark image enhancement, IET Image Process, 9, 11, pp. 1012-1019, (2015); Kim Y.T., Contrast enhancement using brightness preserving bi histogram equalization, IEEE Trans. Consum. Electron., 43, 1, pp. 1-8, (1997); Khan M.F., Ren X.S., Khan E., Semi dynamic fuzzy histogram equalization, Optik, 126, 21, pp. 2848-2853, (2015); Jordanski M., Arsic A., Tuba M., Dynamic recursive sub image histogram equalization algorithm for image contrast enhancement, Telecommunications Forum Telfor, pp. 819-822, (2016); Jagatheeswari P., Kumar S.S., Linda M.M., Quadrant dynamic with automatic plateau limit histogram equalization for image enhancement, Math. Probl. Eng., 2014, pp. 1-8, (2014); Using Weighted Dynamic Range for Histogram Equalization to Improve the Image, (2014); Gonzalez R.C., Woods R.E., Digital Image Processing, (1993); Kim Y.-T., Contrast enhancement using brightness preserving bi histogram equalization, IEEE Trans. Consum. Electron., 43, 1, pp. 1-8, (1997); Wang Y., Zhang B., Image enhancement based on equal area dualistic sub image histogram equalization method, IEEE Trans. Consum. Electron., 45, 1, pp. 68-75, (1999); Chen S., Ramli R., Minimum mean brightness error bi-histogram equalization in contrast enhancement, IEEE Trans. Consum. Electron., 49, 4, pp. 1310-1319, (2003); Abdullah-Al-wadud M., Ali Akber Dewan M., Hasanul Kabir M., Chae O., A dynamic histogram equalization for image contrast enhancement, IEEE Trans. Consum. Electron., 53, 2, pp. 593-600, (2007); Veluchamy M., Mayathevar K., Subramani B., Brightness preserving optimized weighted bi-histogram equalization algorithm and its application to MR brain image segmentation, Int. J. Imaging Syst. Technol., (2019); Heena A., Biradar N., Maroof N.M., Design and implementation of fractional order integral filter for denoising of echocardiographic images. Published in Elsevier SSRN, ISMAC CVB 2020 as Conference Proceedings, (2020); Heena A., Biradar N., Maroof N.M., Comparative analysis of fractional order calculus in image processing, IEEE Digital Explore on 10 February 2020 with ISBN, pp. 978-981, (2020); Zhao C., Wang Z., Li H., Wu X., Qiao S., Sun J., A new approach for medical image enhancement based on luminance-level modulation and gradient modulation, Biomed. Sig. Process. Control, 48, 186-196, (2019); Vijayakumar T., Vinothkanna R., Retrieval of complex images using visual saliency guided cognitive classification, J. Innov. Image Process, 2, 2, pp. 102-109, (2020)","A. Heena; Department of Electronics and Communication Engineering, BKIT Bhalki Karnataka/VTU Belagavi, Belagavi, Karnataka, India; email: ayeshaheena31@gmail.com","Chen J.I.; Tavares J.M.; Iliyasu A.M.; Du K.","Springer Science and Business Media Deutschland GmbH","","2nd International Conference on Image Processing and Capsule Networks, ICIPCN 2021","27 May 2021 through 28 May 2021","Bangkok","265259","23673370","978-303084759-3","","","English","Lect. Notes Networks Syst.","Conference paper","Final","","Scopus","2-s2.0-85115630582"
"Behura A.","Behura, Aradhana (57216374591)","57216374591","Congruence of Deep Learning in Medical Image Processing: Future Prospects and Challenges","2021","Studies in Computational Intelligence","936","","","197","221","24","0","10.1007/978-981-33-4698-7_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102080369&doi=10.1007%2f978-981-33-4698-7_10&partnerID=40&md5=6dcb672ef762524d0d59f0f1bf9f1f1b","Computer Science and Engineering, Veer Surendra Sai University of Technology, Sambalpur, Odisha, India","Behura A., Computer Science and Engineering, Veer Surendra Sai University of Technology, Sambalpur, Odisha, India","Machine Learning and deep learning procedures, in particular deep reinforcement neural networks, have quickly become a smart approach for scrutinizing medical signal and image datasets. The perilous problem like Cancer takes place when the cellular reproduction procedure goes out of control when some parts of the human body’s cells arise to spread into contiguous fleshy tissue and divide without discontinuing which may be a clue to death. This fatal cancer is a dangerous disease categorized by undesirable, uncontrolled, and uncoordinated cell division. So early cancer diagnosis can protect a patient. Here, various types of deep learning techniques are applied for optimized feature extraction, normalization or dataset pre-processing (used to eliminate null value, noises, and outlier), data segmentation, accurate classification, and the common description of flow chart is described in Figs. 1 and 7. The survey of deep learning is used for image classification, carotid ultrasound data investigation, cardi tocography, intravascular ultrasound report, lung CT report, brain tumor prediction from the MRI report, object detection, segmentation, breast cancer prediction, ECG (electrocardiogram) signal, EEG (electroencephalogram), PPG signal registration and psoriasis skin disease as well as cancer detection. Concise summaries are delivered of trainings per application zone: pulmonary, musculoskeletal neuro, digital pathology, abdominal, retinal, breast, cardiac. There are various type of deep learning techniques are present to improve accuracy of the medical dataset. Deep reinforcement learning, Recursive neural network, Multilayer perceptron, Recurrent neural network, Boltzmann machine, Convolution neural network are different types of deep learning techniques used to train the image and signal dataset. Generative adversarial network, Auto encoder and deep belief neural network are coming under unsupervised pretrained neural network. Some well known architectural models of convolution neural networks are ResNet (2015), VGGNet (2014), GoogLeNet (2014), ZFNet (2013) is introduced as the visualization concept of the De-convolutional network, AlexNet (2012) and LeNet are basically used to train image dataset, LSTM technique (long short term memory) is used to train signalized dataset and RHSBoost, genetically optimized neural network are used for multiple classification of datasets efficiently. Dimensionality reduction, feature extraction, overfitting, underfitting and normalization problems can be solved using various types of optimization algorithm. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Attention module; Biomedical image and signal processing; Brain tumor; Breast cancer; Data prediction; Deep learning; Hyper-parameter; Hypercolumn technique; Magnetic resonance image","","","","","","","","Srinivas M., Roy D., Krishna Mohan C., Discriminative feature extraction of X-ray images using deep neural networks, Proceedings of the 41St IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP, (2016); Lecun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Srinivas M., Krishna Mohan C., Efficient clustering approach using incremental and hierarchical clustering methods, Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN), (2010); Brezeale D., Cook D., Automatic video classification: A survey of the literature, IEEE Trans. Syst. Man Cybern. Part C: Appl. Rev., 38, 3, pp. 416-430, (2008); Smeulder A.W.M., Worring M., Santini S., Gupta A., Jain R., Content based image retrieval at the end of the early years, IEEE Trans. Patternanal. Mach. Intell., 22, 12, pp. 1349-1380, (2000); Srinivas M., Krishna Mohan C., Classification of medical images using edge based features and sparse representation, Proceedings of the 41St IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP, (2016); Srinivas M., Krishna Mohan C., Medical image indexing and retrieval using multi-feature extraction method, Proceedings of the IEEE International Conference on Computational Intelligence and Information Technology (CIIT), (2013); Donoho D., Compressed sensing, IEEE Trans. Inf. Theory, 52, pp. 1289-1306, (2006); Guha T., Ward R., A sparse reconstruction based algorithm for image and video classification, Proceedings of the IEEE Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 3601-3604, (2012); Xiang M., Schonfeld D., Khokhar A.A., Video event classification and image segmentation based on non causal multidimensional hidden Markov models, IEEE Trans. Image Process., 18, 6, pp. 1304-1313, (2009); Pourghassem H., Ghassemian H., Content based medical image classification using a new hierarchical merging scheme, Comput. Med. Imaging Graph., 32, 8, pp. 651-661, (2008); Cai W., Feng D., Fulton R., Content-based retrieval of dynamic PET functional images, IEEE Trans. Inf. Technol. Biomed., 4, 2, pp. 152-158, (2000); Krawczyk B., Schaefer G., Ensemble fusion methods for medical data classification, Proceedings of the IEEE International Symposium on Neural Network Applications in Electrical Engineering (NEUREL), Pp. 143–146, 20–22, (2012); Peng F., Li L., Xu W., Liu W., Zhang J., Shao G., The identification of breast mass based on multi agent interactive information fusion method, Proceedings of the IEEE International Conference on Bioinformatics and Biomedical Engineering, pp. 11-13, (2009); Mitchell T., Machine Learning; Kandi H., Mishra D., Gorthi S.R.K.S., Exploring the learning capabilities of convolutional neural networks for robust image watermarking, Comput. Secur., 65, pp. 247-268, (2017); Dvorak P., Menze B., Structured prediction with convolutional neural networks for multimodal brain tumor segmentation, MICCAI Multimodal Brain Tumor Segmentation Challenge (Brats), pp. 13-24, (2015); Hafiz A.M., Bhat G.M., A survey of deep learning techniques for medical diagnosis, Adv. Intell. Syst. Comput., pp. 161-170, (2019); Siva Raja P.M., Rani A.V., Brain tumor classification using a hybrid deep autoencoder with Bayesian fuzzy clustering-based segmentation approach, Biocybern. Biomed. Eng., (2020); Jiao Z., Gao X., Wang Y., Li J., A deep feature based framework for breast masses classification, Neurocomputing, 197, pp. 221-231, (2016); Bishop C., Pattern Recognition and Machine Learning; Duda R.O., Hart P.E., Stork D.G.; Bengio Y., Practical recommendations for gradient-based training of deep architectures (2012), Sutskever, I. (Ed.) Training Recurrent Neural Networks. Ph.D. Thesis, (2013); Le Q.V., Jaitly N., Hinton G.E., A Simple Way to Initialize Recurrent Networks of Rectified Linear Units, (2015); Sutskever I., Et al., On the Importance of Initialization and Momentum in Deep Learning, (2013); Li F.-F., Karpathy A., Cs231n: Convolutional Neural Networks for Visual Recognition; Srivastava N., Et al., Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Ibid, (2014); Zeiler M.D., Fergus R., Stochastic Pooling for Regularization of Deep Convolutional Neural Networks, (2013); Wertheim J.A., Petrowsky H., Saab S., Kupiec-Weglinski J.W., Busuttil R.W., Major challenges limiting liver transplantation in the United States, Am. J. Transplant., 11, pp. 1773-1784, (2011); Weismuller T.J., Fikatas P., Schmidt J., Et al., Multicentric evaluation of model for end-stage liver disease-based allocation and survival after liver transplantation in Germany dlimitations of the “sickest first”-concept, Transpl. Int., 24, pp. 91-99, (2011); Dutkowski P., Linecker M., Deoliveira M.L., Mullhaupt B., Clavien P.A., Challenges to liver transplantation and strategies to improve outcomes, J. Gastroenterol., 148, pp. 307-323, (2015); Han G., Liu F., Tian Y., Wang H., Wang J., Wang Y., Detection of glucose concentration in a turbid medium using a stacked auto-encoder deep neural network, Infrared Phys. Technol., 105, (2020); Khan H., Shah P.M., Shah M.A., Ul Islam S., Rodrigues J.J.P.C., Cascading handcrafted features and convolutional neural network for IoT-enabled brain tumor segmentation, Comput. Commun., (2020); Havaei M., Davy A., Warde-Farley D., Biard A., Courville A., Bengio Y., Pal C., Jodoin P.M., Larochelle H., Brain tumor segmentation with deep neural networks, Med. Image Anal., 35, pp. 18-31, (2017); Togacar M., Ergen B., Comert Z., BrainMRNet: Brain tumor detection using magnetic resonance images with a novel convolutional neural network model, Med. Hypotheses, (2019); Amin J., Sharif M., Gul N., Raza M., Anjum M.A., Nisar M.W., Bukhari S.A.C., Brain tumor detection by using stacked autoencoders in deep learning, J. Med. Syst., 44, 2, (2019); Nema S., Dudhane A., Murala S., Naidu S., RescueNet: An unpaired GAN for brain tumor segmentation, Biomed. Signal Process. Control, 55, (2020); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., Sanchez C.I., A survey on deep learning in medical image analysis, Med. Image Anal., 42, pp. 60-88, (2017); Abdelaziz Ismael S.A., Mohammed A., Hefny H., An enhanced deep learning approach for brain cancer MRI images classification using residual networks, Artif. Intell. Med., (2019); Ghassemi N., Shoeibi A., Rouhani M., Deep neural network with generative adversarial networks pre-training for brain tumor classification based on MR images, Biomed. Signal Process. Control, 57, (2020); Amin J., Sharif M., Gul N., Yasmin M., Shad S.A., Brain tumor classification based on DWT fusion of MRI sequences using convolutional neural network, Pattern Recognit. Lett., (2019)","A. Behura; Computer Science and Engineering, Veer Surendra Sai University of Technology, Sambalpur, Odisha, India; email: aradhanabehura@gmail.com","","Springer Science and Business Media Deutschland GmbH","","","","","","1860949X","","","","English","Stud. Comput. Intell.","Book chapter","Final","","Scopus","2-s2.0-85102080369"
"Pang S.; Du A.; He X.; Díez J.; Orgun M.A.","Pang, Shuchao (55639762100); Du, Anan (56167972000); He, Xiaoli (57218575078); Díez, Jorge (7201552665); Orgun, Mehmet A. (6603681610)","55639762100; 56167972000; 57218575078; 7201552665; 6603681610","Fast and accurate lung tumor spotting and segmentation for boundary delineation on CT slices in a coarse-to-fine framework","2019","Communications in Computer and Information Science","1142 CCIS","","","589","597","8","12","10.1007/978-3-030-36808-1_64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083005148&doi=10.1007%2f978-3-030-36808-1_64&partnerID=40&md5=93f0717bb39997a65cf80cd949d02c2d","Department of Computing, Macquarie University, Sydney, Australia; School of Electrical and Data Engineering, University of Technology, Sydney, Australia; Department of Internal Medicine, Qingdao Huikang Hospital, Qingdao, China; Artificial Intelligence Center, University of Oviedo at Gijon, Gijon, Spain","Pang S., Department of Computing, Macquarie University, Sydney, Australia; Du A., School of Electrical and Data Engineering, University of Technology, Sydney, Australia; He X., Department of Internal Medicine, Qingdao Huikang Hospital, Qingdao, China; Díez J., Artificial Intelligence Center, University of Oviedo at Gijon, Gijon, Spain; Orgun M.A., Department of Computing, Macquarie University, Sydney, Australia","Label noise and class imbalance are two of the critical challenges when training image-based deep neural networks, especially in the biomedical image processing domain. Our work focuses on how to address the two challenges effectively and accurately in the task of lesion segmentation from biomedical/medical images. To address the pixel-level label noise problem, we propose an advanced transfer training and learning approach with a detailed DICOM pre-processing method. To address the tumor/non-tumor class imbalance problem, we exploit a self-adaptive fully convolutional neural network with an automated weight distribution mechanism to spot the Radiomics lung tumor regions accurately. Furthermore, an improved conditional random field method is employed to obtain sophisticated lung tumor contour delineation and segmentation. Finally, our approach has been evaluated using several well-known evaluation metrics on the Lung Tumor segmentation dataset used in the 2018 IEEE VIP-CUP Challenge. Experimental results show that our weakly supervised learning algorithm outperforms other deep models and state-of-the-art approaches. © Springer Nature Switzerland AG 2019.","Boundary delineation; Fully convolutional neural networks; Lung tumor segmentation","Biological organs; Computerized tomography; Convolutional neural networks; Deep learning; Deep neural networks; Image segmentation; Learning systems; Noise pollution; Petroleum reservoir evaluation; Processing; Transfer learning; Tumors; Boundary delineation; Class imbalance problems; Conditional random field; Critical challenges; Lesion segmentations; Pre-processing method; State-of-the-art approach; Weight distributions; Learning algorithms","","","","","","","Pang S., Yu Z., Orgun M.A., A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images, Comput. Methods Programs Biomed, 140, pp. 283-293, (2017); Litjens G., Et al., A survey on deep learning in medical image analysis, Med. Image Anal, 42, pp. 60-88, (2017); Ju W., Xiang D., Zhang B., Wang L., Kopriva I., Chen X., Random walk and graph cut for co-segmentation of lung tumor on pet-ct images, IEEE Trans. Image Process, 24, 12, pp. 5854-5867, (2015); Song Q., Et al., Optimal co-segmentation of tumor in pet-ct images with context information, IEEE Trans. Med. Imaging, 32, 9, pp. 1685-1697, (2013); Pang S., del Coz J.J., Yu Z., Luaces O., Diez J., Deep learning to frame objects for visual target tracking, Eng. Appl. Artif. Intell, 65, pp. 406-420, (2017); Dong H., Yang G., Liu F., Mo Y., Guo Y., Automatic brain tumor detection and segmentation using u-net based fully convolutional networks, MIUA 2017. CCIS, 723, pp. 506-517, (2017); Christ P.F., Et al., Automatic liver and lesion segmentation in CT using cascaded fully convolutional neural networks and 3D conditional random fields, MICCAI 2016. LNCS, 9901, pp. 415-423, (2016); Ronneberger O., Fischer P., Brox T., U-Net: convolutional networks for biomedical image segmentation, MICCAI 2015. LNCS, 9351, pp. 234-241, (2015); Arganda-Carreras I., Et al., Crowdsourcing the creation of image segmentation algorithms for connectomics, Frontiers in Neuroanatomy, 9, (2015); Krahenbuhl P., Koltun V., Efficient inference in fully connected CRFs with gaussian edge potentials, Advances in Neural Information Processing Systems, pp. 109-117, (2011); Aerts H.J., Velazquez E.R., Leijenaar R.T., Parmar C., Grossmann P., Et al., Decoding tumour phenotype by noninvasive imaging using a quantitative radiomics approach, Nat. Commun, 5, (2014); Mohammadi A., Et al., Lung cancer radiomics: highlights from the ieee video and image processing cup 2018 student competition [sp competitions], IEEE Signal Process. Mag, 36, 1, pp. 164-173, (2018); Badrinarayanan V., Kendall A., Cipolla R., Segnet: a deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell, 39, 12, pp. 2481-2495, (2017); Russakovsky O., Et al., Imagenet large scale visual recognition challenge, Int. J. Comput. Vision, 115, 3, pp. 211-252, (2015)","M.A. Orgun; Department of Computing, Macquarie University, Sydney, Australia; email: mehmet.orgun@mq.edu.au","Gedeon T.; Wong K.W.; Lee M.","Springer","","26th International Conference on Neural Information Processing, ICONIP 2019","12 December 2019 through 15 December 2019","Sydney","235079","18650929","978-303036807-4","","","English","Commun. Comput. Info. Sci.","Conference paper","Final","","Scopus","2-s2.0-85083005148"
"Yi F.; Park S.; Moon I.","Yi, Faliu (36560720900); Park, Seonghwan (57222426113); Moon, Inkyu (55388941800)","36560720900; 57222426113; 55388941800","High-throughput label-free cell detection and counting from diffraction patterns with deep fully convolutional neural networks","2021","Journal of biomedical optics","26","3","","","","","7","10.1117/1.JBO.26.3.036001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102710347&doi=10.1117%2f1.JBO.26.3.036001&partnerID=40&md5=cde0d3a0b06953e5a6a86af21803741a","University of Texas Southwestern Medical Center, Department of Clinical Science, Dallas, TX, United States; Daegu Gyeongbuk Institute of Science and Technology, Department of Robotics Engineering, South Korea","Yi F., University of Texas Southwestern Medical Center, Department of Clinical Science, Dallas, TX, United States; Park S., Daegu Gyeongbuk Institute of Science and Technology, Department of Robotics Engineering, South Korea; Moon I., Daegu Gyeongbuk Institute of Science and Technology, Department of Robotics Engineering, South Korea","SIGNIFICANCE: Digital holographic microscopy (DHM) is a promising technique for the study of semitransparent biological specimen such as red blood cells (RBCs). It is important and meaningful to detect and count biological cells at the single cell level in biomedical images for biomarker discovery and disease diagnostics. However, the biological cell analysis based on phase information of images is inefficient due to the complexity of numerical phase reconstruction algorithm applied to raw hologram images. New cell study methods based on diffraction pattern directly are desirable. AIM: Deep fully convolutional networks (FCNs) were developed on raw hologram images directly for high-throughput label-free cell detection and counting to assist the biological cell analysis in the future. APPROACH: The raw diffraction patterns of RBCs were recorded by use of DHM. Ground-truth mask images were labeled based on phase images reconstructed from RBC holograms using numerical reconstruction algorithm. A deep FCN, which is UNet, was trained on the diffraction pattern images to achieve the label-free cell detection and counting. RESULTS: The implemented deep FCNs provide a promising way to high-throughput and label-free counting of RBCs with a counting accuracy of 99% at a throughput rate of greater than 288 cells per second and 200  μm  ×  200  μm field of view at the single cell level. Compared to convolutional neural networks, the FCNs can get much better results in terms of accuracy and throughput rate. CONCLUSIONS: High-throughput label-free cell detection and counting were successfully achieved from diffraction patterns with deep FCNs. It is a promising approach for biological specimen analysis based on raw hologram directly.","cell counting; deep learning; digital holographic microscopy; holography application; optical information processing; red blood cell analysis","Algorithms; Erythrocytes; Holography; Neural Networks, Computer; algorithm; erythrocyte; holography","","","","","","","","","","NLM (Medline)","","","","","","15602281","","","33686845","English","J Biomed Opt","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85102710347"
"Zhang H.; Li Q.; Guan X.","Zhang, Hengliang (57222557855); Li, Qiang (56312497400); Guan, Xin (57192257319)","57222557855; 56312497400; 57192257319","An Improved Three-Dimensional Dual-Path Brain Tumor Image Segmentation Network; [一种改进的三维双路径脑肿瘤图像分割网络]","2021","Guangxue Xuebao/Acta Optica Sinica","41","3","0310002","","","","12","10.3788/AOS202141.0310002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103215412&doi=10.3788%2fAOS202141.0310002&partnerID=40&md5=ba575ce5a2595d458b5aec43fc165686","School of Microelectronics, Tianjin University, Tianjin, 300072, China","Zhang H., School of Microelectronics, Tianjin University, Tianjin, 300072, China; Li Q., School of Microelectronics, Tianjin University, Tianjin, 300072, China; Guan X., School of Microelectronics, Tianjin University, Tianjin, 300072, China","In recent years, the application of deep learning in biomedical image processing has received widespread attention. Based on the basic theories of deep learning and medical applications, this paper proposes an improved three-dimensional dual-path brain tumor image segmentation network to improve the detection accuracy of brain tumors in nuclear magnetic resonance imaging sequences. The proposed algorithm is based on 3D-UNet. First, the improved dual-path network unit is used to form the encoder-decoder structure similar to UNet. While retaining the original features, the network unit can also generate new features in texture, shape, and edge of the brain tumor to improve the accuracy of network segmentation. Second, the multi-fiber structure is added to the dual-path network module, which reduces the amount of parameters while ensuring the accuracy of the segmentation. Finally, after the group convolution in each network module, the channel random mixing module is added to solve the problem of accuracy reduction caused by group convolution, and the weighted Tversky loss function is used to replace the Dice loss function to improve the segmentation accuracy of small targets. The average Dice_ET, Dice_WT, and Dice_TC of the proposed model are better than 3D-ESPNet, DeepMedic, DMFNet, and other algorithms. The research results have certain practical significance and application prospects. © 2021, Chinese Lasers Press. All right reserved.","Brain tumor image segmentation; Dual-path network; Image processing; Neural networks; Weighted-loss function","Brain; Convolution; Deep learning; Image segmentation; Magnetic resonance imaging; Medical applications; Medical imaging; Textures; Three dimensional computer graphics; Tumors; Application prospect; Detection accuracy; Encoder-decoder; Loss functions; Network segmentation; Research results; Segmentation accuracy; Small targets; Image enhancement","","","","","","","Menze B H, Jakab A, Bauer S, Et al., The multimodal brain tumor image segmentation benchmark (BRATS), IEEE Transactions on Medical Imaging, 34, 10, pp. 1993-2024, (2015); Abd-Ellah M K, Awad A I, Khalaf A A M, Et al., A review on brain tumor diagnosis from MRI images: practical implications, key achievements, and lessons learned, Magnetic Resonance Imaging, 61, pp. 300-318, (2019); Li Q, Bai K X, Zhao L, Et al., Progresss and challenges of MRI brain tumor image segmentation, Journal of Image and Graphics, 25, 3, pp. 419-431, (2020); Tong Y F, Li Q, Guan X., An improved multi-modal brain tumor segmentation hybrid algorithm, Journal of Signal Processing, 34, 3, pp. 340-346, (2018); Ren L, Li Q, Guan X, Et al., Three-dimensional segmentation of brain tumors in magnetic resonance imaging based on improved continuous max-flow, Laser & Optoelectronics Progress, 55, 11, (2018); Ronneberger O, Fischer P, Brox T., U-net: convolutional networks for biomedical image segmentation, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2015, pp. 234-241, (2015); Chu J H, Li X C, Zhang J Q, Et al., Fine-granted segmentation method for three-dimensional brain tumors using cascaded convolutional network, Laser & Optoelectronics Progress, 56, 10, (2019); Cicek O, Abdulkadir A, Lienkamp S S, Et al., 3D U-Net: learning dense volumetric segmentation from sparse annotation, Medical Image Computing and Computer-Assisted Intervention-MICCAI 2016, pp. 424-432, (2016); He C E, Xu H J, Wang Z, Et al., Automatic segmentation algorithm for multimodal magnetic resonance-based brain tumor images, Acta Optica Sinica, 40, 6, (2020); Xing B T, Li Q, Guan X., A brain tumor image segmentation method based on improved fully convolutional neural network, Journal of Signal Processing, 34, 8, pp. 911-922, (2018); Chen C, Liu X P, Ding M, Et al., 3D dilated multi-fiber network for real-time brain tumor segmentation in MRI, Medical Image Computing and Computer Assisted Intervention - MICCAI 2019, pp. 184-192, (2019); Nuechterlein N, Mehta S., 3D-ESPNet with pyramidal refinement for volumetric brain tumor image segmentation, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, pp. 245-253, (2019); Zhang X Y, Zhou X Y, Lin M X, Et al., ShuffleNet: an extremely efficient convolutional neural network for mobile devices, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6848-6856, (2018); Salehi S S M, Erdogmus D, Gholipour A., Tversky loss function for image segmentation using 3D fully convolutional deep networks, Machine Learning in Medical Imaging, pp. 379-387, (2017); Chen Y, Li J, Xiao H, Et al., Dual path networks, Advances in Neural Information Processing Systems, pp. 4467-4475, (2017); He K M, Zhang X Y, Ren S Q, Et al., Deep residual learning for image recognition, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778, (2016); Huang G, Liu Z, van der Maaten L, Et al., Densely connected convolutional networks, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269, (2017); Bakas S, Akbari H, Sotiras A, Et al., Advancing the cancer genome atlas glioma MRI collections with expert segmentation labels and radiomic features, Scientific Data, 4, (2017); Kao P Y, Ngo T, Zhang A, Et al., Brain tumor segmentation and tractographic feature extraction from structural MR images for overall survival prediction, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, pp. 128-141, (2019); Myronenko A., 3D MRI brain tumor segmentation using autoencoder regularization, pp. 311-320, (2019)","Q. Li; School of Microelectronics, Tianjin University, Tianjin, 300072, China; email: liqiang@tju.edu.cn","","Chinese Optical Society","","","","","","02532239","","GUXUD","","Chinese","Guangxue Xuebao","Article","Final","","Scopus","2-s2.0-85103215412"
"Reyes A.A.; Paheding S.; Deo M.; Audette M.","Reyes, Abel A. (57669722600); Paheding, Sidike (56585990900); Deo, Makarand (7102166133); Audette, Michel (57195774826)","57669722600; 56585990900; 7102166133; 57195774826","Gabor Filter-Embedded U-Net with Transformer-Based Encoding for Biomedical Image Segmentation","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13594 LNCS","","","76","88","12","3","10.1007/978-3-031-18814-5_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141829849&doi=10.1007%2f978-3-031-18814-5_8&partnerID=40&md5=5eef604edfb2d00d84fc28f7e3d3da2d","Michigan Technological University, Houghton, 49931, MI, United States; Norfolk State University, Norfolk, 23504, VA, United States; Old Dominion University, Norfolk, 23529, VA, United States","Reyes A.A., Michigan Technological University, Houghton, 49931, MI, United States; Paheding S., Michigan Technological University, Houghton, 49931, MI, United States; Deo M., Norfolk State University, Norfolk, 23504, VA, United States; Audette M., Old Dominion University, Norfolk, 23529, VA, United States","Medical image segmentation involves a process of categorization of target regions that are typically varied in terms of shape, orientation and scales. This requires highly accurate algorithms as marginal segmentation errors in medical images may lead to inaccurate diagnosis in subsequent procedures. The U-Net framework has become one of the dominant deep neural network architectures for medical image segmentation. Due to complex and irregular shape of objects involved in medical images, robust feature representations that correspond to various spatial transformations are key to achieve successful results. Although U-Net-based deep architectures can perform feature extraction and localization, the design of specialized architectures or layer modifications is often an intricate task. In this paper, we propose an effective solution to this problem by introducing Gabor filter banks into the U-Net encoder, which has not yet been well explored in existing U-Net-based segmentation frameworks. In addition, global self-attention mechanisms and Transformer layers are also incorporated into the U-Net framework to capture global contexts. Through extensive testing on two benchmark datasets, we show that the Gabor filter-embedded U-Net with Transformer encoders can enhance the robustness of deep-learned features, and thus achieve a more competitive performance. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Biomedical image; Deep learning; Gabor filters; Segmentation; U-Net; Vision transformers","Benchmarking; Deep neural networks; Diagnosis; Encoding (symbols); Image segmentation; Medical imaging; Network architecture; Signal encoding; Biomedical image segmentation; Biomedical images; Deep learning; Encodings; Medical image segmentation; NET framework; Segmentation; Target regions; U-net; Vision transformer; Gabor filters","","","","","","","Lecun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Lecun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc. IEEE, 86, 11, pp. 2278-2324, (1998); Alom M.Z., Et al., A state-of-the-art survey on deep learning theory and architectures, Electronics, 8, 3, (2019); Nie D., Wang L., Gao Y., Shen D., Fully convolutional networks for multi-modality isointense infant brain image segmentation, 2016 IEEE 13Th International Symposium on Biomedical Imaging (ISBI), pp. 1342-1345, (2016); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, (2015); Oktay O., Et al., Attention U-Net: Learning Where to Look for the Pancreas. Arxiv Preprint Arxiv, 1804, (2018); Paheding S., Reyes A.A., Alam M., Asari V.K., Medical image segmentation using U-Net and progressive neuron expansion, Pattern Recognition and Tracking XXXIII, 1101, (2022); Alom M.Z., Hasan M., Yakopcic C., Taha T.M., Asari V.K., Recurrent Residual Convolutional Neural Network Based on U-Net (R2u-Net) for Medical Image Segmentation. Arxiv Preprint Arxiv, 1802, (2018); Siddique N., Paheding S., Alom M.Z., Devabhaktuni V., Recurrent residual U-Net with efficientnet encoder for medical image segmentation, Pattern Recognition and Tracking XXXII, 1135, pp. 134-142, (2021); Siddique N., Paheding S., Elkin C.P., Devabhaktuni V., U-Net and its variants for medical image segmentation: A review of theory and applications, IEEE Access, 9, pp. 82031-82057, (2021); Paheding S., Reyes A.A., Kasaragod A., Oommen T., GAF-NAU: Gramian angular field encoded neighborhood attention U-Net for pixel-wise hyperspectral image classification, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 409-417, (2022); Soares L.P., Dias H.C., Grohmann C.H., Landslide Segmentation with U-Net: Evaluating Different Sampling Methods and Patch Sizes. Arxiv Preprint Arxiv, 2007, (2020); McGlinchy J., Johnson B., Muller B., Joseph M., Diaz J., Application of UNet fully convolutional neural network to impervious surface segmentation in urban environment from high resolution satellite imagery, 2019 IEEE International Geoscience and Remote Sensing Symposium, IGARSS 2019, Pp. 3915–3918. IEEE, (2019); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding. Arxiv Preprint Arxiv, 1810, (2018); Touvron H., Cord M., Douze M., Massa F., Sablayrolles A., Jegou H., Training data-efficient image transformers & distillation through attention, International Conference on Machine Learning, pp. 10347-10357, (2021); Chen J., Et al., Transunet: Transformers Make Strong Encoders for Medical Image Segmentation. Arxiv Preprint Arxiv, 2102, (2021); Dai J., Et al., Deformable convolutional networks, Proceedings of the IEEE International Conference on Computer Vision, pp. 764-773, (2017); Luan S., Chen C., Zhang B., Han J., Liu J., Gabor convolutional networks, IEEE Trans. Image Process., 27, 9, pp. 4357-4366, (2018); Zhou Y., Ye Q., Qiu Q., Jiao J., Oriented response networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 519-528, (2017); Gabor D., Theory of communication. Part 1: The analysis of information, J. Inst. Electr. Eng.-Part III: Radio Commun. Eng., 93, 26, pp. 429-441, (1946); Jain A.K., Ratha N.K., Lakshmanan S., Object detection using Gabor filters, Pattern Recogn, 30, 2, pp. 295-309, (1997); Gong X., Xia X., Zhu W., Zhang B., Doermann D., Zhuo L., Deformable Gabor feature networks for biomedical image classification, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 4004-4012, (2021); Ouyang W., Wang X., Joint deep learning for pedestrian detection, Proceedings of the IEEE International Conference on Computer Vision, pp. 2056-2063, (2013); Zhang B., Yang Y., Chen C., Yang L., Han J., Shao L., Action recognition using 3D histograms of texture and a multi-class boosting classifier, IEEE Trans. Image Process., 26, 10, pp. 4648-4660, (2017); Alekseev A., Bobe A., GaborNet: Gabor filters with learnable parameters in deep convolutional neural network, 2019 International Conference on Engineering and Telecommunication (Ent), Pp. 1–4. IEEE, (2019); Yuan Y., Et al., Adaptive Gabor convolutional networks, Pattern Recogn, 124, (2022); Yang D., Myronenko A., Wang X., Xu Z., Roth H.R., Xu D., T-AutoML: Automated machine learning for lesion segmentation using transformers in 3D medical imaging, Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 3962-3974, (2021); Vaswani A., Et al., Attention is all you need, Advances in Neural Information Processing Systems, 30, (2017); Wang B., Dong P., Et al., Multiscale transunet++: Dense hybrid U-Net with transformer for medical image segmentation, Signal Image Video Process, 16, pp. 1607-1614, (2022); Wang S., Li L., Zhuang X., AttU-Net: Attention U-Net for brain tumor segmentation, Brainles 2021, 1263, pp. 302-311, (2022); Cereda C.W., Et al., A benchmarking tool to evaluate computer tomography perfusion infarct core predictions against a DWI standard, J. Cereb. Blood Flow Metab., 36, 10, pp. 1780-1789, (2016); Hakim A., Et al., Predicting infarct core from computed tomography perfusion in acute ischemia with machine learning: Lessons from the isles challenge, Stroke, 52, 7, pp. 2328-2337, (2021); Maier O., Et al., ISLES 2015-a public evaluation benchmark for ischemic stroke lesion segmentation from multispectral MRI, Med. Image Anal., 35, pp. 250-269, (2017); Xiong Z., A global benchmark of algorithms for segmenting the left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging, Med. Image Anal., 67, (2021)","S. Paheding; Michigan Technological University, Houghton, 49931, United States; email: spahedin@mtu.edu","Li X.; Li Q.; Lv J.; Huo Y.; Dong B.; Leahy R.M.","Springer Science and Business Media Deutschland GmbH","","3rd International Workshop on Multiscale Multimodal Medical Imaging, MMMI 2022, held in conjunction with the 25th International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2022","22 September 2022 through 22 September 2022","Singapore","285209","03029743","978-303118813-8","","","English","Lect. Notes Comput. Sci.","Conference paper","Final","","Scopus","2-s2.0-85141829849"
"Wahid A.; Shah J.A.; Khan A.U.; Ullah M.; Ayob M.Z.","Wahid, Abdul (58028307700); Shah, Jawad Ali (54930956400); Khan, Adnan Umar (57188694672); Ullah, Mukhtar (57192412884); Ayob, Mohd Zaki (24463629400)","58028307700; 54930956400; 57188694672; 57192412884; 24463629400","Multi-layered basis pursuit algorithms for classification of MR images of Knee ACL tear","2020","IEEE Access","8","","","205424","205435","11","4","10.1109/ACCESS.2020.3037745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102800545&doi=10.1109%2fACCESS.2020.3037745&partnerID=40&md5=2d987b3b1c1d71cb6ff6cb4277fcb5d3","Department of Electrical Engineering, International Islamic University, Islamabad, 44000, Pakistan; Electronics Section, UniKL British Malaysian Institute, Selangor, 53100, Malaysia; Electrical Engineering Department, National University of Computer and Emerging Sciences, Islamabad, 44000, Pakistan","Wahid A., Department of Electrical Engineering, International Islamic University, Islamabad, 44000, Pakistan; Shah J.A., Electronics Section, UniKL British Malaysian Institute, Selangor, 53100, Malaysia; Khan A.U., Department of Electrical Engineering, International Islamic University, Islamabad, 44000, Pakistan; Ullah M., Electrical Engineering Department, National University of Computer and Emerging Sciences, Islamabad, 44000, Pakistan; Ayob M.Z., Electronics Section, UniKL British Malaysian Institute, Selangor, 53100, Malaysia","Deep learning architectures have been extensively used in recent years for the classification of biomedical images to assist clinicians for diagnosis and treatment management of patients with different health conditions. These architectures have demonstrated expert level diagnosis, and in some cases, surpassed human experts in diagnosing health conditions. The automation tools based on deep learning frameworks have the potential to transform all stages of medical imaging pipeline from image acquisition to interpretation and analysis. One of the most common areas where these techniques are applied is knee MR image classification for different types of Anterior Cruciate Ligament (ACL) tears. If properly and timely managed, the diagnosis and treatment of ACL tear can avoid further degradation of patients' knee joints and can also help slow the process of subsequent knee arthritis. In this work, we have implemented a novel classification framework based on multilayered basis pursuit algorithms inspired from recent research work in the area of the theoretical foundation of deep learning with the help of celebrated sparse coding theory. We implement an optimal multi-layered Convolutional Sparse Coding (ML-CSC) framework for classification of a labelled dataset of knee MR images with the coronal view and compare the results with traditional convolutional neural network (CNN) based classifiers. Empirical results demonstrate the effectiveness of the ML-CSC framework and show that the framework can successfully learn distinct features on a small dataset and achieve a good efficiency of more than 92% without employing regularization techniques and extensive training on large datasets. In addition to 95% average accuracy on the presence and absence of ACL tears, the framework also performs well on the imbalanced and challenging classification of partial ACL tear with 85% accuracy. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Basis pursuit; Iterative shrinkage algorithms; Knee MR image classification; Multi-layer convolutional sparse coding","Classification (of information); Computer aided diagnosis; Computer programming; Convolution; Convolutional neural networks; Deep learning; Image coding; Joints (anatomy); Large dataset; Magnetic resonance imaging; Medical imaging; Multilayer neural networks; Network architecture; Patient monitoring; Patient treatment; Anterior cruciate ligament; Classification framework; Learning architectures; Learning frameworks; Pursuit algorithms; Regularization technique; Theoretical foundations; Treatment management; Image classification","","","","","British Malaysian Institute, Universiti Kuala Lumpur, BMI, UniKL, (FRGS/1/2019/TK04/UNIKL/02/6); British Malaysian Institute, Universiti Kuala Lumpur, BMI, UniKL","This work was supported by the UniKL BMI Kuala Lumpur under Grant FRGS/1/2019/TK04/UNIKL/02/6.","Sanders T.L., Maradit Kremers H., Bryan A.J., Larson D.R., Dahm D.L., Levy B.A., Stuart M.J., Krych A.J., Incidence of anterior cruciate ligament tears and reconstruction: A 21-year populationbased study, Amer. J. Sports Med., 44, 6, pp. 1502-1507, (2016); Perrone G.S., Proffen B.L., Kiapour A.M., Sieker J.T., Fleming B.C., Murray M.M., Bench-to-bedside: Bridge-enhanced anterior cruciate ligament repair, J. Orthopaedic Res., 35, 12, pp. 2606-2612, (2017); Louboutin H., Debarge R., Richou J., Selmi T.A.S., Donell S.T., Neyret P., Dubrana F., Osteoarthritis in patients with anterior cruciate ligament rupture: A review of risk factors, Knee, 16, 4, pp. 239-244, (2009); Satku K., Kumar V., Ngoi S., Anterior cruciate ligament injuries. To counsel or to operate?, J. Bone Joint Surg. Brit. Volume, 68, 3, pp. 458-461, (1986); Mink J.H., Levy T., Crues J.V., Tears of the anterior cruciate ligament and menisci of the knee: MR imaging evaluation, Radiology, 167, 3, pp. 769-774, (1988); Zhao Z.-Q., Zheng P., Xu S.-T., Wu X., Object detection with deep learning: A review, IEEE Trans. Neural Netw. Learn. Syst., 30, 11, pp. 3212-3232, (2019); McCann M.T., Jin K.H., Unser M., Convolutional neural networks for inverse problems in imaging: A review, IEEE Signal Process. Mag., 34, 6, pp. 85-95, (2017); Schlemper J., Caballero J., Hajnal J.V., Price A.N., Rueckert D., A deep cascade of convolutional neural networks for dynamic MR image reconstruction, IEEE Trans. Med. Imag., 37, 2, pp. 491-503, (2018); Carvalho J.B.S., Moreira J.-M., Figueiredo M.A.T., Papanikolaou N., Automatic detection and segmentation of lung lesions using deep residual CNNs, Proc. IEEE 19th Int. Conf. Bioinf. Bioengineering (BIBE), pp. 977-983, (2019); Zhou Y., He X., Huang L., Liu L., Zhu F., Cui S., Shao L., Collaborative learning of semi-supervised segmentation and classification for medical images, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2079-2088, (2019); Elad M., Sparse and Redundant Representations: From Theory to Applications in Signal and Image Processing 1st Ed., (2010); Wright J., Yang A.Y., Ganesh A., Shankar Sastry S., Ma Y., Robust face recognition via sparse representation, IEEE Trans. Pattern Anal. Mach. Intell., 31, 2, pp. 210-227, (2009); Luo W., Li J., Yang J., Xu W., Zhang J., Convolutional sparse autoencoders for image classification, IEEE Trans. Neural Netw. Learn. Syst., 29, 7, pp. 3289-3294, (2018); Papyan V., Romano Y., Elad M., Convolutional neural networks analyzed via convolutional sparse coding, J. Mach. Learn. Res., 18, 1, pp. 2887-2938, (2017); Papyan V., Romano Y., Sulam J., Elad M., Theoretical foundations of deep learning via sparse representations: A multilayer sparse model and its connection to convolutional neural networks, IEEE Signal Process. Mag., 35, 4, pp. 72-89, (2018); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105, (2012); Rajpurkar P., Irvin J., Zhu K., Yang B., Mehta H., Duan T., Ding D., Bagul A., Langlotz C., Shpanskaya K., Lungren M.P., Ng A.Y., CheXNet: Radiologist-level Pneumonia Detection on Chest X-Rays with Deep Learning, (2017); Wang X., Peng Y., Lu L., Lu Z., Bagheri M., Summers R.M., ChestX-ray8: Hospital-scale chest X-ray database and benchmarks on weaklysupervised classification and localization of common thorax diseases, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2097-2106, (2017); Rajpurkar P., Hannun A.Y., Haghpanahi M., Bourn C., Ng A.Y., Cardiologist-level Arrhythmia Detection with Convolutional Neural Networks, (2017); Liu F., Guan B., Zhou Z., Samsonov A., Rosas H., Lian K., Sharma R., Kanarek A., Kim J., Guermazi A., Kijowski R., Fully automated diagnosis of anterior cruciate ligament tears on knee MR images by using deep learning, Radiol., Artif. Intell., 1, 3, (2019); Chang P.D., Wong T.T., Rasiej M.J., Deep learning for detection of complete anterior cruciate ligament tear, J. Digit. Imag., 32, 6, pp. 980-986, (2019); Kamatsuki Y., Furumatsu T., Fujii M., Kodama Y., Miyazawa S., Hino T., Ozaki T., Complete tear of the lateral meniscus posterior root is associated with meniscal extrusion in anterior cruciate ligament deficient knees, J. Orthopaedic Res., 36, 7, pp. 1894-1900, (2018); Khan N., Shah J., Stavness I., Bridgeout: Stochastic bridge regularization for deep neural networks, IEEE Access, 6, pp. 42961-42970, (2018); Aberdam A., Sulam J., Elad M., Multi-layer sparse coding: The holistic way, SIAM J. Math. Data Sci., 1, 1, pp. 46-77, (2019); Sulam J., Aberdam A., Beck A., Elad M., On multi-layer basis pursuit, efficient algorithms and convolutional neural networks, IEEE Trans. Pattern Anal. Mach. Intell., 42, 8, pp. 1968-1980, (2020); Makhmalbaf H., Moradi A., Ganji S., Omidi-Kashani F., Accuracy of Lachman and anterior drawer tests for anterior cruciate ligament injuries, Arch. Bone Joint Surg., 1, 2, (2013); Hosny A., Parmar C., Quackenbush J., Schwartz L.H., Aerts H.J.W.L., Artificial intelligence in radiology, Nature Rev. Cancer, 18, 8, pp. 500-510, (2018); Beck A., First-Order Methods in Optimization (MOS-SIAM Series on Optimization), 25, (2017); Zhang J., Ghanem B., ISTA-net: Interpretable optimization-inspired deep network for image compressive sensing, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 1828-1837, (2018); Murdock C., Chang M., Lucey S., Deep component analysis via alternating direction neural networks, Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 820-836, (2018); Daubechies I., Defrise M., De Mol C., An iterative thresholding algorithm for linear inverse problems with a sparsity constraint, Commun. Pure Appl. Math., 57, 11, pp. 1413-1457, (2004); Beck A., Teboulle M., A fast iterative shrinkage-thresholding algorithm for linear inverse problems, SIAM J. Imag. Sci., 2, 1, pp. 183-202, (2009); Tibshirani R.J., Taylor J., The solution path of the generalized lasso, Ann. Statist., 39, 3, pp. 1335-1371, (2011); Chartrand R., Yin W., Iteratively reweighted algorithms for compressive sensing, Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 3869-3872, (2008); Gregor K., Lecun Y., Learning fast approximations of sparse coding, Proc. 27th Int. Conf. Int. Conf. Mach. Learn., pp. 399-406, (2010); Sprechmann P., Bronstein A.M., Sapiro G., Learning efficient sparse and low rank models, IEEE Trans. Pattern Anal. Mach. Intell., 37, 9, pp. 1821-1833, (2015); Chen X., Liu J., Wang Z., Yin W., Theoretical linear convergence of unfolded ISTA and its practical weights and thresholds, Proc. Adv. Neural Inf. Process. Syst., pp. 9061-9071, (2018); Ablin P., Moreau T., Massias M., Gramfort A., Learning step sizes for unfolded sparse coding, Proc. Adv. Neural Inf. Process. Syst., pp. 13100-13110, (2019); Razali M.H., Sazwan S.M., Mahmood M., Nazri D., Ali J., Ayob M.Z., Anterior cruciate ligament (ACL) coronal view injury diagnosis system using convolutional neural network, Proc. 2nd Int. Conf. Electron. Electr. Eng. Technol., pp. 118-122, (2019)","J.A. Shah; Electronics Section, UniKL British Malaysian Institute, Selangor, 53100, Malaysia; email: jawad@unikl.edu.my","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85102800545"
"Ryoo J.; Fan M.; Tang X.; Jiang H.; Arunachalam M.; Naveen S.; Kandemir M.T.","Ryoo, Jihyun (57159124500); Fan, Mengran (57215213163); Tang, Xulong (57013793800); Jiang, Huaipan (56451943700); Arunachalam, Meena (57188576053); Naveen, Sharada (57215213244); Kandemir, Mahmut T. (35549787100)","57159124500; 57215213163; 57013793800; 56451943700; 57188576053; 57215213244; 35549787100","Architecture-Centric Bottleneck Analysis for Deep Neural Network Applications","2019","Proceedings - 26th IEEE International Conference on High Performance Computing, HiPC 2019","","","8990516","205","214","9","4","10.1109/HiPC.2019.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080144759&doi=10.1109%2fHiPC.2019.00034&partnerID=40&md5=bcd37f22c8fbea225ae24f3089f81cdd","Pennsylvania State University, United States; Intel","Ryoo J., Pennsylvania State University, United States; Fan M., Pennsylvania State University, United States; Tang X., Pennsylvania State University, United States; Jiang H., Pennsylvania State University, United States; Arunachalam M., Intel; Naveen S., Intel; Kandemir M.T., Pennsylvania State University, United States","The ever-growing complexity and popularity of machine learning and deep learning applications have motivated an urgent need of effective and efficient support for these applications on contemporary computing systems. In this paper, we thoroughly analyze the various DNN algorithms on three widely used architectures (CPU, GPU, and Xeon Phi). The DNN algorithms we choose for evaluation include i) Unet-for biomedical image segmentation, based on Convolutional Neural Network (CNN), ii) NMT-for neural machine translation based on Recurrent Neural Network (RNN), iii) ResNet-50, and iv) DenseNet-both for image processing based on CNNs. The ultimate goal of this paper is to answer four fundamental questions: i) whether the different DNN networks exhibit similar behavior on a given execution platform? ii) whether, across different platforms, a given DNN network exhibits different behaviors? iii) for the same execution platform and the same DNN network, whether different execution phases have different behaviors? and iv) are the current major general-purpose platforms tuned sufficiently well for different DNN algorithms? Motivated by these questions, we conduct an in-depth investigation of running DNN applications on modern systems. Specifically, we first identify the most time-consuming functions (hotspot functions) across different networks and platforms. Next, we characterize performance bottlenecks and discuss them in detail. Finally, we port selected hotspot functions to a cycle-accurate simulator, and use the results to direct architectural optimizations to better support DNN applications. © 2019 IEEE.","Characterization; CPU; DNN; GPU; Xeon Phi","Bioinformatics; Convolutional neural networks; Graphics processing unit; Image segmentation; Network architecture; Program processors; Recurrent neural networks; Architecture-centric; Biomedical image segmentation; Cycle-accurate simulators; Machine translations; Neural network application; Performance bottlenecks; Recurrent neural network (RNN); Xeon Phi; Deep neural networks","","","","","National Science Foundation, NSF, (1439057, 1526750, 1629129, 1629915, 1763681, 1822923, 1908793, 1931531); Intel Corporation","VIII. ACKNOWLEDGEMENT This work is supported in part by NSF grants 1526750, 1763681, 1439057, 1629129, 1629915, 1931531, 1908793, 1822923 and two grants from Intel.","Abadi M., Barham P., Chen J., Chen Z., Davis A., Dean J., Devin M., Ghemawat S., Irving G., Isard M., Kudlur M., Levenberg J., Monga R., Moore S., Murray D.G., Steiner B., Tucker P., Vasudevan V., Warden P., Wicke M., Yu Y., Zheng X., Tensorflow: A system for large-scale machine learning, OSDI, (2016); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, ArXiv, (2014); Binkert N., Beckmann B., Black G., Reinhardt S.K., Saidi A., Basu A., Hestness J., Hower D.R., Krishna T., Sardashti S., Sen R., Sewell K., Shoaib M., Vaish N., Hill M.D., Wood D.A., The gem5 simulator, Comput. Archit. News, (2011); Bojarski M., Del Testa D., Dworakowski D., Firner B., Flepp B., Goyal P., Jackel L.D., Monfort M., Muller U., Zhang J., Et al., End to end learning for self-driving cars, ArXiv, (2016); Chen T., Du Z., Sun N., Wang J., Wu C., Chen Y., Temam O., Diannao: A small-footprint high-throughput accelerator for ubiquitous machine-learning, ACM Sigplan Notices, (2014); Chen Y., Krishna T., Emer J.S., Sze V., Eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks, IEEE Journal of Solid-State Circuits, (2017); Chetlur S., Woolley C., Vandermersch P., Cohen J., Tran J., Catanzaro B., Shelhamer E., CuDNN: Efficient primitives for deep learning, ArXiv, (2014); Choi W., Jeong K., Choi K., Lee K., Park J., Content addressable memory based binarized neural network accelerator using time-domain signal processing, DAC, (2018); Collobert R., Weston J., Bottou L., Karlen M., Kavukcuoglu K., Kuksa P., Natural language processing (almost) from scratch, Journal of Machine Learning Research, (2011); Fowers J., Ovtcharov K., Papamichael M., Massengill T., Liu M., Lo D., Alkalay S., Haselman M., Adams L., Ghandi M., Heil S., Patel P., Sapek A., Weisz G., Woods L., Lanka S., Reinhardt S.K., Caulfield A.M., Chung E.S., Burger D., A configurable cloud-scale dnn processor for real-time ai, ISCA, (2018); Greff K., Srivastava R.K., Koutnik J., Steunebrink B.R., Schmidhuber J., Lstm: A search space odyssey, Transactions on Neural Networks and Learning Systems, (2016); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, CVPR, (2016); Huang G., Liu Z., Van Der Maaten L., Weinberger K.Q., Densely connected convolutional networks, CVPR, (2017); Jiang H., Sarma A., Ryoo J., Kotra J.B., Arunachalam M., Das C.R., Kandemir M.T., A learning-guided hierarchical approach for biomedical image segmentation, SOCC, pp. 227-232, (2018); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, NIPS, pp. 1097-1105, (2012); P100 white paper, NVIDIA Corporation, (2016); Rhu M., Gimelshein N., Clemons J., Zulfiqar A., Keckler S.W., VDNN: Virtualized deep neural networks for scalable, memory-efficient neural network design, Micro, (2016); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, (2015); Ryoo J., Kislal O., Tang X., Kandemir M.T., Quantifying and optimizing data access parallelism on manycores, MASCOTS, (2018); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, ArXiv, (2014); Sodani A., Gramunt R., Corbal J., Kim H., Vinod K., Chinthamani S., Hutsell S., Agarwal R., Liu Y., Knights landing: Second-generation intel xeon phi product, IEEE Micro, 36, 2, pp. 34-46, (2016); Tang X., Kandemir M., Yedlapalli P., Kotra J., Improving bank-level parallelism for irregular applications, MICRO, (2016); Tang X., Taylan Kandemir M., Zhao H., Jung M., Karakoy M., Computing with near data, SIGMETRICS, (2019); Tang X., Kislal O., Kandemir M., Karakoy M., Data movement aware computation partitioning, MICRO, (2017); Tang X., Pattnaik A., Jiang H., Kayiran O., Jog A., Pai S., Ibrahim M., Kandemir M., Das C., Controlled kernel launch for dynamic parallelism in GPUs, HPCA, (2017); Trudeau J.R., Language translation for real-time text-based conversations, (1999)","","","Institute of Electrical and Electronics Engineers Inc.","AMD; Boston; et al.; Google; Infosys; Shell","26th Annual IEEE International Conference on High Performance Computing, HiPC 2019","17 December 2019 through 20 December 2019","Hyderabad","157722","","978-172814535-8","","","English","Proc. - IEEE Int. Conf. High Perform. Computing, HiPC","Conference paper","Final","","Scopus","2-s2.0-85080144759"
"Ge Y.; Li B.; Zhao Y.; Yan W.","Ge, Yunhao (57195494229); Li, Bin (57199787081); Zhao, Yanzheng (36017835600); Yan, Weixin (24367497900)","57195494229; 57199787081; 36017835600; 24367497900","HH-Net: Image driven microscope fast auto-focus with deep neural network","2019","ACM International Conference Proceeding Series","","","","180","185","5","4","10.1145/3326172.3326225","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069223888&doi=10.1145%2f3326172.3326225&partnerID=40&md5=32f9450d2aeb94d8598fce046d5d9e0c","Robotics Institute, Shanghai Jiao Tong University, Shanghai, China; State Key Lab of Mechanical System and Vibration Shanghai, China","Ge Y., Robotics Institute, Shanghai Jiao Tong University, Shanghai, China; Li B., Robotics Institute, Shanghai Jiao Tong University, Shanghai, China; Zhao Y., State Key Lab of Mechanical System and Vibration Shanghai, China; Yan W., State Key Lab of Mechanical System and Vibration Shanghai, China","Computer aid auto-focus system is necessary for accurate microscope diagnosis, especially for the high precision microscope, which leaves little physical distance for focus adjusting manually. We proposed an image-driven microscope fast auto-focus system with a deep neural network. There are two main contributions. First, combining the high-level feature learning ability advantages of convolution neural network (CNN) and the handcraft feature selection ability of statistical learning, we proposed a High-level-Handcraft Neural Network (HH-Net) to accurately determine the distance index between microscope lens and cell smear by evaluating the image focus quality. It deployed 13 layers CNN for the high-level feature extraction from image patches. While the handcraft features which provide global information from the raw image were extracted by statistical algorithms and merged into CNN features. Finally, the combined features are utilized by the fully connected layers in the network to obtain the final distance index by classifying the biomedical image focus quality. Second, cooperated with the HH-Net, we propose an end to end image driven microscope fast auto-focus system, which can learn auto-focus policies from visual input and finish at a clear spot automatically. The accuracy of our patch level focus quality prediction is 92.4% with HH-Net, while the real-time image level focus quality predication can be 99.99% with 0.025s cost time by certainty voting strategy. Our auto-focus system can also cooperate with the X-Y Micro platform to automatically scan the whole cell smear and get the real-time best-in-focus image of a microscope with fast response, accuracy, and robustness. © 2019 Association for Computing Machinery.","Convolutional neural network; Deep neural network; Fast auto-focus; Handcraft features; High-level features; Image focus quality; Microscope","Biomedical engineering; Convolution; Convolutional neural networks; Deep learning; Feature extraction; Image quality; Microscopes; Network layers; Auto focus; Convolution neural network; Handcraft features; High-level feature extractions; High-level features; Image focus; Statistical algorithm; Statistical learning; Deep neural networks","","","","","","","Lee H.-J., Park T.-H., Auto-focusing system for a curved panel using curve estimation, Information and Automation (ICIA), 2016 IEEE International Conference on, (2016); Swathi R., Mahender E., Increase in accuracy of passive atuo focusing by a new sharpness function[J], Engineering and Technology Research, 3, 1, pp. 156-161, (2014); Cao B.X., Et al., Automatic real-time focus control system for laser processing using dynamic focusing optical system, Optics Express, 25, 23, pp. 28427-28441, (2017); All-Optical Microscope Autofocus Based on An Electrically Tunable Lens and A Totally Internally Reflected IR Laser; Jiao P., Et al., Auto-focusing algorithm based on gray level co-occurrence matrix, Optical Technique, 3, (2018); Haiyan J., Shanshan Z., Hongmin Z., An auto-focus algorithm based on machine learning, Microcomputer & Its Applications, 10, (2016); Qiu P., The feasibility of automatic focusing in digital holography by using Fresnel transform as numerical holographic reconstruction algorithm, Optik-International Journal for Light and Electron Optics, 137, pp. 220-227, (2017); Cabazos-Marin A.R., Alvarez-Borrego J., Automatic focus and fusion image algorithm using nonlinear correlation: Image quality evaluation, Optik, 164, pp. 224-242, (2018); Lofroth M., Avci E., An auto-focusing approach for micro objects at different focal planes, 2018 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM), (2018); Yang S.J., Berndl M., Michael Ando D., Barch M., Narayanaswamy A., Christiansen E., Et al., Assessing microscope image focus quality with deep learning, BMC Bioinformatics, 19, (2018); Kooi T., Litjens G., Van Ginneken B., Gubern-Merida A., Sanchez C.I., Mann R., Den Heeten A., Karssemeijer N., Large scale deep learning for computer aided detection of mammographic lesions, Med Image Anal, 35, pp. 303-312, (2017); Simard P.Y., Steinkraus D., Platt J.C., Best practices for convolutional neural networks applied to visual document analysis, Document Analysis and Recognition, pp. 958-963, (2003); Shannon C.E., The mathematical theory of communication. 1963, MD Comput, 14, pp. 306-317, (1997)","","","Association for Computing Machinery","","9th International Conference on Biomedical Engineering and Technology, ICBET 2019","28 March 2019 through 30 March 2019","Tokyo","149151","","978-145036130-9","","","English","ACM Int. Conf. Proc. Ser.","Conference paper","Final","","Scopus","2-s2.0-85069223888"
"Park I.; Lee U.","Park, Ingyu (57195070543); Lee, Unjoo (55598165900)","57195070543; 55598165900","Automatic, qualitative scoring of the clock drawing test (Cdt) based on u‐net, cnn and mobile sensor data","2021","Sensors","21","15","5239","","","","12","10.3390/s21155239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111697363&doi=10.3390%2fs21155239&partnerID=40&md5=3af1a334615e426a559482b7b8b15a5c","Department of Electronic Engineering, Hallym University, Chuncheon, 24252, South Korea","Park I., Department of Electronic Engineering, Hallym University, Chuncheon, 24252, South Korea; Lee U., Department of Electronic Engineering, Hallym University, Chuncheon, 24252, South Korea","The Clock Drawing Test (CDT) is a rapid, inexpensive, and popular screening tool for cognitive functions. In spite of its qualitative capabilities in diagnosis of neurological diseases, the assessment of the CDT has depended on quantitative methods as well as manual paper based methods. Furthermore, due to the impact of the advancement of mobile smart devices imbedding several sensors and deep learning algorithms, the necessity of a standardized, qualitative, and automatic scoring system for CDT has been increased. This study presents a mobile phone application, mCDT, for the CDT and suggests a novel, automatic and qualitative scoring method using mobile sensor data and deep learning algorithms: CNN, a convolutional network, U‐Net, a convolutional network for biomedical image segmentation, and the MNIST (Modified National Institute of Standards and Technology) database. To obtain DeepC, a trained model for segmenting a contour image from a hand drawn clock image, U‐Net was trained with 159 CDT hand‐drawn images at 128 × 128 resolu-tion, obtained via mCDT. To construct DeepH, a trained model for segmenting the hands in a clock image, U‐Net was trained with the same 159 CDT 128 × 128 resolution images. For obtaining DeepN, a trained model for classifying the digit images from a hand drawn clock image, CNN was trained with the MNIST database. Using DeepC, DeepH and DeepN with the sensor data, parameters of contour (0–3 points), numbers (0–4 points), hands (0–5 points), and the center (0–1 points) were scored for a total of 13 points. From 219 subjects, performance testing was completed with images and sensor data obtained via mCDT. For an objective performance analysis, all the images were scored and crosschecked by two clinical experts in CDT scaling. Performance test analysis derived a sensitivity, specificity, accuracy and precision for the contour parameter of 89.33, 92.68, 89.95 and 98.15%, for the hands parameter of 80.21, 95.93, 89.04 and 93.90%, for the numbers parameter of 83.87, 95.31, 87.21 and 97.74%, and for the center parameter of 98.42, 86.21, 96.80 and 97.91%, respec-tively. From these results, the mCDT application and its scoring system provide utility in differentiating dementia disease subtypes, being valuable in clinical practice and for studies in the field. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Automatic scoring; Clock drawing test; CNN; Deep learning; MNIST; U‐Net; Wearable sensor","Algorithms; Cognition; Humans; Mass Screening; Neuropsychological Tests; Research Design; Bioinformatics; Classification (of information); Clocks; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Learning algorithms; Learning systems; Accuracy and precision; Biomedical image segmentation; Convolutional networks; Mobile phone applications; Mobile smart devices; National Institute of Standards and Technology; Neurological disease; Performance analysis; algorithm; cognition; human; mass screening; methodology; neuropsychological test; Image segmentation","","","","","Basic Science Research, (2020R1F1A1048281); Hallym University, Hallym, (HRF‐202003‐021)","Funding: This research was supported by Basic Science Research (2020R1F1A1048281) and Hallym University Research Fund (HRF‐202003‐021).","Biundo R., Weis L., Bostantjopoulou S., Stefanova E., Falup-Pecurariu C., Kramberger M.G., Geurtsen G.J., Antonini A., Weintraub D., Aarsland D., MMSE and MoCA in Parkinson’s disease and dementia with Lewy bodies: A multicenter 1‐year follow‐up study, J. Neural. Transm, 123, pp. 431-438, (2016); Mittal C., Gorthi S.P., Rohatgi S., Early Cognitive Impairment: Role of Clock Drawing Test, Med. J. Armd. Forces India, 66, pp. 25-28, (2010); Aprahamian I., Martinelli J.E., Neri A.L., Yassuda M.S., The Clock Drawing Test: A review of its accuracy in screening for dementia, Dement. Neuropsychol, 3, pp. 74-81, (2009); Youn Y.C., Pyun J, - M., Ryu N., Baek M.J., Jang J, Park Y.H., Ahn S., - W., Shin H, Park K, Kim S.Y., Use of the Clock Drawing Test and the Rey–Osterrieth Complex Figure Test‐copy with convolutional neural networks to predict cognitive impairment, Alzheimer’s Res. Ther, 13, pp. 1-7, (2021); Straus S.H., Use of the automatic clock drawing test to rapidly screen for cognitive impairment in older adults, drivers, and the physically challenged, J. Am. Geriatr. Soc, 55, pp. 310-311, (2007); Chen S., Stromer D., Alabdalrahim H.A., Schwab S., Weih M., Maier A., Automatic dementia screening and scoring by ap-plying deep learning on clock‐drawing tests, Sci. Rep, 10, pp. 1-11, (2020); Park I., Kim Y.J., Kim Y.J., Lee U., Automatic, Qualitative Scoring of the Interlocking Pentagon Drawing Test (PDT) Based on U‐Net and Mobile Sensor Data, Sensors, 20, (2020); Mann D.L., Heart Failure: A Companion to Braunwald’s Heart Disease, (2011); Spenciere B., Alves H., Charchat-Fichman H., Scoring systems for the Clock Drawing Test: A historical review, Dement. Neu-ropsychol, 11, pp. 6-14, (2017); Eknoyan D., Hurley R.A., Taber K.H., The Clock Drawing Task: Common Errors and Functional Neuroanatomy, J. Neuropsy-chiatry Clin. Neurosci, 24, pp. 260-265, (2012); Talwar N.A., Churchill N.W., Hird M.A., Pshonyak I., Tam F., Fischer C.E., Graham S.J., Schweizer T.A., The Neural Correlates of the Clock‐Drawing Test in Healthy Aging, Front. Hum. Neurosci, 13, (2019); Yuan J., Libon D.J., Karjadi C., Ang A.F., Devine S., Auerbach S.H., Au R., Lin H., Association Between the Digital Clock Drawing Test and Neuropsychological Test Performance: Large Community‐Based Prospective Cohort (Framingham Heart Study), J. Med. Internet Res, 23, (2021); Shulman K., Clock‐drawing: Is it the ideal cognitive screening test?, Int. J. Geriatr. Psychiatry, 15, pp. 548-561, (2000); Sunderland T., Hill J.L., Mellow A.M., Lawlor B.A., Gundersheimer J., Newhouse P.A., Grafman J.H., Clock drawing in Alzheimer’s disease, Nov. Meas. Dement. Sev. J. Am. Geriatr Soc, 37, pp. 725-729, (1989); Nasreddine Z.S., Phillips N.A., Bedirian V., Charbonneau S., Whitehead V., Collin I., The Montreal Cognitive Assessment, MoCA: A brief screening tool for mild cognitive impairment, J. Am. Geriatr Soc, 53, pp. 695-699, (2005); Souillard-Mandar W., Davis R., Rudin C., Au R., Libon D.J., Swenson R., Price C.C., Lamar M., Penney D.L., Learning Classification Models of Cognitive Conditions from Subtle Behaviors in the Digital Clock Drawing Test, Mach. Learn, 102, pp. 393-441, (2016); Nirjon S., Emi I.A., Mondol A.S., Salekin A., Stankovic J.A., MOBI‐COG: A Mobile Application for Instant Screening of Dementia Using the Mini‐Cog Test, Proceedings of the Wireless Health 2014 on National Institutes of Health, (2014); Fabricio A.T., Aprahamian I., Yassuda M.S., Qualitative analysis of the Clock Drawing Test by educational level and cognitive profile, Arq. Neuropsiquiatr, 72, pp. 289-295, (2014); Borson S., Scanlan J., Brush M., Vitaliano P., Dokmak A., The mini‐cog: A cognitive “vital signs” measure for dementia screening in multi‐lingual elderly, Int. J. Geriatr. Psychiatry, 15, pp. 1021-1027, (2000); Harbi Z., Hicks Y., Setchi R., Clock Drawing Test Interpretation System, Procedia Comput. Sci, 112, pp. 1641-1650, (2017); Kim H., Cho Y.S., Do E.I., Computational clock drawing analysis for cognitive impairment screening, Proceedings of the Fifth International Conference on Tangible, Embedded, and Embodied Interaction, pp. 297-300, (2011); Caffarraa P., Gardinia S., Diecib F., Copellib S., Maseta L., Concaria L., Farinac E., Grossid E., The qualitative scoring MMSE pentagon test (QSPT): A new method for differentiating dementia with Lewy Body from Alzheimer’s Disease, Behav. Neurol, 27, pp. 213-220, (2013); Davis R., Libon D., Au R., Pitman D., Penney D., Think: Inferring cognitive status from subtle behaviors, IEEE Int. Conf. Robot. Autom, pp. 2898-2905, (2014); Manos P.J., Wu R., The Ten Point Clock Test: A Quick Screen and Grading Method for Cognitive Impairment in Medical and Surgical Patients, Int. J. Psychiatry Med, 24, pp. 229-244, (1994); Royall D.R., A Cordes J., Polk M., CLOX: An executive clock drawing task, J. Neurol. Neurosurg. Psychiatry, 64, pp. 588-594, (1998); Rouleau I., Salmon D.P., Butters N., Kennedy C., McGuire K., Quantitative and qualitative analyses of clock drawings in Alzheimer’s and Huntington’s disease, Brain Cogn, 18, pp. 70-87, (1992); Muayqil T.A., Tarakji A.R., Khattab A.M., Balbaid N.T., Al-Dawalibi A.M., AlQarni S.A., Hazazi R.A., Alanazy M.H., Comparison of Performance on the Clock Drawing Test Using Three Different Scales in Dialysis Patients, Behav. Neurol, 2020, pp. 1-7, (2020); Shao K., Dong F., Guo S., Wang W., Zhao Z., Yang Y., Wang P., Wang J., Clock‐drawing test: Normative data of three quantitative scoring methods for Chinese‐speaking adults in Shijiazhuang City and clinical utility in patients with acute is-chemic stroke, Brain Behav, 10, (2020); De Pandis M.F., Galli M., Vimercati S., Cimolin V., De Angelis M.V., Albertini G., A New Approach for the Quantitative Evaluation of the Clock Drawing Test: Preliminary Results on Subjects with Parkinson’s Disease, Neurol. Res. Int, 2010, pp. 1-6, (2010); Guha A., Kim H., Do E.Y., Automated Clock Drawing Test through Machine Learning and Geometric Analysis, Proceedings of the 16th International Conference on Distributed Multimedia Systems, DMS 2010, (2010); William S., Randall D., Cynthia R., Rhoda A., Dana L.P., Interpretable Machine Learning Models for the Digital Clock Drawing Test, Proceedings of the 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016), (2016); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Huang G., Liu Z., Weinberger K.Q., Densely Connected Convolutional Networks, (2016); Folstein M.F., Folstein S.E., McHugh P.R., mini‐mental state: A practical method for grading the cognitive state of patients for the clinician, J. Psychiatr. Res, 12, pp. 189-198, (1975); Freedman M., Leach L., Kaplan E., Winocur G., Shulman K.I., Delis D., Clock Drawing: A Neuropsychological Analysis, (1994); Mendes-Santos L.C., Mograbi D., Spenciere B., Charchat-Fichman H., Specific algorithm method of scoring the Clock Drawing Test applied in cognitively normal elderly, Dement. Neuropsychol, 9, pp. 128-135, (2015)","U. Lee; Department of Electronic Engineering, Hallym University, Chuncheon, 24252, South Korea; email: ejlee@hallym.ac.kr","","MDPI AG","","","","","","14248220","","","34372476","English","Sensors","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85111697363"
"Goswami M.","Goswami, Mayank (55636509800)","55636509800","Deep learning models for benign and malign ocular tumor growth estimation","2021","Computerized Medical Imaging and Graphics","93","","101986","","","","9","10.1016/j.compmedimag.2021.101986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115792448&doi=10.1016%2fj.compmedimag.2021.101986&partnerID=40&md5=fc369388af10c8443dda0db183aa6ab7","Divyadrishti Imaging Laboratory, Department of Physics, Indian Institute of Technology Roorkee, Roorkee, India","Goswami M., Divyadrishti Imaging Laboratory, Department of Physics, Indian Institute of Technology Roorkee, Roorkee, India","Relatively abundant availability of medical imaging data has provided significant support in the development and testing of Neural Network based image processing methods. Clinicians often face issues in selecting suitable image processing algorithm for medical imaging data. A strategy for the selection of a proper model is presented here. The training data set comprises optical coherence tomography (OCT) and angiography (OCT-A) images of 50 mice eyes with more than 100 days follow-up. The data contains images from treated and untreated mouse eyes. Four deep learning variants are tested for automatic (a) differentiation of tumor region with healthy retinal layer and (b) segmentation of 3D ocular tumor volumes. Exhaustive sensitivity analysis of deep learning models is performed with respect to the number of training and testing images using eight performance indices to study accuracy, reliability/reproducibility, and speed. U-net with UVgg16 is best for malign tumor data set with treatment (having considerable variation) and U-net with Inception backbone for benign tumor data (with minor variation). Loss value and root mean square error (R.M.S.E.) are found most and least sensitive performance indices, respectively. The performance (via indices) is found to be exponentially improving regarding a number of training images. The segmented OCT-Angiography data shows that neovascularization drives the tumor volume. Image analysis shows that photodynamic imaging-assisted tumor treatment protocol is transforming an aggressively growing tumor into a cyst. An empirical expression is obtained to help medical professionals choose a particular model given the number of images and types of characteristics. We recommend that the presented exercise should be taken as standard practice before employing a particular deep learning model for biomedical image analysis. © 2021 Elsevier Ltd","Cancer growth; Deep CNN; Image segmentation; OCT angiography; OCT imaging","Animals; Deep Learning; Image Processing, Computer-Assisted; Mice; Neoplasms; Neural Networks, Computer; Reproducibility of Results; Tomography, Optical Coherence; Angiography; Bayesian networks; Deep learning; Digital storage; Image analysis; Image enhancement; Image quality; Mammals; Mean square error; Ophthalmology; Optical tomography; Reliability analysis; Sensitivity analysis; Statistical tests; Tumors; Cancer growth; Deep CNN; Images segmentations; Imaging data; Learning models; Ocular tumor; Optical coherence tomography angiography; Optical coherence tomography imaging; Tomography imaging; Tumor volumes; A scan; animal experiment; animal model; antineoplastic protocol; Article; B scan; benign neoplasm; cancer growth; cancer size; classifier; convolutional neural network; deep learning; depth perception; diagnostic accuracy; eye cancer; eye tumor; follow up; image analysis; image segmentation; mouse; neovascularization (pathology); nonhuman; ocular blood vessel; optical coherence tomography; optical coherence tomography angiography; photodynamic therapy; reliability; reproducibility; three-dimensional imaging; tumor differentiation; tumor growth; tumor volume; tumor xenograft; animal; image processing; neoplasm; Image segmentation","","","","","BT/IITR; IMPRINT-II; UCDavis","Funding text 1: This work is partially supported by GRANT Code I.M.P./2018/001045 by IMPRINT-II by S.E.R.B. Government of India. We would like to acknowledge the preliminary contribution made by Mr. Adityaojas Sharma, B.Tech, BT/IITR, and Mr. Kishan Kumar, B.Tech. EE/IITR. OCT Tumor Part of the Data was gathered at Eyepod, UCDavis, CA, U.S.A. by M.G. M.G. is grateful to the Alma Mater.; Funding text 2: This work is partially supported by GRANT Code I.M.P./2018/001045 by IMPRINT-II by S.E.R.B., Government of India . We would like to acknowledge the preliminary contribution made by Mr. Adityaojas Sharma, B.Tech, BT/IITR, and Mr. Kishan Kumar, B.Tech. EE/IITR. OCT Tumor Part of the Data was gathered at Eyepod, UCDavis, CA, U.S.A. by M.G. M.G. is grateful to the Alma Mater. ","Aerts H.J.W.L., Velazquez E.R., Leijenaar R.T.H., Parmar C., Grossmann P., Carvalho S., Bussink J., Monshouwer R., Haibe-Kains B., Rietveld D., Hoebers F., Rietbergen M.M., Leemans C.R., Dekker A., Quackenbush J., Gillies R.J., Lambin P., Decoding tumour phenotype by noninvasive imaging using a quantitative radiomics approach, Nat. Commun., 5, (2014); Arcega R., Yong W.H., Xu H., Malignant melanoma mimicking giant cell variant of glioblastoma multiforme: a case report and review of literature, Int. J. Clin. Exp. Pathol., 8, pp. 5929-5933, (2015); Arora R.S., Eden T.O.B., Kapoor G., Epidemiology of childhood cancer in India, Indian J. Cancer, 46, pp. 264-273, (2009); Baid U., Talbar S., Rane S., Gupta S., Thakur M.H., Moiyadi A., Sable N., Akolkar M., Mahajan A., A novel approach for fully automatic intra-tumor segmentation with 3D U-Net architecture for gliomas, Front. Comput. Neurosci., 14, (2020); Bisgin H., Bera T., Ding H., Semey H.G., Wu L., Liu Z., Barnes A.E., Langley D.A., Pava-Ripoll M., Vyas H.J., Tong W., Xu J., Comparing SVM and ANN based machine learning methods for species identification of food contaminating beetles, Sci. Rep., 8, (2018); Broaddus E., Topham A., Singh A.D., Incidence of retinoblastoma in the U.S.A.: 1975-2004, Br. J. Ophthalmol., 93, pp. 21-23, (2009); Cahall D.E., Rasool G., Bouaynaya N.C., Fathallah-Shaykh H.M., Inception modules enhance brain tumor segmentation, Front. Comput. Neurosci., 13, (2019); Chen L., Jiang M., Chen J.X., Image segmentation using iterative watersheding plus ridge detection, 2009 16th IEEE International Conference on Image Processing (I.C.I.P.), pp. 4033-4036, (2009); Cheng C.-Y., Hsu W.-M., Incidence of eye cancer in Taiwan: an 18-year review, Eye (Lond)., 18, pp. 152-158, (2004); Costache M., Patrascu O.M., Adrian D., Costache D., Sajin M., Ungureanu E., Simionescu O., Ciliary body melanoma - a particularly rare type of ocular tumor. Case report and general considerations, Maedica (Buchar), 8, pp. 360-364, (2013); Dimaras H., Corson T.W., Retinoblastoma, the visible C.N.S. tumor: a review, J. Neurosci. Res., 97, pp. 29-44, (2019); Dimaras H., Corson T.W., Cobrinik D., White A., Zhao J., Munier F.L., Abramson D.H., Shields C.L., Chantada G.L., Njuguna F., Gallie B.L., Retinoblastoma, Nat. Rev. Dis. Prim., 1, (2015); Fujimoto J., Swanson E., The development, commercialization, and impact of optical coherence tomography, Invest. Ophthalmol. Vis. Sci., 57, pp. OCT1-OCT13, (2016); Fuller A., Zawadzki R., Choi S., Wiley D., Werner J., Hamann B., Segmentation of three-dimensional retinal image data, IEEE Trans. Vis. Comput. Graph., 13, pp. 1719-1726, (2007); Gaupel A.-C., Wang W.-L.W., Mordan-McCombs S., Yu Lee E.C., Tenniswood M., Chapter 39 - Xenograft, Transgenic, and Knockout Models of Prostate Cancer, pp. 973-995, (2013); Ghorbani M.A., Zadeh H.A., Isazadeh M., Terzi O., A comparative study of artificial neural network (M.L.P., RBF) and support vector machine models for river flow prediction, Environ. Earth Sci., 75, (2016); Goswami M., Wang X., Zhang P., Xiao W., Karlen S.J., Li Y., Zawadzki R.J., Burns M.E., Lam K.S., Pugh E.N., Novel window for cancer nanotheranostics: noninvasive ocular assessments of tumor growth and nanotherapeutic treatment efficacy in vivo, Biomed. Opt. Express, 10, pp. 151-166, (2019); Hau S.C., Papastefanou V., Shah S., Sagoo M.S., Restori M., Cohen V., Evaluation of iris and iridociliary body lesions with anterior segment optical coherence tomography versus ultrasound B-scan, Br. J. Ophthalmol., 99, pp. 81-86, (2015); He K., Zhang X., Ren S., Sun J., Deep Residual Learning for Image Recognition, (2015); He K., Liu X., Li M., Li X., Yang H., Zhang H., Noninvasive K.R.A.S. mutation estimation in colorectal cancer using a deep learning method based on C.T. imaging, BMC Med. Imaging, 20, (2020); Hutson M., Artificial intelligence faces reproducibility crisis, Science, 359, 80-, pp. 725-726, (2018); Iafrate M., Fruhwirth G.O., How noninvasive in vivo cell tracking supports the development and translation of Cancer immunotherapies, Front. Physiol., 11, (2020); Jain M., Rojanaporn D., Chawla B., Sundar G., Gopal L., Khetan V., Retinoblastoma in Asia, Eye (Lond), 33, pp. 87-96, (2019); Jurdy L., Merks J.H.M., Pieters B.R., Mourits M.P., Kloos R.J.H.M., Strackee S.D., Saeed P., Orbital rhabdomyosarcomas: a review, Saudi J. Ophthalmol. Off. J. Saudi Ophthalmol. Soc., 27, pp. 167-175, (2013); Karaca Y., Cattani C., Moonis M., Comparison of deep learning and support vector machine learning for subgroups of multiple sclerosis B.T, - Computational Science and Its Applications – I.C.C.S.A. 2017, pp. 142-153, (2017); Kumar R.S., Anegondi N., Chandapura R.S., Sudhakaran S., Kadambi S.V., Rao H.L., Aung T., Sinha Roy A., Discriminant function of optical coherence tomography angiography to determine disease severity in Glaucoma, Invest. Ophthalmol. Vis. Sci., 57, pp. 6079-6088, (2016); Lahmiri S., Glioma detection based on multi-fractal features of segmented brain M.R.I. by particle swarm optimization techniques, Biomed. Signal Process. Control, 31, pp. 148-155, (2017); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., van der Laak J.A.W.M., van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Med. Image Anal., 42, pp. 60-88, (2017); Liu X., Faes L., Kale A.U., Wagner S.K., Fu D.J., Bruynseels A., Mahendiran T., Moraes G., Shamdas M., Kern C., Ledsam J.R., Schmid M.K., Balaskas K., Topol E.J., Bachmann L.M., Keane P.A., Denniston A.K., A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis, Lancet Digit. Heal., 1, pp. e271-e297, (2019); Livne M., Rieger J., Aydin O.U., Taha A.A., Akay E.M., Kossen T., Sobesky J., Kelleher J.D., Hildebrand K., Frey D., Madai V.I., A U-Net deep learning framework for high performance vessel segmentation in patients with cerebrovascular disease, Front. Neurosci., 13, (2019); Long J., Shelhamer E., Darrell T., Fully Convolutional Networks for Semantic Segmentation, (2014); Malikova H., Koubska E., Weichet J., Klener J., Rulseh A., Liscak R., Vojtech Z., Can morphological M.R.I. differentiate between primary central nervous system lymphoma and glioblastoma?, Cancer Imaging, 16, (2016); Materin M.A., Kuzmik G.A., Jubinsky P.T., Minja F.J., Asnes J.D., Bulsara K.R., Verification of supraselective drug delivery for retinoblastoma using intra-arterial gadolinium, BMJ Case Rep., 2012, (2012); Mehrara E., Forssell-Aronsson E., Ahlman H., Bernhardt P., Quantitative analysis of tumor growth rate and changes in tumor marker level: specific growth rate versus doubling time, Acta Oncol., 48, pp. 591-597, (2009); Migacz J.V., Gorczynska I., Azimipour M., Jonnal R., Zawadzki R.J., Werner J.S., Megahertz-rate optical coherence tomography angiography improves the contrast of the choriocapillaris and choroid in human retinal imaging, Biomed. Opt. Express, 10, pp. 50-65, (2019); Munir K., Elahi H., Ayub A., Frezza F., Rizzi A., Cancer diagnosis using deep learning: a bibliographic review, Cancers (Basel)., (2019); Parekh V.S., Jacobs M.A., Deep learning and radiomics in precision medicine, Expert Rev. Precis. Med. Drug Dev., 4, pp. 59-72, (2019); Pekala M., Joshi N., Liu T.Y.A., Bressler N.M., DeBuc D.C., Burlina P., Deep learning based retinal OCT segmentation, Comput. Biol. Med., 114, (2019); Peshtani A., Kaliki S., Eagle R.C., Shields C.L., Medulloepithelioma: a triad of clinical features, Oman J. Ophthalmol., 7, pp. 93-95, (2014); Raff E., A Step Toward Quantifying Independently Reproducible Machine Learning Research, (2019); Raju A.R., Suresh P., Rao R.R., Bayesian HCS-based multi-SVNN: a classification approach for brain tumor segmentation and classification using Bayesian fuzzy clustering, Biocybern. Biomed. Eng., 38, pp. 646-660, (2018); Ren J., ANN vs. SVM: which one performs better in classification of M.C.C.s in mammogram imaging, Knowledge-Based Syst., 26, pp. 144-153, (2012); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional Networks for Biomedical Image Segmentation, (2015); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional Networks for Biomedical Image Segmentation B.T. - Medical Image Computing and Computer-Assisted Intervention – M.I.C.C.A.I. 2015, pp. 234-241, (2015); Rueden C.T., Schindelin J., Hiner M.C., DeZonia B.E., Walter A.E., Arena E.T., Eliceiri K.W., ImageJ2: ImageJ for the next generation of scientific image data, BMC Bioinformatics, 18, (2017); Sakr G.E., Mokbel M., Darwich A., Khneisser M.N., Hadi A., Comparing deep learning and support vector machines for autonomous waste sorting, 2016 IEEE International Multidisciplinary Conference on Engineering Technology (I.M.C.E.T.), pp. 207-212, (2016); Saxena M., Christofori G., Rebuilding cancer metastasis in the mouse, Mol. Oncol., 7, pp. 283-296, (2013); Scarbrough P.M., Akushevich I., Wrensch M., Il'yasova D., Exploring the association between melanoma and glioma risks, Ann. Epidemiol., 24, pp. 469-474, (2014); Schoenfield L., Uveal melanoma: a pathologist's perspective and review of translational developments, Adv. Anat. Pathol., 21, pp. 138-143, (2014); Si T., De A., Bhattacharjee A.K., Brain M.R.I. Segmentation for tumor detection via entropy maximization using Grammatical Swarm, Int. J. Wavelets, Multiresolution Inf. Process., 13, (2015); Taheri S., Ong S.H., Chong V.F.H., Level-set segmentation of brain tumors using a threshold-based speed function, Image Vis. Comput., 28, pp. 26-37, (2010); Talkington A., Durrett R., Estimating tumor growth rates in vivo, Bull. Math. Biol., 77, pp. 1934-1954, (2015); Tang L.-J., Gu C.-L., Zhang P., Intraocular lymphoma, Int. J. Ophthalmol., 10, pp. 1301-1307, (2017); Am. J. Ophthalmol., 125, pp. 779-796, (1998); Van Rijsbergen C., Information Retrieval (Book 2nd ed), (1979); Verbraeken H.E., Hanssens M., Priem H., Lafaut B.A., De Laey J.-J., Ocular non-Hodgkin{\textquoteright}s lymphoma: a clinical study of nine cases, Br. J. Ophthalmol., 81, pp. 31-36, (1997); Wang C., Zhao Z., Ren Q., Xu Y., Yu Y., Dense U-net based on patch-based learning for retinal vessel segmentation, Entropy, 21, (2019); Welsh J., Chapter 40 - Animal Models for Studying Prevention and Treatment of Breast Cancer, pp. 997-1018, (2013); Zhang P., Zam A., Jian Y., Wang X., Li Y., Lam K.S., Burns M.E., Sarunic M.V., Pugh E.N., Zawadzki R.J., In vivo wide-field multispectral scanning laser ophthalmoscopy–optical coherence tomography mouse retinal imager: longitudinal imaging of ganglion cells, microglia, and Müller glia, and mapping of the mouse retinal and choroidal vasculature, J. Biomed. Opt., 20, (2015); Zhang X., Zou J., He K., Sun J., Accelerating Very Deep Convolutional Networks for Classification and Detection, (2015); Zhang P., Zawadzki R.J., Goswami M., Nguyen P.T., Yarov-Yarovoy V., Burns M.E., Pugh E.N., In vivo optophysiology reveals that G-protein activation triggers osmotic swelling and increased light scattering of rod photoreceptors, Proc. Natl. Acad. Sci. U. S. A., 114, (2017); Zhang P., Miller E.B., Manna S.K., Meleppat R.K., Pugh E.N., Zawadzki R., Temporal speckle-averaging of optical coherence tomography volumes for in-vivo cellular resolution neuronal and vascular retinal imaging, Neurophotonics, 6, pp. 1-13, (2019); Zhang Z., Wu C., Coleman S., Kerr D., DENSE-INception U-net for medical image segmentation, Comput. Methods Programs Biomed., 192, (2020)","","","Elsevier Ltd","","","","","","08956111","","CMIGE","34509705","English","Comput. Med. Imaging Graph.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85115792448"
"Pang S.; Orgun M.A.; Yu Z.","Pang, Shuchao (55639762100); Orgun, Mehmet A. (6603681610); Yu, Zhezhou (8938987700)","55639762100; 6603681610; 8938987700","A novel biomedical image indexing and retrieval system via deep preference learning","2018","Computer Methods and Programs in Biomedicine","158","","","53","69","16","31","10.1016/j.cmpb.2018.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041721081&doi=10.1016%2fj.cmpb.2018.02.003&partnerID=40&md5=83daf49352eb3580b74fd70ba252d771","College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China; Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia","Pang S., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China, Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Orgun M.A., Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Yu Z., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China","Background and Objectives: The traditional biomedical image retrieval methods as well as content-based image retrieval (CBIR) methods originally designed for non-biomedical images either only consider using pixel and low-level features to describe an image or use deep features to describe images but still leave a lot of room for improving both accuracy and efficiency. In this work, we propose a new approach, which exploits deep learning technology to extract the high-level and compact features from biomedical images. The deep feature extraction process leverages multiple hidden layers to capture substantial feature structures of high-resolution images and represent them at different levels of abstraction, leading to an improved performance for indexing and retrieval of biomedical images. Methods: We exploit the current popular and multi-layered deep neural networks, namely, stacked denoising autoencoders (SDAE) and convolutional neural networks (CNN) to represent the discriminative features of biomedical images by transferring the feature representations and parameters of pre-trained deep neural networks from another domain. Moreover, in order to index all the images for finding the similarly referenced images, we also introduce preference learning technology to train and learn a kind of a preference model for the query image, which can output the similarity ranking list of images from a biomedical image database. To the best of our knowledge, this paper introduces preference learning technology for the first time into biomedical image retrieval. Results: We evaluate the performance of two powerful algorithms based on our proposed system and compare them with those of popular biomedical image indexing approaches and existing regular image retrieval methods with detailed experiments over several well-known public biomedical image databases. Based on different criteria for the evaluation of retrieval performance, experimental results demonstrate that our proposed algorithms outperform the state-of-the-art techniques in indexing biomedical images. Conclusions: We propose a novel and automated indexing system based on deep preference learning to characterize biomedical images for developing computer aided diagnosis (CAD) systems in healthcare. Our proposed system shows an outstanding indexing ability and high efficiency for biomedical image retrieval applications and it can be used to collect and annotate the high-resolution images in a biomedical database for further biomedical image research and applications. © 2018 Elsevier B.V.","Biomedical image retrieval; Convolutional neural network; Deep learning; Preference learning","Algorithms; Databases, Factual; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Information Storage and Retrieval; Machine Learning; Neural Networks (Computer); Radiology Information Systems; Bioinformatics; Computer aided diagnosis; Computer aided instruction; Content based retrieval; Convolution; Database systems; Deep learning; Deep neural networks; Efficiency; Image enhancement; Indexing (of information); Medical computing; Network layers; Neural networks; Query processing; Biomedical image database; Biomedical images; Computer Aided Diagnosis(CAD); Content-Based Image Retrieval; Convolutional neural network; Convolutional Neural Networks (CNN); Preference learning; State-of-the-art techniques; article; diagnosis; diagnostic test accuracy study; extraction; image retrieval; learning; nervous system; algorithm; artificial neural network; diagnostic imaging; factual database; human; image processing; information retrieval; machine learning; procedures; radiology information system; Search engines","","","","","Science and Technology Development Plan of Jilin Province, (20150204007GX); National Natural Science Foundation of China, NSFC, (51409117, 51679105, 61702214); National Natural Science Foundation of China, NSFC; China Scholarship Council, CSC; Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP, (20120061110045); Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP","Funding text 1: Shuchao Pang has been supported by the China Scholarship Council (CSC) and Consulate-General of the People's Republic of China in Sydney. ; Funding text 2: This work was supported by the project of Science and Technology Development Plan of Jilin Province, China (Grant 20150204007GX) and Specialized Research Fund for the Doctoral Program of Higher Education of China (Grant 20120061110045), and National Natural Science Foundation of China (Grants 61702214 , 51409117 , 51679105 ). ","Noor A.M., Holmberg L., Gillett C., Grigoriadis A., Big data: the challenge for small research groups in the era of cancer genomics, Br. J. Cancer, (2015); Fang R., Pouyanfar S., Yang Y., Chen S.C., Iyengar S.S., Computational health informatics in the big data age: a survey, ACM Comput. Surv. (CSUR), 49, 1, (2016); Andreu-Perez J., Poon C.C., Merrifield R.D., Wong S.T., Yang G.Z., Big data for health, IEEE J. Biomed. Health Inf., 19, 4, pp. 1193-1208, (2015); Smith B., Arabandi S., Brochhausen M., Calhoun M., Ciccarese P., Doyle S., Gibaud B., Goldberg I., Kahn C.E., Overton J., Tomaszewski J., Biomedical imaging ontologies: a survey and proposal for future work, J. Pathol. Inf., 6, (2015); Welter P., Fischer B., Gunther R.W., Deserno T.M., Generic integration of content-based image retrieval in computer-aided diagnosis, Comput. Methods Progr. Biomed., 108, 2, pp. 589-599, (2012); Muller H., Rosset A., Vallee J.P., Geissbuhler A., Comparing features sets for content-based image retrieval in a medical-case database, Proceedings of the Medical Imaging 2004, International Society for Optics and Photonics, pp. 99-109, (2004); Quellec G., Lamard M., Cazuguel G., Cochener B., Roux C., Wavelet optimization for content-based image retrieval in medical databases, Medical Image Anal., 14, 2, pp. 227-241, (2010); Scott G., Shyu C.R., Knowledge-driven multidimensional indexing structure for biomedical media database retrieval, IEEE Trans. Inf. Tech. Biomed., 11, 3, pp. 320-331, (2007); Rahman M.M., Antani S.K., Thoma G.R., A learning-based similarity fusion and filtering approach for biomedical image retrieval using SVM classification and relevance feedback, IEEE Trans. Inf. Tech. Biomed., 15, 4, pp. 640-646, (2011); Quddus A., Basir O., Semantic image retrieval in magnetic resonance brain volumes, IEEE Trans. Inf. Tech. Biomed., 16, 3, pp. 348-355, (2012); Ojala T., Pietikainen M., Maenpaa T., Multiresolution gray-scale and rotation invariant texture classification with local binary patterns, IEEE Trans. PAMI, 24, 7, pp. 971-987, (2002); Murala S., Wu Q.J., Local mesh patterns versus local binary patterns: biomedical image indexing and retrieval, IEEE J. Biomed. Health Inf., 18, 3, pp. 929-938, (2014); Dubey S.R., Singh S.K., Singh R.K., Local wavelet pattern: a new feature descriptor for image retrieval in medical CT databases, IEEE Trans. Image Proc., 24, 12, pp. 5892-5903, (2015); Murala S., Wu Q.M., Peak valley edge patterns: a new descriptor for biomedical image indexing and retrieval, Proceedings of the IEEE CVPR Workshops, pp. 444-449, (2013); Dubey S.R., Singh S., Singh R., Local bit-plane decoded pattern: a novel feature descriptor for biomedical image retrieval, IEEE J. Biomed. Health Inf., (2015); Wei C.H., Chen S.Y., Liu X., Mammogram retrieval on similar mass lesions, Comput. Methods Progr. Biomed., 106, 3, pp. 234-248, (2012); De Oliveira J.E., Machado A.M., Chavez G.C., Lopes A.P.B., Deserno T.M., Araujo A.D.A., MammoSys: a content-based image retrieval system using breast density patterns, Comput. Methods Progr. Biomed., 99, 3, pp. 289-297, (2010); Polsterl S., Conjeti S., Navab N., Katouzian A., Survival analysis for high-dimensional, heterogeneous medical data: exploring feature extraction as an alternative to feature selection, Artif. Intell. Med., 72, pp. 1-11, (2016); Brea M.L.S., Rodriguez N.B., Marono N.S., Gonzalez A.M., Garcia-Resua C., Fernandez M.J.G., On the development of conjunctival hyperemia computer-assisted diagnosis tools: Influence of feature selection and class imbalance in automatic gradings, Artif. Intell. Med., 71, pp. 30-42, (2016); Pang S., Yu Z., Orgun M.A., A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images, Comput. Methods Progr. Biomed., 140, pp. 283-293, (2017); Shin H.C., Roth H.R., Gao M., Lu L., Xu Z., Nogues I., Yao J., Mollura D., Summers R.M., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning, IEEE Trans. Med. Imaging, 35, 5, pp. 1285-1298, (2016); Wang C., Elazab A., Wu J., Hu Q., Lung nodule classification using deep feature fusion in chest radiography, Comput. Med. Imaging Gr., 57, pp. 10-18, (2017); Kundu M.K., Chowdhury M., Das S., Interactive radiographic image retrieval system, Comput. Methods Progr. Biomed., 139, pp. 209-220, (2017); Pei X., Emphysema classification using convolutional neural networks, Proceedings of the International Conference on Intelligent Robotics and Application, pp. 455-461, (2015); Karabulut E.M., Ibrikci T., Emphysema discrimination from raw HRCT images by convolutional neural networks, Proceedings of the 2015 9th International Conference on Electrical and Electronics Engineering (ELECO), pp. 705-708, (2015); Pang S.C., Orgun M.A., Du A.A., Yu Z.Z., Leveraging deep preference learning for indexing and retrieval of biomedical images, Proceedings of the 8th International IEEE EMBS Neural Engineering Conference, Shanghai, China, pp. 25-28, (2017); Hu R., Collomosse J., A performance evaluation of gradient field hog descriptor for sketch based image retrieval, Comput. Vis. Image Underst., 117, 7, pp. 790-806, (2013); Dalal N., Triggs B., Histograms of oriented gradients for human detection, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1, pp. 886-893, (2005); Bertinetto L., Valmadre J., Golodetz S., Miksik O., Torr P.H., Staple: complementary learners for real-time tracking, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1401-1409, (2016); Henriques J.F., Caseiro R., Martins P., Batista J., High-speed tracking with kernelized correlation filters, IEEE Trans. Pattern Anal. Mach. Intell., 37, 3, pp. 583-596, (2015); Danelljan M., Shahbaz Khan F., Felsberg M., Van de Weijer J., Adaptive color attributes for real-time visual tracking, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1090-1097, (2014); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Su H., Xing F., Kong X., Xie Y., Zhang S., Yang L., Robust cell detection and segmentation in histopathological images using sparse reconstruction and stacked denoising autoencoders, Proceedings of the International Conf. on Med. Image Computing and Computer-Assisted Intervention, pp. 383-390, (2015); Wang N., Yeung D.Y., Learning a deep compact image representation for visual tracking, Proceedings of the Advances in Neural Information Processing. System, pp. 809-817, (2013); Torralba A., Fergus R., Freeman W.T., 80 million tiny images: a large data set for nonparametric object and scene recognition, IEEE Trans. PAMI, 30, 11, pp. 1958-1970, (2008); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Proceedings of the Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Deng J., Dong W., Socher R., Li L.J., Li K., L F.F., Imagenet: a large-scale hierarchical image database, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255, (2009); Wang C., Elazab A., Wu J., Hu Q., Lung nodule classification using deep feature fusion in chest radiography, Comput. Med. Imaging Gr., 57, pp. 10-18, (2017); Bar Y., Diamant I., Wolf L., Greenspan H., Deep learning with non-medical training used for chest pathology identification, 9414, (2015); van Ginneken B., Setio A.A., Jacobs C., Ciompi F., Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans, Proceedings of the 2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI), pp. 286-289, (2015); Sermanet P., Eigen D., Zhang X., Mathieu M., Fergus R., LeCun Y., Overfeat: Integrated recognition, localization and detection using convolutional networks, International Conference on Learning Representations (ICLR2014), CBLS, (2014); Bar Y., Diamant I., Wolf L., Lieberman S., Konen E., Greenspan H., Chest pathology detection using deep learning with non-medical training, Proceedings of the 2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI), pp. 294-297, (2015); Ciompi F., de Hoop B., van Riel S.J., Chung K., Scholten E.T., Oudkerk M., van Ginneken B., Automatic classification of pulmonary peri-fissural nodules in computed tomography using an ensemble of 2D views and a convolutional neural network out-of-the-box, Med. Image Anal., 26, 1, pp. 195-202, (2015); Bahamonde A., Bayon G.F., Diez J., Quevedo J.R., Luaces O., Del Coz J.J., Alonso J., Goyache F., Feature subset selection for learning preferences: a case study, Proceedings of the Twenty-first International Conference on Machine Learning, (2004); Lu K., He N., Xue J., Dong J., Shao L., Learning view-model joint relevance for 3D object retrieval, IEEE Trans. Image Proc., 24, 5, pp. 1449-1459, (2015); Guo Y., Zhao G., PietikaInen M., Discriminative features for texture description, Pattern Recog., 45, 10, pp. 3834-3843, (2012); (2012); Clark K., Vendt B., Smith K., Freymann J., Kirby J., Koppel P., Moore S., Phillips S., Maffitt D., Pringle M., Tarbox L., The cancer imaging archive (TCIA): maintaining and operating a public information repository, J. Digital Imaging, 26, 6, pp. 1045-1057, (2013); Marcus D.S., Wang T.H., Parker J., Csernansky J.G., Morris J.C., Buckner R.L., Open access series of imaging studies (OASIS): cross-sectional MRI data in young, middle aged, nondemented, and demented older adults, J. Cognit. Neurosci., 19, 9, pp. 1498-1507, (2007); Nguyen A., Yosinski J., Clune J., Deep neural networks are easily fooled: High confidence predictions for unrecognizable images, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 427-436, (2015); Szegedy C., Zaremba W., Sutskever I., Bruna J., Erhan D., Goodfellow I., Fergus R., (2014); Moosavi-Dezfooli S.M., Fawzi A., Frossard P., Deepfool: a simple and accurate method to fool deep neural networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574-2582, (2016); Goodfellow I.J., Shlens J., Szegedy C., Explaining and harnessing adversarial examples, stat, 1050, 20, (2015)","Z. Yu; College of Computer Science and Technology, Jilin University, Jilin Province, Qianjin Street: 2699, China; email: yuzz@jlu.edu.cn","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","29544790","English","Comput. Methods Programs Biomed.","Article","Final","","Scopus","2-s2.0-85041721081"
"Mou L.; Zhao Y.; Fu H.; Liu Y.; Cheng J.; Zheng Y.; Su P.; Yang J.; Chen L.; Frangi A.F.; Akiba M.; Liu J.","Mou, Lei (57211999350); Zhao, Yitian (56583188900); Fu, Huazhu (35317209500); Liu, Yonghuai (7410228990); Cheng, Jun (57535555300); Zheng, Yalin (55948134900); Su, Pan (55507687000); Yang, Jianlong (57212326066); Chen, Li (57192579689); Frangi, Alejandro F. (7005249248); Akiba, Masahiro (35868367900); Liu, Jiang (23389932700)","57211999350; 56583188900; 35317209500; 7410228990; 57535555300; 55948134900; 55507687000; 57212326066; 57192579689; 7005249248; 35868367900; 23389932700","CS2-Net: Deep learning segmentation of curvilinear structures in medical imaging","2021","Medical Image Analysis","67","","101874","","","","206","10.1016/j.media.2020.101874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095451000&doi=10.1016%2fj.media.2020.101874&partnerID=40&md5=b009f6bc25ab7c596e88855ddb43479e","Cixi Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Department of Computer Science, Edge Hill University, Ormskirk, United Kingdom; UBTech Research, UBTech Robotics Corp Ltd, Shenzhen, China; Department of Eye and Vision Science, University of Liverpool, Liverpool, United Kingdom; School of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan, China; Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing and School of Medicine, University of Leeds, Leeds, United Kingdom; Leeds Institute of Cardiovascular and Metabolic Medicine, School of Medicine, University of Leeds, Leeds, United Kingdom; Guangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation, Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Medical Imaging Research Centre (MIRC), University Hospital Gasthuisberg, Cardiovascular Sciences and Electrical Engineering Departments, KU Leuven, Leuven, Belgium; R&D Division, Topcon Corporation, Japan","Mou L., Cixi Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China; Zhao Y., Cixi Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China; Fu H., Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Liu Y., Department of Computer Science, Edge Hill University, Ormskirk, United Kingdom; Cheng J., UBTech Research, UBTech Robotics Corp Ltd, Shenzhen, China; Zheng Y., Cixi Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China, Department of Eye and Vision Science, University of Liverpool, Liverpool, United Kingdom; Su P., Cixi Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China; Yang J., Cixi Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China; Chen L., School of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan, China; Frangi A.F., Cixi Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China, Centre for Computational Imaging and Simulation Technologies in Biomedicine (CISTIB), School of Computing and School of Medicine, University of Leeds, Leeds, United Kingdom, Leeds Institute of Cardiovascular and Metabolic Medicine, School of Medicine, University of Leeds, Leeds, United Kingdom, Medical Imaging Research Centre (MIRC), University Hospital Gasthuisberg, Cardiovascular Sciences and Electrical Engineering Departments, KU Leuven, Leuven, Belgium; Akiba M., R&D Division, Topcon Corporation, Japan; Liu J., Cixi Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China, Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China, Guangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation, Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China","Automated detection of curvilinear structures, e.g., blood vessels or nerve fibres, from medical and biomedical images is a crucial early step in automatic image interpretation associated to the management of many diseases. Precise measurement of the morphological changes of these curvilinear organ structures informs clinicians for understanding the mechanism, diagnosis, and treatment of e.g. cardiovascular, kidney, eye, lung, and neurological conditions. In this work, we propose a generic and unified convolution neural network for the segmentation of curvilinear structures and illustrate in several 2D/3D medical imaging modalities. We introduce a new curvilinear structure segmentation network (CS2-Net), which includes a self-attention mechanism in the encoder and decoder to learn rich hierarchical representations of curvilinear structures. Two types of attention modules - spatial attention and channel attention - are utilized to enhance the inter-class discrimination and intra-class responsiveness, to further integrate local features with their global dependencies and normalization, adaptively. Furthermore, to facilitate the segmentation of curvilinear structures in medical images, we employ a 1×3 and a 3×1 convolutional kernel to capture boundary features. Besides, we extend the 2D attention mechanism to 3D to enhance the network's ability to aggregate depth information across different layers/slices. The proposed curvilinear structure segmentation network is thoroughly validated using both 2D and 3D images across six different imaging modalities. Experimental results across nine datasets show the proposed method generally outperforms other state-of-the-art algorithms in various metrics. © 2020","Attention mechanism; Blood vessel; Curvilinear structure; Deep neural network; Nerve fiber; Segmentation","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Neural Networks, Computer; Blood vessels; Convolution; Deep learning; Diagnosis; Image segmentation; Attention mechanisms; Convolution neural network; Curvilinear structures; Hierarchical representation; Image interpretation; Morphological changes; Precise measurements; State-of-the-art algorithms; Article; convolutional neural network; deep learning; diagnostic accuracy; diagnostic imaging; human; image analysis; image segmentation; priority journal; systematic review; three-dimensional imaging; two-dimensional imaging; algorithm; image processing; Medical imaging","","","","","Leeds Radiotherapy Research Centre of Excellence, (CRUK RadNetC19942/A28832); Ningbo “2025 S&T Megaprojects, (2019B10033, 2019B10061); Shenzhen Ministry of Education; Horizon 2020 Framework Programme, H2020, (777119); Key Technology Research and Development Program of Shandong, (2020C03036); Cancer Research UK, CRUK, (C19942/A28832); National Natural Science Foundation of China, NSFC, (61906181); Natural Science Foundation of Zhejiang Province, ZJNSF, (LQ20F030002, LZ19F010001); Horizon 2020, (SC1-PM-16-2017-777119); Shenzhen University, SZU","Funding text 1: This work was supported by grants from the Zhejiang Provincial Natural Science Foundation (LZ19F010001 and LQ20F030002), the Key Research and Development Program of Zhejiang Province (2020C03036), National Science Foundation Program of China (61906181), and Ningbo “2025 S&T Megaprojects” (2019B10033 and 2019B10061). AFF is supported by the RAEng Chair in Emerging Technologies (INSILEX Pnogramme CiET1819/19), European Union's Horizon 2020 Research and Innovation Programme (InSilc SC1-PM-16-2017-777119), Cancer Research UK funding Leeds Radiotherapy Research Centre of Excellence (CRUK RadNetC19942/A28832), and the Pengcheng Visiting Scholars Award at Shenzhen University from Shenzhen Ministry of Education.; Funding text 2: This work was supported by grants from the Zhejiang Provincial Natural Science Foundation ( LZ19F010001 and LQ20F030002 ), the Key Research and Development Program of Zhejiang Province ( 2020C03036 ), National Science Foundation Program of China ( 61906181 ), and Ningbo “2025 S&T Megaprojects” ( 2019B10033 and 2019B10061 ). AFF is supported by the RAEng Chair in Emerging Technologies (INSILEX Pnogramme CiET1819/19), European Union’s Horizon 2020 Research and Innovation Programme ( InSilc SC1-PM-16-2017-777119 ), Cancer Research UK funding Leeds Radiotherapy Research Centre of Excellence ( CRUK RadNet C19942/A28832 ), and the Pengcheng Visiting Scholars Award at Shenzhen University from Shenzhen Ministry of Education.","Al-Diri B., Hunter A., Steel D., An active contour model for segmenting and measuring retinal vessels, IEEE Trans. Med. Imaging, 28, pp. 1488-1497, (2009); Alom M., Et al., (2018); Annunziata R., Et al., A fully automated tortuosity quantification system with application to corneal nerve fibres in confocal microscopy images, Med. Image Anal., 32, pp. 216-232, (2016); Azzopardi G., Strisciuglio N., Vento M., Petkov N., Trainable cosfire filters for vessel delineation with application to retinal images, Med. Image Anal., 19, 1, pp. 46-57, (2015); Badrinarayanan V., Kendall A., Cipolla R., Segnet: a deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, 12, pp. 2481-2495, (2017); Bankhead P., Scholfield C.N., McGeown J.G., Curtis T.M., Fast retinal vessel detection and measurement using wavelets and edge location refinement, PloS One, 7, 3, (2012); Bibiloni P., Gonzalez-Hidalgo M., Massanet S., A survey on curvilinear object segmentation in multiple applications, Pattern Recognit., 60, pp. 949-970, (2016); Bogunovic H., Pozo J., Frangi A., Automated segmentation of cerebral vasculature with aneurysms in 3DRA and TOF-MRA using geodesic active regions: An evaluation study, Med. Phys., 38, pp. 210-222, (2011); de Carlo T., Romano A., Waheed N., Duker J., A review of optical coherence tomography angiography (OCTA), Int. J. Retina Vitreous, 1, (2015); Cetin S., Demir A., Yezzi A., Degertekin M., Unal G., Vessel tractography using an intensity based tensor model with branch detection, IEEE Trans. Med. Imaging, 32, 2, pp. 348-363, (2012); Cetin S., Unal G., A higher-order tensor vessel tractography for segmentation of vascular structures, IEEE Trans. Med. Imaging, 34, 10, pp. 2172-2185, (2015); Chen D., Zhang J., Cohen L.D., Minimal paths for tubular structure segmentation with coherence penalty and adaptive anisotropy, IEEE Trans. Image Process., 28, pp. 1271-1284, (2019); Cheng Y., Hu X., Wang J., Wang Y., Tamura S., Accurate vessel segmentation with constrained b-snake, IEEE Trans. Image Process., 24, 8, pp. 2440-2455, (2015); Chung A., Noble J., Statistical 3d vessel segmentation using a rician distribution, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 82-89, (1999); Cicek O., Abdulkadir A., Lienkamp S., Brox T., Ronneberger O., 3D U-Net: learning dense volumetric segmentation from sparse annotation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 424-432, (2016); Colonna A., Scarpa F., Ruggeri A., Segmentation of corneal nerves using a U-Net-based convolutional neural network, Computational Pathology and Ophthalmic Medical Image Analysis, (2018); Cuadrado-Godia E., Dwivedi P., Sharma S., Santiago A., Gonzalez J., Balcells M., Laird J., Turk M., Suri H., Nicolaides A., Cerebral small vessel disease: a review focusing on pathophysiology, biomarkers, and machine learning strategies, J. Stroke, 20, 3, (2018); Dai J., Li Y., He K., Sun J., R-FCN: object detection via region-based fully convolutional networks, Advances in Neural Information Processing Systems, pp. 379-387, (2016); Diaz M., Novo J., Cutrin P., Gomez-Ulla F., Penedo M., Ortega M., Automatic segmentation of the foveal avascular zone in ophthalmological OCT-A images, PLoS One, 14, 2, (2019); Ding C., Xia Y., Li Y., Supervised segmentation of vasculature in retinal images using neural networks, 2014 International Conference on Orange Technologies, pp. 49-52, (2014); Eladawi N., Et al., Automatic blood vessels segmentation based on different retinal maps from OCTA scans, Comput. Biol. Med., 89, pp. 150-161, (2017); Frangi A., Niessen W., Vincken K., Viergever M., Multiscale vessel enhancement filtering, International Conference on Medical Image Computing and Computer-Assisted Intervention, 1496, pp. 130-137, (1998); Frangi A.F., Niessen W.J., Vincken K.L., Viergever M.A., Multiscale vessel enhancement filtering, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 130-137, (1998); Franklin S.W., Rajan S.E., Computerized screening of diabetic retinopathy employing blood vessel segmentation in retinal images, Biocybern. Biomed. Eng., 34, 2, pp. 117-124, (2014); Fraz M., Remagnino P., Hoppe A., Uyyanonvara B., Rudnicka A., Owen C., Barman S., Blood vessel segmentation methodologies in retinal images - a survey, Comput. Methods Prog. Biomed., 108, 1, pp. 407-433, (2012); Fu H., Xu Y., Lin S., Wong D., Liu J., Deepvessel: retinal vessel segmentation via deep learning and conditional random field, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 132-139, (2016); Fu J., Liu J., Tian H., Li Y., Bao Y., Fang Z., Lu H., Dual attention network for scene segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3146-3154, (2019); Gibson E., Giganti F., Hu Y., Bonmati E., Bandula S., Gurusamy K., Davidson B., Pereira S., Clarkson M., Barratt D., Automatic multi-organ segmentation on abdominal ct with dense v-networks, IEEE Trans. Med. Imaging, 37, 8, pp. 1822-1834, (2018); Gu Z., Cheng J., Fu H., Zhou K., Hao H., Zhao Y., Zhang T., Gao S., Liu J., Ce-Net: context encoder network for 2d medical image segmentation., IEEE Trans. Med. Imaging, 38, 10, pp. 2281-2292, (2019); Guimaraes P., Wigdahl J., Ruggeri A., A fast and efficient technique for the automatic tracing of corneal nerves in confocal microscopy, Trans. Vis. Sci. Technol., 5, 5, (2016); Jassi P., Hamarneh G., VascuSynth: simulating vascular trees for generating volumetric image data with ground-truth segmentation and tree analysis, Computerized medical imaging and graphics, 34, 8, pp. 605-616, (2010); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Heisler M., Chan F., Mammo Z., Balaratnasingam C., Prentasic P., Docherty G., Ju M., Rajapakse S., Lee S., Merkur A., (2019); Hosseinaee Z., Tan B., Kralj O., Han L., Wong A., Sorbara L., Bizheva K., Fully automated corneal nerve segmentation algorithm for corneal nerves analysis from in-vivo UHR-OCT images, Ophthalmic Technologies XXIX, 10858, (2019); Ioffe S., Szegedy C., (2015); Jin Q., Meng Z., Pham T., Chen Q., Wei L., Su R., Dunet: a deformable network for retinal vessel segmentation, Knowl. Based Syst., 178, pp. 149-162, (2019); Kim J., Markoulli M., Automatic analysis of corneal nerves imaged using in vivo confocal microscopy., Clin. Exp. Optom., 101 2, 2, pp. 147-161, (2018); Kim J., Markoulli M., Automatic analysis of corneal nerves imaged using in vivo confocal microscopy, Clin. Exp. Optom., 101, 2, pp. 147-161, (2018); Lathen G., Jonasson J., Borga M., Blood vessel segmentation using multi-scale quadrature filtering, Pattern Recognit. Lett., 31, 8, pp. 762-767, (2010); Lesage D., Angelini E., Bloch I., Funka-Lea G., Bayesian maximal paths for coronary artery segmentation from 3D CT angiograms, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 222-229, (2009); Li Y., Gong H., Wu W., Liu G., Chen G., An automated method using hessian matrix and random walks for retinal blood vessel segmentation, International Congress on Image and Signal Processing (CISP), pp. 423-427, (2015); Liao W., Rohr K., Kang C., Cho Z., Worz S., Automatic human brain vessel segmentation from 3D 7 Tesla MRA images using fast marching with anisotropic directional prior, 2012 9th IEEE International Symposium on Biomedical Imaging (ISBI), pp. 1140-1143, (2012); Liskowski P., Krawiec K., Segmenting retinal blood vessels with deep neural networks, IEEE Trans. Med. Imaging, 35, 11, pp. 2369-2380, (2016); Maninis K., Pont-Tuset J., Arbelaez P., Gool L.V., Deep retinal image understanding, International Conference on Medical Image Computing and Computer-Assisted Intervention, 9901, pp. 140-148, (2016); Milletari F., Navab N., Ahmadi S., V-Net: fully convolutional neural networks for volumetric medical image segmentation, 2016 Fourth International Conference on 3D Vision (3DV), pp. 565-571, (2016); Mo J., Zhang L., Multi-level deep supervised networks for retinal vessel segmentation, Int. J. Comput. Assist. Radiol. Surg., 12, 12, pp. 2181-2193, (2017); Mou L., Et al., Cs-Net: channel and spatial attention network for curvilinear structure segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 721-730, (2019); Oakley J., Russakoff D., Weinberg R., McCarron M., Izzi J., Mankowski J., (2019); Oktay O., Et al., (2018); Peng C., Zhang X., Yu G., Luo G., Sun J., Large kernel matters–improve semantic segmentation by global convolutional network, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4353-4361, (2017); Poulain E., Malandain G., Vaillant R., 3D coronary vessel tree tracking in X-ray projections, International Conference on Functional Imaging and Modeling of the Heart, pp. 388-396, (2019); Ren S., He K., Girshick R., Sun J., Faster R-CNN: towards real-time object detection with region proposal networks, Advances in Neural Information Processing Systems, pp. 91-99, (2015); Rieber J., Huber A., Erhard I., Mueller S., Schweyer M., Koenig A., Schiele T., Theisen K., Siebert U., Schoenberg S., Cardiac magnetic resonance perfusion imaging for the functional assessment of coronary artery disease: a comparison with coronary angiography and fractional flow reserve, Eur. Heart J., 27, 12, pp. 1465-1471, (2006); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Sanchesa P., Meyer C., Vigon V., Naegel B., Cerebrovascular network segmentation of MRA images with deep learning, 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), pp. 768-771, (2019); Schneider M., Reichold J., Weber B., Szekely G., Hirsch S., Tissue metabolism driven arterial tree generation, Med. Image Anal., 16, 7, pp. 1397-1414, (2012); Shang Y., Deklerck R., Nyssen E., Markova A., de Mey J., Yang X., Sun K., Vascular active contour for vessel tree segmentation, IEEE Trans. Biomed. Eng., 58, pp. 1023-1032, (2011); Shin S., Lee S., Yun I., Lee K., Deep vessel segmentation by learning graphical connectivity, Med. Image Anal., 58, (2019); Soares J.V.B., Leandro J.J.G., Cesar R.M., Jelinek H.F., Cree M.J., Retinal vessel segmentation using the 2-D Gabor wavelet and supervised classification, IEEE Trans. Med. Imaging, 25, 9, pp. 1214-1222, (2006); Staal J., Abramoff M., Niemeijer M., Viergever M., Van Ginneken B., Ridge-based vessel segmentation in color images of the retina, IEEE Trans. Med. Imaging, 23, 4, pp. 501-509, (2004); Szegedy C., Ioffe S., Vanhoucke V., Alemi A.A., Inception-v4, inception-ResNet and the impact of residual connections on learning, Thirty-First AAAI Conference on Artificial Intelligence, (2017); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., Rethinking the inception architecture for computer vision, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826, (2016); Tetteh G., Efremov V., Forkert N., Schneider M., Kirschke J., Weber B., Zimmer C., Piraud M., Menze B., (2018); Wang F., Gu Y., Liu W., Yu Y., He S., Pan J., Context-aware spatio-recurrent curvilinear structure segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 12648-12657, (2019); Wang H., Zhang D., Song Y., Liu S., Wang Y., Feng D., Peng H., Cai W., Segmenting neuronal structure in 3D optical microscope images via knowledge distillation with teacher-student network, 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), pp. 228-231, (2019); Wang J., Chung A., High-order oriented cylindrical flux for curvilinear structure detection and vessel segmentation, International Conference on Information Processing in Medical Imaging, pp. 479-491, (2019); Wang X., Jiang X., Ren J., Blood vessel segmentation from fundus image by a cascade classification framework, Pattern Recognit., 88, pp. 331-341, (2019); Williams B.M., Borroni D., Liu R., Zhao Y., Zhang J., Lim J., Ma B., Romano V., Qi H., Ferdousi M., Et al., An artificial intelligence-based deep learning algorithm for the diagnosis of diabetic neuropathy using corneal confocal microscopy: a development and validation study, Diabetologia, 63, 2, pp. 419-430, (2020); Wilson D., An improved planning protocol for the endovascular treatment of intracranial aneurysms, (1998); Yokogawa H., Kobayashi A., Sugiyama K., Mapping of normal corneal k-structures by in vivo laser confocal microscopy, Cornea, 27, 8, pp. 879-883, (2008); Zhang J., Chen Y., Bekkers E., Wang M., Dashtbozorg B., ter Haar Romeny B., Retinal vessel delineation using a brain-inspired wavelet transform and random forest, Pattern Recognit., 69, pp. 107-123, (2017); Zhang J., Dashtbozorg B., Bekkers E., Pluim J., Duits R., ter Haar Romeny B., Robust retinal vessel segmentation via locally adaptive derivative frames in orientation scores, IEEE Trans. Med. Imaging, 35, 12, pp. 2631-2644, (2016); Zhang Z., Liu Q., Wang Y., Road extraction by deep residual U-Net, IEEE Geosci. Remote Sens. Lett., 15, 5, pp. 749-753, (2018); Zhao H., Shi J., Qi X., Wang X., Jia J., Pyramid scene parsing network, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2281-2890, (2017); Zhang J., Qiao Y., Sarabi M.S., Khansari M.M., Gahm J.K., Kashani A.H., Shi Y., 3D shape modeling and analysis of retinal microvasculature in OCT-angiography images, IEEE Trans. Med. imaging, 39, 5, pp. 1335-1346, (2019); Zhao J., Ai D., Yang Y., Song H., Huang Y., Wang Y., Yang J., Deep feature regression (DFR) for 3D vessel segmentation, Phys. Med. Biol., 64, 11, (2019); Zhao Y., Rada L., Chen K., Harding S.P., Zheng Y., Automated vessel segmentation using infinite perimeter active contour model with hybrid region information with application to retinal images., IEEE Transactions on Medical Imaging, 9, pp. 1797-1807, (2015); Zhao Y., Zhao J., Yang J., Liu Y., Zhao Y., Zheng Y., Xia L., Wang Y., Saliency driven vasculature segmentation with infinite perimeter active contour model, Neurocomputing, 259, pp. 201-209, (2017); Zhao Y., Zheng Y., Liu Y., Zhao Y., Luo L., Yang S., Na T., Wang Y., Liu J., Automatic 2-D/3-D vessel enhancement in multiple modality images using a weighted symmetry filter, IEEE Trans. Med. Imaging, 37, 2, pp. 438-450, (2018); Zhao Y., Zheng Y., Liu Y., Zhao Y., Luo L., Yang S., Na T., Wang Y., Liu J., Automatic 2D/3D vessel enhancement in multiple modality images using a weighted symmetry filter, IEEE Trans. Med. Imaging, 37, 2, pp. 438-450, (2018); Zhou Z., Siddiquee M., Tajbakhsh N., Liang J., Unet++: a nested U-Net architecture for medical image segmentation, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 3-11, (2018)","Y. Zhao; Cixi Institute of Biomedical Engineering, Ningbo Institute of Materials Technology and Engineering, Chinese Academy of Sciences, Ningbo, China; email: yitian.zhao@nimte.ac.cn","","Elsevier B.V.","","","","","","13618415","","MIAEC","33166771","English","Med. Image Anal.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85095451000"
"Dhar S.; Shamir L.","Dhar, Sanchari (57408095800); Shamir, Lior (8906230500)","57408095800; 8906230500","Evaluation of the benchmark datasets for testing the efficacy of deep convolutional neural networks","2021","Visual Informatics","5","3","","92","101","9","15","10.1016/j.visinf.2021.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122645738&doi=10.1016%2fj.visinf.2021.10.001&partnerID=40&md5=b91cbee058e7ab1be4e83952a91a98ac","Kansas State University, Manhattan, 66506, KS, United States","Dhar S., Kansas State University, Manhattan, 66506, KS, United States; Shamir L., Kansas State University, Manhattan, 66506, KS, United States","In the past decade, deep neural networks, and specifically convolutional neural networks (CNNs), have been becoming a primary tool in the field of biomedical image analysis, and are used intensively in other fields such as object or face recognition. CNNs have a clear advantage in their ability to provide superior performance, yet without the requirement to fully understand the image elements that reflect the biomedical problem at hand, and without designing specific algorithms for that task. The availability of easy-to-use libraries and their non-parametric nature make CNN the most common solution to problems that require automatic biomedical image analysis. But while CNNs have many advantages, they also have certain downsides. The features determined by CNNs are complex and unintuitive, and therefore CNNs often work as a “Black Box”. Additionally, CNNs learn from any piece of information in the pixel data that can provide a discriminative signal, making it more difficult to control what the CNN actually learns. Here we follow common practices to test whether CNNs can classify biomedical image datasets, but instead of using the entire image we use merely parts of the images that do not have biomedical content. The experiments show that CNNs can provide high classification accuracy even when they are trained with datasets that do not contain any biomedical information, or can be systematically biased by irrelevant information in the image data. The presence of such consistent irrelevant data is difficult to identify, and can therefore lead to biased experimental results. Possible solutions to this downside of CNNs can be control experiments, as well as other protective practices to validate the results and avoid biased conclusions based on CNN-generated annotations. © 2021 The Author(s)","Convolutional neural networks; Data acquisition bias; Deep learning; Experimental design","Bioinformatics; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Face recognition; Image analysis; Benchmark datasets; Biomedical image analysis; Biomedical problems; Convolutional neural network; Data acquisition bias; Deep learning; Image elements; Learn+; Nonparametrics; Performance; Data acquisition","","","","","Zhejiang University Press; National Science Foundation, NSF, (AST-1903823)","Funding text 1: The research was funded in part by NSF, United States grant AST-1903823. We would like to thank the two knowledgeable anonymous reviewers for the insightful comments that helped to improve the manuscript. We would also like to thank Zhejiang University Press for the funding that makes the paper open access. The study does not involve human subjects. All data used in the study are taken from public databases that were published in the past.; Funding text 2: The research was funded in part by NSF, United States grant AST-1903823 . We would like to thank the two knowledgeable anonymous reviewers for the insightful comments that helped to improve the manuscript. We would also like to thank Zhejiang University Press for the funding that makes the paper open access. ","Abraham V.C., Taylor D.L., Haskins J.R., High content screening applied to large-scale cell biology, Trends Biotechnol., 22, pp. 15-22, (2004); Aina O.E., Adeshina S.A., Aibinu A., Deep learning for image-based cervical cancer detection and diagnosis—a survey, 2019 15th International Conference on Electronics, Computer and Computation, pp. 1-7, (2019); Anwar S.M., Majid M., Qayyum A., Awais M., Alnowami M., Khan M.K., Medical image analysis using convolutional neural networks: a review, J. Med. Syst., 42, pp. 1-13, (2018); Bychkov D., Linder N., Turkki R., Nordling S., Kovanen P.E., Verrill C., Walliander M., Lundin M., Haglund C., Lundin J., Deep learning based tissue analysis predicts outcome in colorectal cancer, Sci. Rep., 8, pp. 1-11, (2018); Cao C., Liu F., Tan H., Song D., Shu W., Li W., Zhou Y., Bo X., Xie Z., Deep learning and its applications in biomedicine, Genom. Proteom. Bioinform., 16, pp. 17-32, (2018); Chen Y.C., Hong D.J.K., Wu C.W., Mupparapu M., Et al., The use of deep convolutional neural networks in biomedical imaging: A review, J. Orofacial Sci., 11, 3, (2019); Goodfellow I.J., Shlens J., Szegedy C., Explaining and harnessing adversarial examples, (2014); Hu Z., Tang J., Wang Z., Zhang K., Zhang L., Sun Q., Deep learning for image-based cancer detection and diagnosis- a survey, Pattern Recognit., 83, pp. 134-149, (2018); Huang L., Joseph A.D., Nelson B., Rubinstein B.I., Tygar J.D., pp. 43-58, (2011); Jaipuria N., Zhang X., Bhasin R., Arafa M., Chakravarty P., Shrivastava S., Manglani S., Murali V.N., pp. 772-773, (2020); Kermany D.S., Goldbaum M., Cai W., Valentim C.C., Liang H., Baxter S.L., McKeown A., Yang G., Wu X., Yan F., Et al., Identifying medical diagnoses and treatable diseases by image-based deep learning, Cell, 172, pp. 1122-1131, (2018); Khan A.I., Shah J.L., Bhat M.M., Coronet: A deep neural network for detection and diagnosis of covid-19 from chest x-ray images, Comput. Methods Programs Biomed., 196, (2020); Khosla A., Zhou T., Malisiewicz T., Efros A.A., Torralba A., Undoing the damage of dataset bias, European Conference on Computer Vision, pp. 158-171, (2012); Kingma D.P., Ba J., Adam: A method for stochastic optimization, (2014); Kortylewski A., Egger B., Schneider A., Gerig T., Morel-Forster A., Vetter T., (2019); LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc. IEEE, 86, pp. 2278-2324, (1998); Li Y., Vasconcelos N., REPAIR: Removing representation bias by dataset resampling, 2019 IEEE International Conference on Computer Vision and Pattern Recognition (CVPR), pp. 9572-9581, (2019); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., Van Der Laak J.A., Van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Med. Image Anal., 42, pp. 60-88, (2017); Liu S., Wang X., Liu M., Zhu J., Towards better analysis of machine learning models: A visual analytics perspective, Vis. Inf., 1, pp. 48-56, (2017); McLaughlin N., Del Rincon J.M., Miller P., Data-augmentation for reducing dataset bias in person re-identification, 2015 12th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), pp. 1-6, (2015); Min S., Lee B., Yoon S., Deep learning in bioinformatics, Brief. Bioinform., 18, pp. 851-869, (2017); Nene S.A., Nayar S.K., Murase H., Et al., Columbia object image library (coil-100), (1996); Nene S.A., Nayar S.K., Murase H., Et al., Columbia object image library (coil-20), (1996); Otsu N., A threshold selection method from gray-level histograms, IEEE Trans. Syst. Man Cybern., 9, pp. 62-66, (1979); Paul H.Y., Singh D., Harvey S.C., Hager G.D., Mullen L.A., Deepcat: Deep computer-aided triage of screening mammography, J. Digital Imag., 34, pp. 27-35, (2021); Pogorelov K., Randel K.R., Griwodz C., Eskeland S.L., de Lange T., Johansen D., Spampinato C., Dang-Nguyen D.T., Lux M., Schmidt P.T., Riegler M., Halvorsen P., Kvasir: A multi-class image dataset for computer aided gastrointestinal disease detection, Proceedings of the 8th ACM on Multimedia Systems Conference, pp. 164-169, (2017); Shamir L., Assessing the efficacy of low-level image content descriptors for computer-based fluorescence microscopy image analysis, J. Microsc., 243, pp. 284-292, (2011); Shamir L., Delaney J.D., Orlov N., Eckley D.M., Goldberg I.G., Pattern recognition software and techniques for biological image analysis, PLoS Comput. Biol., 6, (2010); Shamir L., Eckley D.M., Delaney J., Orlov N., Goldberg I.G., An image informatics method for automated quantitative analysis of phenotype visual similarities, 2009 IEEE/NIH Life Science Systems and Applications Workshop, pp. 96-99, (2009); Shamir L., Orlov N., Eckley D.M., Macura T.J., Goldberg I.G., Iicbu 2008: a proposed benchmark suite for biological image analysis, Med. Biol. Eng. Comput., 46, pp. 943-947, (2008); Shamir L., Orlov N., Eckley D.M., Macura T., Johnston J., Goldberg I.G., Wndchrm–an open source utility for biological image analysis, Source Code Biol. Med., 3, pp. 1-13, (2008); Shen D., Wu G., Suk H.I., Deep learning in medical image analysis, Annu. Rev. Biomed. Eng., 19, pp. 221-248, (2017); Singh S., Carpenter A.E., Genovesio A., Increasing the content of high-content screening: an overview, J. Biomolecular Screen., 19, pp. 640-650, (2014); Sultana F., Sufian A., Dutta P., Advancements in image classification using convolutional neural network, 2018 Fourth International Conference on Research in Computational Intelligence and Communication Networks (ICRCICN), pp. 122-129, (2018); Thomsen K., Christensen A.L., Iversen L., Lomholt H.B., Winther O., Deep learning for diagnostic binary classification of multiple-lesion skin diseases, Front. Med., 7, 604, (2020); Tommasi T., Patricia N., Caputo B., Tuytelaars T., A Deeper Look At Dataset Bias, pp. 37-55, (2017); Torralba A., Efros A.A., Unbiased look at dataset bias, CVPR 2011, pp. 1521-1528, (2011); Wainberg M., Merico D., Delong A., Frey B.J., Deep learning in biomedicine, Nature Biotechnol., 36, pp. 829-838, (2018); Zanella F., Lorens J.B., Link W., High content screening: seeing is believing, Trends Biotechnol., 28, pp. 237-245, (2010); Zhang Y., Lin H., Yang Z., Wang J., Sun Y., Xu B., Zhao Z., Neural network-based approaches for biomedical relation classification: a review, J. Biomed. Inform., 99, (2019); Zhang H., Zhu L., Zhu Y., Yang Y., Motion-excited sampler: Video adversarial attack with sparked prior, Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August (2020) 23–28, Proceedings, Part XX 16, pp. 240-256, (2020)","L. Shamir; Kansas State University, Manhattan, 66506, United States; email: lshamir@mtu.edu","","Elsevier B.V.","","","","","","25432656","","","","English","Vis. Inform.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122645738"
"Alhudhaif A.; Cömert Z.; Polat K.","Alhudhaif, Adi (56404673400); Cömert, Zafer (36543652400); Polat, Kemal (8945093900)","56404673400; 36543652400; 8945093900","Otitis media detection using tympanic membrane images with a novel multi-class machine learning algorithm","2021","PeerJ Computer Science","7","","","1","22","21","19","10.7717/PEERJ-CS.405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102847468&doi=10.7717%2fPEERJ-CS.405&partnerID=40&md5=d579a118956eff6bd2f0fd6cb9d67610","Department of Computer Science, College of Computer Engineering and Sciences in Al-kharj, Prince Sattam bin Abdulaziz University, Alkharj, Saudi Arabia; Department of Software Engineering, Samsun University, Samsun, Turkey; Department of Electrical and Electronics Engineering, Faculty of Engineering, Bolu Abant Izzet Baysal University, Bolu, Turkey","Alhudhaif A., Department of Computer Science, College of Computer Engineering and Sciences in Al-kharj, Prince Sattam bin Abdulaziz University, Alkharj, Saudi Arabia; Cömert Z., Department of Software Engineering, Samsun University, Samsun, Turkey; Polat K., Department of Electrical and Electronics Engineering, Faculty of Engineering, Bolu Abant Izzet Baysal University, Bolu, Turkey","Background: Otitis media (OM) is the infection and inflammation of the mucous membrane covering the Eustachian with the airy cavities of the middle ear and temporal bone. OM is also one of the most common ailments. In clinical practice, the diagnosis of OM is carried out by visual inspection of otoscope images. This vulnerable process is subjective and error-prone. Methods: In this study, a novel computer-aided decision support model based on the convolutional neural network (CNN) has been developed. To improve the generalized ability of the proposed model, a combination of the channel and spatial model (CBAM), residual blocks, and hypercolumn technique is embedded into the proposed model. All experiments were performed on an open-access tympanic membrane dataset that consists of 956 otoscopes images collected into five classes. Results: The proposed model yielded satisfactory classification achievement. The model ensured an overall accuracy of 98.26%, sensitivity of 97.68%, and specificity of 99.30%. The proposed model produced rather superior results compared to the pre-trained CNNs such as AlexNet, VGG-Nets, GoogLeNet, and ResNets. Consequently, this study points out that the CNN model equipped with the advanced image processing techniques is useful for OM diagnosis. The proposed model may help to field specialists in achieving objective and repeatable results, decreasing misdiagnosis rate, and supporting the decision-making processes. © 2021. Alhudhaif et al.","Biomedical image processing; Convolutional neural networks; Decision support system; Deep learning; Otitis media","Convolutional neural networks; Decision making; Decision support systems; Image processing; Learning algorithms; Clinical practices; Computer-aided decision supports; Decision making process; Image processing technique; Misdiagnosis rate; Overall accuracies; Repeatable results; Tympanic membranes; Machine learning","","","","","Prince Sattam bin Abdulaziz University, Alkharj, Saudi Arabia; Deanship of Scientific Research, King Saud University","This publication was supported by the Deanship of Scientific Research at Prince Sattam bin Abdulaziz University, Alkharj, Saudi Arabia. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.","Aduda DSO, Macharia IM, Mugwe P, Oburra H, Farragher B, Brabin B, Mackenzie I., Bacteriology of chronic suppurative otitis media (CSOM) in children in Garissa district, Kenya: a point prevalence study, International Journal of Pediatric Otorhinolaryngology, 77, 7, pp. 1107-1111, (2013); Albu S, Babighian G, Trabalzini F., Prognostic factors in tympanoplasty, American Journal of Otolaryngology, 19, 2, pp. 136-140, (1998); Altuntas Y, Comert Z, Kocamaz AF., Identification of haploid and diploid maize seeds using convolutional neural networks and a transfer learning approach, Computers and Electronics in Agriculture, 163, (2019); Amin J, Sharif M, Anjum MA, Raza M, Bukhari SAC., Convolutional neural network with batch normalization for glioma and stroke lesion detection using MRI, Cognitive Systems Research, 59, pp. 304-311, (2020); Basaran E, Comert Z, Sengur A, Budak U, Celik Y, Togacar M., Chronic tympanic membrane diagnosis based on deep convolutional neural network, 4th International Conference on Computational Mathematics and Engineering Sciences, pp. 1-4, (2019); Basaran E, Sengur A, Comert Z, Budak U, Celik Y, Velappan S., Normal and acute tympanic membrane diagnosis based on gray level co-occurrence matrix and artificial neural networks, 2019 International Artificial Intelligence and Data Processing Symposium, pp. 1-6, (2019); Basaran E, Comert Z, Celik Y., Convolutional neural network approach for automatic tympanic membrane detection and classification, Biomedical Signal Processing and Control, 56, (2020); Bock S, Weiss M., A proof of local convergence for the adam optimizer, IJCNN 2019: International Joint Conference on Neural Network, pp. 1-8, (2019); Budak U., Güzel AB. Automatic grading system for diagnosis of breast cancer exploiting co-occurrence shearlet transform and histogram features, IRBM, 41, 2, pp. 106-114, (2020); Cha D, Pae C, Seong S-B, Choi JY, Park H-J., Automated diagnosis of ear disease using ensemble deep learning with a big otoendoscopy image database, EBioMedicine, 45, pp. 606-614, (2019); Chiong CM, Acuin JM, Labra PJP, Chan AL., 2—ear, nose, and throat disorders, Hunter’s Tropical Medicine and Emerging Infectious Diseases, pp. 105-113, (2020); Comert Z., Fusing fine-tuned deep features for recognizing different tympanic membranes, Biocybernetics and Biomedical Engineering, 40, 1, pp. 40-51, (2020); Comert Z, Kocamaz AF., Open-access software for analysis of fetal heart rate signals, Biomedical Signal Processing and Control, 45, pp. 98-108, (2018); Di Maria D, Cioffi L, Malafronte L, Capocasale MF, Capocasale P., The “TIP algorithm” for the accurate diagnosis of pediatric otitis media, International Journal of Pediatric Otorhinolaryngology, 124, 1, pp. 185-189, (2019); Eckle K, Schmidt-Hieber J., A comparison of deep networks with ReLU activation function and linear spline-type methods, Neural Networks, 110, 2–3, pp. 232-242, (2019); Goggin LS, Eikelboom RH, Atlas MD., Clinical decision support systems and computer-aided diagnosis in otology, Otolaryngology-Head and Neck Surgery, 136, pp. s21-s26, (2007); Gupta A, Harrison PJ, Wieslander H, Pielawski N, Kartasalo K, Partel G, Solorzano L, Suveer A, Klemm AH, Spjuth O, Sintorn I-M, Wahlby C., Deep learning in image cytometry: a review, Cytometry Part A, 95, 4, pp. 366-380, (2019); Kaytez SK, Ocal R, Yumusak N, Celik H, Arslan N, Ibas M., Effect of probiotics in experimental otitis media with effusion, International Journal of Pediatric Otorhinolaryngology, 132, 2, (2020); Kim SH, Kim J-R, Song J-J, Chae S-W., Trend and patterns in the antibiotics prescription for the acute otitis media in Korean children, International Journal of Pediatric Otorhinolaryngology, 130, (2020); Kuruvilla A, Shaikh N, Hoberman A, Kovacevic J., Automated diagnosis of otitis media: vocabulary and grammar, International Journal of Biomedical Imaging, 2013, 1, pp. 1-15, (2013); Lee JY, Choi S-H, Chung JW., Automated classification of the tympanic membrane using a convolutional neural network, Applied Sciences, 9, 9, (2019); Loshchilov I, Hutter F., SGDR: stochastic gradient descent with warm restarts, (2017); Maharjan S, Alsadoon A, Prasad PWC, Al-Dalain T, Alsadoon OH., A novel enhanced softmax loss function for brain tumour detection using deep learning, Journal of Neuroscience Methods, 330, (2020); Mironica I, Vertan C, Gheorghe DC., Automatic pediatric otitis detection by classification of global image features, 2013 E Health and Bioengineering Conference (EHB), pp. 1-4, (2011); Myburgh HC, Jose S, Swanepoel DW, Laurent C., Towards low cost automated smartphone- and cloud-based otitis media diagnosis, Biomedical Signal Processing and Control, 39, 6, pp. 34-52, (2018); Myburgh HC, Van Zijl WH, Swanepoel D, Hellstrom S, Laurent C., Otitis media diagnosis for developing countries using tympanic membrane image-analysis, EBioMedicine, 5, 4, pp. 156-160, (2016); Nakagawa H, Toyoda Y, Albrecht T, Tsukamoto M, Praetorius M, Ishikawa T, Kamiya K, Kusunoki T, Ikeda K, Sertel S., Are human ATP-binding cassette transporter C11 and earwax associated with the incidence of cholesteatoma?, Medical Hypotheses, 114, pp. 19-22, (2018); Nakasima-Lopez S, Castro JR, Sanchez MA, Mendoza O, Rodriguez-Diaz A., An approach on the implementation of full batch, online and mini-batch learning on a Mamdani based neuro-fuzzy system with center-of-sets denazification: analysis and evaluation about its functionality, performance, and behavior, PLOS ONE, 14, 9, (2019); Nesterova AP, Klimov EA, Zharkova M, Sozin S, Sobolev V, Ivanikova NV, Shkrob M, Yuryev A., Diseases of the Ear, Disease Pathways, 2020, pp. 297-325, (2019); Pichichero ME., Otitis media, Pediatric Clinics of North America, 60, 2, pp. 391-407, (2013); Ratre A., Stochastic gradient descent-whale optimization algorithm-based deep convolutional neural network to crowd emotion understanding, Computer Journal, 63, 2, pp. 267-282, (2019); Salah LB, Fourati F., Deep MLP neural network control of bioreactor, 2019 10th International Renewable Energy Congress (IREC), pp. 1-5, (2019); Shie CK, Chang HT, Fan FC, Chen CJ, Fang TY, Wang PC., A hybrid feature-based segmentation and classification system for the computer aided self-diagnosis of otitis media, 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society EMBC 2014, pp. 4655-4658, (2014); Talo M., Automated classification of histopathology images using transfer learning, Artificial Intelligence in Medicine, 101, 8, (2019); Togacar M, Ergen B, Comert Z., COVID-19 detection using deep learning models to exploit Social Mimic Optimization and structured chest X-ray images using fuzzy color and stacking approaches, Computers in Biology and Medicine, 121, (2020); Togacar M, Ergen B, Comert Z., BrainMRNet: brain tumor detection using magnetic resonance images with a novel convolutional neural network model, Medical Hypotheses, 134, 20, pp. 2020-109531, (2020); Togacar M, Ozkurt KB, Ergen B, Comert Z., BreastNet: a novel convolutional neural network model through histopathological images for the diagnosis of breast cancer, Physica A: Statistical Mechanics and its Applications, 545, (2019); Vanneste P, Page C., Otitis media with effusion in children: pathophysiology, diagnosis, and treatment: a review, Journal of Otology, 14, 2, (2019); Vertan C, Gheorghe DC, Ionescu B., Eardrum color content analysis in video-otoscopy images for the diagnosis support of pediatric otitis, ISSCS 2011—International Symposium on Signals, Circuits and Systems, Proceedings, pp. 129-132, (2011); Xu C, Yang J, Lai H, Gao J, Shen L, Yan S., UP-CNN: un-pooling augmented convolutional neural network, Pattern Recognition Letters, 119, 11, pp. 34-40, (2019); Yue B, Fu J, Liang J., Residual recurrent neural networks for learning sequential representations, Information, 9, 3, (2018); Zhang A, Lipton ZC, Li M, Alexander JS., Dive into deep learning, (2020); Zhang C, Pan X, Li H, Gardiner A, Sargent I, Hare J, Atkinson PM., A hybrid MLP-CNN classifier for very fine resolution remotely sensed image classification, ISPRS Journal of Photogrammetry and Remote Sensing, 140, pp. 133-144, (2018); Zhao Z, Zhang Y, Comert Z, Deng Y., Computer-aided diagnosis system of fetal hypoxia incorporating recurrence plot with convolutional neural network, Frontiers in Physiology10, (2019)","A. Alhudhaif; Department of Computer Science, College of Computer Engineering and Sciences in Al-kharj, Prince Sattam bin Abdulaziz University, Alkharj, Saudi Arabia; email: a.alhudhaif@psau.edu.sa","","PeerJ Inc.","","","","","","23765992","","","","English","PeerJ Comput. Sci.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85102847468"
"Zheng Z.; Yan H.; Setzer F.C.; Shi K.J.; Mupparapu M.; Li J.","Zheng, Zhiyang (57219469626); Yan, Hao (56276514800); Setzer, Frank C. (19934334800); Shi, Katherine J. (57216731760); Mupparapu, Mel (7003536251); Li, Jing (37081011600)","57219469626; 56276514800; 19934334800; 57216731760; 7003536251; 37081011600","Anatomically Constrained Deep Learning for Automating Dental CBCT Segmentation and Lesion Detection","2021","IEEE Transactions on Automation Science and Engineering","18","2","9219218","603","614","11","67","10.1109/TASE.2020.3025871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092913468&doi=10.1109%2fTASE.2020.3025871&partnerID=40&md5=b9e40c8229bff18c5891786f55f21b96","H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA, United States; School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ, United States; School of Dental Medicine, University of Pennsylvania, Philadelphia, PA, United States; University of Pennsylvania, Philadelphia, PA, United States; School of Dental Medicine, Tufts University, Boston, 02155, MA, United States","Zheng Z., H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Yan H., School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ, United States; Setzer F.C., School of Dental Medicine, University of Pennsylvania, Philadelphia, PA, United States; Shi K.J., University of Pennsylvania, Philadelphia, PA, United States, School of Dental Medicine, Tufts University, Boston, 02155, MA, United States; Mupparapu M., School of Dental Medicine, University of Pennsylvania, Philadelphia, PA, United States; Li J., H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA, United States","Compared with the rapidly growing artificial intelligence (AI) research in other branches of healthcare, the pace of developing AI capacities in dental care is relatively slow. Dental care automation, especially the automated capability for dental cone beam computed tomography (CBCT) segmentation and lesion detection, is highly needed. CBCT is an important imaging modality that is experiencing ever-growing utilization in various dental specialties. However, little research has been done for segmenting different structures, restorative materials, and lesions using deep learning. This is due to multifold challenges such as content-rich oral cavity and significant within-label variation on each CBCT image as well as the inherent difficulty of obtaining many high-quality labeled images for training. On the other hand, oral-Anatomical knowledge exists in dentistry, which shall be leveraged and integrated into the deep learning design. In this article, we propose a novel anatomically constrained Dense U-Net for integrating oral-Anatomical knowledge with data-driven Dense U-Net. The proposed algorithm is formulated as a regularized or constrained optimization and solved using mean-field variational approximation to achieve computational efficiency. Mathematical encoding for transforming descriptive knowledge into a quantitative form is also proposed. Our experiment demonstrates that the proposed algorithm outperforms the standard Dense U-Net in both lesion detection accuracy and dice coefficient (DICE) indices in multilabel segmentation. Benefited from the integration with anatomical domain knowledge, our algorithm performs well with data from a small number of patients included in the training. Note to Practitioners-This article proposes a novel deep learning algorithm to enable the automated capability for cone beam computed tomography (CBCT) segmentation and lesion detection. Despite the growing adoption of CBCT in various dental specialties, such capability is currently lacking. The proposed work will provide tools to help reduce subjectivity and human errors, as well as streamline and expedite the clinical workflow. This will greatly facilitate dental care automation. Furthermore, due to the capacity of integrating oral-Anatomical knowledge into the deep learning design, the proposed algorithm does not require many high-quality labeled images to train. The algorithm can provide good accuracy under limited training samples. This ability is highly desirable for practitioners by saving labor-intensive, costly labeling efforts, and enjoying the benefits provided by AI.  © 2004-2012 IEEE.","Biomedical image segmentation; healthcare automation; machine learning; neural networks","Approximation algorithms; Computational efficiency; Computerized tomography; Constrained optimization; Data integration; Dentistry; Knowledge management; Cone-beam computed tomography; Dice coefficient; Different structure; Domain knowledge; Imaging modality; Lesion detection; Restorative materials; Variational approximation; Deep learning","","","","","NSF DMS, (1830363, 1903135)","Manuscript received July 9, 2020; revised August 16, 2020; accepted September 18, 2020. Date of publication October 9, 2020; date of current version April 7, 2021. This article was recommended for publication by Lead Guest Editor A. Si and Editor M. Zhang upon evaluation of the reviewers’ comments. This work was supported in part by the NSF DMS under Award 1830363 and Award 1903135. (Corresponding author: Jing Li.) Zhiyang Zheng and Jing Li are with H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA 30332 USA (e-mail: zzheng93@gatech.edu; jing.li@isye.gatech.edu).","Dutra K.L., Et al., Diagnostic accuracy of cone-beam computed tomography and conventional radiography on apical periodontitis: A systematic review and meta-Analysis, J. Endodontics, 42, 3, pp. 356-364, (2016); Parker J.M., Mol A., Rivera E.M., Tawil P.Z., Cone-beam computed tomography uses in clinical endodontics: Observer variability in detecting periapical lesions, J. Endodontics, 43, 2, pp. 184-187, (2017); Aamodt A., Et al., Determination of the hounsfield value for CT-based design of custom femoral stems, J. Bone Joint Surg. Brit, 81, 1, pp. 143-147, (1999); Prevrhal S., Engelke K., Kalender W.A., Accuracy limits for the determination of cortical width and density: The influence of object size and CT imaging parameters, Phys. Med. Biol, 44, 3, (1999); Abdolali F., Zoroofi R.A., Otake Y., Sato Y., Automatic segmentation of maxillofacial cysts in cone beam CT images, Comput. Biol. Med, 72, pp. 108-119, (2016); Li S., Fevens T., Krzyzak A., Jin C., Li S., Toward automatic computer aided dental X-ray analysis using level set method, Proc. Int. Conf. Med. Image Comput.-Assist. Intervent, pp. 670-678, (2005); Okada K., Rysavy S., Flores A., Linguraru M.G., Noninvasive differential diagnosis of dental periapical lesions in cone-beam CT scans, Med. Phys, 42, 4, pp. 1653-1665, (2015); Hiew L.T., Ong S.H., Foong K.W.C., Weng C., Tooth segmentation from cone-beam CT using graph cut, Proc. 2nd Apsipa Annu. Summit Conf, pp. 272-275, (2010); Berdouses E.D., Koutsouri G.D., Tripoliti E.E., Matsopoulos G.K., Oulis C.J., Fotiadis D.I., A computer-Aided automated methodology for the detection and classification of occlusal caries from photographic color images, Comput. Biol. Med, 62, pp. 119-135, (2015); Kida S., Et al., Cone beam computed tomography image quality improvement using a deep convolutional neural network, Cureus, 10, 4, (2018); Lei Y., Et al., Image quality improvement in cone-beam CT using deep learning, Proc. Spie, (2019); Yang H., Liang K., Zhang L., Kang K., Xing Y., Improve 3D conebeam CT reconstruction by slice-wise deep learning, Proc Ieee Nucl. Sci. Symp. Med. Imag. Conf. NSS/MIC, pp. 1-3, (2018); Pei Y., Ai X., Zha H., Xu T., Ma G., 3D exemplar-based random walks for tooth segmentation from cone-beam computed tomography images, Med. Phys, 43, 9, pp. 5040-5050, (2016); Tan C., Sun F., Kong T., Zhang W., Yang C., Liu C., A survey on deep transfer learning, Proc. Int. Conf. Artif. Neural Netw. Mach. Learn. (ICANN). Cham, Switzerland, pp. 270-279, (2018); Perez L., Wang J., The effectiveness of data augmentation in image classification using deep learning, arXiv:1712 04621, (2017); Wang S., Et al., Diabetic retinopathy diagnosis using multichannel generative adversarial network with semisupervision, Ieee Trans. Autom. Sci. Eng., Early Access, (2020); Jegou S., Drozdzal M., Vazquez D., Romero A., Bengio Y., The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation, Proc Ieee Conf. Comput. Vis. Pattern Recognit. Workshops, pp. 11-19, (2017); Hermann K.M., Et al., Teaching machines to read and comprehend, Proc. Adv. Neural Inf. Process. Syst, pp. 1693-1701, (2015); Kumar A., Et al., Ask me anything: Dynamic memory networks for natural language processing, Proc. Int. Conf. Mach. Learn, pp. 1378-1387, (2016); Chen H., Sun M., Tu C., Lin Y., Liu Z., Neural sentiment classification with user and product attention, Proc. Conf. Empirical Methods Natural Lang. Process, pp. 1650-1659, (2016); Shen Y., Huang P.-S., Gao J., Chen W., ReasoNet: Learning to stop reading in machine comprehension, Proc. 23rd Acm Sigkdd Int. Conf. Knowl. Discovery Data Mining, pp. 1047-1055, (2017); Sordoni A., Bachman P., Trischler A., Bengio Y., Iterative alternating neural attention for machine reading, arXiv:1606 02245, (2016); Dhingra B., Liu H., Yang Z., Cohen W.W., Salakhutdinov R., Gated-Attention readers for text comprehension, arXiv:1606 01549, (2016); Sun H., Dhingra B., Zaheer M., Mazaitis K., Salakhutdinov R., Cohen W.W., Open domain question answering using early fusion of knowledge bases and text, arXiv:1809 00782, (2018); Sirignano J., Spiliopoulos K., DGM: A deep learning algorithm for solving partial differential equations, J. Comput. Phys, 375, pp. 1339-1364, (2018); Long Z., Lu Y., Ma X., Dong B., PDE-net: Learning PDEs from data, arXiv:1710 09668, (2017); Richardson M., Domingos P., Markov logic networks, Mach. Learn, 62, 12, pp. 107-136, (2006); Garcez A.D.A., Et al., Neural-symbolic learning and reasoning: Contributions and challenges presented at the AAAI Spring Symp, Ser. Stanford, CA, USA: Stanford Univ, (2015); Towell G.G., Shavlik J.W., Knowledge-based artificial neural networks, Artif. Intell, 70, 12, pp. 119-165, (1994); Franca M.V.M., Zaverucha G., Avila Garcez A.S., Fast relational learning using bottom clause propositionalization with artificial neural networks, Mach. Learn, 94, 1, pp. 81-104, (2014); Kusner M.J., Paige B., Hernandez-Lobato J.M., Grammar variational autoencoder, Proc. 34th Int. Conf. Mach. Learn, 70, pp. 1945-1954, (2017); Collobert R., Weston J., Bottou L., Karlen M., Kavukcuoglu K., Kuksa P., Natural language processing (almost) from scratch, J. Mach. Learn. Res, 12, pp. 2493-2537, (2011); Karaletsos T., Belongie S., Ratsch G., Bayesian representation learning with oracle constraints, arXiv:1506 05011, (2015); Hu Z., Ma X., Liu Z., Hovy E., Xing E., Harnessing deep neural networks with logic rules, arXiv:1603 06318, (2016); Hu Z., Et al., Deep generative models with learnable knowledge constraints, Proc. Adv. Neural Inf. Process. Syst, pp. 10501-10512, (2018); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Proc. Int. Conf. Med. Image Comput.-Assist. Intervent. (MICCAI). Cham, Switzerland, pp. 234-241, (2015); Huang G., Liu Z., Maaten Der L.Van, Weinberger K.Q., Densely connected convolutional networks, Proc Ieee Conf. Comput. Vis. Pattern Recognit, pp. 4700-4708, (2017); Guha Roy A., Conjeti S., Navab N., Wachinger C., QuickNAT: A fully convolutional network for quick and accurate segmentation of neuroanatomy, NeuroImage, 186, pp. 713-727, (2019); Noh H., Hong S., Han B., Learning deconvolution network for semantic segmentation, Proc Ieee Int. Conf. Comput. Vis, pp. 1520-1528, (2015); Ibtehaz N., Rahman M.S., MultiResUNet: Rethinking the U-Net architecture for multimodal biomedical image segmentation, Neural Netw, 121, pp. 74-87, (2020); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proc Ieee Conf. Comput. Vis. Pattern Recognit, pp. 770-778, (2016); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., Unet++: A nested u-net architecture for medical image segmentation, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 3-11, (2018); Miki Y., Et al., Classification of teeth in cone-beam CT using deep convolutional neural network, Comput. Biol. Med, 80, pp. 24-29, (2017); Pavaloiu I.-B., Et al., Neural network based edge detection for CBCT segmentation, Proc. E-Health Bioeng. Conf. EHB, pp. 1-4, (2015); Zakirov A., Ezhov M., Gusarev M., Alexandrovsky V., Shumilov E., Dental pathology detection in 3D cone-beam CT, "" Diagnocat Co., Moscow, Russia, arXiv:1810 10309, (2018); Wainwright M.J., Jordan M.I., Graphical models, exponential families, and variational inference, Found. Trends Mach. Learn, 1, 12, pp. 1-305, (2007); Xing E.P., Jordan M.I., Russell S., A generalized mean field algorithm for variational inference in exponential families, arXiv:1212 2512, (2012); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, Proc Ieee Int. Conf. Comput. Vis, pp. 2980-2988, (2017); Dice L.R., Measures of the amount of ecologic association between species, Ecology, 26, 3, pp. 297-302, (1945); Abadi M., Et al., TensorFlow: A system for large-scale machine learning, Proc. 12th Usenix Symp. Operating Syst. Design Implement. (OSDI, pp. 265-283, (2016); Schloss T., Sonntag D., Kohli M.R., Setzer F.C., A comparison of 2-And 3-dimensional healing assessment after endodontic surgery using cone-beam computed tomographic volumes or periapical radiographs, J. Endodontics, 43, 7, pp. 1072-1079, (2017); Ma H., Et al., Volumetric assessment of sinus membrane dimensions in relation to endodontically treated and healthy teeth, J. Endodontics, 44, (2018); Poly A., Et al., The ability of four different instrumentation systems in shaping oval canals: A micro-computed tomographic analysis, J. Endodontics, 44, (2018)","J. Li; H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, United States; email: jing.li@isye.gatech.edu","","Institute of Electrical and Electronics Engineers Inc.","","","","","","15455955","","","","English","IEEE Trans. Autom. Sci. Eng.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85092913468"
"Gupta H.; Jin K.H.; Nguyen H.Q.; McCann M.T.; Unser M.","Gupta, Harshit (57213136047); Jin, Kyong Hwan (55153576800); Nguyen, Ha Q. (57219758824); McCann, Michael T. (55617614400); Unser, Michael (7102049045)","57213136047; 55153576800; 57219758824; 55617614400; 7102049045","CNN-Based Projected Gradient Descent for Consistent CT Image Reconstruction","2018","IEEE Transactions on Medical Imaging","37","6","","1440","1453","13","283","10.1109/TMI.2018.2832656","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046484652&doi=10.1109%2fTMI.2018.2832656&partnerID=40&md5=8a89ac9acbadc64cfa2118f00e090f92","Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, 1015, Switzerland; Viettel Research and Development Institute, Hanoi, VN-100000, Viet Nam; Center for Biomedical Imaging, Signal Processing Core and the Biomedical Imaging Group, École Polytechnique, Fédérale de Lausanne, Lausanne, 1015, Switzerland","Gupta H., Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, 1015, Switzerland; Jin K.H., Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, 1015, Switzerland; Nguyen H.Q., Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, 1015, Switzerland, Viettel Research and Development Institute, Hanoi, VN-100000, Viet Nam; McCann M.T., Center for Biomedical Imaging, Signal Processing Core and the Biomedical Imaging Group, École Polytechnique, Fédérale de Lausanne, Lausanne, 1015, Switzerland; Unser M., Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, 1015, Switzerland","We present a new image reconstruction method that replaces the projector in a projected gradient descent (PGD) with a convolutional neural network (CNN). Recently, CNNs trained as image-to-image regressors have been successfully used to solve inverse problems in imaging. However, unlike existing iterative image reconstruction algorithms, these CNN-based approaches usually lack a feedback mechanism to enforce that the reconstructed image is consistent with the measurements. We propose a relaxed version of PGD wherein gradient descent enforces measurement consistency, while a CNN recursively projects the solution closer to the space of desired reconstruction images. We show that this algorithm is guaranteed to converge and, under certain conditions, converges to a local minimum of a non-convex inverse problem. Finally, we propose a simple scheme to train the CNN to act like a projector. Our experiments on sparse-view computed-tomography reconstruction show an improvement over total variation-based regularization, dictionary learning, and a state-of-the-art deep learning-based direct reconstruction technique. © 2017 IEEE.","biomedical image reconstruction; Deep learning; inverse problems; low-dose computed tomography","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Signal-To-Noise Ratio; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Differential equations; Functions; Inverse problems; Iterative methods; Neural networks; Problem solving; Biomedical measurements; Convex functions; Convolutional Neural Networks (CNN); Image reconstruction methods; Iterative image reconstruction algorithm; Low dose; Reconstruction techniques; Tomography reconstruction; article; computer assisted tomography; feedback system; image reconstruction; learning; nervous system; algorithm; human; image processing; procedures; signal noise ratio; x-ray computed tomography; Image reconstruction","","","","","European Union’s Horizon 2020 Frame-work Programme; H2020-ERC; National Institute of Biomedical Imaging and Bioengineering, NIBIB; Mayo Clinic; Nvidia; American Association of Physicists in Medicine, AAPM; Canadian Light Source, CLS; Horizon 2020 Framework Programme, H2020, (665667, 692726); European Research Council, ERC; Paul Scherrer Institut, PSI","Funding text 1: The authors thank Emmanuel Soubies for his helpful suggestions on training the CNN and Dr. Cynthia McCollough, the Mayo Clinic, the American Association of Physicists in Medicine, and the National Institute of Biomedical Imaging and Bioengineering for the Mayo-clinic dataset. They also thank Dr. Marco Stampanoni, Swiss Light Source, Paul Scher-rer Institute, Villigen, Switzerland, for the rat-brain dataset. They also thankfully acknowledge the support of the NVIDIA Corporation, in providing the Titan X GPU for this research.; Funding text 2: Manuscript received February 13, 2018; revised April 24, 2018; accepted April 25, 2018. Date of publication May 3, 2018; date of current version May 31, 2018. This work was supported in part by the European Research Council (H2020-ERC Project GlobalBioIm) under Grant 692726 and in part by the European Union’s Horizon 2020 Frame-work Programme for Research and Innovation (call 2015) under Grant 665667. (Corresponding author: Harshit Gupta.) H. Gupta, K. H. Jin, and M. Unser are with the Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, 1015 Lausanne, Switzerland (e-mail: harshit.gupta.cor@gmail.com).; Funding text 3: The authors thank Emmanuel Soubies for his helpful suggestions on training the CNN and Dr. Cynthia McCollough, the Mayo Clinic, the American Association of Physicists in Medicine, and the National Institute of Biomedical Imaging and Bioengineering for the Mayo-clinic dataset. They also thank Dr. Marco Stampanoni, Swiss Light Source, Paul Scherrer Institute, Villigen, Switzerland, for the rat-brain dataset. They also thankfully acknowledge the support of the NVIDIA Corporation, in providing the Titan X GPU for this research.","Lustig M., Donoho D., Pauly J.M., Sparse MRI: The application of compressed sensing for rapid MR imaging, Magn. Reson. Med., 58, 6, pp. 1182-1195, (2007); Kak A.C., Slaney M., Principles of Computerized Tomographic Imaging, (2001); Pan X.C., Sidky E.Y., Vannier M., Why do commercial CT scanners still employ traditional, filtered back-projection for image reconstruction?, Inverse Problems, 25, 12, (2009); Bouman C., Sauer K., A generalized Gaussian image model for edge-preserving MAP estimation, IEEE Trans. Image Process, 2, 3, pp. 296-310, (1993); Charbonnier P., Blanc-Feraud L., Aubert G., Barlaud M., Deterministic edge-preserving regularization in computed imaging, IEEE Trans. Image Process, 6, 2, pp. 298-311, (1997); Candes E., Romberg J., Sparsity and incoherence in compressive sampling, Inverse Probl., 23, 3, pp. 969-985, (2007); Ramani S., Fessler J.A., Parallel MR image reconstruction using augmented Lagrangian methods, IEEE Trans. Med. Imag., 30, 3, pp. 694-706, (2011); Elad M., Aharon M., Image denoising via sparse and redundant representations over learned dictionaries, IEEE Trans. Image Process, 15, 12, pp. 3736-3745, (2006); Candes E.J., Eldar Y.C., Needell D., Randall P., Compressed sensing with coherent and redundant dictionaries, Appl. Comput. Harmon. Anal., 31, 1, pp. 59-73, (2011); Ravishankar S., Nadakuditi R.R., Fessler J.A., Efficient sum of outer products dictionary learning (SOUP-DIL) and its application to inverse problems, IEEE Trans. Comput. Imag., 3, 4, pp. 694-709, (2017); Figueiredo M.A.T., Nowak R.D., An em algorithm for waveletbased image restoration, IEEE Trans. Image Process, 12, 8, pp. 906-916, (2003); Daubechies I., Defrise M., De Mol C., An iterative thresholding algorithm for linear inverse problems with a sparsity constraint, Commun. Pure Appl. Math., 57, 11, pp. 1413-1457, (2004); Beck A., Teboulle M., A fast iterative shrinkage-thresholding algorithm for linear inverse problems, SIAM J. Imag. Sci., 2, 1, pp. 183-202, (2009); Boyd S., Parikh N., Chu E., Peleato B., Eckstein J., Distributed optimization and statistical learning via the alternating direction method of multipliers, Found. Trends Mach. Learn., 3, 1, pp. 1-122, (2011); McCann M.T., Jin K.H., Unser M., Convolutional neural networks for inverse problems in imaging: A review, IEEE Signal Process. Mag., 34, 6, pp. 85-95, (2017); Jin K.H., McCann M.T., Froustey E., Unser M., Deep convolutional neural network for inverse problems in imaging, IEEE Trans. Image Process, 26, 9, pp. 4509-4522, (2017); Han Y.S., Yoo J., Ye J.C., Deep Learning with Domain Adaptation for Accelerated Projection-reconstruction MR, (2017); Antholzer S., Haltmeier M., Schwab J., Deep Learning for Photoacoustic Tomography from Sparse Data, (2017); Wang S., Et al., Accelerating magnetic resonance imaging via deep learning, Proc. IEEE Int. Symp. Biomed. Imag. (ISBI), pp. 514-517, (2016); Mousavi A., Baraniuk R.G., Learning to Invert: Signal Recovery Via Deep Convolutional Networks, (2017); Gregor K., Le Cun Y., Learning fast approximations of sparse coding, Proc. Int. Conf. Mach. Learn. (ICML), pp. 399-406, (2010); Yang Y., Sun J., Li H., Xu Z., Deep ADMM-net for compressive sensing MRI, Proc. Adv. Neural Inf. Process. Syst. (NIPS), pp. 10-18, (2016); Adler J., Oktem O., Solving Ill-posed Inverse Problems Using Iterative Deep Neural Networks, (2017); Putzky P., Welling M., Recurrent Inference Machines for Solving Inverse Problems, (2017); Schlemper J., Caballero J., Hajnal J.V., Price A., Rueckert D., A deep cascade of convolutional neural networks for MR image reconstruction, Proc. Int. Conf. Inf. Process. Med. Imag., pp. 647-658, (2017); Venkatakrishnan S.V., Bouman C.A., Wohlberg B., Plug-andplay priors for model based reconstruction, Proc. IEEE Global Conf. Signal Inf. Process. (GlobalSIP), pp. 945-948, (2013); Chan S.H., Wang X., Elgendy O.A., Plug-and-play ADMM for image restoration: Fixed-point convergence and applications, IEEE Trans. Comput. Imag., 3, 1, pp. 84-98, (2017); Sreehari S., Et al., Plug-and-play priors for bright field electron tomography and sparse interpolation, IEEE Trans. Comput. Imag., 2, 4, pp. 408-423, (2016); Romano Y., Elad M., Milanfar P., The little engine that could: Regularization by denoising (RED), SIAM J. Imag. Sci., 10, 4, pp. 1804-1844, (2017); Chang J.H.R., Li C.-L., Poczos B., Kumar B.V.K.V., Sankaranarayanan A.C., One Network to Solve Them All-Solving Linear Inverse Problems Using Deep Projection Models, (2017); Bora A., Jalal A., Price E., Dimakis A.G., Compressed Sensing Using Generative Models, (2017); Kelly B., Matthews T.P., Anastasio M.A., Deep Learningguided Image Reconstruction from Incomplete Data, (2017); Liang J.Z., La Riviere P.J., El Fakhri G., Glick S.J., Siewerdsen J., Guest editorial low-dose CT: What has been done, and what challenges remain?, IEEE Trans. Med. Imag., 36, 12, pp. 2409-2416, (2017); Ramani S., Fessler J.A., A splitting-based iterative algorithm for accelerated statistical X-ray CT reconstruction, IEEE Trans. Med. Imag., 31, 3, pp. 677-688, (2012); Xu Q., Yu H., Mou X., Zhang L., Hsieh J., Wang G., Low-dose X-ray CT reconstruction via dictionary learning, IEEE Trans. Med. Imag., 31, 9, pp. 1682-1697, (2012); Niu S., Et al., Sparse-view X-ray CT reconstruction via total generalized variation regularization, Phys. Med. Biol., 59, 12, pp. 2997-3017, (2014); Gjesteby L., Yang Q., Xi Y., Zhou Y., Zhang J., Wang G., Deep learning methods to guide CT image reconstruction and reduce metal artifacts, Proc. SPIE, (2017); Chen H., Et al., Low-dose CT with a residual encoder-decoder convolutional neural network, IEEE Trans. Image Process, 36, 12, pp. 2524-2535, (2017); Kang E., Min J., Ye J.C., A deep convolutional neural network using directional wavelets for low-dose X-ray CT reconstruction, Med. Phys., 44, 10, pp. e360-e375, (2017); Han Y.S., Yoo J., Ye J.C., Deep Residual Learning for Compressed Sensing CT Reconstruction Via Persistent Homology Analysis, (2016); Eicke B., Iteration methods for convexly constrained ill-posed problems in Hilbert space, Numer. Funct. Anal. Optim., 13, 5-6, pp. 413-429, (1992); Landweber L., An iteration formula for fredholm integral equations of the first kind, Amer. J. Math., 73, 3, pp. 615-624, (1951); Bertsekas D.P., Nonlinear Programming, (1999); Combettes P.L., Wajs V.R., Signal recovery by proximal forward-backward splitting, Multiscale Model. Simul., 4, 4, pp. 1168-1200, (2005); Combettes P.L., Pesquet J.-C., Proximal Splitting Methods in Signal Processing, pp. 185-212, (2011); Bect J., Blanc-Feraud L., Aubert G., Chambolle A., A ℓ<sub>1</sub>-unified variational framework for image restoration, Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 1-13, (2004); Aldroubi A., Tessera R., On the existence of optimal unions of subspaces for data modeling and clustering, Found. Comput. Math., 11, 3, pp. 363-379, (2011); Goodfellow I., Bengio Y., Courville A., Deep Learning, (2016); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Proc. Med. Image. Comput. Comput. Assist. Intervent. (MICCAI), pp. 234-241, (2015); Orhan A.E., Pitkow X., Skip Connections Eliminate Singularities, (2017); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778, (2016); McCollough C., TU-FG-207A-04: Overview of the low dose CT grand challenge, Med. Phys., 43, 6, pp. 3759-3760, (2016); Wang Z., Simoncelli E.P., Bovik A.C., Multiscale structural similarity for image quality assessment, Proc. 37th Asilomar Conf. Signals, Syst. Comput., 2, pp. 1398-1402, (2003); Mairal J., Bach F., Ponce J., Sapiro G., Online learning for matrix factorization and sparse coding, J. Mach. Learn. Res., 11, pp. 19-60, (2010); Tropp J.A., Gilbert A.C., Signal recovery from random measurements via orthogonal matching pursuit, IEEE Trans. Inf. Theory, 53, 12, pp. 4655-4666, (2007); Sauer K., Bouman C., A local update strategy for iterative reconstruction from projections, IEEE Trans. Signal Process, 41, 2, pp. 534-548, (1993); Elbakri I.A., Fessler J.A., Statistical image reconstruction for polyenergetic X-ray computed tomography, IEEE Trans. Med. Imag., 21, 2, pp. 89-99, (2002); Bauschke H.H., Combettes P.L., Convex Analysis and Monotone Operator Theory in Hilbert Spaces, (2011)","H. Gupta; Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, 1015, Switzerland; email: harshit.gupta.cor@gmail.com","","Institute of Electrical and Electronics Engineers Inc.","","","","","","02780062","","ITMID","29870372","English","IEEE Trans. Med. Imaging","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85046484652"
"Liu C.; Wu S.; Wu S.; Wang Z.; Xiao K.","Liu, Chang (57157480800); Wu, Shaozhi (35172143800); Wu, Su (57208176651); Wang, Ziheng (57208178955); Xiao, Kai (55129739300)","57157480800; 35172143800; 57208176651; 57208178955; 55129739300","Reliable Automatic Organ Segmentation from CT Images using Deep CNN","2019","Proceedings - Companion of the 19th IEEE International Conference on Software Quality, Reliability and Security, QRS-C 2019","","","8859477","368","374","6","1","10.1109/QRS-C.2019.00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073881185&doi=10.1109%2fQRS-C.2019.00075&partnerID=40&md5=70cd0096e99cb72ccc03fbec851b9a78","University of Electronic Science and Technology of China, China; Tongji University, China; Shanghai Jiao Tong University, China","Liu C., University of Electronic Science and Technology of China, China; Wu S., University of Electronic Science and Technology of China, China; Wu S., University of Electronic Science and Technology of China, China; Wang Z., Tongji University, China; Xiao K., Shanghai Jiao Tong University, China","In the field of biomedical image analysis, segmentation is critical for disease diagnosis and treatment planning. While manual segmentation is tedious, time consuming and subjective due to the large shape and appearance variance among different subject, accurate and reliable segmentation is very challenging for automatic segmentation methods at the same time. In this paper, we present our recent effort on developing a reliable segmentation algorithm in the form of a convolutional neural network. Our network architecture is inspired by the popular U-Net and its variation (3D U-Net) and has been carefully modified to maximize bladder and rectum segmentation performance. We transfer our data to four channels to augment the data and prevent overfitting. The Dice similarity coefficient (DSC) is used to evaluate the network's performance. The outcome of experiments demonstrates the superiority of the proposed method. © 2019 IEEE.","CNN; CT; deep learning; Dice similarity coefficient; segmentation","C (programming language); Computer software selection and evaluation; Computerized tomography; Deep learning; Diagnosis; Network architecture; Neural networks; Software reliability; Automatic segmentations; Biomedical image analysis; Convolutional neural network; Manual segmentation; Organ segmentation; Segmentation algorithms; Segmentation performance; Similarity coefficients; Image segmentation","","","","","","","LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proceedings of the IEEE, 86, 11, pp. 2278-2324, (1998); Fukushima K., Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position, Biological Cybernetics, 36, 4, pp. 193-202, (1980); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Process-ing Systems., (2012); Deng J., Berg A., Satheesh S., Su H., Khosla A., Fei-Fei L., Imagenet Large Scale Visual Recognition Competition 2012 (ILSVRC2012), (2012); Girshick R., Et al., Rich feature hierarchies for accurate object detection and semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., (2014); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-scale Image Recognition, (2014); Paoletti M.E., Haut J.M., Plaza J., Plaza A., A new deep convolutional neural network for fast hyperspectral image classification, ISPRS Journal of Photogrammetry and Remote Sensing, 145, pp. 120-147, (2018); Hsieh J., Computed Tomography: Principles, Design, Artifacts, and Recent Advances, (2009); Siegel R.L., Miller K.D., Jemal A., Cancer statistics, 2019, CA: A Cancer Journal for Clinicians, 69, 1, pp. 7-34, (2019); Collier D.C., Burnett S.S., Amin M., Bilton S., Brooks C., Ryan A., Starkschall G., Assessment of consistency in contouring of normaltissue anatomic structures, Journal of Applied Clinical Medical Physics, 4, 1, pp. 17-24, (2003); Li Q., Gao Z., Wang Q., Xia J., Zhang H., Zhang H., Li S., Glioma segmentation with a unified algorithm in multimodal MRI images, IEEE Access, 6, pp. 9543-9553, (2018); Kushibar K., Valverde S., Gonzalez-Villa S., Bernal J., Cabezas M., Oliver A., Llado X., Automated Subcortical Brain Structure Segmentation Combining Spatial and Deep Convolutional Features, (2017); Wu Z., Guo Y., Park S.H., Gao Y., Dong P., Lee S.W., Shen D., Robust brain ROI segmentation by deformation regression and deformable shape model, Medical Image Analysis, 43, pp. 198-213, (2018); Zimmerman J.B., Pizer S.M., Staab E.V., Perry J.R., McCartney W., Brenton B.C., An Evaluation of the Effectiveness of Adaptive Histogram Equalization for Contrast Enhancement, (1987); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-Net: Learning dense volumetric segmentation from sparse annotation, International Conference on Medical Image Computing and Computer-assisted Intervention, pp. 424-432, (2016); Setio A.A.A., Ciompi F., Litjens G., Gerke P., Jacobs C., Van Riel S.J., Van Ginneken B., Pulmonary nodule detection in CT images: False positive reduction using multi-view convolutional networks, IEEE Transactions on Medical Imaging, 35, 5, pp. 1160-1169, (2016); Han X., Automatic Liver Lesion Segmentation Using A Deep Convolutional Neural Network Method, (2017); Milletari F., Navab N., Ahmadi S.A., V-net: Fully convolutional neural networks for volumetric medical image segmentation, 2016 Fourth International Conference on 3D Vision (3DV), pp. 565-571, (2016); Kamnitsas K., Ledig C., Newcombe V.F., Simpson J.P., Kane A.D., Menon D.K., Glocker B., Efficient multiscale 3D CNN with fully connected CRF for accurate brain lesion segmentation, Medical Image Analysis, 36, pp. 61-78, (2017); Yu L., Yang X., Chen H., Qin J., Heng P.A., Volumetric ConvNets with mixed residual connections for automated prostate segmentation from 3D MR images, Thirty-first AAAI Conference on Artificial Intelligence, (2017); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-assisted Intervention, pp. 234-241, (2015); Wang Y., Chen Q., Zhang B., Image enhancement based on equal area dualistic sub-image histogram equalization method, IEEE Transactions on Consumer Electronics, 45, 1, pp. 68-75, (1999); Wongsritong K., Kittayaruasiriwat K., Cheevasuvit F., Dejhan K., Somboonkaew A., Contrast enhancement using multipeak histogram equalization with brightness preserving, IEEE. APCCAS 1998. 1998 IEEE Asia-Pacific Conference on Circuits and Systems. Microelectronics and Integrating Systems. Proceedings (Cat. No. 98EX242), pp. 455-458, (1998); Pizer S.M., Amburn E.P., Austin J.D., Cromartie R., Geselowitz A., Greer T., Zuiderveld K., Adaptive histogram equalization and its variations, Computer Vision, Graphics, and Image Processing, 39, 3, pp. 355-368, (1987); Canny J., A computational approach to edge detection, Readings in Computer Vision, pp. 184-203, (1987); Ulyanov D., Vedaldi A., Lempitsky V., Instance Normalization: The Missing Ingredient for Fast Stylization, (2016); Gulli A., Pal S., Deep Learning with Keras, (2017); Glorot X., Bengio Y., Understanding the difficulty of training deep feedforward neural networks, Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pp. 249-256, (2010); LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proceedings of the IEEE, 86, 11, pp. 2278-2324, (1998); Gao Y., Lian J., Shen D., Joint learning of image regressor and classifier for deformable segmentation of CT pelvic organs, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 114-122, (2015); Shao Y., Gao Y., Wang Q., Yang X., Shen D., Locally-constrained boundary regression for segmentation of prostate and rectum in the planning CT images, Medical Image Analysis, 26, 1, pp. 345-356, (2015)","","","Institute of Electrical and Electronics Engineers Inc.","IEEE Reliability Society","19th IEEE International Conference on Software Quality, Reliability and Security Companion, QRS-C 2019","22 July 2019 through 26 July 2019","Sofia","152544","","978-172813925-8","","","English","Proc. - Companion IEEE Int. Conf. Softw. Qual., Reliab. Secur., QRS-C","Conference paper","Final","","Scopus","2-s2.0-85073881185"
"Guo N.; Bai Z.","Guo, Ning (58966932800); Bai, Zhengyao (23388661700)","58966932800; 23388661700","The integration of attention mechanism and dense atrous convolution for lung image segmentation; [注意力机制下密集空洞卷积的肺部图像分割]","2021","Journal of Image and Graphics","26","9","","2146","2155","9","5","10.11834/jig.200429","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115214474&doi=10.11834%2fjig.200429&partnerID=40&md5=448243ac44323510cf898d7e1dfe3628","School of Information Science and Engineering, Yunnan University, Kunming, 650500, China","Guo N., School of Information Science and Engineering, Yunnan University, Kunming, 650500, China; Bai Z., School of Information Science and Engineering, Yunnan University, Kunming, 650500, China","Objective: As an important criterion for the diagnosis of early-stage lung cancer, chest computed tomography (CT) images-based pulmonary nodules detection have been implemented via location observation, scope and shape of the lesions. The CT image has been analyzed lung organizational structures like the lung parenchyma and the contextual part, such as hydrops, trachea, bronchus, and ribs. CT images-based lung parenchyma has been hard to interpret automatically and precisely. The precise extraction of lung parenchyma has played a vital role in lung-based diseases analyses. Most of lung segmentation have been conducted based on regular image processing algorithms like threshold or morphological operation. The convolutional neural networks (CNNs) have been used in computerized pulmonary disease analysis. CNN-driven lung segmentation algorithms have been adopted in computer-aided diagnosis (CAD). The U-shape structure has been designed for medical image segmentation based on end-to-end fully convolutional network (FCN) structure. The credibility for biomedical image segmentations have been realized based on the encoding and decoding symmetric network structure. A novel convolutional neural network based on U-Net architecture has been illustrated via integrating attention mechanism and dense atrous convolution (DAC). Method: The network has contained an encoder and a decoder. The encoder has consisted of convolution and down sampling. The deductible spatial dimension of feature maps have been used to learn more semantic information. And the attention mechanism decoder has been implemented for de-convolution and up-sampling to re-configure the spatial dimension of the feature maps. The decoding mode using attention mechanism has been manipulated to make the target area output more effectively. Meanwhile, the algorithm of lung image segmentation has been used to identify the target-oriented neural network's attention using transmitted skip-connection to improve the weight of the salient feature. The feature resolution capability has been enhanced to the requirements for intensive spatial prediction via pooling consecutive operations and convolution striding. The DAC block has been deployed between the encoder and the decoder to extract multi-scale information of the context sufficiently. The advantages of Inception, ResNet and atrous convolution for the block have been inherited to capture multi-sized features consequently. The max-pooling and up-sampling operators have been utilized to reduce and increase the resolution of feature maps intensively based on the classic U-Net framework, which could lead to feature loss and accuracy reduced problems during training. The original max-pooling and up-sampling operators have been replaced via down-sample and up-sample block with inception structure to widen the multi-filters network and avoid feature loss. The Dice coefficient loss function has been used instead of the cross entropy loss to identify the gap between prediction and ground-truth. The deep learning framework Pytorch have been used on a server with two NVIDIA GeForce RTX 2080Ti graphics cards and each GPU has 11 Gigabyte memory. At the experimental stage, the original images have been resized to 256×256 pixels and 80% of these for training besides the test remaining. The proposed model has been trained for 120 epochs. Based on an initial learning rate of 0.000 1, the Adam has been opted as the optimization algorithm. Result: In order to verify the efficiency of the proposed method, we conduct multi-compatible verifications called FCN-8 s, U-Net, UNet++, ResU-Net and CE-Net (context encoder network) have been conducted. Four segmentation metrics have been adopted to assess the segmentation. These metrics has evolved the Dice similarity coefficient (DSC), the intersection over union (IoU), sensitivity (SE) and accuracy (ACC). The experimental results on the LUNA16 dataset have demonstrated the priorities in terms of all metrics results. The average Dice similarity coefficient has reached 0.985 9, which has 0.443% higher than the segmentation results of the second-performing CE-Net. The model consequence has achieved 0.972 2, 0.993 8, and 0.982 2 each in terms of IoU, ACC and SE. This second qualified segmentation performance has reached: 0.272%, 0.512% and 0.374% each (more better). Compared with other algorithms, the predictable results of modeling has closer to the label made. The adhesive difficulties on the left and right lung cohesion issue have been resolved well. Conclusion: An encoded/decoded structure in novel convolutional neural network has been integrated via attention mechanism and dense atrous convolution for lungs segmentation. The experiment results have illustrated that the qualified and effective framework for segmenting the lung parenchyma area have its own priority. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.","Attention mechanism; Computer-aided diagnosis(CAD); Convolutional neural networks(CNN); Dense atrous convolution(DAC); Lung segmentation","","","","","","","","Chen L C, Papandreou G, Kokkinos I, Murphy K, Yuille A L., DeepLab: semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs, IEEE Transactions on Pattern Analysis and Machine Intelligence, 40, 4, pp. 834-848, (2018); Glorot X, Bordes A, Bengio Y., Deep sparse rectifier neural networks, (2011); Gu Z W, Cheng J, Fu H Z, Zhou K, Hao H Y, Zhao Y T, Zhang T Y, Gao S H, Liu J., CE-Net: context encoder network for 2D medical image segmentation, IEEE Transactions on Medical Imaging, 38, 10, pp. 2281-2292, (2019); He K M, Zhang X Y, Ren S Q, Sun J., Deep residual learning for image recognition, Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Ioffe S, Szegedy C., Batch normalization: accelerating deep network training by reducing internal covariate shift [EB/OL], (2015); Kingma D P, Ba J L., Adam: a method for stochastic optimization, (2015); Long J, Shelhamer E, Darrell T., Fully convolutional networks for semantic segmentation, IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, 4, pp. 640-651, (2015); Luong M, Pham H, Manning C D., Effective approaches to attention-based neural machine translation, Proceedings of 2015 Conference on Empirical Methods in Natural Language, pp. 1412-1421, (2015); Milletari F, Navab N, Ahmadi S A., V-Net: fully convolutional neural networks for volumetric medical image segmentation, Proceedings of the 4th International Conference on 3D Vision, pp. 565-571, (2016); Oktay O, Schlempe J, Le Folgoc L, Lee M, Heinrich M, Misawa K, Mori K, McDonagh S, Hammerla N Y, Kainz B, Glocker B, Rueckert D., Attention U-Net: learning where to look for the pancreas, (2018); Ronneberger O, Fischer P, Brox T., U-Net: convolutional networks for biomedical image segmentation, Medical Image Computing and Computer-Assisted Intervention. Lecture Notes in Computer Science, 9351, pp. 234-241, (2015); Shojaii R, Alirezaie J, Babyn P., Automatic lung segmentation in CT images using watershed transform, Proceedings of 2005 IEEE International Conference on Image Processing, pp. 1270-1273, (2005); Skourt B A, El Hassani A, Majda A., Lung CT image segmentation using deep neural networks, Procedia Computer Science, 127, pp. 109-113, (2018); Szegedy C, Liu W, Jia Y Q, Sermanet P, Reed S, Anguelov D, Erhan D, Vanhoucke V, Rabinovich A., Going deeper with convolutions, Proceedings of 2015 IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z., Rethinking the inception architecture for computer vision, Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826, (2016); Szegedy C, Ioffe S, Vanhoucke V, Alemi A., Inception-v4, inception-ResNet and the impact of residual connections on learning, (2017); Yu F, Koltun V., Multi-scale context aggregation by dilated convolutions [EB/OL], (2016); Yuan K H, Xiang L X., Automated lung segmentation for chest CT images used for computer aided diagnostics, Journal of Tsinghua University (Science and Technology), 51, 1, pp. 90-95, (2011); Zhang Z, Wu C D, Coleman S, Kerr D., DENSE-INception U-net for medical image segmentation, Computer Methods and Programs in Biomedicine, 192, (2020); Zhou Z W, Rahman Siddiquee M, Tajbakhsh N, Liang J M., UNet++: a nested U-net architecture for medical image segmentation, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support. Lecture Notes in Computer Science, 11045, pp. 3-11, (2018)","Z. Bai; School of Information Science and Engineering, Yunnan University, Kunming, 650500, China; email: baizhy@ynu.edu.cn","","Editorial and Publishing Board of JIG","","","","","","10068961","","","","Chinese","J. Image and Graphics","Article","Final","","Scopus","2-s2.0-85115214474"
"Sharma A.; Kumar R.","Sharma, Ajay (57210974822); Kumar, Raj (57217189034)","57210974822; 57217189034","Recent Advancement and Challenges in Deep Learning, Big Data in Bioinformatics","2022","Studies in Big Data","105","","","251","284","33","3","10.1007/978-3-030-95419-2_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127835715&doi=10.1007%2f978-3-030-95419-2_12&partnerID=40&md5=fb261fefcffcf2e94b989f3ecd06ceda","Departmetn of Biotechnology and Bioinformatics, Jaypee University of Information Technology (JUIT), Himachal Pradesh, Waknaghat Solan, 173234, India","Sharma A., Departmetn of Biotechnology and Bioinformatics, Jaypee University of Information Technology (JUIT), Himachal Pradesh, Waknaghat Solan, 173234, India; Kumar R., Departmetn of Biotechnology and Bioinformatics, Jaypee University of Information Technology (JUIT), Himachal Pradesh, Waknaghat Solan, 173234, India","More data have been produced in recent years than in the thousands of years of human history. This data represents an important gold mine for policymakers in terms of commercial value and reference material. But much of this value is untapped, worse, wrongly comprehended as long as it is impossible to use the tools needed to process the stunning amount of information. In this book chapter, we will examine how machine learning can give us a glimpse of the patterns in Big Data and obtain key information in all fields of biology, healthcare. An analysis, ineffectiveness storage, and depth of learning algorithms in this field are essential to the electronic equipment which generates an anonymous scale of data referring to diversity and veracity. The architecture of Hadoop-based maps and deep learning algorithms like Convolutional Neural Network, Recurrent Neural Network have transformed the way we analyze massive data. The role, impact, and prospect of deep learning algorithms, reinforcement learning to manage big data in the area of bioinformatics, computer aided drug design, structural biology and computational biology are discussed in this book chapter. In last section author has discussed about the role of deep learning in next generation sequencing, biomedical image processing and drug discovery and molecular modelling and dynamics studies. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Big Data; Bioinformatics; Convolutional neural network (CNN); Deep learning; Drug design; Hadoop; Healthcare; Map-reduce; Reinforcement learning; Structural biology","Bioinformatics; Convolution; Convolutional neural networks; Deep neural networks; Digital storage; Health care; Image processing; Information management; Learning algorithms; Oscillators (electronic); Recurrent neural networks; Reinforcement learning; Amount of information; Convolutional neural network; Deep learning; Drug Design; Hadoop; Map-reduce; Policy makers; Reference material; Structural biology; Big data","","","","","","","Greene C.S., Et al., Big data bioinformatics, J. Cell. Physiol., 229, 12, pp. 1896-1900, (2014); Li Y., Et al., Deep learning in bioinformatics: Introduction, application, and perspective in the big data era, Methods, 166, pp. 4-21, (2019); Azmoodeh A., Dehghantanha A., Big data and privacy: Challenges and opportunities, Handbook of Big Data Privacy, pp. 1-5, (2020); Wang J., Et al., Big data service architecture: A survey, J. Internet Technol., 21, 2, pp. 393-405, (2020); Sagiroglu S., Sinanc D., Big data: A review, 2013 International Conference on Collaboration Technologies and Systems (CTS). IEEE, (2013); Anuradha J., A brief introduction on Big Data 5Vs characteristics and Hadoop technology, Procedia Comput. Sci., 48, pp. 319-324, (2015); Dean J., Ghemawat S., MapReduce: simplified data processing on large clusters, Commun. ACM, 51, 1, pp. 107-113, (2008); Dean J., Ghemawat S., Mapreduce: Simplified Data Processing on Large Clusters, (2004); Liu J., Et al., A novel configuration tuning method based on feature selection for hadoop MapReduce, IEEE Access, 8, pp. 63862-63871, (2020); Shastry K.A., Sanjay H., Machine learning for bioinformatics, Statistical Modelling and Machine Learning Principles for Bioinformatics Techniques, Tools, and Applications, Pp. 25– 39. Springer, (2020); Li H., Et al., Modern deep learning in bioinformatics, J. Mol. Cell Biol., (2020); Srinivasa K., Siddesh G., Manisekhar S., Statistical Modelling and Machine Learning Principles for Bioinformatics Techniques, Tools, and Applications, Springer Nature, (2020); Pezeshki M., Et al., Gradient Starvation: A Learning Proclivity in Neural Networks. Arxiv Preprint Arxiv, 2011, (2020); Havaei M., Et al., Brain tumor segmentation with deep neural networks, Med. Image Anal., 35, pp. 18-31, (2017); Leshno M., Et al., Multilayer feedforward networks with a nonpolynomial activation function can approximate any function, Neural Netw, 6, 6, pp. 861-867, (1993); Ramachandran P., Zoph B., Le Q.V., Searching for Activation Functions. Arxiv Preprint Arxiv, 1710, (2017); Gomes G.S.D.S., Ludermir T.B., Lima L.M., Comparison of new activation functions in neural network for forecasting financial time series, Neural Comput. Appl., 20, 3, pp. 417-439, (2011); Sharma S., Sharma S., Activation functions in neural networks, Towards Data Sci, 6, 12, pp. 310-316, (2017); Agostinelli F., Et al., Learning Activation Functions to Improve Deep Neural Networks. Arxiv Preprint Arxiv, 1412, (2014); Obla S., Et al., Effective activation functions for homomorphic evaluation of deep neural networks, IEEE Access, 8, pp. 153098-153112, (2020); Goyal M., Et al., Activation functions, Deep Learning: Algorithms and Applications, pp. 1-30, (2020); Zadeh M.R., Et al., Daily outflow prediction by multi layer perceptron with logistic sigmoid and tangent sigmoid activation functions, Water Resour. Manag., 24, 11, pp. 2673-2688, (2010); Gomar S., Mirhassani M., Ahmadi M., Precise digital implementations of hyperbolic tanh and sigmoid function, 2016 50Th Asilomar Conference on Signals, Systems and Computers. IEEE, (2016); Kalman B.L., Kwasny S.C., Why tanh: Choosing a sigmoidal function, Proceedings 1992 IJCNN International Joint Conference on Neural Networks. IEEE, (1992); Xu B., Et al., Empirical Evaluation of Rectified Activations in Convolutional Network. Arxiv Preprint Arxiv, 1505, (2015); Agarap A.F., Deep Learning Using Rectified Linear Units (RELU). Arxiv Preprint Arxiv, 1803, (2018); Zhang X., Zou Y., Shi W., Dilated convolution neural network with LeakyReLU for environmental sound classification, 2017 22Nd International Conference on Digital Signal Processing (DSP). IEEE, (2017); Chan J.O., An architecture for big data analytics, Commun. IIMA, 13, 2, (2013); Boja C., Pocovnicu A., Batagan L., Distributed parallel architecture for “big data, Inf. Econ., 16, 2, (2012); Hutter F., Kotthoff L., Vanschoren J., Automated Machine Learning: Methods, (2019); Li H., Deep learning for natural language processing: Advantages and challenges, Natl. Sci. Rev., (2017); Sharma O., Deep challenges associated with deep learning, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (Comitcon). IEEE, (2019); Angelov P., Sperduti A., Challenges in Deep Learning, (2016); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Adv. Neural. Inf. Process. Syst., 25, pp. 1097-1105, (2012); Deng J., Et al., Imagenet: A large-scale hierarchical image database, 2009 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, (2009); Albawi S., Mohammed T.A., Al-Zawi S., Understanding of a convolutional neural network, 2017 International Conference on Engineering and Technology (ICET). IEEE, (2017); Ma N., Et al., Shufflenet v2: Practical guidelines for efficient cnn architecture design, Proceedings of the European Conference on Computer Vision (ECCV), (2018); Sun Y., Et al., Completely automated CNN architecture design based on blocks, IEEE Trans. Neural Netw. Learn. Syst., 31, 4, pp. 1242-1254, (2019); Yu D., Et al., Mixed pooling for convolutional neural networks, International Conference on Rough Sets and Knowledge Technology, (2014); Zhao H., Et al., Loss functions for image restoration with neural networks, IEEE Trans. Comput. Imaging, 3, 1, pp. 47-57, (2016); Liu W., Et al., Large-Margin Softmax Loss for Convolutional Neural Networks, (2016); Bartlett P.L., Wegkamp M.H., Classification with a reject option using a hinge loss, J. Mach. Learn. Res., 9, 8, (2008); de Soete G., Carroll J.D., K-means clustering in a low-dimensional Euclidean space, New Approaches in Classification and Data Analysis, pp. 212-219, (1994); Sherstinsky A., Fundamentals of recurrent neural network (RNN) and long short-term memory (LSTM) network, Phys. D: Nonlinear Phenom., 404, (2020); Yin R., Et al., Tempel: Time-series mutation prediction of influenza A viruses via attention-based recurrent neural networks, Bioinformatics, 36, 9, pp. 2697-2704, (2020); Millham R., Agbehadji I.E., Yang H., Parameter tuning onto recurrent neural network and long short-term memory (RNN-LSTM) network for feature selection in classification of high-dimensional bioinformatics datasets, Bio-Inspired Algorithms for Data Streaming and Visualization, Big Data Management, and Fog Computing, Pp. 21–42 Springer, (2021); Gerratana L., Et al., Abstract P5-01-10: Next generation sequencing-based gene variant-oriented characterization in metastatic breast cancer: An innovative analysis using ctDNA, AACR, (2020); Schmidt B., Hildebrandt A., Deep learning in next-generation sequencing, Drug Discov. Today, (2020); Naito T., Et al., A deep learning method for HLA imputation and trans-ethnic MHC fine-mapping of type 1 diabetes, Nat. Commun., 12, 1, pp. 1-14, (2021); Cosgun E., Oh M., Exploring the consistency of the quality scores with machine learning for next-generation sequencing experiments, Biomed. Res. Int., (2020); Tonkovic P., Et al., Literature on applied machine learning in metagenomic classification: A scoping review, Biology, 9, 12, (2020); Huang Y., Zhang P., Evaluation of machine learning approaches for cell-type identification from single-cell transcriptomics data, Brief. Bioinf., (2021); Loher P., Karathanasis N., Machine learning approaches identify genes containing spatial information from single-cell transcriptomics data, Front. Genet., 11, 1743, (2021); Oller-Moreno S., Et al., Algorithmic advances in machine learning for single cell expression analysis, Urrent Opin. Syst. Biol., . C, (2021); Kupari J., Et al., Single cell transcriptomics of primate sensory neurons identifies cell types associated with chronic pain, Nat. Commun., 12, 1, pp. 1-15, (2021); Zhu W., Et al., The application of deep learning in cancer prognosis prediction, Cancers, 12, 3, (2020); Wei R., Mahmood A., Recent advances in variational autoen-coders with representation learning for biomedical informatics: A survey, IEEE Access, (2020); de Vivo M., Et al., Role of molecular dynamics and related methods in drug discovery, J. Med. Chem., 59, 9, pp. 4035-4061, (2016); Lima A.N., Et al., Use of machine learning approaches for novel drug discovery, Expert Opin. Drug Discov., 11, 3, pp. 225-239, (2016); Gertrudes J., Et al., Machine learning techniques and drug design, Curr. Med. Chem., 19, 25, pp. 4289-4297, (2012); Klambauer G.N., Hochreiter S., Rarey M., Machine Learning in Drug Discovery, ACS Publications, (2019); Zhang S., Et al., Learning for personalized medicine: A comprehensive review from a deep learning perspective, IEEE Rev. Biomed. Eng., 12, pp. 194-208, (2018)","R. Kumar; Departmetn of Biotechnology and Bioinformatics, Jaypee University of Information Technology (JUIT), Waknaghat Solan, Himachal Pradesh, 173234, India; email: rajkumar250287@gmail.com","","Springer Science and Business Media Deutschland GmbH","","","","","","21976503","","","","English","Stud. Big. Data.","Book chapter","Final","","Scopus","2-s2.0-85127835715"
"Kermany D.S.; Goldbaum M.; Cai W.; Valentim C.C.S.; Liang H.; Baxter S.L.; McKeown A.; Yang G.; Wu X.; Yan F.; Dong J.; Prasadha M.K.; Pei J.; Ting M.; Zhu J.; Li C.; Hewett S.; Dong J.; Ziyar I.; Shi A.; Zhang R.; Zheng L.; Hou R.; Shi W.; Fu X.; Duan Y.; Huu V.A.N.; Wen C.; Zhang E.D.; Zhang C.L.; Li O.; Wang X.; Singer M.A.; Sun X.; Xu J.; Tafreshi A.; Lewis M.A.; Xia H.; Zhang K.","Kermany, Daniel S. (57193116279); Goldbaum, Michael (7005893154); Cai, Wenjia (57196088938); Valentim, Carolina C.S. (57200758379); Liang, Huiying (35334583200); Baxter, Sally L. (57200760006); McKeown, Alex (55880755400); Yang, Ge (57200758769); Wu, Xiaokang (57200754293); Yan, Fangbing (57200756883); Dong, Justin (57200757776); Prasadha, Made K. (57200757714); Pei, Jacqueline (55913141300); Ting, Magdalena (57195422417); Zhu, Jie (56297070000); Li, Christina (57200752315); Hewett, Sierra (57211733435); Dong, Jason (57200757774); Ziyar, Ian (57200761977); Shi, Alexander (57200750760); Zhang, Runze (57194446671); Zheng, Lianghong (56828486500); Hou, Rui (59032425700); Shi, William (56888195600); Fu, Xin (58832881500); Duan, Yaou (55331946100); Huu, Viet A.N. (56473600000); Wen, Cindy (55913674200); Zhang, Edward D. (57194448343); Zhang, Charlotte L. (57202885027); Li, Oulan (7003521973); Wang, Xiaobo (57221484941); Singer, Michael A. (54915646600); Sun, Xiaodong (23482893500); Xu, Jie (58009380800); Tafreshi, Ali (59026773600); Lewis, M. Anthony (57224603791); Xia, Huimin (56533028500); Zhang, Kang (56418957000)","57193116279; 7005893154; 57196088938; 57200758379; 35334583200; 57200760006; 55880755400; 57200758769; 57200754293; 57200756883; 57200757776; 57200757714; 55913141300; 57195422417; 56297070000; 57200752315; 57211733435; 57200757774; 57200761977; 57200750760; 57194446671; 56828486500; 59032425700; 56888195600; 58832881500; 55331946100; 56473600000; 55913674200; 57194448343; 57202885027; 7003521973; 57221484941; 54915646600; 23482893500; 58009380800; 59026773600; 57224603791; 56533028500; 56418957000","Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning","2018","Cell","172","5","","1122","1131.e9","","2973","10.1016/j.cell.2018.02.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042389905&doi=10.1016%2fj.cell.2018.02.010&partnerID=40&md5=e83d2ef0a11cfa54b6663a859ef708fe","Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China; Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Heidelberg Engineering, Heidelberg, Germany; Molecular Medicine Research Center, State Key Laboratory of Biotherapy, The National Clinical Research Center of Senile Disease, West China Hospital, Sichuan University, Chengdu, China; Guangzhou KangRui Biological Pharmaceutical Technology Company, Guangzhou, 510005, China; YouHealth AI, Guangzhou, 510005, China; Beihai Hospital, Dalian, 116021, China; Department of Ophthalmology, University of Texas Health Science Center, San Antonio, 78229, TX, United States; Shanghai Key Laboratory of Ocular Fundus Diseases, Shanghai General Hospital, Shanghai JiaoTong University, Shanghai, 200080, China; Beijing Instute of Ophthalmology, Beijing Tongren Eye Center, Beijing Tongren Hospital, Capital Medical University, Beijing, China; Qualcomm, San Diego, 92121, CA, United States; Guangzhou Regenerative Medicine and Health Guangdong Laboratory, Guangzhou, 510005, China; Veterans Administration Healthcare System, San Diego, 92037, CA, United States","Kermany D.S., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Goldbaum M., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Cai W., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Valentim C.C.S., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Liang H., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China; Baxter S.L., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; McKeown A., Heidelberg Engineering, Heidelberg, Germany; Yang G., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Wu X., Molecular Medicine Research Center, State Key Laboratory of Biotherapy, The National Clinical Research Center of Senile Disease, West China Hospital, Sichuan University, Chengdu, China; Yan F., Molecular Medicine Research Center, State Key Laboratory of Biotherapy, The National Clinical Research Center of Senile Disease, West China Hospital, Sichuan University, Chengdu, China; Dong J., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China; Prasadha M.K., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Pei J., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Ting M., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Zhu J., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Guangzhou KangRui Biological Pharmaceutical Technology Company, Guangzhou, 510005, China; Li C., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Hewett S., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Dong J., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China; Ziyar I., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Shi A., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Zhang R., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Zheng L., YouHealth AI, Guangzhou, 510005, China; Hou R., Guangzhou KangRui Biological Pharmaceutical Technology Company, Guangzhou, 510005, China; Shi W., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Fu X., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Duan Y., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Huu V.A.N., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Wen C., Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Zhang E.D., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Zhang C.L., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Li O., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States; Wang X., Beihai Hospital, Dalian, 116021, China; Singer M.A., Department of Ophthalmology, University of Texas Health Science Center, San Antonio, 78229, TX, United States; Sun X., Shanghai Key Laboratory of Ocular Fundus Diseases, Shanghai General Hospital, Shanghai JiaoTong University, Shanghai, 200080, China; Xu J., Beijing Instute of Ophthalmology, Beijing Tongren Eye Center, Beijing Tongren Hospital, Capital Medical University, Beijing, China; Tafreshi A., Heidelberg Engineering, Heidelberg, Germany; Lewis M.A., Qualcomm, San Diego, 92121, CA, United States; Xia H., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China; Zhang K., Guangzhou Women and Children's Medical Center, Guangzhou Medical University, Guangzhou, 510005, China, Shiley Eye Institute, Institute for Engineering in Medicine, Institute for Genomic Medicine, University of California, San Diego, La Jolla, 92093, CA, United States, Molecular Medicine Research Center, State Key Laboratory of Biotherapy, The National Clinical Research Center of Senile Disease, West China Hospital, Sichuan University, Chengdu, China, Guangzhou Regenerative Medicine and Health Guangdong Laboratory, Guangzhou, 510005, China, Veterans Administration Healthcare System, San Diego, 92037, CA, United States","The implementation of clinical-decision support algorithms for medical imaging faces challenges with reliability and interpretability. Here, we establish a diagnostic tool based on a deep-learning framework for the screening of patients with common treatable blinding retinal diseases. Our framework utilizes transfer learning, which trains a neural network with a fraction of the data of conventional approaches. Applying this approach to a dataset of optical coherence tomography images, we demonstrate performance comparable to that of human experts in classifying age-related macular degeneration and diabetic macular edema. We also provide a more transparent and interpretable diagnosis by highlighting the regions recognized by the neural network. We further demonstrate the general applicability of our AI system for diagnosis of pediatric pneumonia using chest X-ray images. This tool may ultimately aid in expediting the diagnosis and referral of these treatable conditions, thereby facilitating earlier treatment, resulting in improved clinical outcomes. Video Abstract: [Figure presented] Image-based deep learning classifies macular degeneration and diabetic retinopathy using retinal optical coherence tomography images and has potential for generalized applications in biomedical image interpretation and medical decision making. © 2018 Elsevier Inc.","age-related macular degeneration; artificial intelligence; choroidal neovascularization; deep learning; diabetic macular edema; diabetic retinopathy; optical coherence tomography; pneumonia; screening; transfer learning","Child; Deep Learning; Diagnostic Imaging; Humans; Neural Networks (Computer); Pneumonia; Reproducibility of Results; ROC Curve; Tomography, Optical Coherence; Article; artificial intelligence; bacterial pneumonia; bacterium detection; clinical outcome; comparative effectiveness; diabetic macular edema; diabetic retinopathy; diagnostic accuracy; diagnostic imaging; drusen; learning algorithm; macular degeneration; medical decision making; nerve cell network; optical coherence tomography; pathology; pneumonia; priority journal; retina disease; subretinal neovascularization; thorax radiography; virus pneumonia; artificial neural network; child; human; pneumonia; receiver operating characteristic; reproducibility","","","","","Dick and Carol Hertzberg Fund; Guangzhou Women and Children’s Medical Center; Michael Martin Fund; Richard Annesser Fund; National Natural Science Foundation of China, NSFC, (81700882, 81771629); National Natural Science Foundation of China, NSFC; National Key Research and Development Program of China, NKRDPC, (2017YFC1104600); National Key Research and Development Program of China, NKRDPC; Guangzhou Regenerative Medicine and Health Guangdong Laboratory, GRMH-GDL","This study was funded by the National Key Research and Development Program of China ( 2017YFC1104600 ), National Natural Science Foundation of China ( 81771629 and 81700882 ), Guangzhou Women and Children’s Medical Center , Guangzhou Regenerative Medicine and Health Guangdong Laboratory , the Richard Annesser Fund , the Michael Martin Fund , and the Dick and Carol Hertzberg Fund . ","Adegbola R.A., Childhood pneumonia as a global health priority and the strategic interest of the Bill & Melinda Gates Foundation, Clin. Infect. Dis., 54, pp. S89-S92, (2012); Chaudhuri S., Chatterjee S., Katz N., Nelson M., Goldbaum M., Detection of blood vessels in retinal images using two-dimensional matched filters, IEEE Trans. Med. Imaging, 8, pp. 263-269, (1989); Donahue J., Jia Y., Vinyals O., Hoffman J., Zhang N., Tzeng E., Darrell T., 32, pp. 647-655, (2013); Ferrara N., Vascular endothelial growth factor and age-related macular degeneration: from basic science to therapy, Nat. Med., 16, pp. 1107-1111, (2010); Friedman D.S., O'Colmain B.J., Munoz B., Tomany S.C., McCarty C., de Jong P.T., Nemesure B., Mitchell P., Kempen J., Prevalence of age-related macular degeneration in the United States, Arch. Ophthalmol., 122, pp. 564-572, (2004); Goldbaum M., Moezzi S., Taylor A., Chatterjee S., Boyd J., Hunter E., Jain R., 3, pp. 695-698, (1996); Gulshan V., Peng L., Coram M., Stumpe M.C., Wu D., Narayanaswamy A., Venugopalan S., Widner K., Madams T., Cuadros J., Et al., Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs, JAMA, 316, pp. 2402-2410, (2016); Hoover A., Goldbaum M., Locating the optic nerve in a retinal image using the fuzzy convergence of the blood vessels, IEEE Trans. Med. Imaging, 22, pp. 951-958, (2003); Hoover A., Kouznetsova V., Goldbaum M., Locating blood vessels in retinal images by piecewise threshold probing of a matched filter response, IEEE Trans. Med. Imaging, 19, pp. 203-210, (2000); Kaiser P.K., Brown D.M., Zhang K., Hudson H.L., Holz F.G., Shapiro H., Schneider S., Acharya N.R., Ranibizumab for predominantly classic neovascular age-related macular degeneration: subgroup analysis of first-year ANCHOR results, Am. J. Ophthalmol., 144, pp. 850-857, (2007); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Commun. ACM, 60, pp. 84-90, (2017); Lee C.S., Baughman D.M., Lee A.Y., Deep Learning Is Effective for the Classification of OCT Images of Normal versus Age-Related Macular Degeneration, Ophthamol. Retina, 1, pp. 322-327, (2016); Mcluckie A., Respiratory disease and its management, 57, (2009); Razavian A.S., Azizpour H., Sullivan J., Carlsson S., pp. 512-519, (2014); Rudan I., Boschi-Pinto C., Biloglav Z., Mulholland K., Campbell H., Epidemiology and etiology of childhood pneumonia, Bull. World Health Organ., 86, pp. 408-416, (2008); Swanson E.A., Fujimoto J.G., The ecosystem that powered the translation of OCT from fundamental research to clinical and commercial impact [Invited], Biomed. Opt. Express, 8, pp. 1638-1664, (2017); Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., pp. 2818-2826, (2016); Varma R., Bressler N.M., Doan Q.V., Gleeson M., Danese M., Bower J.K., Selvin E., Dolan C., Fine J., Colman S., Turpcu A., Prevalence of and risk factors for diabetic macular edema in the United States, JAMA Ophthalmol., 132, pp. 1334-1340, (2014); Wong W.L., Su X., Li X., Cheung C.M., Klein R., Cheng C.Y., Wong T.Y., Global prevalence of age-related macular degeneration and disease burden projection for 2020 and 2040: a systematic review and meta-analysis, Lancet Glob. Health, 2, pp. e106-e116, (2014); Yosinski J., Clune J., Bengio Y., Lipson H., 2, pp. 3320-3328, (2014); Zeiler M.D., Fergus R., Visualizing and Understanding Convolutional Networks, Lect. Notes Comput. Sci., 8689, pp. 818-833, (2014)","K. Zhang; Veterans Administration Healthcare System, San Diego, 92037, United States; email: kang.zhang@gmail.com","","Cell Press","","","","","","00928674","","CELLB","29474911","English","Cell","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85042389905"
"Pelka O.; Friedrich C.M.; Seco de Herrera A.G.; Müller H.","Pelka, Obioma (57190736323); Friedrich, Christoph M. (35232936500); Seco de Herrera, Alba G. (57348565300); Müller, Henning (8501863000)","57190736323; 35232936500; 57348565300; 8501863000","Overview of the ImageCLEFmed 2020 Concept Prediction Task: Medical Image Understanding","2020","CEUR Workshop Proceedings","2696","","","","","","17","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121819918&partnerID=40&md5=70f5ae79f59c26b2d08e01a59db04cf5","Department of Computer Science, University of Applied Sciences and Arts, Dortmund, Germany; Department of Diagnostic and Interventional Radiology and Neuroradiology, University Hospital Essen, Germany; Institute for Medical Informatics, Biometry and Epidemiology (IMIBE), University Hospital Essen, Germany; University of Essex, United Kingdom; University of Applied Sciences Western Switzerland (HES-SO), Switzerland; University of Geneva, Switzerland","Pelka O., Department of Computer Science, University of Applied Sciences and Arts, Dortmund, Germany, Department of Diagnostic and Interventional Radiology and Neuroradiology, University Hospital Essen, Germany; Friedrich C.M., Department of Computer Science, University of Applied Sciences and Arts, Dortmund, Germany, Institute for Medical Informatics, Biometry and Epidemiology (IMIBE), University Hospital Essen, Germany; Seco de Herrera A.G., University of Essex, United Kingdom; Müller H., University of Applied Sciences Western Switzerland (HES-SO), Switzerland, University of Geneva, Switzerland","This paper describes the ImageCLEFmed 2020 Concept Detection Task. After first being proposed at ImageCLEF 2017, the medical task is in its 4th edition this year, as the automatic detection from medical images still remains a challenging task. In 2020, the format remained the same as in 2019, with a single sub-task. The concept detection task is part of the medical tasks, alongside the tuberculosis and visual question and answering tasks. Similar to the 2019 edition, the data set focuses on radiology images rather than biomedical images, however with an increased number of images. The distributed images were extracted from the biomedical open access literature (PubMed Central). The development data consists of 65,753 training and 15,970 validation images. Each image has corresponding Unified Medical Language System (UMLS™) concepts, that were extracted from the original article image captions. In this edition, additional imaging acquisition technique labels were included in the distributed data, which were adopted for pre-filtering steps, concept selection and ensemble algorithms. Most applied approaches for the automatic detection of concepts were deep learning based architectures. Long short-term memory (LSTM) recurrent neural networks (RNN), adversarial auto-encoder, convolutional neural networks (CNN) image encoders and transfer learning-based multi-label classification models were adopted. The performances of the submitted models (best score 0.3940) were evaluated using F1-scores computed per image and averaged across all 3,534 test images. Copyright © 2020 for this paper by its authors.","Computer vision; Concept detection; Image modality; Image understanding; ImageCLEF 2020; Radiology","Classification (of information); Computer vision; Image understanding; Long short-term memory; Medical imaging; Radiation; Signal encoding; Automatic Detection; Concept detection; Data set; Detection tasks; Image modality; ImageCLEF; ImageCLEF 2020; Medical image understanding; Prediction tasks; Subtask; Radiology","","","","","","","Chollet F., Xception: Deep Learning with Depthwise Separable Convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR, pp. 1800-1807, (2017); Devi S., ImageCLEF 2020: Image Caption Prediction using Multilabel Convolutional Neural Network, CLEF2020 Working Notes. CEUR Workshop Proceedings, (2020); Eickhoff C., Schwall I., de Herrera A.G.S., Muller H., Overview of ImageCLEFcaption 2017 - Image Caption Prediction and Concept Detection for Biomedical Images, Working Notes of CLEF 2017 - Conference and Labs of the Evaluation Forum, (2017); Ferro N., Peters C., Information Retrieval Evaluation in a Changing World Lessons Learned from 20 Years of CLEF: Lessons Learned from 20 Years of CLEF, (2019); He K., Zhang X., Ren S., Sun J., Deep Residual Learning for Image Recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR, pp. 770-778, (2016); de Herrera A.G.S., Andrade F.P., Bentley L., Compean A.A., Essex at ImageCLEFcaption 2020 task, CLEF2020 Working Notes. CEUR Workshop Proceedings, (2020); de Herrera A.G.S., Eickhoff C., Andrearczyk V., Muller H., Overview of the ImageCLEF 2018 Caption Prediction Tasks, Working Notes of CLEF 2018 - Conference and Labs of the Evaluation Forum, (2018); Huang G., Liu Z., Van Der Maaten L., Weinberger K.Q., Densely Connected Convolutional Networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR, pp. 2261-2269, (2017); Ionescu B., Muller H., Peteri R., Abacha A.B., Datla V., Hasan S.A., Demner-Fushman D., Kozlovski S., Liauchuk V., Cid Y.D., Kovalev V., Pelka O., Friedrich C.M., de Herrera A.G.S., Ninh V.T., Le T.K., Zhou L., Piras L., Riegler M., Halvorsen P., Tran M.T., Lux M., Gurrin C., Dang-Nguyen D.T., Chamberlain J., Clark A., Campello A., Fichou D., Berari R., Brie P., Dogariu M., Stefan L.D., Constantin M.G., Overview of the ImageCLEF 2020: Multimedia Retrieval in Medical, Lifelogging, Nature, and Internet Applications, Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the 11th International Conference of the CLEF Association (CLEF 2020), vol. 12260. LNCS Lecture Notes in Computer Science, (2020); Kalimuthu M., Nunnari F., Sonntag D., A Competitive Deep Neural Network Approach for the ImageCLEFmed Caption 2020 Task, CLEF2020 Working Notes. CEUR Workshop Proceedings, (2020); Kalpathy-Cramer J., de Herrera A.G.S., Demner-Fushman D., Antani S.K., Bedrick S., Muller H., Evaluating performance of biomedical image retrieval systems - An overview of the medical image retrieval task at ImageCLEF 2004-2013, Comp. Med. Imag. and Graph, 39, pp. 55-61, (2015); Karatzas B., Pavlopoulos J., Kougia V., Androutsopoulo I., AUEB NLP Group at ImageCLEFmed Caption 2020, CLEF2020 Working Notes. CEUR Workshop Proceedings, (2020); Koitka S., Friedrich C.M., Optimized Convolutional Neural Network Ensembles for Medical Subfigure Classification, Experimental IR Meets Multilinguality, Multimodality, and Interaction at the 8th International Conference of the CLEF Association, pp. 57-68, (2017); Lyode O., Rahman M., Concept Detection in Biomedical Images with Deep Learning Based Multilabel Classification, CLEF2020 Working Notes. CEUR Workshop Proceedings, (2020); Muller H., Clough P.D., Deselaers T., Caputo B., ImageCLEF, Experimental Evaluation in Visual Information Retrieval, (2010); Pelka O., Friedrich C.M., de Herrera A.G.S., Muller H., Overview of the ImageCLEFmed 2019 Concept Detection Task, Working Notes of CLEF 2019 - Conference and Labs of the Evaluation Forum, 2380, (2019); Pelka O., Koitka S., Ruckert J., Nensa F., Friedrich C.M., Radiology Objects in COntext (ROCO): A Multimodal Image Dataset, Intravascular Imaging and Computer Assisted Stenting - and - Large-Scale Annotation of Biomedical Data and Expert Label Synthesis - 7th Joint International Workshop, CVII-STENT 2018 and Third International Workshop, LABELS 2018, Held in Conjunction with MICCAI 2018, pp. 180-189, (2018); Pelka O., Nensa F., Friedrich C.M., Adopting Semantic Information of Grayscale Radiographs for Image Classification and Retrieval, Proceedings of the 11th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC 2018) - Volume 2: BIOIMAGING, pp. 179-187, (2018); Pelka O., Nensa F., Friedrich C.M., Variations on Branding with Text Occurrence for Optimized Body Parts Classification, Proceedings of the 41th Annual International Conference of the IEEE Engineering in Medicine and Biology Society EMBC 2019, pp. 890-894, (2019); Roberts R.J., PubMed Central: The GenBank of the published literature, Proceedings of the National Academy of Sciences of the United States of America, 98, 2, pp. 381-382, (2001); Russakovsky O., Deng J., Su H., Krause J., Satheesh S., Ma S., Huang Z., Karpathy A., Khosla A., Bernstein M., Berg A., Fei-Fei L., ImageNet Large Scale Visual Recognition Challenge, International Journal of Computer Vision, 115, (2014); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, (2014); Soldaini L., Goharian N., QuickUMLS: a fast, unsupervised approach for medical concept extraction, MedIR Workshop, SIGIR, (2016); Sonker R., Mishra A., Bansal P., Pattnaik A., Techniques for Medical Concept Detection from Multi-Modal Images, CLEF2020 Working Notes. CEUR Workshop Proceedings, (2020); Udas N., Beuth F., Kowerko D., TUC MC group at ImageCLEFmed 2020 concept detection task using Xception models, CLEF2020 Working Notes. CEUR Workshop Proceedings, (2020); Wang X., Peng Y., Lu L., Lu Z., Bagheri M., Summers R.M., ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR, pp. 3462-3471, (2017)","","De Carolis B.; Gena C.; Lieto A.; Rossi S.; Sciutti A.","CEUR-WS","","11th Conference and Labs of the Evaluation Forum, CLEF 2020","22 September 2020 through 25 September 2020","Thessaloniki","163832","16130073","","","","English","CEUR Workshop Proc.","Conference paper","Final","","Scopus","2-s2.0-85121819918"
"Alsaade F.W.; Alzahrani M.S.","Alsaade, Fawaz Waselallah (22937047900); Alzahrani, Mohammed Saeed (57483011800)","22937047900; 57483011800","Classification and Detection of Autism Spectrum Disorder Based on Deep Learning Algorithms","2022","Computational Intelligence and Neuroscience","2022","","8709145","","","","68","10.1155/2022/8709145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126076335&doi=10.1155%2f2022%2f8709145&partnerID=40&md5=8c4de86b15f3a2ce9a831dd6f8e79852","College of Computer Science and Information Technology, King Faisal University, P.O. Box 4000, Al-Ahsa, Saudi Arabia","Alsaade F.W., College of Computer Science and Information Technology, King Faisal University, P.O. Box 4000, Al-Ahsa, Saudi Arabia; Alzahrani M.S., College of Computer Science and Information Technology, King Faisal University, P.O. Box 4000, Al-Ahsa, Saudi Arabia","Autism spectrum disorder (ASD) is a type of mental illness that can be detected by using social media data and biomedical images. Autism spectrum disorder (ASD) is a neurological disease correlated with brain growth that later impacts the physical impression of the face. Children with ASD have dissimilar facial landmarks, which set them noticeably apart from typically developed (TD) children. Novelty of the proposed research is to design a system that is based on autism spectrum disorder detection on social media and face recognition. To identify such landmarks, deep learning techniques may be used, but they require a precise technology for extracting and producing the proper patterns of the face features. This study assists communities and psychiatrists in experimentally detecting autism based on facial features, by using an uncomplicated web application based on a deep learning system, that is, a convolutional neural network with transfer learning and the flask framework. Xception, Visual Geometry Group Network (VGG19), and NASNETMobile are the pretrained models that were used for the classification task. The dataset that was used to test these models was collected from the Kaggle platform and consisted of 2,940 face images. Standard evaluation metrics such as accuracy, specificity, and sensitivity were used to evaluate the results of the three deep learning models. The Xception model achieved the highest accuracy result of 91%, followed by VGG19 (80%) and NASNETMobile (78%). © 2022 Fawaz Waselallah Alsaade and Mohammed Saeed Alzahrani.","","Algorithms; Autism Spectrum Disorder; Brain; Child; Deep Learning; Humans; Neural Networks, Computer; Convolutional neural networks; Deep learning; Face recognition; Learning algorithms; Social networking (online); Statistical tests; Autism spectrum disorders; Biomedical images; Children with autisms; Data images; Facial landmark; Learning techniques; Mental illness; Neurological disease; Social media; Social media datum; algorithm; autism; brain; child; human; Diseases","","","","","","","Paula C.S., Ribeiro S.H., Fombonne E., Mercadante M.T., Brief report: Prevalence of pervasive developmental disorder in Brazil: A pilot study, Journal of Autism and Developmental Disorders, 41, 12, pp. 1738-1742, (2011); Nunes L.C., Pinheiro P.R., Pinheiro M.C.D., Visvizi A., Lytras M.D., A Hybrid Model to Guide the Consultation of Children with Autism Spectrum Disorder, pp. 419-431; Diagnostic and Statistical Manual of Mental Disorders (DSM -5), (2020); Carette R., Cilia F., Dequen G., Bosche J., Guerin J.-L., Vandromme L., Automatic Autism Spectrum Disorder Detection Thanks to Eye-tracking and Neural Network-based Approach, pp. 75-81; Kanner L., Autistic disturbances of affective contact, Nerv. Child, 2, pp. 217-250, (1943); Fombonne E., Epidemiology of pervasive developmental disorders, Pediatric Research, 65, 6, pp. 591-598, (2009); International Statistical Classification of Diseases and Related Health Problems (ICD); Yolcu G., Oztel I., Kazan S., Oz C., Palaniappan K., Lever T.E., Bunyak F., Deep Learning-based Facial Expression Recognition for Monitoring Neurological Disorders, pp. 1652-1657; Yolcu G., Oztel I., Kazan S., Oz C., Palaniappan K., Lever T.E., Bunyak F., Facial expression recognition for monitoring neurological disorders based on convolutional neural network, Multimedia Tools and Applications, 78, 22, pp. 31581-31603, (2019); Haque M.I.U., Valles D., A Facial Expression Recognition Approach Using DCNN for Autistic Children to Identify Emotions, pp. 546-551; Rudovic O., Utsumi Y., Lee J., Hernandez J., Ferrer E.C., Schuller B., Picard R.W., CultureNet: A Deep Learning Approach for Engagement Intensity Estimation from Face Images of Children with Autism, pp. 339-346; Satu M.S., Farida Sathi F., Arifen M.S., Hanif Ali M., Moni M.A., Early Detection of Autism by Extracting Features: A Case Study in Bangladesh, pp. 400-405; Guillon Q., Hadjikhani N., Baduel S., Roge B., Visual social attention in autism spectrum disorder: Insights from eye tracking studies, Neuroscience & Biobehavioral Reviews, 42, pp. 279-297, (2014); Akter T., Satu M.S., Barua L., Sathi F.F., Ali M.H., Statistical analysis of the activation area of fusiform gyrus of human brain to explore autism, International Journal of Computer Science and Information Security, 15, pp. 331-337, (2017); Schelinski S., Borowiak K., Von Kriegstein K., Temporal voice areas exist in autism spectrum disorder but are dysfunctional for voice identity recognition, Social Cognitive and Affective Neuroscience, 11, 11, pp. 1812-1822, (2016); Jiang X., Chen Y.-F., Bunke H., Kandel A., Last M., Facial image processing, Applied Pattern Recognition, pp. 29-48, (2008); Duda M., Ma R., Haber N., Wall D.P., Use of machine learning for behavioral distinction of autism and ADHD, Translational Psychiatry, 6, 2, (2016); Deshpande G., Libero L.E., Sreenivasan K.R., Deshpande H.D., Kana R.K., Identification of neural connectivity signatures of autism using machine learning, Frontiers in Human Neuroscience, 7, (2013); Parikh M.N., Li H., He L., Enhancing diagnosis of autism with optimized machine learning models and personal characteristic data, Frontiers in Computational Neuroscience, (2019); Thabtah F., Peebles D., A new machine learning model based on induction of rules for autism detection, Health Informatics Journal, 26, 1, pp. 264-286, (2020); Al Banna M.H., Ghosh T., Taher K.A., Kaiser M.S., Mahmud M., A Monitoring System for Patients of Autism Spectrum Disorder Using Artificial Intelligence, pp. 251-262; Li M., Tang D., Zeng J., Zhou T., Zhu H., Chen B., Zou X., An automated assessment framework for atypical prosody and stereotyped idiosyncratic phrases related to autism spectrum disorder, Computer Speech & Language, 56, pp. 80-94, (2019); Pokorny F.B., Schuller B.W., Marschik P.B., Brueckner R., Nystrom P., Cummins N., Bolte S., Einspieler C., Falck-Ytter T., Earlier Identification of Children with Autism Spectrum Disorder: An Automatic Vocalisation-based Approach; Eyben F., Scherer K.R., Schuller B.W., Sundberg J., Andre E., Busso C., Devillers L.Y., Epps J., Laukka P., Narayanan S.S., Truong K.P., The Geneva minimalistic acoustic parameter set (GeMAPS) for voice research and affective computing, IEEE Transactions on Affective Computing, 7, 2, pp. 190-202, (2016); Jack A., Neuroimaging in neurodevelopmental disorders: Focus on resting-state fMRI analysis of intrinsic functional brain connectivity, Current Opinion in Neurology, 31, 2, pp. 140-148, (2018); Fu C.H.Y., Costafreda S.G., Neuroimaging-based biomarkers in psychiatry: Clinical opportunities of a paradigm shift, Canadian Journal of Psychiatry, 58, 9, pp. 499-508, (2013); Moon S.J., Hwang J., Kana R., Torous J., Kim J.W., Accuracy of machine learning algorithms for the diagnosis of autism spectrum disorder: Systematic review and meta-analysis of brain magnetic resonance imaging studies, JMIR Mental Health, 6, 12, (2019); Sarabadani S., Schudlo L.C., Samadani A.A., Kushski A., Physiological detection of affective states in children with autism spectrum disorder, IEEE Transactions on Affective Computing, 11, 4, pp. 588-600, (2020); Liu W., Li M., Yi L., Identifying children with autism spectrum disorder based on their face processing abnormality: A machine learning framework, Autism Research, 9, 8, pp. 888-898, (2016); Alcaniz Raya M., Chicchi Giglioli I.A., Marin-Morales J., Higuera-Trujillo J.L., Olmos E., Minissi M.E., Teruel Garcia G., Sirera M., Abad L., Application of supervised machine learning for behavioral biomarkers of autism spectrum disorder based on electrodermal activity and virtual reality, Frontiers in Human Neuroscience, 14, (2020); Hashemi J., Dawson G., Carpenter K.L.H., Campbell K., Qiu Q., Espinosa S., Marsan S., Baker J.P., Egger H.L., Sapiro G., Computer vision analysis for quantification of autism risk behaviors, IEEE Trans. Affect. Comput., 3045, pp. 1-12, (2018); Dahiya A.V., McDonnell C., Delucia E., Scarpa A., A systematic review of remote telehealth assessments for early signs of autism spectrum disorder: Video and mobile applications, Practice Innovations, 5, 2, pp. 150-164, (2020); Shahamiri S.R., Thabtah F., Autism AI: A new autism screening system based on artificial intelligence, Cognitive Computation, 12, 4, pp. 766-777, (2020); Piosenka G., Detect Autism from A Facial Image, (2021); Garcia C., Ostermann J., Cootes T., Facial image processing, Eurasip J. Image Video Process, 2007, pp. 1-2, (2008); Tamilarasi F.C., Shanmugam J., Convolutional Neural Network Based Autism Classification, pp. 1208-1212; Jahanara S., Padmanabhan S., Detecting Autism from Facial Image, (2021)","F.W. Alsaade; College of Computer Science and Information Technology, King Faisal University, P.O. Box 4000, Al-Ahsa, Saudi Arabia; email: falsaade@kfu.edu.sa","","Hindawi Limited","","","","","","16875265","","","35265118","English","Comput. Intell. Neurosci.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85126076335"
"Ashok M.; Gupta A.","Ashok, Malvika (57219146342); Gupta, Abhishek (55430473100)","57219146342; 55430473100","Comparative Study of TRANS - GAN Architecture for Bio-Medical Image Semantic Segmentation","2022","7th International Conference on Communication and Electronics Systems, ICCES 2022 - Proceedings","","","","1564","1570","6","1","10.1109/ICCES54183.2022.9835992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136319840&doi=10.1109%2fICCES54183.2022.9835992&partnerID=40&md5=dbf693663a1d3e649cd47a4e7a57e494","Shri Mata Vaishno Devi University, School of Computer Science and Engineering, Jammu and Kashmir, Katra, India","Ashok M., Shri Mata Vaishno Devi University, School of Computer Science and Engineering, Jammu and Kashmir, Katra, India; Gupta A., Shri Mata Vaishno Devi University, School of Computer Science and Engineering, Jammu and Kashmir, Katra, India","In the area of biomedical image processing, medical image segmentation plays a crucial role. Today due to the deep sculptures of deep neural networks and innovative by-passes like the Transformers this field has rejuvenated. This paper analyzes various algorithmic advancements regarding Transformers and Generative Adversarial Networks (GAN) which have paved the anatomy of image segmentation. The GAN network is not only able to regenerate feature spaces but also can transpose the inputs from the transformer. These algorithms are not only at par with the bifurcation of networks like U-net and ResNet but showcase a strong and more intuitive idea of human neural intelligence. Finally, all methods are compared based on accuracy, dice score, architectural evaluation, etc. The ability of these networks are deduced to regenerate and recreate the feature spaces for the given input image and thus can segment high features for prediction.  © 2022 IEEE.","Automatic segmentation; Bio-Medical Imaging; CT segmentation; Deep learning; Generative Adversarial Networks Convolutional Neural Network; Medical modalities; Supervised and Unsupervised Transformers; Traditional Architecture; Transformers","Computerized tomography; Convolutional neural networks; Deep neural networks; Medical imaging; Network architecture; Semantic Segmentation; Semantics; Automatic segmentations; Bio-medical; Bio-medical imaging; Convolutional neural network; CT segmentation; Deep learning; Generative adversarial network convolutional neural network; Medical modality; Supervised and unsupervised transformer; Traditional architecture; Transformer; Generative adversarial networks","","","","","","","Gupta A., Challenges for computer aided diagnosticss using X-ray and tomographic reconst ruction images in craniofacial applications, International Journal of Computational Vision and Robotics, 10, pp. 360-371, (2020); Shrestha A., Mahmood A., Review of deep learning algorithms and architectures, IEEE Access, 7, pp. 53040-53065, (2019); Pandey M., Gupta A., A systematic review of the automatic kidney segmentation methods in abdominal images, Biocybernetics and Biomedical Engineering, 41, pp. 1601-1628, (2021); Trivedi M., Gupta A., A lightweight deep learning architecture for the automatic detection of pneumonia using chest X-ray images, Multimedia Tools and Applications, 81, pp. 5515-5536, (2022); Bansal P., Gehlot K., Singhal A., Gupta A., Automatic detection of osteosarcoma based on integrated features and feature selection using binary arithmetic optimization algorithm, Multimedia Tools and Applications, pp. 1-28, (2022); Gupta A., Current research opportunities for image processing and computer vision, Computer Science, 20, (2019); Ashok M., Gupta A., A systematic review of the techniques for the automatic segmentation of organsat- risk in thoracic computed tomography images, Archives of Computational Methods in Engineering, 28, pp. 3245-3267, (2021); Ashok M., Gupta A., Deep learning-based techniques for the automatic segmentation of organs in thoracic computed tomography images: A Comparative study, 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), pp. 198-202, (2021); Trivedi M., Gupta A., Automatic monitoring of the growth of plants using deep learning-based leaf segmentation, International Journal of Applied Science and Engineering, 18, pp. 1-9, (2021); Emmert-Streib F., Yang Z., Feng H., Tripathi S., Dehmer M., An int roductory review of deep learning for prediction models with big data, Front Artif Intell, 3, (2020); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in neural information processing systems, 25, pp. 1097-1105, (2012); Girshick R., Fast r-cnn, Proceedings of the IEEE international conference on computer vision, pp. 1440-1448, (2015); Ren S., He K., Girshick R., Sun J., Faster r-cnn: Towards real-time object detection with region proposal networks, Advances in neural information processing systems, 28, pp. 91-99, (2015); Ronneberger O., Fischer P., Brox T., U-net : Convolutional networks for biomedical image segmentation, International Conference on Medical image computing and computer-assisted intervention, pp. 234-241, (2015); Suganthi K., Review of medical image synthesis using gan techniques, ITM Web of Conferences, (2021); Gupta R.K., Sahu Y., Kunhare N., Gupta A., Prakash D., Deep learning based mathematical model for feature ext raction to detect corona virus disease using chest x-ray images, International Journal of Uncertainty, Fuzziness & Knowledge- Based Systems, pp. 921-947, (2021); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Et al., At tention is all you need, Advances in neural information processing systems, pp. 5998-6008, (2017); Goodfellow I., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., Et al., Generative adversarial nets, Advances in neural information processing systems, 27, (2014); Chen J., Lu Y., Yu Q., Luo X., Adeli E., Wang Y., Et al., Transunet: Transformers make st rong encoders for medical image segmentation, (2021); Feng X., Qing K., Tustison N.J., Meyer C.H., Chen Q., Deep convolutional neural network for segmentation of thoracic organs-at-risk using cropped 3D images, Med Phys, 46, pp. 2169-2180, (2019); Hatamizadeh A., Yang D., Roth H., Xu D., Unet r: Transformers for 3d medical image segmentation, (2021); Valanarasu J.M.J., Oza P., Hacihaliloglu I., Patel V.M., Medical transformer: Gated axial-attention for medical image segmentation, (2021); Kitchen A., Seah J., Deep generative adversarial neural networks for realistic prostate lesion MRI synthesis, (2017); Chartsias A., Joyce T., Dharmakumar R., Tsaftaris S.A., Adversarial image synthesis for unpaired multi-modal cardiac data, International workshop on simulation and synthesis in medical imaging, pp. 3-13, (2017); Karras T., Aila T., Laine S., Lehtinen J., Progressive growing of gans for improved quality, stability, and variation, (2017); Gu J., Li Z., Wang Y., Yang H., Qiao Z., Yu J., Deep generative adversarial networks for thinsection infant MR image reconst ruction, IEEE Access, 7, pp. 68290-68304, (2019); Zhang L., Gooya A., Frangi A.F., Semisupervised assessment of incomplete LV coverage in cardiac MRI using generative adversarial nets, International Workshop on Simulation and Synthesis in Medical Imaging, pp. 61-68, (2017); Lee D., Kim J., Moon W.-J., Ye J.C., CollaGAN: Collaborative GAN for missing image data imputation, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2487-2496, (2019); Lan L., You L., Zhang Z., Fan Z., Zhao W., Zeng N., Et al., Generative adversarial networks and its applications in biomedical informatics, Frontiers in Public Health, 8, (2020); Ghahramani A., Watt F.M., Luscombe N.M., Generative adversarial networks uncover epidermal regulators and predict single cell perturbations, (2018); Gupta A., Zou J., Feedback GAN (FBGAN) for DNA: A novel feedback-loop architecture for optimizing protein functions, (2018)","","","Institute of Electrical and Electronics Engineers Inc.","","7th International Conference on Communication and Electronics Systems, ICCES 2022","22 June 2022 through 24 June 2022","Coimbatore","181470","","978-166549634-6","","","English","Int. Conf. Commun. Electron. Syst., ICCES - Proc.","Conference paper","Final","","Scopus","2-s2.0-85136319840"
"Gao Y.; Zhang Y.; Jiang X.","Gao, Yalan (57218452855); Zhang, Yanqiong (57205725582); Jiang, Xianwei (57211990320)","57218452855; 57205725582; 57211990320","An Optimized Convolutional Neural Network with Combination Blocks for Chinese Sign Language Identification","2022","CMES - Computer Modeling in Engineering and Sciences","132","1","","95","117","22","3","10.32604/cmes.2022.019970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138463147&doi=10.32604%2fcmes.2022.019970&partnerID=40&md5=dbf1db6cfa369b745c128c141ccd9992","Nanjing Normal University of Special Education, Nanjing, 210038, China","Gao Y., Nanjing Normal University of Special Education, Nanjing, 210038, China; Zhang Y., Nanjing Normal University of Special Education, Nanjing, 210038, China; Jiang X., Nanjing Normal University of Special Education, Nanjing, 210038, China","(Aim) Chinese sign language is an essential tool for hearing-impaired to live, learn and communicate in deaf communities. Moreover, Chinese sign language plays a significant role in speech therapy and rehabilitation. Chinese sign language identification can provide convenience for those hearing impaired people and eliminate the communication barrier between the deaf community and the rest of society. Similar to the research of many biomedical image processing (such as automatic chest radiograph processing, diagnosis of chest radiological images, etc.), with the rapid development of artificial intelligence, especially deep learning technologies and algorithms, sign language image recognition ushered in the spring. This study aims to propose a novel sign language image recognition method based on an optimized convolutional neural network. (Method) Three different combinations of blocks: Conv-BN-ReLU-Pooling, Conv-BN-ReLU, Conv-BN-ReLU-BN were employed, including some advanced technologies such as batch normalization, dropout, and Leaky ReLU. We proposed an optimized convolutional neural network to identify 1320 sign language images, which was called as CNN-CB method. Totally ten runs were implemented with the hold-out randomly set for each run. (Results) The results indicate that our CNN-CB method gained an overall accuracy of 94.88 ± 0.99%. (Conclusion) Our CNN-CB method is superior to thirteen state-of-the-art methods: eight traditional machine learning approaches and five modern convolutional neural network approaches. © 2022 Tech Science Press. All rights reserved.","batch normalization; Chinese sign language; combination blocks; Convolutional neural network; dropout; Leaky ReLU; M-fold cross-validation","Audition; Bioinformatics; Convolution; Deep learning; Image processing; Image recognition; Learning systems; Natural language processing systems; Batch normalization; Chinese sign language; Combination block; Convolutional neural network; Cross validation; Dropout; Leaky ReLU; M-fold cross-validation; Normalisation; Sign language image; Convolutional neural networks","","","","","WITH Foundation, (20BTQ065); Philosophy and Social Science Foundation of Hunan Province","Funding text 1: This work was supported from The National Philosophy and Social Sciences Foundation (Grant No. 20BTQ065).; Funding text 2: Funding Statement: This work was supported from The Foundation (Grant No. 20BTQ065).","Li X., Research on Chinese sign language recognition for middle and small vocabulary based on neural network, pp. 1-2, (2017); Yu X., He H., A review on domestic sign language study, Chinese Journal of Special Education, 4, pp. 36-41, (2009); Jia Z., Sign language linguistics: A review of “Chinese Sign Language”, Journalism and Writing, 2, (2018); Kamal S. M., Chen Y., Li S., Shi X., Zheng J., Technical approaches to Chinese sign language processing: A review, IEEE Access, 7, pp. 96926-96935, (2019); Zhang J., Zhou W., Xie C., Pu J., Li H., Chinese sign language recognition with adaptive HMM, IEEE International Conference on Multimedia and Expo, pp. 1-6, (2016); Wang H., Chai X., Zhou Y., Chen X., Fast sign language recognition benefited from low rank approximation, 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, 1, pp. 1-6, (2015); Sidig A. A. I., Luqman H., Mahmoud S. A., Arabic sign language recognition using vision and hand tracking features with HMM, International Journal of Intelligent Systems Technologies and Applications, 18, 5, pp. 430-447, (2019); He J., Liu Z., Zhang J., Chinese sign language recognition based on trajectory and hand shape features, Visual Communications and Image Processing, pp. 1-4, (2016); Chen Y., Zhang W., Research and implementation of sign language recognition method based on kinect, 2nd IEEE International Conference on Computer and Communications, pp. 1947-1951, (2016); Song N., Yang H., Wu P., A Gesture-to-emotional speech conversion by combining gesture recognition and facial expression recognition, First Asian Conference on Affective Computing and Intelligent Interaction, pp. 1-6, (2018); Fatmi R., Rashad S., Integlia R., Comparing ANN, SVM, and HMM based machine learning methods for American sign language recognition using wearable motion sensors, IEEE 9th Annual Computing and Communication Workshop and Conference, pp. 290-297, (2019); Zhang Y., Wu L., Segment-based coding of color images, Science in China Series F: Information Sciences, 52, 6, pp. 914-925, (2009); Zhang Y. D., Zhao G., Sun J., Wu X., Wang Z. H., Et al., Smart pathological brain detection by synthetic minority oversampling technique, extreme learning machine, and Jaya algorithm, Multimedia Tools and Applications, 77, 17, pp. 22629-22648, (2018); Yang J., Jiang Q., Wang L., Liu S., Zhang Y. D., Et al., An adaptive encoding learning for artificial bee colony algorithms, Journal of Computational Science, 30, pp. 11-27, (2019); Zhang Y. D., Zhang Z., Zhang X., Wang S. H., MIDCAN: A multiple input deep convolutional attention network for COVID-19 diagnosis based on chest CT and chest X-ray, Pattern Recognition Letters, 150, pp. 8-16, (2021); Zhang Y., Zhang X., Zhu W., ANC: Attention network for COVID-19 explainable diagnosis based on convolutional block attention module, Computer Modeling in Engineering & Sciences, 127, 3, pp. 1037-1058, (2021); Yang S., Zhu Q., Video-based Chinese sign language recognition using convolutional neural network, IEEE 9th International Conference on Communication Software and Networks, pp. 929-934, (2017); Huang J., Zhou W., Li H., Li W., Attention-based 3D-CNNs for large-vocabulary sign language recognition, IEEE Transactions on Circuits and Systems for Video Technology, 29, 9, pp. 2822-2832, (2018); Liang Z. J., Liao S. B., Hu B. Z., 3D convolutional neural networks for dynamic sign language recognition, The Computer Journal, 61, 11, pp. 1724-1736, (2018); Sajanraj T. D., Beena M. V., Indian sign language numeral recognition using region of interest convolutional neural network, Second International Conference on Inventive Communication and Computational Technologies, pp. 636-640, (2018); Jiang X., Zhang Y. D., Chinese sign language fingerspelling via six-layer convolutional neural network with leaky rectified linear units for therapy and rehabilitation, Journal of Medical Imaging and Health Informatics, 9, 9, pp. 2031-2090, (2019); Jiang X., Lu M., Wang S. H., An eight-layer convolutional neural network with stochastic pooling, batch normalization and dropout for fingerspelling recognition of Chinese sign language, Multimedia Tools and Applications, 79, 21, pp. 15697-15715, (2020); Suri K., Gupta R., Convolutional neural network array for sign language recognition using wearable IMUs, 6th International Conference on Signal Processing and Integrated Networks, pp. 483-488, (2019); Soodtoetong N., Gedkhaw E., The efficiency of sign language recognition using 3D convolutional neural networks, 15th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, pp. 70-73, (2018); Kumar E. K., Kishore P. V. V., Sastry A. S. C. S., Kumar M. T. K., Kumar D. A., Training CNNs for 3-D sign language recognition with color texture coded joint angular displacement maps, IEEE Signal Processing Letters, 25, 5, pp. 645-649, (2018); Farooq U., Asmat A., Rahim M. S. B. M., Khan N. S., Abid A., A comparison of hardware based approaches for sign language gesture recognition systems, InternationalConference on Innovative Computing, pp. 1-6, (2019); Yang L., Zhu Y., Li T., Towards computer-aided sign language recognition technique: A directional review, IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference, 1, pp. 721-725, (2019); Kishore P. V. V., Prasad M. V., Prasad C. R., Rahul R., 4-Camera model for sign language recognition using elliptical Fourier descriptors and ANN, International Conference on Signal Processing and Communication Engineering Systems, pp. 34-38, (2015); Dinh D. L., Lee S., Kim T. S., Hand number gesture recognition using recognized hand parts in depth images, Multimedia Tools and Applications, 75, 2, pp. 1333-1348, (2016); Liu T., Zhou W., Li H., Sign language recognition with long short-term memory, IEEE International Conference on Image Processing, pp. 2871-2875, (2016); Liao Y., Xiong P., Min W., Min W., Lu J., Dynamic sign language recognition based on video sequence with BLSTM-3D residual networks, IEEE Access, 7, pp. 38044-38054, (2019); Fukushima K., Miyake S., Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition, Competition and cooperation in neural nets, pp. 267-285, (1982); Goel S., Klivans A., Meka R., Learning one convolutional layer with overlapping patches, Proceedings of the 35th International Conference on Machine Learning, pp. 1783-1791, (2018); Wang S. H., Satapathy S. C., Anderson D., Chen S. X., Zhang Y. D., Deep fractional max pooling neural network for COVID-19 recognition, Frontiers in Public Health, 9, (2021); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Et al., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Han K., Yu D., Tashev I., Speech emotion recognition using deep neural network and extreme learning machine, 15th Annual Conference of the International Speech Communication Association, (2014); Wang S. H., Wu K., Chu T., Fernandes S. L., Zhou Q., Et al., SOSPCNN: Structurally optimized stochastic pooling convolutional neural network for tetralogy of fallot recognition, Wireless Communications and Mobile Computing, 2021, (2021); Ba J., Frey B., Adaptive dropout for training deep neural networks, Advances in Neural Information Processing Systems, 26, pp. 3084-3092, (2013); Roth H. R., Yao J., Lu L., Stieger J., Burns J. E., Et al., Detection of sclerotic spine metastases via random aggregation of deep convolutional neural network classifications, Recent advances in computational methods and clinical applications for spine imaging, pp. 3-12, (2015); Wang S., Celebi M. E., Zhang Y. D., Yu X., Lu S., Et al., Advances in data preprocessing for biomedical data fusion: An overview of the methods, challenges, and prospects, Information Fusion, 76, pp. 376-421, (2021); Zhang Y. D., Dong Z., Wang S. H., Yu X., Yao X., Et al., Advances in multimodal data fusion in neuroimaging: Overview, challenges, and novel orientation, Information Fusion, 64, pp. 149-187, (2020); Xu B., Wang N., Chen T., Li M., Empirical evaluation of rectified activations in convolutional network, (2015); Nair V., Hinton G. E., Rectified linear units improve restricted boltzmann machines, Proceedings of the 27th International Conference on Machine Learning, (2010); Sun Y., Wang X., Tang X., Deeply learned face representations are sparse, selective, and robust, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2892-2900, (2015); Zhang X., Zou Y., Shi W., Dilated convolution neural network with LeakyReLU for environmental sound classification, 22nd International Conference on Digital Signal Processing, pp. 1-5, (2017); Zhang X., Luo H., Fan X., Xiang W., Sun Y., Et al., Alignedreid: Surpassing human-level performance in person re-identification, (2017); Duggal R., Gupta A., P-TELU: Parametric tan hyperbolic linear unit activation for deep neural networks, Proceedings of the IEEE International Conference on Computer Vision Workshops, pp. 974-978, (2017); Hinton G. E., Srivastava N., Krizhevsky A., Sutskever I., Salakhutdinov R. R., Improving neural networks by preventing co-adaptation of feature detectors, (2012); Wu H., Gu X., Towards dropout training for convolutional neural networks, Neural Networks, 71, pp. 1-10, (2015); Bouthillier X., Konda K., Vincent P., Memisevic R., Dropout as data augmentation, (2015); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: A simple way to prevent neural networks from overfitting, The Journal of Machine Learning Research, 15, 1, pp. 1929-1958, (2014); Shao J., Linear model selection by cross-validation, Journal of the American Statistical Association, 88, 422, pp. 486-494, (1993); Hawkins D. M., Basak S. C., Mills D., Assessing model fit by cross-validation, Journal of Chemical Information and Computer Sciences, 43, 2, pp. 579-586, (2003); Bengio Y., Grandvalet Y., No unbiased estimator of the variance of k-fold cross-validation, Journal of Machine Learning Research, 5, pp. 1089-1105, (2004); Wang S. H., Jiang X., Zhang Y. D., Multiple sclerosis recognition by biorthogonal wavelet features and fitness-scaled adaptive genetic algorithm, Frontiers in Neuroscience, 15, (2021); Anguita D., Ghelardoni L., Ghio A., Oneto L., Ridella S., The ‘K’ in K-fold cross validation, 20th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, pp. 441-446, (2012); Yang H. D., Lee S. W., Robust sign language recognition with hierarchical conditional random fields, 2010 20th International Conference on Pattern Recognition, pp. 2202-2205, (2010); Kumar P., Saini R., Roy P. P., Dogra D. P., A position and rotation invariant framework for sign language recognition (SLR) using kinect, Multimedia Tools and Applications, 77, 7, pp. 8823-8846, (2018); Lee G. C., Yeh F. H., Hsiao Y. H., Kinect-based Taiwanese sign-language recognition system, Multimedia Tools and Applications, 75, 1, pp. 261-279, (2016); Jiang X., Isolated Chinese sign language recognition using gray-level co-occurrence matrix and parameter-optimized medium gaussian support vector machine, Frontiers in intelligent computing: Theory and applications, pp. 182-193, (2020); Jiang X., Zhu Z., Chinese sign language identification via wavelet entropy and support vector machine, International Conference on Advanced Data Mining and Applications, pp. 726-736, (2019); Gao Y., Wang R., Xue C., Gao Y., Qiao Y., Et al., Chinese fingerspelling recognition via Hu moment invariant and RBF support vector machine, International Conference on Multimedia Technology and Enhanced Learning, pp. 382-392, (2020); Gao Y., Xue C., Wang R., Jiang X., Chinese fingerspelling recognition via gray-level co-occurrence matrix and fuzzy support vector machine, EAI Endorsed Transactions on e-Learning, 7, 20, (2021); Zhu Z., Zhang M., Jiang X., Fingerspelling identification for Chinese sign language via wavelet entropy and kernel support vector machine, Intelligent data engineering and analytics, pp. 539-549, (2021); Jiang X., Hu B., Chandra Satapathy S., Wang S. H., Zhang Y. D., Fingerspelling identification for Chinese sign language via AlexNet-based transfer learning and adam optimizer, Scientific Programming, 2020, (2020); Gao Y., Jia C., Chen H., Jiang X., Chinese fingerspelling sign language recognition using a nine-layer convolutional neural network, EAI Endorsed Transactions on e-Learning, 7, 20, (2021); Gao Y., Zhu R., Gao R., Weng Y., Jiang X., An optimized seven-layer convolutional neural network with data augmentation for classification of Chinese fingerspelling sign language, International Conference on Multimedia Technology and Enhanced Learning, pp. 21-42, (2021)","X. Jiang; Nanjing Normal University of Special Education, Nanjing, 210038, China; email: jxw@njts.edu.cn","","Tech Science Press","","","","","","15261492","","","","English","CMES Comput. Model. Eng. Sci.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85138463147"
"Seum A.; Raj A.H.; Sakib S.; Hossain T.","Seum, Ashek (57223048161); Raj, Amir Hossain (57223044264); Sakib, Shadman (56296982100); Hossain, Tonmoy (57208082515)","57223048161; 57223044264; 56296982100; 57208082515","A comparative study of CNN transfer learning classification algorithms with segmentation for COVID-19 detection from CT scan images","2020","Proceedings of 2020 11th International Conference on Electrical and Computer Engineering, ICECE 2020","","","9393129","234","237","3","15","10.1109/ICECE51571.2020.9393129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104673230&doi=10.1109%2fICECE51571.2020.9393129&partnerID=40&md5=3297d86c230010e2d5eedfee1fc208f6","Ahsanullah University of Science and Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh","Seum A., Ahsanullah University of Science and Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh; Raj A.H., Ahsanullah University of Science and Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh; Sakib S., Ahsanullah University of Science and Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh; Hossain T., Ahsanullah University of Science and Technology, Department of Computer Science and Engineering, Dhaka, Bangladesh","After it's inception, COVID-19 has spread rapidly all across the globe. Considering this outbreak, by far, it is the most decisive task to detect early and isolate the patients quickly to contain the spread of this virus. In such cases, artificial intelligence and machine learning or deep learning methods can come to aid. For that purpose, we have conducted a qualitative investigation to inspect 12 off-the-shelf Convolution Neural Network (CNN) architectures in classifying COVID-19 from CT scan images. Furthermore, a segmentation algorithm for biomedical images - U-Net, is analyzed to evaluate the performance of the CNN models. A publicly available dataset (SARS-COV-2 CT-Scan) containing a total of 2481 CT scan images is employed for the performance evaluation. In terms of feature extraction by excluding the segmentation technique, a performance of 88.60% as the F1 Score and 89.31% as accuracy is achieved by training DenseNet169 architecture. Adopting the U-Net segmentation method, we accomplished the most optimal accuracy and F1 Scores as 89.92% and 89.67% respectively on DenseNet201 model. Furthermore, evaluating the performances, we can affirm that a combination of a Transfer Learning architecture with a segmentation technique (U-Net) enhances the performance of the classification model. © 2020 IEEE.","CNN; COVID-19; CT scan; DenseNet; Transfer learning; U-Net","Bioinformatics; Deep learning; Diseases; Image classification; Image segmentation; Learning algorithms; Learning systems; Network architecture; Transfer learning; Classification algorithm; Classification models; Comparative studies; Convolution neural network; Learning architectures; Segmentation algorithms; Segmentation methods; Segmentation techniques; Computerized tomography","","","","","","","Ai T., Yang Z., Hou H., Zhan C., Chen C., Lv W., Tao Q., Sun Z., Xia L., Correlation of chest ct and rt-PCR testing for coronavirus disease 2019 (covid-19) in China: A report of 1014 cases, Radiology, 2, (2020); Ahuja S., Panigrahi B.K., Dey N., Rajinikanth V., Gandhi T.K., Deep Transfer Learning-based Automated Detection of covid-19 from Lung Ct Scan Slices, (2020); Chen X., Yao L., Zhang Y., Residual Attention U-net for Automated Multi-class Segmentation of covid-19 Chest Ct Images, (2020); Shi F., Wang J., Shi J., Wu Z., Wang Q., Tang Z., He K., Shi Y., Shen D., Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19, IEEE Reviews in Biomedical Engineering, pp. 1-1, (2020); Das D., Santosh K., Pal U., Truncated inception net: Covid-19 outbreak screening using chest x-rays, Physical and Engineering Sciences in Medicine, 43, (2020); Loey M., Smarandache F., Khalifa N.E., Within the lack of chest covid-19 x-ray dataset: A novel detection model based on gan and deep transfer learning, Symmetry, 12, (2020); Miranda Pereira R., Bertolini D., Teixeira L., Silla C., Costa Y., Covid-19 identification in chest x-ray images on flat and hierarchical classification scenarios, Computer Methods and Programs in Biomedicine, 194, (2020); He X., Yang X., Zhang S., Zhao J., Zhang Y., Xing E., Xie P., Sample-efficient deep learning for covid-19 diagnosis based on ct scans, MedRxiv, (2020); Amyar A., Modzelewski R., Ruan S., Multi-task deep learning based ct imaging analysis for covid-19: Classification and segmentation, MedRxiv, (2020); Maghdid H.S., Asaad A.T., Ghafoor K., Sadiq A.S., Khan M., Diagnosing covid-19 pneumonia from x-ray and ct images using deep learning and transfer learning algorithms, (2020); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-scale Image Recognition, (2014); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Huang G., Liu Z., Van Der Maaten L., Weinberger K.Q., Densely connected convolutional networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4700-4708, (2017); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-assisted Intervention, pp. 234-241, (2015); PlamenEduardo, (2020)","","","Institute of Electrical and Electronics Engineers Inc.","","11th International Conference on Electrical and Computer Engineering, ICECE 2020","17 December 2020 through 19 December 2020","Virtual, Dhaka","168323","","978-166542254-3","","","English","Proc. Int. Conf. Electr. Comput. Eng., ICECE","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85104673230"
"Wang L.; Wang S.; Chen R.; Qu X.; Chen Y.; Huang S.; Liu C.","Wang, Liansheng (36740418500); Wang, Shuxin (57208402040); Chen, Rongzhen (57189524400); Qu, Xiaobo (22958150800); Chen, Yiping (56233739200); Huang, Shaohui (55851000700); Liu, Changhua (57092307400)","36740418500; 57208402040; 57189524400; 22958150800; 56233739200; 55851000700; 57092307400","Nested dilation networks for brain tumor segmentation based on magnetic resonance imaging","2019","Frontiers in Neuroscience","13","APR","285","","","","26","10.3389/fnins.2019.00285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068225715&doi=10.3389%2ffnins.2019.00285&partnerID=40&md5=d457c3b5142be4b8c5426545da71ad93","Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China; Department of Computer Science, School of Information Science and Engineering, Xiamen University, Xiamen, China; Department of Electronic Science, Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China; Department of Medical Imaging, Chenggong Hospital Affiliated to, Xiamen University, Xiamen, China","Wang L., Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China, Department of Computer Science, School of Information Science and Engineering, Xiamen University, Xiamen, China; Wang S., Department of Computer Science, School of Information Science and Engineering, Xiamen University, Xiamen, China; Chen R., Department of Computer Science, School of Information Science and Engineering, Xiamen University, Xiamen, China; Qu X., Department of Electronic Science, Fujian Provincial Key Laboratory of Plasma and Magnetic Resonance, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China; Chen Y., Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China, Department of Computer Science, School of Information Science and Engineering, Xiamen University, Xiamen, China; Huang S., Department of Computer Science, School of Information Science and Engineering, Xiamen University, Xiamen, China; Liu C., Department of Medical Imaging, Chenggong Hospital Affiliated to, Xiamen University, Xiamen, China","Aim: Brain tumors are among the most fatal cancers worldwide. Diagnosing and manually segmenting tumors are time-consuming clinical tasks, and success strongly depends on the doctor's experience. Automatic quantitative analysis and accurate segmentation of brain tumors are greatly needed for cancer diagnosis. Methods:This paper presents an advanced three-dimensional multimodal segmentation algorithm called nested dilation networks (NDNs). It is inspired by the U-Net architecture, a convolutional neural network (CNN) developed for biomedical image segmentation and is modified to achieve better performance for brain tumor segmentation. Thus, we propose residual blocks nested with dilations (RnD) in the encoding part to enrich the low-level features and use squeeze-and-excitation (SE) blocks in both the encoding and decoding parts to boost significant features. To prove the reliability of the network structure, we compare our results with those of the standard U-Net and its transmutation networks. Different loss functions are considered to cope with class imbalance problems to maximize the brain tumor segmentation results. A cascade training strategy is employed to run NDNs for coarse-to-fine tumor segmentation. This strategy decomposes the multiclass segmentation problem into three binary segmentation problems and trains each task sequentially. Various augmentation techniques are utilized to increase the diversity of the data to avoid overfitting. Results: This approach achieves Dice similarity scores of 0.6652, 0.5880, and 0.6682 for edema, non-enhancing tumors, and enhancing tumors, respectively, in which the Dice loss is used for single-pass training. After cascade training, the Dice similarity scores rise to 0.7043, 0.5889, and 0.7206, respectively. Conclusion: Experiments show that the proposed deep learning algorithm outperforms other U-Net transmutation networks for brain tumor segmentation. Moreover, applying cascade training to NDNs facilitates better performance than other methods. The findings of this study provide considerable insight into the automatic and accurate segmentation of brain tumors. Copyright © 2019 Wang, Wang, Chen, Qu, Chen, Huang and Liu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.","Brain tumor segmentation; Coarse-to-fine; Nested dilation networks; Residual blocks nested with dilations; Squeeze-and-excitation blocks","Article; artificial neural network; brain edema; brain tumor; deep learning; diagnostic accuracy; diagnostic value; glioma; human; image processing; image segmentation; information processing; intermethod comparison; learning algorithm; multimodal imaging; nested dilation network; neuroimaging; nuclear magnetic resonance imaging; three dimensional imaging; tumor diagnosis","","","","","Dominant Disciplines’ Talent Team Development Scheme of Higher Education of Shandong Province; Scientific Research Foundation of Binzhou Medical University, (BY2016KYQD01); Taishan Scholars Construction Engineering of Shandong Province; Yantai High-End Talent Introduction Plan; National Natural Science Foundation of China, NSFC, (31870338, 61571380, 61601392, 61671399, 81602556, 81872162); Natural Science Foundation of Shandong Province, (ZR2017JL030); National Basic Research Program of China (973 Program), (2017YFC0108703); Fundamental Research Funds for the Central Universities, (20720180056)","Funding text 1: This work was partially supported by the National Natural Science Foundation of China (Grant No. 61671399, 61601392, 61571380), National Key R&D Program of China (Grant No. 2017YFC0108703), and Fundamental Research Funds for the Central Universities (Grant No. 20720180056).; Funding text 2: This study was funded by the National Natural Science Foundation of China (Grant No. 81872162 and Grant No. 81602556 to DL, Grant No. 31870338 to QZ), the Natural Science Foundation of Shandong Province (Grant No. ZR2017JL030 to DL), Taishan Scholars Construction Engineering of Shandong Province (to DL), the Yantai High-End Talent Introduction Plan “Double Hundred” (to DL), the Scientific Research Foundation of Binzhou Medical University (Grant No. BY2016KYQD01 to DL), and the Dominant Disciplines’ Talent Team Development Scheme of Higher Education of Shandong Province (to DL).","Abadi M., Barham P., Chen J., Chen Z., Davis A., Dean J., Et al., TensorFlow: A system for large-scale machine learning, OSDI'16 Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation, 16, pp. 265-283, (2016); Bauer S., Wiest R., Nolte L.-P., Reyes M., A survey of mri-based medical image analysis for brain tumor studies, Phys. Med. Biol., 58, (2013); Bogdanska M.U., Bodnar M., Piotrowska M.J., Murek M., Schucht P., Beck J., Et al., A mathematical model describes the malignant transformation of low grade gliomas: Prognostic implications, PLoS ONE, 12, (2017); Castillo L.S., Daza L.A., Rivera L.C., Arbelaez P., Volumetric multimodality neural network for brain tumor segmentation, 13th International Conference on Medical Information Processing and Analysis, 10572, (2017); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected Crfs, (2014); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs, IEEE Trans. Pattern Anal. Mach. Intel., 40, pp. 834-848, (2018); Chen L.-C., Papandreou G., Schroff F., Adam H., Rethinking Atrous Convolution for Semantic Image Segmentation, (2017); Cho H.-H., Park H., Classification of low-grade and high-grade glioma using multi-modal image radiomics features, Engineering in Medicine and Biology Society (EMBC), 2017 39th Annual International Conference of the IEEE, pp. 3081-3084, (2017); Chollet F., Rahman F., Lee T., De Marmiesse G., Zabluda O., Pumperla M., Keras, (2015); Dong H., Yang G., Liu F., Mo Y., Guo Y., Automatic brain tumor detection and segmentation using u-net based fully convolutional networks, Annual Conference on Medical Image Understanding and Analysis, pp. 506-517, (2017); Gerlee P., Nelander S., The impact of phenotypic switching on glioblastoma growth and invasion, PLoS Comp. Biol., 8, (2012); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Hinton G.E., Srivastava N., Krizhevsky A., Sutskever I., Salakhutdinov R.R., Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors, (2012); Hu J., Shen L., Sun G., Squeeze-and-Excitation Networks, (2017); Huang G., Liu Z., Van Der Maaten L., Weinberger K.Q., Densely connected convolutional networks, Computer Vision and Pattern Recognition, 1, (2017); Ioffe S., Szegedy C., Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, (2015); Iqbal S., Ghani M.U., Saba T., Rehman A., Brain tumor segmentation in multi-spectral mri using convolutional neural networks (cnn), Microsc. Res. Tech., 81, pp. 419-427, (2018); Isensee F., Kickingereder P., Wick W., Bendszus M., Maier-Hein K.H., Brain tumor segmentation and radiomics survival prediction: Contribution to the brats 2017 challenge, International MICCAI Brainlesion Workshop, pp. 287-297, (2017); Kamnitsas K., Ferrante E., Parisot S., Ledig C., Nori A.V., Criminisi A., Et al., Deepmedic for brain tumor segmentation, International Workshop on Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries, pp. 138-149, (2016); Kamnitsas K., Ledig C., Newcombe V.F., Simpson J.P., Kane A.D., Menon D.K., Et al., Efficient Multi-Scale 3d Cnn with Fully Connected Crf for Accurate Brain Lesion Segmentation, (2016); Kayalibay B., Jensen G., Van Der Smagt P., Cnn-Based Segmentation of Medical Imaging Data, (2017); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Le H.T., Pham H.T.-T., Brain tumour segmentation using u-net based fully convolutional networks and extremely randomized trees, Vietnam J. Sci. Tech. Eng., 60, pp. 19-25, (2018); LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc. IEEE, 86, pp. 2278-2324, (1998); Li X., Chen H., Qi X., Dou Q., Fu C.-W., Heng P.A., H-Denseunet: Hybrid Densely Connected Unet for Liver and Liver Tumor Segmentation from Ct Volumes, (2017); Lin T.Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, IEEE Trans. Pattern Anal. Mach. Intel., 99, pp. 2999-3007, (2017); Lin W., Tong T., Gao Q., Guo D., Du X., Yang Y., Et al., Convolutional neural networks-based mri image analysis for the alzheimers disease prediction from mild cognitive impairment, Front. Neurosci., 12, (2018); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, (2015); Mazzara G.P., Velthuizen R.P., Pearlman J.L., Greenberg H., Wagner H.N., Brain tumor target volume determination for radiation treatment planning through automated mri segmentation, Int. J. Radiat. Oncol. Biol. Phys., 59, pp. 300-312, (2004); Ren S., He K., Girshick R., Sun J., Faster R-CNN: Towards real-time object detection with region proposal networks, Advances in Neural Information Processing Systems, pp. 91-99, (2015); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, (2014); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Et al., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Wang G., Li W., Ourselin S., Vercauteren T., Automatic brain tumor segmentation using cascaded anisotropic convolutional neural networks, International MICCAI Brainlesion Workshop, pp. 178-190, (2017); Wang P., Chen P., Yuan Y., Liu D., Huang Z., Hou X., Et al., Understanding convolution for semantic segmentation, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pp. 1451-1460, (2018); Wang X., Wang D., Yao Z., Xin B., Wang B., Lan C., Et al., Machine learning models for multiparametric glioma grading with quantitative result interpretations, Front. Neurosci., 12, (2018); Wen P.Y., Macdonald D.R., Reardon D.A., Cloughesy T.F., Sorensen A.G., Galanis E., Et al., Updated response assessment criteria for high-grade gliomas: Response assessment in neuro-oncology working group, J. Clin. Oncol., 28, pp. 1963-1972, (2010); Yang Y., Yan L.-F., Zhang X., Han Y., Nan H.-Y., Hu Y.-C., Et al., Glioma grading on conventional mr images: A deep learning study with transfer learning, Front. Neurosci., 12, (2018); Zeiler M.D., Fergus R., (2014); Yu F., Koltun V., Multi-Scale Context Aggregation by Dilated Convolutions, (2015); Zhao X., Wu Y., Song G., Li Z., Zhang Y., Fan Y., A deep learning model integrating FCNNs and CRFs for brain tumor segmentation, Med. Image Anal., 43, pp. 98-111, (2018); Zhou C., Ding C., Lu Z., Wang X., Tao D., One-pass multi-task convolutional neural networks for efficient brain tumor segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 637-645, (2018)","C. Liu; Department of Medical Imaging, Chenggong Hospital Affiliated to, Xiamen University, Xiamen, China; email: liuxingc@126.com","","Frontiers Media S.A.","","","","","","16624548","","","","English","Front. Neurosci.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85068225715"
"Liu X.; Song L.; Liu S.; Zhang Y.","Liu, Xiangbin (15077163000); Song, Liping (57221765586); Liu, Shuai (56434677500); Zhang, Yudong (35786830100)","15077163000; 57221765586; 56434677500; 35786830100","A review of deep-learning-based medical image segmentation methods","2021","Sustainability (Switzerland)","13","3","1224","1","29","28","391","10.3390/su13031224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100085131&doi=10.3390%2fsu13031224&partnerID=40&md5=14135b26ced230c5cdc28001ad7dd3eb","Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha, 410000, China; College of Information Science and Engineering, Hunan Normal University, Changsha, 410000, China; Xiangjiang Institute of Artificial Intelligence, Changsha, 410000, China; School of Informatics, University of Leicester, Leicester, LE1 7RH, United Kingdom","Liu X., Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha, 410000, China, College of Information Science and Engineering, Hunan Normal University, Changsha, 410000, China, Xiangjiang Institute of Artificial Intelligence, Changsha, 410000, China; Song L., Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha, 410000, China, College of Information Science and Engineering, Hunan Normal University, Changsha, 410000, China, Xiangjiang Institute of Artificial Intelligence, Changsha, 410000, China; Liu S., Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha, 410000, China, College of Information Science and Engineering, Hunan Normal University, Changsha, 410000, China, Xiangjiang Institute of Artificial Intelligence, Changsha, 410000, China; Zhang Y., School of Informatics, University of Leicester, Leicester, LE1 7RH, United Kingdom","As an emerging biomedical image processing technology, medical image segmentation has made great contributions to sustainable medical care. Now it has become an important research direction in the field of computer vision. With the rapid development of deep learning, medical image processing based on deep convolutional neural networks has become a research hotspot. This paper focuses on the research of medical image segmentation based on deep learning. First, the basic ideas and characteristics of medical image segmentation based on deep learning are introduced. By explaining its research status and summarizing the three main methods of medical image segmentation and their own limitations, the future development direction is expanded. Based on the discussion of different pathological tissues and organs, the specificity between them and their classic segmentation algorithms are summarized. Despite the great achievements of medical image segmentation in recent years, medical image segmentation based on deep learning has still encountered difficulties in research. For example, the segmentation accuracy is not high, the number of medical images in the data set is small and the resolution is low. The inaccurate segmentation results are unable to meet the actual clinical requirements. Aiming at the above problems, a comprehensive review of current medical image segmentation methods based on deep learning is provided to help researchers solve existing problems. © 2021 by the authors.","Convolutional neural network; Deep learning; Image segmentation; Medical image","accuracy assessment; algorithm; artificial neural network; computer vision; image processing; image resolution; numerical method; segmentation","","","","","Scientific Research Fund of Hunan Provincial Education, (14C0710); Natural Science Foundation of Hunan Province, (2020JJ4434); Education Department of Henan Province, (19A312); Science and Technology Program of Hunan Province, (2018RS3065, 2018TP1018)","This research was funded by the Natural Science Foundation of Hunan Province with No.2020JJ4434, Key Scientific Research Projects of Department of Education of Hunan Province with No.19A312; Hunan Provincial Science & Technology Project Foundation (2018TP1018, 2018RS3065); Scientific Research Fund of Hunan Provincial Education(14C0710).","Lateef F., Ruichek Y., Survey on semantic segmentation using deep learning techniques, Neurocomputing, 338, pp. 321-348, (2019); Shen D., Wu G., Suk H.I., Deep learning in medical image analysis, Annu. Rev. Biomed. Eng, 19, pp. 221-248, (2017); Goodfellow I., Bengio Y., Courville A., Bengio Y., Deep Learning, (2016); Almeida G., Tavares J.M.R.S., Deep learning in radiation oncology treatment planning for prostate cancer: A systematic review, J. Med. Syst, 44, pp. 1-15, (2020); Hesamian M.H., Jia W., He X., Kennedy P., Deep learning techniques for medical image segmentation: Achievements and challenges, J. Digit. Imaging, 32, pp. 582-596, (2019); Altaf F., Islam S.M.S., Akhtar N., Nanjua N.K., Going deep in medical image analysis: Concepts, methods, challenges, and future directions, IEEE Access, 7, pp. 99540-99572, (2019); Hu P., Cao Y., Wang W., Wei B., Computer Assisted Three-Dimensional Reconstruction for Laparoscopic Resection in Adult Teratoma, J. Med. Imaging Health Inform, 9, pp. 956-961, (2019); Ess A., Muller T., Grabner H., Van Gool L., Segmentation-Based Urban Traffic Scene Understanding, BMVC, 1, (2009); Geiger A., Lenz P., Urtasun R., Are we ready for autonomous driving? The kitti vision benchmark suite, Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 3354-3361, (2012); Ma Z., Tavares J.M.R.S., Jorge R.M.N., A review on the current segmentation algorithms for medical images, Proceedings of the 1st International Conference on Imaging Theory and Applications, (2009); Ferreira A., Gentil F., Tavares J.M.R.S., Segmentation algorithms for ear image data towards biomechanical studies, Comput. Methods Biomech. Biomed. Eng, 17, pp. 888-904, (2014); Ma Z., Tavares J.M.R.S., Jorge R.N., Mascarenhas T., A review of algorithms for medical image segmentation and their applications to the female pelvic cavity, Comput. Methods Biomech. Biomed. Eng, 13, pp. 235-246, (2010); Xu A., Wang L., Feng S., Qu Y., Threshold-based level set method of image segmentation, Proceedings of the Third International Conference on Intelligent Networks and Intelligent Systems, pp. 703-706, (2010); Cigla C., Alatan A.A., Region-based image segmentation via graph cuts, Proceedings of the 2008 15th IEEE International Conference on Image Processing, pp. 2272-2275, (2008); Yu-Qian Z., Wei-Hua G., Zhen-Cheng C., Tang J.-T., Li L.-Y., Medical images edge detection based on mathematical morphology, Proceedings of the 2005 IEEE Engineering in Medicine and Biology 27th Annual Conference, pp. 6492-6495, (2006); He K., Gkioxari G., Dollar P., Girschik R., Mask r-cnn, Proceedings of the IEEE International Conference on Computer Vision, pp. 2961-2969, (2017); Lin G., Milan A., Shen C., Reid I., Refinenet: Multi-path refinement networks for high-resolution semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1925-1934, (2017); Noh H., Hong S., Han B., Learning deconvolution network for semantic segmentation, Proceedings of the IEEE International Conference on Computer Vision, pp. 1520-1528, (2015); Zhu X.J., Semi-Supervised Learning Literature Survey, (2005); Zeiler M.D., Fergus R., Visualizing and understanding convolutional networks, Proceedings of the European Conference on Computer Vision, pp. 818-833, (2014); Gu J., Wang Z., Kuen J., Ma L., Shshroudy A., Shuai B., Liu I., Wang X., Wang G., Cai J., Et al., Recent advances in convolutional neural networks, Pattern Recognit, 77, pp. 354-377, (2018); Hubel D.H., Wiesel T.N., Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex, J. Physiol, 160, (1962); Fukushima K., Miyake S., Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition, Competition and Cooperation in Neural Nets, pp. 267-285, (1982); Lecun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, IEEE, 86, pp. 2278-2324, (1998); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Adv. Neural Inf. Process. Syst, 60, pp. 1097-1105, (2012); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, (2014); Qiu Z., Yao T., Mei T., Learning spatio-temporal representation with pseudo-3d residual networks, Proceedings of the IEEE International Conference on Computer Vision, pp. 5533-5541, (2017); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Rundo L., Han C., Nagano Y., Zhang J., Hataya R., Militello C., Tangherloni A., Nobile M.S., Ferreti C., Besozzi D., Et al., USE-Net, Incorporating Squeeze-and-Excitation blocks into U-Net for prostate zonal segmentation of multi-institutional MRI datasets, Neurocomputing, 365, pp. 31-43, (2019); Badrinarayanan V., Kendall A., Cipolla R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell, 39, pp. 2481-2495, (2017); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, (2015); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Zhao H., Shi J., Qi X., Wang X., Jia J., Pyramid scene parsing network, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2881-2890, (2017); Ren S., He K., Girshick R., Sun J., Faster r-cnn: Towards real-time object detection with region proposal networks, Adv. Neural Inf. Process. Syst, 39, pp. 91-99, (2015); Chen L.C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Semantic image segmentation with deep convolutional nets and fully connected crfs, (2014); Krahenbuhl P., Koltun V., Efficient inference in fully connected crfs with gaussian edge potentials, Adv. Neural Inf. Process. Syst, 24, pp. 109-117, (2011); Chen L.C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs, IEEE Trans. Pattern Anal. Mach. Intell, 40, pp. 834-848, (2017); Chen L.C., Papandreou G., Schroff F., Adam H., Rethinking atrous convolution for semantic image segmentation, (2017); Chen L.C., Zhu Y., Papandreou G., Schroff F., Adam H., Encoder-decoder with atrous separable convolution for semantic image segmentation, Proceedings of the European Conference on Computer Vision (ECCV), pp. 801-818, (2018); Zhou X., Takayama R., Wang S., Hara T., Fujita H., Deep learning of the sectional appearances of 3D CT images for anatomical structure segmentation based on an FCN voting method, Med. Phys, 44, pp. 5221-5233, (2017); Christ P.F., Elshaer M.E.A., Ettlinger F., Tatavarty S., Bickel M., Bilic P., Rempfler M., Armbruster M., Hoffman F., D'Anastasi M., Et al., Automatic liver and lesion segmentation in CT using cascaded fully convolutional neural networks and 3D conditional random fields, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 415-423, (2016); Zhou X.Y., Shen M., Riga C., Yang G.-Z., Lee S.-L., Focal fcn: Towards small object segmentation with limited training data, (2017); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-Net: Learning dense volumetric segmentation from sparse annotation, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 424-432, (2016); Milletari F., Navab N., Ahmadi S.-A., V-net: Fully convolutional neural networks for volumetric medical image segmentation, Proceedings of the 2016 Fourth International Conference on 3D Vision (3DV), pp. 565-571, (2016); Xiao X., Lian S., Luo Z., Li S., Weighted Res-UNet for high-quality retina vessel segmentation, Proceedings of the 9th International Conference on Information Technology in Medicine and Education (ITME), pp. 327-331, (2018); Li X., Chen H., Qi X., Dou Q., Fu C.-W., Heng P.A., H-DenseUNet: Hybrid densely connected UNet for liver and tumor segmentation from CT volumes, IEEE Trans. Med. Imaging, 37, pp. 2663-2674, (2018); Ibtehaz N., Rahman M.S., MultiResUNet: Rethinking the U-Net architecture for multimodal biomedical image segmentation, Neural Netw, 121, pp. 74-87, (2020); Oktay O., Schlemper J., Folgoc L.L., Lee M., Heinrich M., Misawa K., Mori K., Mcdonagh S., Hammerla N.Y., Kainz B., Et al., Attention u-net: Learning where to look for the pancreas, (2018); Wang Z., Zou N., Shen D., Ji S., Non-Local U-Nets for Biomedical Image Segmentation, Proceedings of the AAAI, pp. 6315-6322, (2020); Goodfellow I., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., Courville A., Bengio Y., Generative adversarial nets, Adv. Neural Inf. Process. Syst, 27, pp. 2672-2680, (2014); Luc P., Couprie C., Chintala S., Verbeek J., Semantic segmentation using adversarial networks, (2016); Xue Y., Xu T., Zhang H., Long L.R., Huang X., Seg AN, Adversarial Network with Multi-scale L1 Loss for Medical Image Segmentation, Neuroinformatics, 16, pp. 383-392, (2018); Dai W., Dong N., Wang Z., Liang X., Zhang H., Xing E.P., Scan: Structure correcting adversarial network for organ segmentation in chest x-rays, Mining Data for Financial Applications, pp. 263-273, (2018); Khosravan N., Mortazi A., Wallace M., Bagci U., Pan: Projective adversarial network for medical image segmentation, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 68-76, (2019); Chang Q., Qu H., Zhang Y., Sabuncu M., Chen C., Zhang T., Metaxas D.N., Synthetic Learning: Learn from Distributed Asynchronized Discriminator GAN Without Sharing Medical Image Data, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, Virtual, pp. 13856-13866, (2020); Zhao M., Wang L., Chen J., Nie D., Cong Y., Ahmad S., Ho A., Yuan P., Fung S.H., Deng H.H., Et al., Craniomaxillofacial bony structures segmentation from MRI with deep-supervision adversarial learning, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 720-727, (2018); Mondal A.K., Dolz J., Desrosiers C., Few-shot 3d multi-modal medical image segmentation using generative adversarial learning, (2018); Zhang Y., Yang L., Chen J., Fredericksen M., Hughes D.P., Chen D.Z., Deep adversarial networks for biomedical image segmentation utilizing unannotated images, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 408-416, (2017); Yang D., Xu D., Zhou S.K., Georgescu B., Chen M., Grbic S., Metaxas D., Comaniciu D., Automatic liver segmentation using an adversarial image-to-image network, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 507-515, (2017); Mirza M., Osindero S., Conditional generative adversarial nets, (2014); Zhu J.Y., Park T., Isola P., Efros A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks, Proceedings of the IEEE International Conference on Computer Vision, pp. 2223-2232, (2017); Bayramoglu N., Kaakinen M., Eklund L., Heikkila J., Towards virtual h&e staining of hyperspectral lung histology images using conditional generative adversarial networks, Proceedings of the IEEE International Conference on Computer Vision, pp. 64-71, (2017); Dar S.U.H., Yurt M., Karacan L., Erdem A., Erdem E., Cukur T., Image synthesis in multi-contrast MRI with conditional generative adversarial networks, IEEE Trans. Med. Imaging, 38, pp. 2375-2388, (2019); Wolterink J.M., Dinkla A.M., Savenije M.H.F., Seevinck P.R., van den Berg C.A., Isgum I., Deep MR to CT synthesis using unpaired data, Proceedings of the International Workshop on Simulation and Synthesis in Medical Imaging, pp. 14-23, (2017); Tuan T.A., Pham T.B., Kim J.Y., Tavares J.M.R., Alzheimer’s diagnosis using deep learning in segmenting and classifying 3D brain MR images, Int. J. Neurosci, pp. 1-10, (2020); Myronenko A., 3D MRI brain tumor segmentation using autoencoder regularization, Proceedings of the International MICCAI Brainlesion Workshop, pp. 311-320, (2018); Nie D., Wang L., Adeli E., Lao C., Lin W., Shen D., 3-D fully convolutional networks for multimodal isointense infant brain image segmentation, IEEE Trans. Cybern, 49, pp. 1123-1136, (2019); Wang S., Yi L., Chen Q., Meng Z., Dong H., He Z., Edge-aware Fully Convolutional Network with CRF-RNN Layer for Hippocampus Segmentation, Proceedings of the 2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC), pp. 803-806, (2019); Borne L., Riviere D., Mangin J.F., Combining 3D U-Net and bottom-up geometric constraints for automatic cortical sulci recognition, Proceedings of the International Conference onMedical Imaging with Deep Learning, (2019); Casamitjana A., Cata M., Sanchez I., Combalia M., Vilaplana V., Cascaded V-Net using ROI masks for brain tumor segmentation, Proceedings of the International MICCAI Brainlesion Workshop, pp. 381-391, (2017); Moeskops P., Veta M., Lafarge M.W., Eppenhof K.A.J., Pluim J.P.W., Adversarial training and dilated convolutions for brain MRI segmentation, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 56-64, (2017); Rezaei M., Harmuth K., Gierke W., Kellermeier T., Fischer M., Yang H., Meinel C., A conditional adversarial network for semantic segmentation of brain tumor, Proceedings of the International MICCAI Brainlesion Workshop, pp. 241-252, (2017); Giacomello E., LoIacono D., Mainardi L., Brain MRI Tumor Segmentation with Adversarial Networks, (2019); Leopold H.A., Orchard J., Zelek J.S., Lakshminarayanan V., Pixelbnn: Augmenting the pixelcnn with batch normalization and the presentation of a fast architecture for retinal vessel segmentation, J. Imaging, 5, (2019); Zhang Y., Chung A.C.S., Deep supervision with additional labels for retinal vessel segmentation task, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 83-91, (2018); Son J., Park S.J., Jung K.H., Retinal vessel segmentation in fundoscopic images with generative adversarial networks, (2017); Edupuganti V.G., Chawla A., Amit K., Automatic optic disk and cup segmentation of fundus images using deep learning, Proceedings of the 25th IEEE International Conference on Image Processing (ICIP), pp. 2227-2231, (2018); Shankaranarayana S.M., Ram K., Mitra K., Sivaprakasam M., Joint optic disc and cup segmentation using fully convolutional and adversarial networks, Fetal, Infant and Ophthalmic Medical Image Analysis, pp. 168-176, (2017); Bhandary A., Prabhu G.A., Rajinikanth V., Thanaraj K.P., Satapathy S.C., Robbins D.E., Shasky C., Zhang Y.-D., Tavares J.M.R., Raja N.S.M., Deep-learning framework to detect lung abnormality-A study with chest X-Ray and lung CT scan images, Pattern Recognit. Lett, 129, pp. 271-278, (2020); Novikov A.A., Lenis D., Major D., Hlad° uvka J., Wimmer M., Buhler K., Fully convolutional architectures for multiclass segmentation in chest radiographs, IEEE Trans. Med. Imaging, 37, pp. 1865-1876, (2018); Anthimopoulos M.M., Christodoulidis S., Ebner L., Geiser T., Christe A., Mougiakakou S., Semantic Segmentation of Pathological Lung Tissue with Dilated Fully Convolutional Networks, IEEE J. Biomed. Health Inform, 23, pp. 714-722, (2019); Jue J., Jason H., Neelam T., Andreas R., Sean B.L., Joseph D.O., Harini V., Integrating cross-modality hallucinated MRI with CT to aid mediastinal lung tumor segmentation, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 221-229, (2019); Christ P.F., Ettlinger F., Grun F., Elshaera M.E.A., Lipkova J., Schlecht S., Ahmaddy F., Tatavarty S., Bickel M., Bilic P., Et al., Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks, (2017); Han X., Automatic liver lesion segmentation using a deep convolutional neural network method, (2017); Huo Y., Xu Z., Bao S., Bermudez C., Plassard A.J., Yao Y., Liu J., Assad A., Abramson R.G., Landman B.A., Splenomegaly segmentation using global convolutional kernels and conditional generative adversarial networks, Med. Imaging, 10574, (2018); Tran P.V., A fully convolutional neural network for cardiac segmentation in short-axis MRI, (2016); Xu Z., Wu Z., Feng J., CFUN: Combining faster R-CNN and U-net network for efficient whole heart segmentation, (2018); Dong S., Luo G., Wang K., Cao S., Mercado A., Shmuilovich O., Zhang H., Li S., VoxelAtlasGAN: 3D left ventricle segmentation on echocardiography with atlas guided generation and voxel-to-voxel discrimination, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 622-629, (2018); Zhang J., Du J., Liu H., Hou X., Zhao Y., Ding M., LU-NET: An Improved U-Net for Ventricular Segmentation, IEEE Access, 7, pp. 92539-92546, (2019); Ye C., Wang W., Zhang S., Wang K., Multi-depth fusion network for whole-heart CT image segmentation, IEEE Access, 7, pp. 23421-23429, (2019); Xia Q., Yao Y., Hu Z., Hao A., Automatic 3D atrial segmentation from GE-MRIs using volumetric fully convolutional networks, Proceedings of the International Workshop on Statistical Atlases and Computational Models of the Heart, pp. 211-220, (2018); Chen C., Qin C., Qiu H., Tarroni G., Duan J., Bai W., Rueckert D., Deep Learning for Cardiac Image Segmentation: A Review, Front. Cardiovasc. Med, 7, (2020); Arshad H., Khan M.A., Sharif M.I., Yasmin M., Tavares J.M.R., Zhang Y.D., Satapathy S.C., A multilevel paradigm for deep convolutional neural network features selection with an application to human gait recognition, Expert Syst, (2020); Wang Y., Chen Y., Yang N., Zheng L., Dey N., Ashour A.S., Rajinikanth V., Tavares J.M.R.S., Shi F., Classification of mice hepatic granuloma microscopic images based on a deep convolutional neural network, Appl. Soft Comput, 74, pp. 40-50, (2019); Liu F., Zhou Z., Jang H., Samsonov A., Zhao G., Kijowski R., Deep convolutional neural network and 3D deformable approach for tissue segmentation in musculoskeletal magnetic resonance imaging, Magn. Reson. Med, 79, pp. 2379-2391, (2018); Tran T., Kwon O.H., Kwon K.R., Lee S.H., Kang K.W., Blood cell images segmentation using deep learning semantic segmentation, Proceedings of the IEEE International Conference on Electronics and Communication Engineering, pp. 13-16, (2018); Sekuboyina A., Rempfler M., Kukacka J., Tetteh G., Valentinitsch A., Kirschke J., Menze B.H., Btrfly net: Vertebrae labelling with energy-based adversarial learning of local spine prior, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 649-657, (2018); Han Z., Wei B., Mercado A., Leung S., Li S., Spine -GAN, Semantic segmentation of multiple spinal structures, Med. Image Anal, 50, pp. 23-35, (2018); Kohl S., Bonekamp D., Schlemmer H.P., Yaqubi K., Hohenfellner M., Hadaschik B., Radtke J.P., Maier-Hein K., Adversarial networks for the detection of aggressive prostate cancer, (2017); Taha A., Lo P., Li J., Zhao T., Kid-net: Convolution networks for kidney vessels segmentation from ct-volumes, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 463-471, (2018); Izadi S., Mirikharaji Z., Kawahara J., Hamarneh G., Generative adversarial networks to segment skin lesions, Proceedings of the IEEE 15th International Symposium on Biomedical Imaging, pp. 881-884, (2018); Mirikharaji Z., Hamarneh G., Star shape prior in fully convolutional networks for skin lesion segmentation, Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 737-745, (2018); Wang D., Gu C., Wu K., Guan X., Adversarial neural networks for basal membrane segmentation of microinvasive cervix carcinoma in histopathology images, Proceedings of the 2017 International Conference on Machine Learning and Cybernetics, (2017); Simpson A.L., Antonelli M., Bakas S., Bilello M., Farahani K., Van Ginneken B., Kopp-Schneider A., Landman B.A., Litjens G., Menze B., Et al., A large annotated medical image dataset for the development and evaluation of segmentation algorithms, (2019); Van Ginneken B., Stegmann M.B., Loog M., Segmentation of anatomical structures in chest radiographs using supervised methods: A comparative study on a public database, Med. Image Anal, 10, pp. 19-40, (2006); Menze B.H., Jakab A., Bauer S., Kalpathy-Cramer J., Farahani K., Kirby J., Burren Y., Porz N., Slotboom J., Wiest R., Et al., The multimodal brain tumor image segmentation benchmark (BRATS), IEEE Trans. Med. Imaging, 34, pp. 1993-2024, (2014); Heath M., Bowyer K., Kopans D., Kegelmeyer P., Moore R., Chang K., Munishkumaran S., The digital database for screening mammography, Proceedings of the 5th International Workshop on Digital Mammography, pp. 212-218, (2000); Bilic P., Christ P.F., Vorontsov E., Chlebus G., Chen H., Dou Q., Fu C.-W., Han X., Heng P.-A., Hesser J., Et al., The liver tumor segmentation benchmark (lits), (2019); Armato S.G., McLennan G., Bidaut L., McNitt-Gray M.F., Meyer C.R., Reeves A.P., Zhao B., Aberle D.A., Henschke C.I., Hoffman E.A., Et al., The lung image database consortium (LIDC) and image database resource initiative (IDRI): A completed reference database of lung nodules on CT scans, Med. Phys, 38, pp. 915-931, (2011); Marcus D.S., Fotenos A.F., Csernansky J.G., Morris J.C., Buckner R.L., Open access series of imaging studies: Longitudinal MRI data in nondemented and demented older adults, J. Cogn. Neurosci, 22, pp. 2677-2684, (2010); Staal J., Abramoff M.D., Niemeijer M., Viergever M.A., Van Ginneken B., Ridge-based vessel segmentation in color images of the retina, IEEE Trans. Med. Imaging, 23, pp. 501-509, (2004); Suckling J.P., The mammographic image analysis society digital mammogram database, Digit. Mammo, 17, pp. 375-386, (1994); Fonseca C.G., Backhaus M., Bluemke D.A., Britten R.D., Chung J.D., Cowan B.R., Dinov I.D., Finn J.P., Hunter P.J., Kadish A.H., Et al., The Cardiac Atlas Project-An imaging database for computational modeling and statistical atlases of the heart, Bioinformatics, 27, pp. 2288-2295, (2011)","S. Liu; Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha, 410000, China; email: liushuai@hunnu.edu.cn","","MDPI","","","","","","20711050","","","","English","Sustainability","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85100085131"
"Seo H.; Badiei Khuzani M.; Vasudevan V.; Huang C.; Ren H.; Xiao R.; Jia X.; Xing L.","Seo, Hyunseok (56125023000); Badiei Khuzani, Masoud (55390716200); Vasudevan, Varun (57209329840); Huang, Charles (55890598500); Ren, Hongyi (57215971063); Xiao, Ruoxiu (57212428138); Jia, Xiao (57192916619); Xing, Lei (7103349003)","56125023000; 55390716200; 57209329840; 55890598500; 57215971063; 57212428138; 57192916619; 7103349003","Machine learning techniques for biomedical image segmentation: An overview of technical aspects and introduction to state-of-art applications","2020","Medical Physics","47","5","","e148","e167","19","176","10.1002/mp.13649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084860873&doi=10.1002%2fmp.13649&partnerID=40&md5=349f96d644e266fdafe4e9e0a0995596","Medical Physics Division in the Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, 94305-5847, CA, United States; Institute for Computational and Mathematical Engineering, School of Engineering, Stanford University, Stanford, 94305-4042, CA, United States; Department of Bioengineering, School of Engineering and Medicine, Stanford University, Stanford, 94305-4245, CA, United States","Seo H., Medical Physics Division in the Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, 94305-5847, CA, United States; Badiei Khuzani M., Medical Physics Division in the Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, 94305-5847, CA, United States; Vasudevan V., Institute for Computational and Mathematical Engineering, School of Engineering, Stanford University, Stanford, 94305-4042, CA, United States; Huang C., Department of Bioengineering, School of Engineering and Medicine, Stanford University, Stanford, 94305-4245, CA, United States; Ren H., Medical Physics Division in the Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, 94305-5847, CA, United States; Xiao R., Medical Physics Division in the Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, 94305-5847, CA, United States; Jia X., Medical Physics Division in the Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, 94305-5847, CA, United States; Xing L., Medical Physics Division in the Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, 94305-5847, CA, United States","In recent years, significant progress has been made in developing more accurate and efficient machine learning algorithms for segmentation of medical and natural images. In this review article, we highlight the imperative role of machine learning algorithms in enabling efficient and accurate segmentation in the field of medical imaging. We specifically focus on several key studies pertaining to the application of machine learning methods to biomedical image segmentation. We review classical machine learning algorithms such as Markov random fields, k-means clustering, random forest, etc. Although such classical learning models are often less accurate compared to the deep-learning techniques, they are often more sample efficient and have a less complex structure. We also review different deep-learning architectures, such as the artificial neural networks (ANNs), the convolutional neural networks (CNNs), and the recurrent neural networks (RNNs), and present the segmentation results attained by those learning models that were published in the past 3 yr. We highlight the successes and limitations of each machine learning paradigm. In addition, we discuss several challenges related to the training of different machine learning models, and we present some heuristics to address those challenges. © 2019 American Association of Physicists in Medicine","deep learning; machine learning; medical Image; overview; segmentation","Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Decision trees; Image segmentation; K-means clustering; Learning algorithms; Markov processes; Medical imaging; Biomedical image segmentation; Deep learning; Learning models; Machine learning algorithms; Machine learning techniques; Machine-learning; Medical image; Overview; Segmentation; Technical aspects; conference paper; controlled study; convolutional neural network; deep learning; diagnostic imaging; heuristics; image segmentation; k means clustering; Markov random field; random forest; recurrent neural network; diagnostic imaging; human; image processing; machine learning; procedures; Recurrent neural networks","","","","","National Institutes of Health, NIH; National Cancer Institute, NCI, (R01CA176553); National Cancer Institute, NCI; Google; Varian Medical Systems","This work was partially supported by NIH/NCI (1R01 CA176553), Varian Medical Systems, a gift fund from Huiyihuiying Medical Co, and a Faculty Research Award from Google Inc. ","Mao K.Z., Zhao P., Tan P.-H., Supervised learning-based cell image segmentation for p53 immunohistochemistry, IEEE Trans Biomed Eng, 53, pp. 1153-1163, (2006); Wachinger C., Golland P., Atlas-based under-segmentation, (2014); Li D., Liu L., Chen J., Et al., Augmenting atlas-based liver segmentation for radiotherapy treatment planning by incorporating image features proximal to the atlas contours, Phys Med Biol, 62, (2016); Noh H., Hong S., Han B., Learning deconvolution network for semantic segmentation, (2015); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, (2016); Litjens G., Kooi T., Bejnordi B.E., Et al., A survey on deep learning in medical image analysis, Med Image Anal, 42, pp. 60-88, (2017); Men K., Zhang T., Chen X., Et al., Fully automatic and robust segmentation of the clinical target volume for radiotherapy of breast cancer using big data and deep learning, Physica Med, 50, pp. 13-19, (2018); Xu Y., Wang Y., Yuan J., Cheng Q., Wang X., Carson P.L., Medical breast ultrasound image segmentation by machine learning, Ultrasonics, 91, pp. 1-9, (2019); Raudaschl P.F., Zaffino P., Sharp G.C., Et al., Evaluation of segmentation methods on head and neck CT: auto-segmentation challenge 2015, Med Phys, 44, pp. 2020-2036, (2017); Wang J., Lu J., Qin G., Et al., Technical Note: A deep learning-based autosegmentation of rectal tumors in MR images, Med Phys, 45, pp. 2560-2564, (2018); Dolz J.X., Dolz J., Xu X., Et al., Multiregion segmentation of bladder cancer structures in MRI with progressive dilated convolutional networks, Med Phys, 45, pp. 5482-5493, (2018); Chen H., Lu W., Chen M., Et al., A recursive ensemble organ segmentation (REOS) framework: application in brain radiotherapy, Phys Med Biol, 64, (2019); Bernhard S.A., Smola J., Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond, (2001); Chen J., Stern M., Wainwright M.J., Jordan M.I., Kernel feature selection via conditional covariance minimization, (2017); Robnik-Sikonja M., Kononenko I., Theoretical and empirical analysis of ReliefF and RReliefF, Mach Learn, 53, pp. 23-69, (2003); Gu Q., Li Z., Han J., Generalized fisher score for feature selection, (2012); Han K., Wang Y., Zhang C., Li C., Xu C., AutoEncoder inspired unsupervised feature selection, (2017); Rahimi A., Recht B., Random features for large-scale kernel machines, (2007); Rahimi A., Recht B., Weightssed sums of random kitchen sinks: replacing minimization with randomization in learning, (2008); Bochner S., Harmonic Analysis and the Theory of Probability, (2005); Geoffrey M.L.H., Visualizing data using t-SNE, J Mach Learn Res, 9, pp. 2579-2605, (2008); Ho T.K.A., Data complexity analysis of comparative advantages of decision forest constructors, Pattern Anal Appl, 5, pp. 102-112, (2002); Neter J., Wasserman W., Kutner M.H., Applied Linear Regression Models, (1989); Geman S., Geman D., Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images, Readings in Computer Vision, pp. 568-584, (1987); Held K., Kops E.R., Krause B.J., Wells W.M., Kikinis R., Muller-Gartner H., Markov random field segmentation of brain MR images, IEEE Trans Med Imaging, 16, pp. 878-886, (1997); Ibragimov B., Xing L., Segmentation of organs-at-risks in head and neck CT images using convolutional neural networks, Med Phys, 44, pp. 547-557, (2017); Li S., Fevens T., Krzyzak A., A SVM-based framework for autonomous volumetric medical image segmentation using hierarchical and coupled level sets, (2004); Song W., Weiyu Z., Zhi-Pei L., Shape deformation: SVM regression and application to medical image segmentation, (2001); Chittajallu D.R., Shah S.K., Kakadiaris I.A., A shape-driven MRF model for the segmentation of organs in medical images, (2010); Ait-Aoudia S., Belhadj F., Meraihi-Naimi A., Segmentation of Volumetric Medical Data Using Hidden Markov Random Field Model, (2009); Michal K.O.S., Semi-automatic C.T., Semi-automatic CT image segmentation using random forests learned from partial annotations, (2018); Duda R.O., Hart P.E., Pattern Classification and Scene Analysis, 3, (1973); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, (2015); Bruna J., Mallat S., Invariant scattering convolution networks; Rohlfing T., Brandt R., Menzel R., Russakoff D.B., Maurer C.R., Quo vadis, atlas-based segmentation?, Handbook of biomedical image analysis, pp. 435-486, (2005); Kalinic H., Atlas-Based Image Segmentation. A Survey, (2009); Tsechpenakis G., Deformable model-based medical image segmentation, Multi Modality State-of-the-Art Medical Image Segmentation and Registration Methodologies, pp. 33-67, (2011); Achanta R., Shaji A., Smith K., Lucchi A., Fua P., Susstrunk S., SLIC superpixels compared to state-of-the-art superpixel methods, IEEE Trans Pattern Anal Mach Intell, 34, pp. 2274-2282, (2012); Liu M., Tuzel O., Ramalingam S., Chellappa R., Entropy rate superpixel segmentation, (2011); Zhang Y., Li X., Gao X., Zhang C., A simple algorithm of superpixel segmentation with boundary constraint, IEEE Trans Circuits Syst Video Technol, 27, pp. 1502-1514, (2017); Tian Z., Liu L., Zhang Z., Fei B., Superpixel-based segmentation for 3D prostate MR images, IEEE Trans Med Imaging, 35, pp. 791-801, (2016); Ji S., Wei B., Yu Z., Yang G., Yin Y., A new multistage medical segmentation method based on superpixel and fuzzy clustering, Comput Math Methods Med, 2014, (2014); Irving B., maskSLIC: regional superpixel generation with application to local pathology characterisation in medical images, (2016); Xu C., Pham D.L., Prince J.L., Image segmentation using deformable models, Handbook of Medical Imaging, 2, pp. 129-174, (2000); Cabezas M., Oliver A., Llado X., Freixenet J., Cuadra M.B., A review of atlas-based segmentation for magnetic resonance brain images, Comput Methods Programs Biomed, 104, pp. e158-e177, (2011); Nikolov S., Blackwell S., Mendes R., Et al., Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy, (2018); Qin W., Wu J., Han F., Et al., Superpixel-based and boundary-sensitive convolutional neural network for automated liver segmentation, Phys Med Biol, 63, (2018); Albayrak A., Bilgin G., A hybrid method of superpixel segmentation algorithm and deep learning method in histopathological image segmentation, (2018); McCulloch W.S., Pitts W., A logical calculus of the ideas immanent in nervous activity, Bull Math Biophys, 5, pp. 115-133, (1943); Rosenblatt F., The perceptron: a probabilistic model for information storage and organization in the brain, Psychol Rev, 65, (1958); LeCun Y., Boser B., Denker J.S., Et al., Backpropagation applied to handwritten zip code recognition, Neural Comput, 1, pp. 541-551, (1989); Kingma D.P., Adam B.J., A method for stochastic optimization, (2014); Janocha K., Czarnecki W.M., On loss functions for deep neural networks in classification, (2017); Ghosh A., Kumar H., Sastry P., Robust loss functions under label noise for deep neural networks, (2017); Rumelhart D.E., McClelland J.L., Group P.R., Parallel Distributed Processing, 1, (1988); Bengio Y., Courville A., Vincent P., Representation learning: A review and new perspectives, IEEE Trans Pattern Anal Mach Intell, 35, pp. 1798-1828, (2013); Schmidhuber J., Deep learning in neural networks: An overview, Neural networks, 61, pp. 85-117, (2015); Blanz W., Gish S.L., A connectionist classifier architecture applied to image segmentation, (1990); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, (2015); LeCun Y., Haffner P., Bottou L., Bengio Y., Object recognition with gradient-based learning, Shape, Contour and Grouping in Computer Vision, pp. 319-345, (1999); Nair V., Hinton G.E., Rectified linear units improve restricted boltzmann machines, (2010); Maas A.L., Hannun A.Y., Ng A.Y., Rectifier nonlinearities improve neural network acoustic models; He K., Zhang X., Ren S., Sun J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification, (2015); Lguensat R., Sun M., Fablet R., Tandeo P., Mason E., Chen G., EddyNet: a deep neural network for pixel-wise classification of oceanic eddies, (2018); Kotsiantis S.B., Zaharakis I., Pintelas P., Supervised machine learning: A review of classification techniques, Emerg Artificial Intel Appl Comp Eng, 160, pp. 3-24, (2007); Wang J., Lu J., Qin G., Et al., A deep learning-based autosegmentation of rectal tumors in MR images, Med Phys, 45, pp. 2560-2564, (2018); Ker J., Wang L., Rao J., Lim T., Deep learning applications in medical image analysis, IEEE Access, 6, pp. 9375-9389, (2018); Russakovsky O., Deng J., Su H., Et al., Imagenet large scale visual recognition challenge, Int J Comput Vision, 115, pp. 211-252, (2015); Yuan Y., Qin W., Buyyounouski M., Et al., Prostate cancer classification with multi-parametric mri transfer learning Model, Med Phys, 46, pp. 756-765, (2018); Ibragimov B., Toesca D., Chang D., Yuan Y., Koong A., Xing L., Development of deep neural network for individualized hepatobiliary toxicity prediction after liver SBRT, Med Phys, 45, pp. 4763-4774, (2018); Tajbakhsh N., Shin J.Y., Gurudu S.R., Et al., Convolutional neural networks for medical image analysis: full training or fine tuning?, IEEE Trans Med Imaging, 35, pp. 1299-1312, (2016); Ravishankar H., Sudhakar P., Venkataramani R., Et al., Understanding the mechanisms of deep transfer learning for medical images, Deep Learning and Data Labeling for Medical Applications, pp. 188-196, (2016); Ghafoorian M., Mehrtash A., Kapur T., Et al., Transfer learning for domain adaptation in MRI: application in brain lesion segmentation, (2017); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput, 9, pp. 1735-1780, (1997); Cho K., Van Merrienboer B., Gulcehre C., Et al., Learning phrase representations using RNN encoder-decoder for statistical machine translation, (2014); Akkus Z., Galimzianova A., Hoogi A., Rubin D.L., Erickson B.J., Deep learning for brain MRI segmentation: state of the art and future directions, J Digit Imaging, 30, pp. 449-459, (2017); Kamnitsas K., Ledig C., Newcombe V.F., Et al., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation, Med Image Anal, 36, pp. 61-78, (2017); Pereira S., Pinto A., Alves V., Silva C.A., Brain tumor segmentation using convolutional neural networks in MRI images, IEEE Trans Med Imaging, 35, pp. 1240-1251, (2016); Havaei M., Davy A., Warde-Farley D., Et al., Brain tumor segmentation with deep neural networks, Med Image Anal, 35, pp. 18-31, (2017); Zhang W., Li R., Deng H., Et al., Deep convolutional neural networks for multi-modality isointense infant brain image segmentation, NeuroImage, 108, pp. 214-224, (2015); Chaudhari A.S., Fang Z., Kogan F., Et al., Super-resolution musculoskeletal MRI using deep learning, Magn Reson Med, 80, pp. 2139-2154, (2018); Moeskops P., Viergever M.A., Mendrik A.M., de Vries L.S., Benders M.J., Isgum I., Automatic segmentation of MR brain images with a convolutional neural network, IEEE Trans Med Imaging, 35, pp. 1252-1261, (2016); Nie D., Wang L., Gao Y., Sken D., Fully convolutional networks for multi-modality isointense infant brain image segmentation, (2016); Brosch T., Tang L.Y., Yoo Y., Li D.K., Traboulsee A., Tam R., Deep 3D convolutional encoder networks with shortcuts for multiscale feature integration applied to multiple sclerosis lesion segmentation, IEEE Trans Med Imaging, 35, pp. 1229-1239, (2016); Roth H.R., Oda H., Hayashi Y., Et al., Hierarchical 3D fully convolutional networks for multi-organ segmentation, (2017); Chlebus G., Schenk A., Moltz J.H., van Ginneken B., Hahn H.K., Meine H., Automatic liver tumor segmentation in CT with fully convolutional neural networks and object-based postprocessing, Sci Rep, 8, (2018); Ronneberger O., Fischer P., U-net B.T., Convolutional networks for biomedical image segmentation, (2015); Milletari F., Navab N., Ahmadi S.-A., V-net: fully convolutional neural networks for volumetric medical image segmentation, (2016); He K., Zhang X., Ren S., Sun J., Identity mappings in deep residual networks, (2016); Zeiler M.D., Fergus R., Visualizing and understanding convolutional networks, (2014); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-Net: learning dense volumetric segmentation from sparse annotation, (2016); Wang C., MacGillivray T., Macnaught G., Yang G., Newby D., A two-stage 3D Unet framework for multi-class segmentation on full resolution image, (2018); Zhou Z., Mahfuzur Rahman Siddiquee M., Tajbakhsh N., Liang J., UNet++: A nested u-net architecture for medical image segmentation; Casamitjana A., Cata M., Sanchez I., Combalia M., Vilaplana V., Cascaded V-Net using ROI masks for brain tumor segmentation, (2018); Sadegh Mohseni Salehi S., Erdogmus D., Gholipour A., Tversky loss function for image segmentation using 3D fully convolutional deep networks, (2017); Dou Q., Chen H., Yu L., Et al., Automatic detection of cerebral microbleeds From MR Images via 3D convolutional neural networks, IEEE Trans Med Imaging, 35, pp. 1182-1195, (2016); Christ P.F., Ettlinger F., Grun F., Et al., Automatic liver and tumor segmentation of CT and MRI volumes using cascaded fully convolutional neural networks, (2017); Cortes C., Gonzalvo X., Kuznetsov V., Mohri M., Yang S., Adanet: adaptive structural learning of artificial neural networks, (2017); Stollenga M.F., Byeon W., Liwicki M., Schmidhuber J., Parallel multi-dimensional LSTM, with application to fast biomedical volumetric image segmentation, (2015); Yang X., Yu L., Wu L., Et al., Fine-grained recurrent neural networks for automatic prostate segmentation in ultrasound images, (2017); Chen J., Yang L., Zhang Y., Alber M., Chen D.Z., Combining Fully Convolutional and Recurrent Neural Networks for 3D Biomedical Image Segmentation, (2016); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, 1, (2012); Srivastava N., Hinton G., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: a simple way to prevent neural networks from overfitting, J Mach Learn Res, 15, pp. 1929-1958, (2014); LeCun Y., Bottou L., Orr G.B., Muller K.-R., Efficient BackProp, Neural Networks: Tricks of the Trade, pp. 9-50, (1998); Zaremba W., Sutskever I., Vinyals O., Recurrent Neural Network Regularization, (2014); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs, (2016); Men K., Boimel P., Janopaul-Naylor J., Et al., Cascaded atrous convolution and spatial pyramid pooling for more accurate tumor target segmentation for rectal cancer radiotherapy, Phys Med Biol, 63, (2018); Mazdak Abulnaga S., Rubin J., Ischemic stroke lesion segmentation in CT perfusion scans using pyramid pooling and focal loss, (2018); Myronenko A., 3D MRI brain tumor segmentation using autoencoder regularization, (2018); Wu Y., He K., Group normalization, (2018); Jia Y., Shelhamer E., Donahue J., Et al., Caffe: Convolutional Architecture for Fast Feature Embedding, (2014); Abadi M., Agarwal A., Barham P., Et al., TensorFlow: Large-scale machine learning on heterogeneous distributed systems, (2016); Collobert R., van der Maaten L., Joulin A., Torchnet: an open-source platform for (deep) learning research, (2016); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, (2014); Szegedy C., Liu W., Jia Y., Et al., Going deeper with convolutions, (2014); Scardapane S., Comminiello D., Hussain A., Uncini A., Group sparse regularization for deep neural networks, (2016); Goodfellow I.J., Warde-Farley D., Mirza M., Courville A., Bengio Y., Maxout networks, (2013); Cho J., Lee K., Shin E., Choy G., Do S., How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?, (2015); Wong S.C., Gatt A., Stamatescu V., McDonnell M.D., Understanding data augmentation for classification: when to warp?, (2016); Zhao W.H., Han B., Yang Y., Et al., Image information into image guided radiation therapy, Med Phys, 45, (2018); Zhao W., Han B., Yang Y., Et al., Visualizing the invisible in prostate radiation therapy: markerless prostate target localization via a deep learning model and monoscopic Kv projection x-ray image, Int J Radiat Oncol Biol Phys, 102, pp. S128-S129, (2018); Goodfellow I.J., Pouget-Abadie J., Mirza M., Et al., Generative adversarial networks, (2014); Antoniou A., Storkey A., Edwards H., Data augmentation generative adversarial networks, (2017); Huang H., Yu P.S., Wang C., An introduction to image synthesis with generative adversarial nets, (2018); Frid-Adar M., Klang E., Amitai M., Goldberger J., Greenspan H., Synthetic data augmentation using GAN for improved liver lesion classification, (2018); Moriya T., Roth H.R., Nakamura S., Et al., Unsupervised segmentation of 3D medical images based on clustering and deep representation learning, (2018); Zhou J., Cui G., Zhang Z., Et al., Graph neural networks: a review of methods and applications, (2018); Scarselli F., Gori M., Tsoi A.C., Hagenbuchner M., Monfardini G., The graph neural network model, IEEE Trans Neural Networks, 20, pp. 61-80, (2009); Roth H.R., Lu L., Seff A., Et al., A new 2.5 D representation for lymph node detection using random sets of deep convolutional neural network observations, (2014); Angermann C., Haltmeier M., Steiger R., Pereverzyev S., Gizewski E., Projection-based 2.5 D U-net architecture for fast volumetric segmentation, (2019); Zhao T., Ruan D., A 2.5 D assembly framework to segment high-dimensionality medical images by Bayesian aggregation of parallel 2D CNNs, Biom Phys Eng Express, 4, (2018); Lisin D.A., Mattar M.A., Blaschko M.B., Learned-Miller E.G., Benfield M.C., Combining local and global image features for object class recognition, (2005); Domhan T., Springenberg J.T., Hutter F., Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves, (2015); Shen C., Gonzalez Y., Chen L., Jiang S.B., Jia X., intelligent parameter tuning in optimization-based iterative CT reconstruction via deep reinforcement learning, (2017)","L. Xing; Medical Physics Division in the Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, 94305-5847, United States; email: lei@stanford.edu","","John Wiley and Sons Ltd","","","","","","00942405","","MPHYA","32418337","English","Med. Phys.","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85084860873"
"Topiwala A.; Al-Zogbi L.; Fleiter T.; Krieger A.","Topiwala, Anirudh (57215272056); Al-Zogbi, Lidia (57209216829); Fleiter, Thorsten (6701460715); Krieger, Axel (57201238593)","57215272056; 57209216829; 6701460715; 57201238593","Adaptation and evaluation of deep learning techniques for skin segmentation on novel abdominal dataset","2019","Proceedings - 2019 IEEE 19th International Conference on Bioinformatics and Bioengineering, BIBE 2019","","","8941944","752","759","7","18","10.1109/BIBE.2019.00141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078574668&doi=10.1109%2fBIBE.2019.00141&partnerID=40&md5=7bc1b5319e4fee368fb934229d6ef1ce","Department of Mechanical Engineering, University of Maryland, College Park, 20742, MD, United States; R. Cowley Shock Trauma Center, Department of Diagnostic Radiology, School of Medicine, University of Maryland, Baltimore, 21201, MD, United States","Topiwala A., Department of Mechanical Engineering, University of Maryland, College Park, 20742, MD, United States; Al-Zogbi L., Department of Mechanical Engineering, University of Maryland, College Park, 20742, MD, United States; Fleiter T., R. Cowley Shock Trauma Center, Department of Diagnostic Radiology, School of Medicine, University of Maryland, Baltimore, 21201, MD, United States; Krieger A., Department of Mechanical Engineering, University of Maryland, College Park, 20742, MD, United States","Skin segmentation plays an important role in a wide variety of biomedical image processing applications, such as skin cancer identification, skin lesion detection, and wound isolation. However, contemporary research has been mainly based on facial and hand skin datasets, with no other body regions considered for skin pixels sampling. Segmenting skin specifically in the abdominal region can aid in robotic abdominal surgeries and treatment procedures, such as robot-assisted laparoscopic surgeries and abdominal ultrasounds. A robust and highly accurate abdominal skin detection technique thus becomes imperative. To this end, we compiled a novel dataset of 1,400 segmented abdominal pictures and adapted and compared four abdominal skin segmentation techniques: one based on thresholding and three deep learning techniques, namely a fully connected neural network for pixel-level classification, and two convolution-based networks, U-Net and Mask-RCNN. We show that the U-Net model outperforms the other segmentation techniques, resulting in a pixel-to-pixel mean cross-validation accuracy of 95.51% on our Abdominal dataset. The incorporation of the Abdominal dataset in the training helped improve the abdominal skin segmentation accuracy by 10.19%. The U-Net model proved to be computationally the fastest, enabling real time skin segmentation with a processing rate of 37 frames per second. © 2019 IEEE.","Deep Learning; Semantic Skin Dataset; Semantic Skin Segmentation","Bioinformatics; Classification (of information); Dermatology; Image segmentation; Learning algorithms; Object recognition; Pixels; Robotic surgery; Semantics; Surgery; Abdominal surgery; Biomedical images; Frames per seconds; Fully connected neural network; Laparoscopic surgery; Learning techniques; Segmentation techniques; Skin segmentation; Deep learning","","","","","","","Singha J., Roy A., Laskar R.H., Dynamic hand gesture recognition using vision-based approach for human-computer interaction, Neural Computing and Applications, 29, 4, pp. 1129-1141, (2018); Islam A.R., Alammari A., Buckles B., Skin detection in image and video founded in clustering and region growing, Mobile Multimedia/Image Processing, Security, and Applications 2019, (2019); Benini S., Khan K., Leonardi R., Mauro M., Migliorati P., Fasseg: A face semantic segmentation repository for face image analysis, Data in Brief, (2019); Codella N.C., Nguyen Q.-B., Pankanti S., Gutman D., Helba B., Halpern A., Smith J.R., Deep learning ensembles for melanoma recognition in dermoscopy images, IBM Journal of Research and Development, 61, 4-5, pp. 1-5, (2017); Yu L., Chen H., Dou Q., Qin J., Heng P.-A., Automated melanoma recognition in dermoscopy images via very deep residual networks, IEEE Transactions on Medical Imaging, 36, 4, pp. 994-1004, (2016); Rajinikanth V., Thanaraj K.P., Satapathy S.C., Fernandes S.L., Dey N., Shannons entropy and watershed algorithm based technique to inspect ischemic stroke wound, Smart Intelligent Computing and Applications, pp. 23-31, (2019); Vasconcelos F.F.X., Medeiros A.G., Peixoto S.A., Reboucas Filho P.P., Automatic skin lesions segmentation based on a new morphological approach via geodesic active contour, Cognitive Systems Research, 55, pp. 44-59, (2019); Codella N.C., Anderson D., Philips T., Porto A., Massey K., Snowdon J., Feris R., Smith J., Segmentation of both diseased and healthy skin from clinical photographs in a primary care setting, 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). IEEE, pp. 3414-3417, (2018); Kawulok M., Kawulok J., Nalepa J., Smolka B., Self-adaptive algorithm for segmenting skin regions, EURASIP Journal on Advances in Signal Processing, 2014, 1, (2014); Tan W.R., Chan C.S., Yogarajah P., Condell J., A fusion approach for efficient human skin detection, IEEE Transactions on Industrial Informatics, 8, 1, pp. 138-147, (2012); Casati J.P.B., Moraes D.R., Rodrigues E.L.L., SFA: A human skin image database based on FERET and AR facial images, IX Workshop de Visao Computational, (2013); Mathur B., Topiwala A., Saeidi H., Fleiter T., Krieger A., Evaluation of Control Strategies for A Tele-manipulated Robotic System for Remote Trauma Assessment, pp. 7-14; Phung S.L., Bouzerdoum A., Chai D., Skin segmentation using color and edge information, Seventh International Symposium on Signal Processing and Its Applications, 2003. Proceedings., 1, pp. 525-528, (2003); Santos A., Paiva J., Toledo C., Pedrini H., Improved human skin segmentation using fuzzy fusion based on optimized thresholds by genetic algorithms, Hybrid Soft Computing for Image Segmentation, pp. 185-207, (2016); Varma S.L., Behera V., Human skin detection using histogram processing and Gaussian mixture model based on color spaces, 2017 International Conference on Intelligent Sustainable Systems (ICISS). IEEE, pp. 116-120, (2017); Storring M., Kocka T., Andersen H.J., Granum E., Tracking regions of human skin through illumination changes, Pattern Recognition Letters, 24, 11, pp. 1715-1723, (2003); Roheda S., A multi-scale approach to skin pixel detection, Electronic Imaging, 2017, 4, pp. 18-23, (2017); Ma C.-H., Shih H.-C., Human skin segmentation using fully convolutional neural networks, 2018 IEEE 7th Global Conference on Consumer Electronics (GCCE). IEEE, pp. 168-170, (2018); Zuo H., Fan H., Blasch E., Ling H., Combining convolutional and recurrent neural networks for human skin detection, IEEE Signal Processing Letters, 24, 3, pp. 289-293, (2017); Chaichulee S., Villarroel M., Jorge J., Arteta C., Green G., Mc-Cormick K., Zisserman A., Tarassenko L., Multi-task convolutional neural network for patient detection and skin segmentation in continuous non-contact vital sign monitoring, 2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017). IEEE, pp. 266-272, (2017); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-assisted Intervention, pp. 234-241, (2015); Christ P.F., Elshaer M.E.A., Ettlinger F., Tatavarty S., Bickel M., Bilic P., Rempfler M., Armbruster M., Hofmann F., Danastasi M., Et al., Automatic liver and lesion segmentation in CT using cascaded fully convolutional neural networks and 3D conditional random fields, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 415-423, (2016); Dourado A., Guth F., De Campos T.E., Weigang L., Domain Adaptation for Holistic Skin Detection, (2019); Johnson J.W., Adapting Mask-rcnn for Automatic Nucleus Segmentation, (2018); He K., Gkioxari G., Dollar P., Girshick R., Mask r-cnn, Proceedings of the IEEE International Conference on Computer Vision, pp. 2961-2969, (2017); Jones M.J., Rehg J.M., Statistical color models with application to skin detection, International Journal of Computer Vision, 46, 1, pp. 81-96, (2002); Zhu Q., Wu C.-T., Cheng K.-T., Wu Y.-L., An adaptive skin model and its application to objectionable image filtering, Proceedings of the 12th Annual ACM International Conference on Multimedia. ACM, pp. 56-63, (2004); Phung S.L., Bouzerdoum A., Chai D., Skin segmentation using color pixel classification: Analysis and comparison, IEEE Transactions on Pattern Analysis & Machine Intelligence, 1, pp. 148-154, (2005); SanMiguel J.C., Suja S., Skin detection by dual maximization of detectors agreement for video monitoring, Pattern Recognition Letters, 34, 16, pp. 2102-2109, (2013); Schmugge S.J., Jayaram S., Shin M.C., Tsap L.V., Objective evaluation of approaches of skin detection using ROC analysis, Computer Vision and Image Understanding, 108, 1-2, pp. 41-51, (2007); Shaik K.B., Ganesan P., Kalist V., Sathish B., Jenitha J.M.M., Comparative study of skin color detection and segmentation in HSV and YCbCr color space, Procedia Computer Science, 57, pp. 41-48, (2015); Abdulla W., Mask R-cnn for Object Detection and Instance Segmentation on Keras and Tensorflow, (2017); Kim Y., Hwang I., Cho N.I., Convolutional neural networks and training strategies for skin detection, 2017 IEEE International Conference on Image Processing (ICIP). IEEE, pp. 3919-3923, (2017)","","","Institute of Electrical and Electronics Engineers Inc.","","19th International Conference on Bioinformatics and Bioengineering, BIBE 2019","28 October 2019 through 30 October 2019","Athens","156417","","978-172814617-1","","","English","Proc. - IEEE Int. Conf. Bioinform. Bioeng., BIBE","Conference paper","Final","","Scopus","2-s2.0-85078574668"
"Ahmed I.; Balestrieri E.; Carni D.L.; Lamonaca F.","Ahmed, Imran (58833622300); Balestrieri, Eulalia (8105381900); Carni, Domenico Luca (6603245529); Lamonaca, Francesco (21933997900)","58833622300; 8105381900; 6603245529; 21933997900","Comparison of U -NET backbones for morphometric measurements of white blood cell","2022","2022 IEEE International Symposium on Medical Measurements and Applications, MeMeA 2022 - Conference Proceedings","","","","","","","5","10.1109/MeMeA54994.2022.9856479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137890022&doi=10.1109%2fMeMeA54994.2022.9856479&partnerID=40&md5=1ff791e8664687a79a450099fc64f552","University of Sannio, Department of Engineering, Benevento, Italy; Dept. of Computer Science, Modelling, Electronics and Systems Engineering, University of Calabria, Arcavacata di Rende, Italy","Ahmed I., University of Sannio, Department of Engineering, Benevento, Italy; Balestrieri E., University of Sannio, Department of Engineering, Benevento, Italy; Carni D.L., Dept. of Computer Science, Modelling, Electronics and Systems Engineering, University of Calabria, Arcavacata di Rende, Italy; Lamonaca F., Dept. of Computer Science, Modelling, Electronics and Systems Engineering, University of Calabria, Arcavacata di Rende, Italy","Measurements of Morphometric Parameters of Blood Cells (MPBC) playa key role in haematological examination, and it is considered as one of the principal needs for clinicians in the diagnosis of various diseases in human and animals. Obliviously, the correctness of the diagnosis, and, as a consequence, the effectiveness of clinician actions is highly dependent on the accuracy of MPBC measurements. In this context, deep learning based MPBC measurement systems are a promising solution. In recent studies, researchers have applied semantic segmentation with various backbone networks for white blood cell measurements. Vice versa, few investigations were done about the achieved accuracy. Indeed, accurate segmentation of white blood cell remains a challenging task because of the complex nature of cell images, staining techniques, and imaging conditions which strongly affects the accuracy of the MPBC measurements. This paper presents a comparison among the segmentation performance carried out by U-Net deep learning algorithm with different backbones typically used for MPBC. The goal is to make a first step towards a whole MPBC measurement system capable of evaluating the effects of the influencing magnitudes, attenuate them (if possible), and evaluate the accuracy of the measurements. The aims are to increase measurement reliability and to give clinicians further information to take their decisions.  © 2022 IEEE.","backbone networks; biomedical image segmentation; convolution neural network; morphometric measurement of blood cells; U-Net; white blood cell size measurement","Blood; Cells; Cytology; Deep learning; Learning algorithms; Semantic Segmentation; Semantics; Back-bone network; Biomedical image segmentation; Blood cells; Cell-size; Convolution neural network; Measurements of; Morphometric measurement of blood cell; Morphometric measurements; Size measurements; U-net; White blood cell size measurement; White blood cells; Diagnosis","","","","","","","Ceccarelli M., Et al., Automatic detection and surface measurements of micronucleus by a computer vision approach, IEEE Trans. on Instrum. And Measurement, 59, 9, pp. 2383-2390, (2010); Carni D.L., Et al., Preprocessing Correction for Micronucleus Image Detection Affected by Contemporaneous Alterations, IEEE Transactions on Instrumentation and Measurement, 56, 4, pp. 1202-1211, (2007); Spagnolo V., Et al., Blood Oxygen Saturation Measurement By Smartphone Camera, Proc. of MeMeA 2015-IEEE Intern. Symp. on Medical Measurements and Applications, pp. 359-363, (2015); Colaprico A., Et al., An Overview on Internet of Medical Things in Blood Pressure Monitoring, proc. of IEEE International Symposium on Medical Measurements and Applications, pp. 1-6, (2019); Kurylyak Y., Et al., Photoplethysmogram-based Blood Pressure Evaluation using Kalman Filtering and Neural Networks, Proc. of IEEE Intern. Symp. on Medical Measurements and Applications (MeMeA 2013), pp. 170-174, (2013); Carni D.L., Grimaldi D., Lamonaca F., Image pre-processing for micro nucleuses detection in lymphocyte, Proc. of IDAACS 2005-IEEE International Workshop on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2005), pp. 570-575, (2005); Rahman M., Et al., Evaluation of Erythrocyte Morphometric Indices in Juvenile Red Spotted Grouper, E. Akaara under Elevated Water Temperature, Dev Reprod, 4, 23, pp. 345-353, (2019); Diez-Silva M., Et al., Shape and biomechanical characteristics of human red blood cells in health and disease, MRS Bull, 35, 5, pp. 382-388, (2010); Ahmed I., Et al., Morphometric measurements of blood cell, Measurement: Sensors, 18, (2021); Zhao Y., Et al., Self-mixing interferometry-based micro flow cytometry system for label-free cells classification, Appl. Sci, 2, 10, (2020); Ahmed I., Et al., Self-mixing interferometric signal enhancement using generative adversarial network for laser metric sensing applications, IEEE Access, 7, pp. 174641-174650, (2019); Ahmed I., Et al., Fast estimation of feedback parameters for a selfmixing interferometric displacement sensor, Proc. Of C-CODE, pp. 407-411, (2017); Kammel M., Et al., Flow cytometer for reference measurements of blood cell concentrations with low uncertainty, 2015 IEEE International Symposium on Medical Measurements and Applications (MeMeA) Proceedings, pp. 517-520, (2015); Garone E., Et al., Clock Synchronization for Wireless Sensor Network with Communication Delay, Proc. of American Control Conference, pp. 771-776, (2013); Nastro A., Et al., Sub-s synchronization accuracy in distributed measurement system by PDA and PC triggers realignement, Proc. of I2MTC 2013-IEEE International Instrumentation and Measurement Technology Conference, pp. 801-806, (2013); Lamonaca F., Grimaldi D., Trigger Realignment by Networking Synchronized Embedded Hardware, IEEE Transactions on Instrumentation and Measurement, 62, 1, pp. 38-49, (2013); Carni D.L., Et al., Synchronization of measurement instruments cooperating into the W-DMS, Proc. of IMTC 2007-IEEE Instrumentation and Measurement Technology Conference, pp. 1-6, (2007); Balestrieri E., Et al., Sensors and measurements for unmanned systems: An overview, Sensors, 21, 4, pp. 1-27, (2021); Scuro C., Et al., Synchronization of Wireless Sensor Networks for Biomedical Measurement Systems, Proc. of 15th International Conference on Advanced Technologies, Systems and Services in Telecommunications, TELSIKS 2021, pp. 325-328, (2021); Ahmed I., Balestrieri E., Lamonaca F., IoMT-based biomedical measurement systems for healthcare monitoring: A review, Acta IMEKO, 10, 2, pp. 174-184, (2021); Guo Y., Et al., A review of semantic segmentation using deep neural networks, Int. J. Multimedia Inf. Retr, 7, 2, pp. 87-93, (2018); Ahmad M., Et al., Comparison of Deep-Learning-Based Segmentation Models: Using Top View Person Images, IEEE Access, 8, pp. 136361-136373, (2020); J. Long E., Et al., Fully convolutional networks for semantic segmentation, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3431-3440, (2015); He K., Et al., Mask R-CNN, 2017 IEEE International Conference on Computer Vision (ICCV), pp. 2980-2988, (2017); Ronneberger O., Et al., U-Net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, (2015); Mu X., Et al., AD-Link: An Adaptive Approach for User Identity Linkage, 2019 IEEE International Conference on Big Knowledge (ICBK), pp. 183-190, (2019); Yang Z., Et al., Deeplab_v3_plus-net for Image Semantic Segmentation with Channel Compression, 2020 IEEE 20th International Conference on Communication Technology (ICCT), pp. 1320-1324, (2020); Ru Q., Et al., Brain Tumor Image Segmentation Method Based on MUnet Network, 2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI), pp. 243-246, (2021); Wu J., Et al., Skin Lesion Segmentation with C-UNet, 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 2785-2788, (2019); Kesavan S.M., Et al., Res-UNet Supported Segmentation and Evaluation of COVID19 Lesion in Lung CT, 2021 International Conference on System, Computation, Automation and Networking (ICSCAN), pp. 1-4, (2021); Li D., Et al., Robust Blood Cell Image Segmentation Method Based on Neural Ordinary Differential Equations, Computational and Mathematical Methods in Medicine, (2021); Zhong Z., Et al., White blood cell segmentation via sparsity and geometry constraints, IEEE Access, 7, pp. 167593-167604, (2019); Fan H., Et al., LeukocyteMask: An automated localization and segmentation method for leukocyte in blood smear images using deep neural networks, J. Biophoton, 12, (2019); Ahmed I., Et al., Recent developments in IoMT based biomedical measurement systems: A review, IMEKO TC4 2020, pp. 23-28, (2020); Baheti B., Et al., Eff-UNet: A Novel Architecture for Semantic Segmentation in Unstructured Environment, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 1473-1481, (2020); Putra T.A., Rufaida S.I., Leu J.-S., Enhanced Skin Condition Prediction Through Machine Learning Using Dynamic Training and Testing Augmentation, IEEE Access, 8, pp. 40536-40546, (2020); Iglovikov V., Et al., Ternausnet: U-Net with VGG11 encoder pretrained on ImageNet for image segmentation, (2018); Tan M., Le Q.V., EfficientNet: Improving accuracy and efficiency through automl and model scaling, (2019); He K., Et al., Deep Residual Learning for Image Recognition, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778, (2016); Zheng X., Et al., Fast and Robust Segmentation of White Blood Cell Images by Self-supervised Learning, Micron, 107, pp. 55-71, (2018); Kim Y., Convolutional neural networks for sentence classification, Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1746-1751, (2014)","","","Institute of Electrical and Electronics Engineers Inc.","et al.; IEEE; IEEE Instrumentation and Measurement Society; IEEE Sensors Council Italy Chapter; Politecnico di Torino; Universita degli Studi di Messina","17th IEEE International Symposium on Medical Measurements and Applications, MeMeA 2022","22 June 2022 through 24 June 2022","Messina","182236","","978-166548299-8","","","English","IEEE Int. Symp. Med. Meas. Appl., MeMeA - Conf. Proc.","Conference paper","Final","","Scopus","2-s2.0-85137890022"
"Li H.; Yin Z.","Li, Haohan (56352698800); Yin, Zhaozheng (36351279000)","56352698800; 36351279000","Attention, suggestion and annotation: A deep active learning framework for biomedical image segmentation","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12261 LNCS","","","3","13","10","19","10.1007/978-3-030-59710-8_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093106221&doi=10.1007%2f978-3-030-59710-8_1&partnerID=40&md5=7ee6b521db4ef10095a9b800a9f75f32","Department of Computer Science, Missouri University of Science and Technology, Rolla, 65409, MO, United States; AI Institute, Department of Biomedical Informatics, Department of Computer Science, Department of Applied Mathematics and Statistics (Affiliated), Stony Brook University, Stony Brook, 11794, NY, United States","Li H., Department of Computer Science, Missouri University of Science and Technology, Rolla, 65409, MO, United States; Yin Z., AI Institute, Department of Biomedical Informatics, Department of Computer Science, Department of Applied Mathematics and Statistics (Affiliated), Stony Brook University, Stony Brook, 11794, NY, United States","Despite the great success, deep learning based segmentation methods still face a critical obstacle: the difficulty in acquiring sufficient training data due to high annotation costs. In this paper, we propose a deep active learning framework that combines the attention gated fully convolutional network (ag-FCN) and the distribution discrepancy based active learning algorithm (dd-AL) to significantly reduce the annotation effort by iteratively annotating the most informative samples to train the ag-FCN for the better segmentation performance. Our framework is evaluated on 2015 MICCAI Gland Segmentaion dataset and 2017 MICCAI 6-month infant brain MRI Segmentation dataset. Experiment results show that our framework can achieve state-of-the-art segmentation performance by using only a portion of the training data. © Springer Nature Switzerland AG 2020.","","Convolutional neural networks; Deep learning; Image annotation; Image segmentation; Iterative methods; Magnetic resonance imaging; Medical computing; Medical imaging; Active Learning; Active-learning algorithm; Biomedical image segmentation; Convolutional networks; Learning-based segmentation; Segmentation performance; State of the art; Training data; Learning algorithms","","","","","","","Kamnitsas K., Ledig C., Et al., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation, Med. Image Anal., 36, pp. 61-78, (2017); Liao F., Liang M., Et al., Evaluate the malignancy of pulmonary nodules using the 3-D deep leaky noisy-or network, IEEE Trans. Neural Netw. Learn. Syst., 30, 11, pp. 3484-3495, (2019); Long J., Shelhamer E., Et al., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, (2015); He K., Gkioxari G., Et al., Mask R-CNN, Proceedings of the IEEE International Conference on Computer Vision, pp. 2961-2969, (2017); Papandreou G., Chen L.C., Et al., Weakly-And Semi-Supervised Learning of a DCNN for Semantic Image Segmentation. Arxiv, Arxiv Preprint Arxiv, 1502, (2015); Xiao H., Wei Y., Et al., Transferable semi-supervised semantic segmentation, AAAI Conference on Artificial Intelligence, (2018); Hong S., Noh H., Et al., Decoupled deep neural network for semi-supervised semantic segmentation, Advances in Neural Information Processing Systems, pp. 1495-1503, (2015); Settles B., Active Learning Literature Survey, (2009); Dutt Jain S., Grauman K., Active image segmentation propagation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2864-2873, (2016); Yang L., Zhang Y., Et al., Suggestive annotation: A deep active learning framework for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 399-407, (2017); Wang X., Girshick R., Et al., Non-local neural networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7794-7803, (2018); Sirinukunwattana K., Pluim J.P., Et al., Gland segmentation in colon histology images: The glas challenge contest, Med. Image Anal., 35, pp. 489-502, (2017); Wang L., Nie D., Et al., Benchmark on automatic six-month-old infant brain segmentation algorithms: The iSeg-2017 challenge, IEEE Trans. Med. Imaging, 38, 9, pp. 2219-2230, (2019); Graham S., Chen H., Et al., MILD-Net: Minimal information loss dilated network for gland instance segmentation in colon histology images, Med. Image Anal., 52, pp. 199-211, (2019); Graham S., Chen H., Et al., DCAN: Deep contour-aware networks for accurate gland segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2487-2496, (2016); Ding H., Pan Z., Et al., Multi-scale fully convolutional network for gland segmentation using three-class classification, Neurocomputing, 380, pp. 150-161, (2020); TESLA V100 Performance Guide; Cicek O., Abdulkadir A., Et al., 3D U-Net: Learning dense volumetric segmentation from sparse annotation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 424-432, (2016); Chen H., Dou Q., Et al., VoxResNet: Deep voxelwise residual networks for brain segmentation from 3D MR images, Neuroimage, 170, pp. 446-455, (2018); Bui T.D., Shin J., Et al., Skip-connected 3D DenseNet for volumetric infant brain MRI segmentation, Biomed. Signal Process. Control, 54, (2019)","H. Li; Department of Computer Science, Missouri University of Science and Technology, Rolla, 65409, United States; email: hl87c@umsystem.edu","Martel A.L.; Abolmaesumi P.; Stoyanov D.; Mateus D.; Zuluaga M.A.; Zhou S.K.; Racoceanu D.; Joskowicz L.","Springer Science and Business Media Deutschland GmbH","","23rd International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2020","4 October 2020 through 8 October 2020","Lima","249659","03029743","978-303059709-2","","","English","Lect. Notes Comput. Sci.","Conference paper","Final","","Scopus","2-s2.0-85093106221"
"Toğaçar M.; Ergen B.; Cömert Z.","Toğaçar, Mesut (57205581917); Ergen, Burhan (6508022484); Cömert, Zafer (36543652400)","57205581917; 6508022484; 36543652400","Application of breast cancer diagnosis based on a combination of convolutional neural networks, ridge regression and linear discriminant analysis using invasive breast cancer images processed with autoencoders","2020","Medical Hypotheses","135","","109503","","","","63","10.1016/j.mehy.2019.109503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075195028&doi=10.1016%2fj.mehy.2019.109503&partnerID=40&md5=58e8df55c2b555f9f2e258a668d99ec8","Department of Computer Technology, Fırat University, Elazig, Turkey; Department of Computer Engineering, Faculty of Engineering, Fırat University, Elazig, Turkey; Department of Software Engineering, Faculty of Engineering, Samsun University, Samsun, Turkey","Toğaçar M., Department of Computer Technology, Fırat University, Elazig, Turkey; Ergen B., Department of Computer Engineering, Faculty of Engineering, Fırat University, Elazig, Turkey; Cömert Z., Department of Software Engineering, Faculty of Engineering, Samsun University, Samsun, Turkey","Invasive ductal carcinoma cancer, which invades the breast tissues by destroying the milk channels, is the most common type of breast cancer in women. Approximately, 80% of breast cancer patients have invasive ductal carcinoma and roughly 66.6% of these patients are older than 55 years. This situation points out a powerful relationship between the type of breast cancer and progressed woman age. In this study, the classification of invasive ductal carcinoma breast cancer is performed by using deep learning models, which is the sub-branch of artificial intelligence. In this scope, convolutional neural network models and the autoencoder network model are combined. In the experiment, the dataset was reconstructed by processing with the autoencoder model. The discriminative features obtained from convolutional neural network models were utilized. As a result, the most efficient features were determined by using the ridge regression method, and classification was performed using linear discriminant analysis. The best success rate of classification was achieved as 98.59%. Consequently, the proposed approach can be admitted as a successful model in the classification. © 2019 Elsevier Ltd","Autoencoder network; Biomedical image processing; Decision support; Deep learning; Feature selection; Invasive breast cancer","Algorithms; Artificial Intelligence; Breast Neoplasms; Carcinoma, Ductal, Breast; Diagnosis, Computer-Assisted; Discriminant Analysis; Female; Humans; Image Processing, Computer-Assisted; Linear Models; Machine Learning; Neoplasm Invasiveness; Neural Networks, Computer; Programming Languages; Reproducibility of Results; Sensitivity and Specificity; Software; adult; Article; artificial intelligence; autoencoder; breast carcinoma; cancer diagnosis; controlled study; convolutional neural network; deep learning; discriminant analysis; feature selection; female; human; human tissue; image processing; information processing; major clinical study; middle aged; tumor classification; algorithm; breast tumor; computer assisted diagnosis; computer language; discriminant analysis; image processing; machine learning; Paget nipple disease; procedures; reproducibility; sensitivity and specificity; software; statistical model; tumor invasion","","","","","","","Sun Y.-S., Zhao Z., Yang Z.-N., Xu F., Lu H.-J., Zhu Z.-Y., Et al., Risk factors and preventions of breast cancer, Int J Biol Sci, 13, pp. 1387-1397, (2017); WHO, Breast cancer: prevention and control, (2016); Akram M., Iqbal M., Daniyal M., Khan A.U., Awareness and current knowledge of breast cancer, Biol Res, 50, (2017); Lee J., Oh M., Ko S., Park C., Lee E.S., Kim H.-A., Et al., Parity differently affects the breast cancer specific survival from ductal carcinoma in situ to invasive cancer: a registry-based retrospective study from Korea, Breast Cancer (Auckl), 13, (2019); Sharma G.N., Dave R., Sanadya J., Sharma P., Sharma K.K., Various types and management of breast cancer: an overview, J Adv Pharm Technol Res, 1, pp. 109-126, (2010); Cruz-Roa A., Gilmore H., Basavanhally A., Feldman M., Ganesan S., Shih N.N.C., Et al., Accurate and reproducible invasive breast cancer detection in whole-slide images: a Deep Learning approach for quantifying tumor extent, Sci Rep, 7, (2017); Togacar M., Ergen B., pp. 1-5, (2018); Comert Z., Kocamaz A.F., Fetal hypoxia detection based on deep convolutional neural network with transfer learning approach, Softw. Eng. Algorithms Intell. Syst., pp. 239-248, (2019); Cruz-Roa A., Basavanhally A., Gonzalez F., Gilmore H., Feldman M., Ganesan S., Et al.; Roy S., Kumar R., Mittal V., Gupta D., Classification models for Invasive Ductal Carcinoma Progression, based on gene expression data-trained supervised machine learning, BioRxiv, 666222, (2019); Gecer B., Aksoy S., Mercan E., Shapiro L.G., Weaver D.L., Elmore J.G., Detection and classification of cancer in whole slide breast histopathology images using deep convolutional networks, Pattern Recognit, 84, pp. 345-356, (2018); Mercan E., Mehta S., Bartlett J., Shapiro L.G., Weaver D.L., Elmore J.G., Assessment of machine learning of breast pathology structures for automated differentiation of breast cancer and high-risk proliferative lesions, JAMA Netw Open, 2, (2019); Tapak L., Shirmohammadi-Khorram N., Amini P., Alafchi B., Hamidi O., Poorolajal J., Prediction of survival and metastasis in breast cancer patients using machine learning classifiers, Clin Epidemiol Glob Heal, pp. 1-7, (2018); Alom M.Z., Yakopcic C., Nasrin M.S., Taha T.M., Asari V.K., Breast cancer classification from histopathological images with inception recurrent residual convolutional neural network, J Digit Imaging, (2019); Kadhim M., Abed M., (2019); Sertkaya M.E., Ergen B., Togacar M., pp. 1-5, (2019); Altuntas Y., Comert Z., Kocamaz A.F., Identification of haploid and diploid maize seeds using convolutional neural networks and a transfer learning approach, Comput Electron Agric, 163, (2019); Togacar M., Ergen B., Sertkaya M.E.; Pape-Zambito D., Jiang Z., Wu H., Devarajan K., Slater C.M., Cai K.Q., Et al., Identifying a highly-aggressive DCIS subgroup by studying intra-individual DCIS heterogeneity among invasive breast cancer patients, PLoS ONE, 9, (2014); Mooney P.; Janowczyk A., Madabhushi A., Deep learning for digital pathology image analysis: a comprehensive tutorial with selected use cases, J Pathol Inform, 7, (2016); Huk M., Maleszka M., Szczerbicki E., Intelligent information and database systems: recent developments, (2019); Comert Z., Sengur A., Budak U., Kocamaz A.F., Prediction of intrapartum fetal hypoxia considering feature selection algorithms and machine learning models, Heal Inf Sci Syst, 7, (2019); Zhang M., Li L., Wang H., Liu Y., Qin H., Zhao W., Optimized compression for implementing convolutional neural networks on FPGA, Electronics, 8, (2019); Togacar M., Ergen B., Sertkaya M.E., Subclass separation of white blood cell images using convolutional neural network models, Elektron Ir Elektrotechnika, 25, pp. 63-68, (2019); Gebrehiwot A., Hashemi-Beni L., Thompson G., Kordjamshidi P., Langan T.E., Deep convolutional neural network for flood extent mapping using unmanned aerial vehicles data, Sensors (Basel), 19, (2019); Scherer D., Muller A., Behnke S., pp. 92-101, (2010); Yamashita R., Nishio M., Do R.K.G., Togashi K., Convolutional neural networks: an overview and application in radiology, Insights Imaging, 9, pp. 611-629, (2018); Huang J., Dwivedi K., Roig G., (2019); Comert Z., Kocamaz A.F., Subha V., Prognostic model based on image-based time-frequency features and genetic algorithm for fetal hypoxia assessment, Comput Biol Med, (2018); Togacar M., Ergen B., Comert Z., A deep feature learning model for pneumonia detection applying a combination of mRMR feature selection and machine learning models, (2019); Szegedy C., pp. 1-9, (2015); Mehdipour Ghazi M., Yanikoglu B., Aptoula E., Plant identification using deep neural networks via optimization of transfer learning parameters, Neurocomputing, 235, pp. 228-235, (2017); Olsen A., Konovalov D.A., Philippa B., Ridd P., Wood J.C., Johns J., Et al., DeepWeeds: a multiclass weed species image dataset for deep learning, Sci Rep, 9, (2019); Mateen M., Wen J., Nasrullah D., Song S., Huang Z., Fundus image classification using VGG-19 architecture with PCA and SVD, Symmetry (Basel), 11, (2018); Mandelkow H., de Zwart J.A., Duyn J.H., Linear discriminant analysis achieves high classification accuracy for the BOLD fMRI response to naturalistic movie stimuli, Front Hum Neurosci, 10, (2016); Bernstein R., Osadchy M., Keren D., Schuster A., LDA classifier monitoring in distributed streaming systems, J Parallel Distrib Comput, 123, pp. 156-167, (2019); Usman U., Zakari Y.; Toka O., A comparative study on regression methods in the presence of multicollinearity, J Stat Stat Actuar Sci, 2, pp. 47-53, (2016); Hu Q., Feng M., Lai L., Pei J., Prediction of drug-likeness using deep autoencoder neural networks, Front Genet, 9, (2018); Yu J., A selective deep stacked denoising autoencoders ensemble with negative correlation learning for gearbox fault diagnosis, Comput Ind, 108, pp. 62-72, (2019); Meng Q., Catchpoole D., Skillicom D., Kennedy P.J., Relational autoencoder for feature extraction, Proc Int Jt Conf Neural Netw, pp. 364-371, (2017); Chollet F.; Tahmassebi A., Gandomi A.H., Fong S., Meyer-Baese A., Foo S.Y., Multi-stage optimization of a deep model: a case study on ground motion modeling, PLoS One, 13, (2018); Yang Z., Wang C., Zhang Z., Li J., Mini-batch algorithms with online step size, Knowledge-Based Syst, 165, pp. 228-240, (2019); Park H., Lee J.H., Oh Y., Ha S., Lee S.; Loshchilov I., Hutter F.S.; Shindjalova R., Prodanova K., Svechtarov V., Modeling data for tilted implants in grafted with bio-oss maxillary sinuses using logistic regression, AIP Conf Proc, 1631, pp. 58-62, (2014); Wibowo A., Wiryawan P.W., Nuqoyati N.I., Optimization of neural network for cancer microRNA biomarkers classification, J Phys Conf Ser, 1217, (2019); Mansoor A., Bagci U., Foster B., Xu Z., Papadakis G.Z., Folio L.R., Et al., Segmentation and image analysis of abnormal lungs at CT: current approaches, challenges, and future trends, Radiographics, 35, pp. 1056-1076, (2015); Hooda N., Jakhar K., (2018); Togacar M., Ergen B., Biyomedikal Görüntülerde Derin Öğrenme ile Mevcut Yöntemlerin Kıyaslanması, Fırat Üniversitesi Mühendislik Bilim Derg, 31, pp. 109-121, (2019); Budak U., Comert Z., Cibuk M., Sengur A., DCCMED-Net: densely connected and concatenated multi Encoder-Decoder CNNs for retinal vessel extraction from fundus images, Med Hypotheses, 134, (2020); Chatterjee C., Krishna G., A novel method for IDC prediction in breast cancer histopathology images using deep residual, (2019); Mohapatra P., Panda B., Swain S., Enhancing histopathological breast cancer image classification using deep learning, Int J Innov Technol Explor Eng, 8, pp. 2024-2032, (2019); He J., Pedroza I., Liu Q.","M. Toğaçar; Department of Computer Technology, Fırat University, Elazig, Turkey; email: mtogacar@firat.edu.tr","","Churchill Livingstone","","","","","","03069877","","MEHYD","31760247","English","Med. Hypotheses","Article","Final","","Scopus","2-s2.0-85075195028"
"Dobratulin K.; Gaidel A.; Kapishnikov A.; Ivleva A.; Aupova I.; Zelter P.","Dobratulin, Konstantin (57219685346); Gaidel, Andrey (55652819400); Kapishnikov, Aleksandr (6507900025); Ivleva, Anna (57216846125); Aupova, Irina (57241900300); Zelter, Pavel (56512149200)","57219685346; 55652819400; 6507900025; 57216846125; 57241900300; 56512149200","The efficiency of deep learning algorithms for detecting anatomical reference points on radiological images of the head profile","2020","Proceedings of ITNT 2020 - 6th IEEE International Conference on Information Technology and Nanotechnology","","","9253067","","","","6","10.1109/ITNT49337.2020.9253067","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097611242&doi=10.1109%2fITNT49337.2020.9253067&partnerID=40&md5=e7b6e0cbb37d2c59bbf5d8be4b76d6f9","Samara National Research University, Faculty of Informatics, Samara, Russian Federation; Crystallography and Photonics Ras, Image Processing Systems Institute of Ras - Branch of the Fsrc, Samara, Russian Federation; SamSMU Moh Russia, Department of Radiology and Radiotherapy with the Course of Medicine Informatics Fsbei He, Samara, Russian Federation; Iccs Ras, Laboratory of Analysis and Modeling of Complex Systems, Samara, Russian Federation; Fsbei He SamSMU Moh Russia, Department of Pediatric Dentistry, Samara, Russian Federation","Dobratulin K., Samara National Research University, Faculty of Informatics, Samara, Russian Federation; Gaidel A., Crystallography and Photonics Ras, Image Processing Systems Institute of Ras - Branch of the Fsrc, Samara, Russian Federation; Kapishnikov A., SamSMU Moh Russia, Department of Radiology and Radiotherapy with the Course of Medicine Informatics Fsbei He, Samara, Russian Federation; Ivleva A., Iccs Ras, Laboratory of Analysis and Modeling of Complex Systems, Samara, Russian Federation; Aupova I., Fsbei He SamSMU Moh Russia, Department of Pediatric Dentistry, Samara, Russian Federation; Zelter P., SamSMU Moh Russia, Department of Radiology and Radiotherapy with the Course of Medicine Informatics Fsbei He, Samara, Russian Federation","In this article we investigate the efficiency of deep learning algorithms in solving the task of detecting anatomical reference points on radiological images of the head in lateral projection using a fully convolutional neural network and a fully convolutional neural network with an extended architecture for biomedical image segmentation - U-Net. A comparison is made for the results of detection anatomical reference points for each of the selected neural network architectures and their comparison with the results obtained when orthodontists detected anatomical reference points. Based on the obtained results, it was concluded that a U-Net neural network allows performing the detection of anatomical reference points more accurately than a fully convolutional neural network. The results of the detection of anatomical reference points by the U-Net neural network are closer to the average results of the detection of reference points by agroupoforthodontists. © 2020 IEEE.","biomedical imagery; convolution neural networks; deep learning; image processing; localization; orthodontic; radiological images; radiology; u-net","Bioinformatics; Convolution; Convolutional neural networks; Deep learning; Efficiency; Image segmentation; Nanotechnology; Network architecture; Biomedical image segmentation; Radiological images; Reference points; Learning algorithms","","","","","RF Ministry of Science and Higher Education, (007-GZ/Ch3363/26); Russian Foundation for Basic Research, РФФИ, (18-07-01390, 19-29-01135, 19-29-01235)","The work was partially funded by the Russian Foundation for Basic Research under grants No. 18-07-01390, 19-29-01235 and 19-29-01135 (theoretical results) and the RF Ministry of Science and Higher Education within the government project of the FSRC “Crystallography and Photonics” RAS under grant No. 007-GZ/Ch3363/26 (numerical calculations).","Persin L., Ortodontiia, Moskva:"" Inzhener, (2016); Alshahrani I., Kamran M., Alhaizaey A., Abumelha N., Evaluation of skeletal variations and establishment of Cephalometric Norms in Saudi Sub Population using Bjork Jarabak's analysis, Pakistan Journal of Medical Sciences, 34, 5, (2018); Gunenkova I., Samoylova N., Bondarets A., Optimization of diagnostics and orthodontic treatment planning in children and adolescents with multiply adentia, Stomatologiya, 94, 3, (2015); Desautels J., Rangayyan R., Mudigonda N., Gradient and texture analysis for the classification of mammographic masses, IEEE Transactions on Medical Imaging, 19, 10, pp. 1032-1043, (2000); Vasamsetti S., Sardana V., Kumar P., Kharbanda O., Sardana H., Automatic landmark identification in lateral cephalometric images using optimized template matching, Journal of Medical Imaging and Health Informatics, 5, 3, pp. 458-470, (2015); Shelhamer E., Long J., Darrell T., Fully convolutional networks for semantic segmentation, IEEE Transactions on Pattern Analysis and Machine Intelligence, 39, 4, pp. 640-651, (2017); Agafonova Y., Gaidel A., Zelter P., Kapishnikov A., Efficiency of machine learning algorithms and convolutional neural network for de-tection of pathological changes in MR images of the brain, Computer Optics, 44, 2, pp. 266-273, (2020); Press W., Teukolsky S., Vetterling W., Flannery B., Numerical Recipes, (2002); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, Medical Image Computing and Computer-Assisted Intervention-MICCAI, pp. 234-241, (2015); Kingma D., Ba J., Adam: A Method for Stochastic Optimization, (2020); Arnett G., Bergman R., Facial keys to orthodontic diagnosis and treatment planning. Part i, American Journal of Orthodontics and Dentofacial Orthopedics, 103, 4, pp. 299-312, (1993)","","","Institute of Electrical and Electronics Engineers Inc.","","6th IEEE International Conference on Information Technology and Nanotechnology, ITNT 2020","26 May 2020 through 29 May 2020","Virtual, Samara","165002","","978-172817041-1","","","English","Proc. ITNT - IEEE Int. Conf. Inf. Technol. Nanotechnol.","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85097611242"
"Zhang W.; Li Z.; Sun Z.; Jia K.; Feng J.","Zhang, Wanlong (57561548600); Li, Zhe (57040021800); Sun, Zhonghua (56035911600); Jia, Kebin (8659887500); Feng, Jinchao (55990624400)","57561548600; 57040021800; 56035911600; 8659887500; 55990624400","A novelty convolutional neural network based direct reconstruction for MRI guided diffuse optical tomography","2022","Progress in Biomedical Optics and Imaging - Proceedings of SPIE","11952","","119520B","","","","0","10.1117/12.2606836","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129183459&doi=10.1117%2f12.2606836&partnerID=40&md5=cf7215310351b7ae79cd081de91e5689","Beijing Key Laboratory of Computational Intelligence and Intelligent System, Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; Beijing Laboratory of Advanced Information Networks, Beijing, 100124, China","Zhang W., Beijing Key Laboratory of Computational Intelligence and Intelligent System, Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, Beijing Laboratory of Advanced Information Networks, Beijing, 100124, China; Li Z., Beijing Key Laboratory of Computational Intelligence and Intelligent System, Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, Beijing Laboratory of Advanced Information Networks, Beijing, 100124, China; Sun Z., Beijing Key Laboratory of Computational Intelligence and Intelligent System, Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, Beijing Laboratory of Advanced Information Networks, Beijing, 100124, China; Jia K., Beijing Key Laboratory of Computational Intelligence and Intelligent System, Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, Beijing Laboratory of Advanced Information Networks, Beijing, 100124, China; Feng J., Beijing Key Laboratory of Computational Intelligence and Intelligent System, Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China, Beijing Laboratory of Advanced Information Networks, Beijing, 100124, China","Diffuse Optical Tomography (DOT) is a promising non-invasive and relatively low-cost biomedical image technology. The aim of DOT is to reconstruct optical properties of the tissue from boundary measurements. However, the DOT reconstruction is a severely ill-posed problem. To reduce the ill-posedness of DOT and to improve image quality, imageguided DOT has attracted more attention. In this paper, a reconstruction algorithm for DOT is proposed based on the convolutional neural network (CNN). It uses both optical measurements and magnetic resonance imaging (MRI) images as the input of the CNN, and directly reconstructs the distribution of absorption coefficient. The merits of the proposed algorithm are without segmenting MRI images and modeling light propagation. The performance of the proposed algorithm is evaluated using numerical simulation experiments. Our results reveal that the proposed method can achieve superior performance compared with conventional reconstruction algorithms and other deep learning methods. Our result shows that the average SSIM of reconstructed images is above 0.88, and the average PSNR is more than 35 dB.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Convolutional neural network; Deep learning; Diffuse optical tomography; Image-guided reconstruction","Convolution; Convolutional neural networks; Deep learning; Image enhancement; Image reconstruction; Image segmentation; Optical data processing; Optical properties; Optical tomography; Biomedical images; Convolutional neural network; Deep learning; Diffuse optical tomography; Image-guided; Image-guided reconstruction; Low-costs; Network-based; Performance; Reconstruction algorithms; Magnetic resonance imaging","","","","","National Natural Science Foundation of China, NSFC, (82171992)","This paper is supported by the Project for the National Natural Science Foundation of China under Grants No. 82171992,","Shihab Uddin K. M., Menghao Zh., Anastasio M., Quing Zh, Optimal breast cancer diagnostic strategy using combined ultrasound and diffuse optical tomography, Biomed. Opt. Express, 11, pp. 2722-2737, (2020); Tromberg B. J., Pogue B. W., Paulsen K. D., Yodh A. G., Boas D. A., Cerussi A. E., Assessing the future of diffuse optical imaging technologies for breast cancer management, Medical Physics, 35, pp. 2443-2451, (2008); Zhu Q., Ricci A., Hegde P., Kane M., Cronin E., Cronin A., Merkulov Y. Xu., Tavakoli B., Tannenbaum S., Assessment of Functional Differences in Malignant and Benign Breast Lesions and Improvement of Diagnostic Accuracy by Using US-guided Diffuse Optical Tomography in Conjunction with Conventional US, Radiology, 280, 2, (2016); Boas D. A., Brooks D. H., Miller E. L., DiMarzio C. A., Kilmer M. R., Gaudette J., Quan Zh, Imaging the body with diffuse optical tomography, IEEE Signal Processing Magazine, 18, 6, pp. 57-75, (2001); Srinivasan S., Pogue B. W., Jiang S., Dehghani H., Kogel C., Soho S., Interpreting hemoglobin and water concentration, oxygen saturation, and scattering measured in vivo by near-infrared breast tomography, Proceedings of the National Academy of Sciences of the United States of America, 100, 21, pp. 12349-12354, (2003); Hebden J. C., Gibson A., Yusof R. M., Everdell N., Hillman E., Delpy D. T., Arridge S. R., Austin T., Meek J. H., Wyatt J. S., Three-dimensional optical tomography of the premature infant brain, Physics in Medicine & Biology, 47, 23, pp. 4155-4166, (2002); Carpenter C. M., Image-guided optical spectroscopy provides molecular-specific information in vivo: MRIguided spectroscopy of breast cancer hemoglobin, water, and scatterer size, Optics Letters, 32, pp. 933-935, (2007); Pogue B. W., Davis S. C., Leblond F., Mastanduno M. A., Dehghani H., Paulsen K. D., Implicit and explicit prior information in near-infrared spectral imaging: Accuracy, quantification and diagnostic value, Philos Trans A Math Phys Eng, 369, 1955, pp. 4531-4557, (2011); Quing Zhu, Edward B., Cronin Allen, Currier A., Benign versus malignant breast masses: optical differentiation with us-guided optical imaging reconstruction, Radiology, 237, pp. 57-66, (2005); Huiquan W., Nian W., Zhe Zh., Guang H., Jun Zh., Jinhai W., Continuous monitoring method of cerebral subdural hematoma based on MRI guided DOT, Biomed. Opt. Express, 11, pp. 2964-2975, (2020); Shiqi X., Uddin K. M., Quing Zh, Improving DOT reconstruction with a Born iterative method and USguided sparse regularization, Biomed. Opt. Express, 10, pp. 2528-2541, (2019); Brooksby B., Dehghani H., Pogue B. W., Paulsen K. D., Near-Infrared (NIR) Tomography for Breast Cancer Imaging, 3rd World Congress on Industrial Process Tomography, 9, 2, pp. 199-209, (2003); Intes X., Maloux C., Guven M., Yazici B., Chance B., Diffuse optical tomography with physiological and spatial a priori constraints, Physics in Medicine & Biology, 49, 12, pp. 155-163, (2004); Adler J., Oktem O., Solving ill-posed inverse problems using iterative deep neural networks, Inverse Problems, 33, 12, (2017); Cai C., Deng K., Ma C., Luo J., End-To-end deep neural network for optical inversion in quantitative photoacoustic imaging, Optics Letters, 43, 12, pp. 2752-2755, (2018); Gao Y., Wang K., An Y., Jiang S., Meng H., Tian J., Nonmodel-based bioluminescence tomography using a machine-learning reconstruction strategy, Optica, 5, 11, pp. 1451-1454, (2018); Guo L., Liu F., Cai C., Liu J., Zhang G., 3D deep encoder-decoder network for fluorescence molecular tomography, Optics Letters, 44, 8, pp. 1892-1895, (2019); Yu S., Xia Z., Kamilov U. S., Efficient and accurate inversion of multiple scattering with deep learning, Opt. Express, 26, 11, pp. 14678-14688, (2018); Zhang L., Zhao Y., Jiang S., Pogue B. W., Paulsen K. D., Direct regularization from co-registered anatomical images for MRI-guided near-infrared spectral tomographic image reconstruction, Biomed. Opt. Express, 6, 9, (2015); Feng J., Jiang S., Xu J., Zhao Y., Pogue B. W., Paulsen K. D., Multiobjective guided priors improve the accuracy of near-infrared spectral tomography for breast imaging, J. Biomed. Opt, 21, 9, (2016); Zhu B., Liu J., Cauley S., Rosen B., Rosen M., Image reconstruction by domain-Transform manifold learning, Nature, 555, pp. 487-492, (2018); Lan H., Jiang D., Yang C., Gao F., Gao F., Y-Net: Hybrid deep learning image reconstruction for photoacoustic tomography in vivo, Photoacoustics, 20, (2020); Dehghani H., Eames M. E., Yalavarthyetal P. K., Davis S. C., Srinivasan S., Carpenter C. M., Pogue B. W., Paulsen K. D., Near infrared optical tomography using NIRFAST: Algorithm for numerical model and image reconstruction, Commun. Num. Methods Eng, 25, 6, pp. 711-732, (2009); Pogue B. W., Song X., Tosteson T. D., McBride T. O., Jiang S., Paulsen K. D., Statistical analysis of nonlinearly reconstructed near-infrared tomographic images: part I-Theory and simulations, IEEE Trans. Med. Imaging, 21, 7, pp. 755-763, (2002); Cuadros A. P., Arce G. R., Coded aperture optimization in compressive X-ray tomography: A gradient descent approach, Opt. Express, 25, 20, pp. 23833-23849, (2017); Wang Z., Bovik A. C., Sheikh H. R., Simoncelli E. P., Image quality assessment: from error visibility to structural similarity, IEEE Trans. Med Imaging, 13, 4, pp. 600-612, (2004)","J. Feng; Beijing Key Laboratory of Computational Intelligence and Intelligent System, Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China; email: fengjc@bjut.edu.cn","Azar F.S.; Intes X.; Fang Q.","SPIE","The Society of Photo-Optical Instrumentation Engineers (SPIE)","Multimodal Biomedical Imaging XVII 2022","22 January 2022 through 27 January 2022","San Francisco","178872","16057422","978-151064775-6","","","English","Progr. Biomed. Opt. Imaging Proc. SPIE","Conference paper","Final","","Scopus","2-s2.0-85129183459"
"Pang S.; Du A.; Orgun M.A.; Yu Z.","Pang, Shuchao (55639762100); Du, Anan (56167972000); Orgun, Mehmet A. (6603681610); Yu, Zhezhou (8938987700)","55639762100; 56167972000; 6603681610; 8938987700","A novel fused convolutional neural network for biomedical image classification","2019","Medical and Biological Engineering and Computing","57","1","","107","121","14","63","10.1007/s11517-018-1819-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049792899&doi=10.1007%2fs11517-018-1819-y&partnerID=40&md5=8ca3352a38bcbdb12e2a314503d6dec5","Department of Computational Intelligence, College of Computer Science and Technology, Jilin University, Qianjin Street 2699, Changchun, Jilin Province, China; Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; China Mobile (HangZhou) Information Technology Co., Ltd, Hangzhou, China","Pang S., Department of Computational Intelligence, College of Computer Science and Technology, Jilin University, Qianjin Street 2699, Changchun, Jilin Province, China, Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Du A., China Mobile (HangZhou) Information Technology Co., Ltd, Hangzhou, China; Orgun M.A., Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Yu Z., Department of Computational Intelligence, College of Computer Science and Technology, Jilin University, Qianjin Street 2699, Changchun, Jilin Province, China","With the advent of biomedical imaging technology, the number of captured and stored biomedical images is rapidly increasing day by day in hospitals, imaging laboratories and biomedical institutions. Therefore, more robust biomedical image analysis technology is needed to meet the requirement of the diagnosis and classification of various kinds of diseases using biomedical images. However, the current biomedical image classification methods and general non-biomedical image classifiers cannot extract more compact biomedical image features or capture the tiny differences between similar images with different types of diseases from the same category. In this paper, we propose a novel fused convolutional neural network to develop a more accurate and highly efficient classifier for biomedical images, which combines shallow layer features and deep layer features from the proposed deep neural network architecture. In the analysis, it was observed that the shallow layers provided more detailed local features, which could distinguish different diseases in the same category, while the deep layers could convey more high-level semantic information used to classify the diseases among the various categories. A detailed comparison of our approach with traditional classification algorithms and popular deep classifiers across several public biomedical image datasets showed the superior performance of our proposed method for biomedical image classification. In addition, we also evaluated the performance of our method in modality classification of medical images using the ImageCLEFmed dataset. [Figure not available: see fulltext.]. © 2018, International Federation for Medical and Biological Engineering.","Biomedical image classification; Convolutional neural networks; Deep feature; Deep learning; Shallow feature","Bioinformatics; Classification (of information); Classifiers; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Medical imaging; Network architecture; Neural networks; Semantics; Biomedical image analysis; Biomedical imaging; Classification algorithm; Classification methods; Convolutional neural network; Deep feature; High level semantics; Shallow feature; Article; classification algorithm; convolutional neural network; digital imaging and communications in medicine; diseases; feature extraction; human; image analysis; intermethod comparison; k nearest neighbor; learning algorithm; machine learning; nuclear magnetic resonance imaging; priority journal; support vector machine; Image classification","","","","","","","Andreu-Perez J., Poon C.C., Merrifield R.D., Wong S.T., Yang G.Z., Big data for health, IEEE JBHI, 19, 4, pp. 1193-1208, (2015); Depeursinge A., Van de Ville D., Platon A., Geissbuhler A., Poletti P.A., Muller H., Near-affine-invariant texture learning for lung tissue analysis using isotropic wavelet frames, IEEE Trans Inf Technol Biomed, 16, 4, pp. 665-675, (2012); Song Y., Cai W., Huang H., Zhou Y., Feng D.D., Wang Y., Fulham M.J., Chen M., Large margin local estimate with applications to medical image classification, IEEE Trans Med Imaging, 34, 6, pp. 1362-1377, (2015); Khachane M.Y., Ramteke R.J., Modality based medical image classification, Emerging Research in Computing, Information, Communication and Applications, pp. 597-606, (2016); Ertugrul O.F., Kaya Y., Tekin R., A novel approach for SEMG signal classification with adaptive local binary patterns, Med Biol Eng Comput, 54, 7, pp. 1137-1146, (2016); Li Q., Cai W., Wang X., Zhou Y., Feng D.D., Chen M., Medical image classification with convolutional neural network, Control Automation Robotics & Vision (ICARCV), 13Th IEEE International Conference On, pp. 844-848, (2014); Gao Z., Zhang J., Zhou L., Wang L., HEp-2 cell image classification with convolutional neural networks, Pattern Recognition Techniques for Indirect Immunofluorescence Images (I3A), pp. 24-28, (2014); Abbas Q., Fondon I., Sarmiento A., Jimenez S., Alemany P., Automatic recognition of severity level for diagnosis of diabetic retinopathy using deep visual features, Med Biol Eng Comput, pp. 1-16, (2017); Ahn E., Kumar A., Kim J., Li C., Feng D., Fulham M., X-ray image classification using domain transferred convolutional neural networks and local sparse spatial pyramid, IEEE 13Th ISBI, pp. 855-858, (2016); Phan H.T.H., Kumar A., Kim J., Feng D., Transfer learning of a convolutional neural network for HEp-2 cell image classification, IEEE 13Th ISBI, pp. 1208-1211, (2016); Pang S., Yu Z., Orgun M.A., A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images, Comput Methods Prog Biomed, 140, pp. 283-293, (2017); Shi J., Wu J., Li Y., Zhang Q., Ying S., Histopathological image classification with color pattern random binary hashing-based PCANet and matrix-form classifier, IEEE J Biomed Health Inform, 21, 5, pp. 1327-1337, (2017); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Ouyang W., Wang X., Zhang C., Yang X., Factors in finetuning deep model for object detection with long-tail distribution, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 864-873, (2016); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, (2015); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, (2014); Long M., Wang J., Jordan M.I., Deep Transfer Learning with Joint Adaptation Networks, (2016); Jia Y., Shelhamer E., Donahue J., Karayev S., Long J., Girshick R., Guadarrama S., Darrell T., Caffe: Convolutional architecture for fast feature embedding, Proceedings of the 22Nd ACM International Conference on Multimedia, pp. 675-678, (2014); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Murala S., Wu Q.M., Peak valley edge patterns: A new descriptor for biomedical image indexing and retrieval, Proc. IEEE CVPR Workshops, pp. 444-449, (2013); Dubey S.R., Singh S., Singh R., Local bit-plane decoded pattern: a novel feature descriptor for biomedical image retrieval, IEEE J Biomed Health Inform, 20, 4, pp. 1139-1147, (2015); (2012); Clark K., Vendt B., Smith K., Freymann J., Kirby J., Koppel P., Moore S., Phillips S., Maffitt D., Pringle M., Tarbox L., The Cancer Imaging Archive (TCIA): maintaining and operating a public information repository, J Digit Imaging, 26, 6, pp. 1045-1057, (2013); Marcus D.S., Wang T.H., Parker J., Csernansky J.G., Morris J.C., Buckner R.L., Open Access Series of Imaging Studies (OASIS): cross-sectional MRI data in young, middle aged, nondemented, and demented older adults, J Cogn Neurosci, 19, 9, pp. 1498-1507, (2007); de Herrera A.G.S., Muller H., Bromuri S., Overview of the ImageCLEF 2015 Medical Classification Task, CLEF (Working Notes), (2015); Kalpathy-Cramer J., de Herrera A.G.S., Demner-Fushman D., Antani S., Bedrick S., Muller H., Evaluating performance of biomedical image retrieval systems—an overview of the medical image retrieval task at ImageCLEF 2004–2013, Comput Med Imaging Graph, 39, pp. 55-61, (2015); Pelka O., Friederich C.M., FHDO Biomedical Computer Science Group at Medical Classification Task of ImageCLEF 2015, CLEF (Working Notes), (2015); Cirujeda P., Binefa X., Medical image classification via 2D color feature based covariance descriptors, CLEF (Working Notes), (2015); Lyndon D., Kumar A., Kim J., Leong P.H.W., Feng D., Convolutional neural networks for subfigure classification, CLEF (Working Notes), (2015); Laurens Van D.M., Accelerating t-SNE using tree-based algorithms, J Mach Learn Res, 15, 1, pp. 3221-3245, (2014); Rippel O., Paluri M., Dollar P., Bourdev L., Metric Learning with Adaptive Density Discrimination, (2015)","Z. Yu; Department of Computational Intelligence, College of Computer Science and Technology, Jilin University, Changchun, Qianjin Street 2699, China; email: yuzz@jlu.edu.cn","","Springer Verlag","","","","","","01400118","","MBECD","","English","Med. Biol. Eng. Comput.","Article","Final","","Scopus","2-s2.0-85049792899"
"Habib G.; Qureshi S.","Habib, Gousia (57221589277); Qureshi, Shaima (26325864200)","57221589277; 26325864200","Biomedical Image Classification using CNN by Exploiting Deep Domain Transfer Learning","2021","International Journal of Computing and Digital Systems","10","1","","1075","1083","8","7","10.12785/ijcds/100197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122768002&doi=10.12785%2fijcds%2f100197&partnerID=40&md5=f3f6430ee3623ef8a7289af25c067020","Department of Computer Science and Engineering, National Institute of Technology, Srinagar, India","Habib G., Department of Computer Science and Engineering, National Institute of Technology, Srinagar, India; Qureshi S., Department of Computer Science and Engineering, National Institute of Technology, Srinagar, India","Accurate biomedical image classification is essential for the clinical investigation of different hazardous maladies. A fair diagnosis of the disease is essential to provide proper treatment and to save precious human lives. Classification methods that support handcrafted features and use artificial neural networks trained with restricted data-set cannot viably enhance the precision rate and meet the stipulations for classification of biomedical images End-to-End deep learning machines empowers direct mapping from crude information to the desired output, eliminating the need for handcrafted features. Deep learning has proven as a powerful classification method as evidenced by its success in recent computer vision competitions. A unique deep convolutional neural network (CNN) model for brain tumor classification has been proposed in this paper. The model tested on the OASIS MRI data-set and gives an average accuracy of 90:84%. The present model is based on a pre- trained vgg-19 model on a large Image-Net database. Novel CNN model does not require training from scratch wasting weeks or days, rather uses transfer learning for knowledge distillation. Also to further enhance the training acceleration other optimization methods have been used, weights are initialized by the Gaussian initialization method followed by the ReLu activation function. ADAMS SGD optimization has been used and a drop-out algorithm is implemented to get rid of the overfitting of the model. The model when implemented on the biomedical image dataset has achieved the highest classification accuracy rate, outperforming all existing techniques with lesser training time. © 2021 University of Bahrain. All rights reserved.","ADAMS; CNN; CONVONET; FC; HOG; LRN; MRI; OASIS; PHT; ReLu; SGD; SIFT; Soft-max","","","","","","","","Chaplot S., Patnaik L.M., Jagannathan N.R., Classification of magnetic resonance brain images using wavelets as input to support vector machine and neural network, Biomed. Signal Process Control, 1, 1, pp. 86-92, (2006); Zhang Y. D., Wu L., Wang S., Magnetic resonance brain image classification by an improved artificial bee colony algorithm, Progress in Electromagnetics Research, 116, pp. 65-79, (2011); Maitra M., Chatterjee A., A Slant let transform-based intelligent system for magnetic resonance brain image classification, Biomedical Signal Processing and Control, 1, 4, pp. 299-306, (2011); Zhang Y. D., Wu L., An MR brain images classifier via principal component analysis and kernel support vector machine, Progress in Electromagnetics Research, 130, pp. 369-388, (2012); Kumar S., Dabas C., Godara S., Classification of brain MRI tumor images: A hybrid approach, Information Technology and Quantitative Management (Itqm2017) Procedia Computer Science, 122, pp. 510-517, (2017); Natteshan N.V.S., Angel A.J.J., Automatic classification of brain MRI images using SVM and neural network classifiers, Advances in Intelligent Informatics. Advances in Intelligent Systems and Computing, 320, pp. 19-30, (2015); Ibrahim W.H., Osman A.A.A., Mohamed Y.I., MRI brain image classification using neural networks, Proceedings of International Conference on Computing, Electrical and Electronic Engineering (ICCEEE 2013), pp. 253-258, (2013); Felzenszwalb PF, Girshick RB, McAllister D, Ramanan D, Object detection with discriminatively trained part-based models, IEEE Trans. Pattern Analysis and Machine Intelligence, 32, 9, pp. 1627-1645, (2010); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Communications ACM, 60, 6, pp. 84-90, (2017); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., van der Laak JAWM., van Ginneken B., Sanchez CI., A survey on deep learning in medical image analysis, Medical Image Analysis, 42, pp. 60-88, (2017); Razzak M.I., Naz S., Zaib A., Deep learning for medical image processing' Overview, Challenges and the Future, Classification in BioApps. Lecture Notes in Computational Vision and Biomechanics, 26, pp. 323-359, (2018); Neuberger C., Evaluation of convolutional neural networks for visual recognition, IEEE Trans Neural Net w, 9, pp. 685-695, (1998); IEEE Transactions on Pattern Analysis and Machine Intelligence, 35, 8, (2013); Bengio Y., Courville A., Vincent P., Representation learning: A review and new perspectives, Pattern Analysis and Machine Intelligence, 35, 8, pp. 1798-1828, (2013); Ertas G, Gulcur H.O, Osman O, Ucan O.N, Tunaci M, Dursun M., MR segmentation and lesion detection with cellular neural networks and 3D template matching, Computers, Biology, and Medicine, 38, 1, pp. 116-126, (2008); Sampaio WB, Diniz EM, Silva AC, de Paiva AC, Gattass M., Detection of masses in mammogram images using CNN' Geostatistic Functions and SVM, Computers in Biology and Medicine, 41, pp. 653-664, (2011); Anthimopoulos M, Christodoulidis S, Ebner L, Christe A, Mougiakakou S, Lung pattern classification for interstitial lung diseases using a deep convolutional neural network, Medical Imaging, 35, 5, pp. 1207-1216, (2016); Taj bakhsh N., Suzuki K., Comparing two classes of end-to-end machine learning models in lung nodule detection and classification MANNS VS, CNN' Pattern Recognition, 63, pp. 476-486, (2017); Mohsen H, El-Dahshan ES, El-Horbaty ES, Salem A.B, Classification using deep learning neural networks for brain tumors, Future Computing and Informatics Journal, 3, 1, pp. 68-71, (2018); Annual international conference of IEEE engineering in machine and Biology society; Antony A., Ancy Brigit M.A, Fathima K.A., Raju D, Binish M.C., Brain tumor detection and classification in MRI images, International Journal of Innovative Research in Science, Engineering and Technology, 6, 5, pp. 84-89, (2017); Milletari F., Ahmadi S. A, . C Kroll, Maiostre J., Levin J., Ertl-Wagner B., Boetzel K., Hough-CNN: Deep learning for segmentation of deep brain regions in MRI and ultrasound, Computer Vision and Image Understanding, 164, pp. 92-102, (2017); Cheng Jun, Brain Tumor Dataset' Figshare, (2017); Pang S., Yu Z., Orgun M. A., A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images, Computer methods and programs in biomedicine, 140, pp. 283-293, (2017)","G. Habib; Department of Computer Science and Engineering, National Institute of Technology, Srinagar, India; email: Gousiahabib_01phd19@nitsri.net","","University of Bahrain","","","","","","2210142X","","","","English","Int. J. Comput. Digit. Syst.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122768002"
"Xie Y.; Xing F.; Shi X.; Kong X.; Su H.; Yang L.","Xie, Yuanpu (56903340500); Xing, Fuyong (38461688800); Shi, Xiaoshuang (56029222900); Kong, Xiangfei (55613407300); Su, Hai (44661704600); Yang, Lin (55771607100)","56903340500; 38461688800; 56029222900; 55613407300; 44661704600; 55771607100","Efficient and robust cell detection: A structured regression approach","2018","Medical Image Analysis","44","","","245","254","9","96","10.1016/j.media.2017.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026880496&doi=10.1016%2fj.media.2017.07.003&partnerID=40&md5=d73d834859cceefb038129b72398e8cb","Department of Biomedical Engineering, University of Florida, FL 32611, United States; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, 32611, United States; School of Electrical and Electronic Engineering, Nanyang Technological University, Nanyang Drive 637553, Singapore","Xie Y., Department of Biomedical Engineering, University of Florida, FL 32611, United States; Xing F., Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, 32611, United States; Shi X., Department of Biomedical Engineering, University of Florida, FL 32611, United States; Kong X., School of Electrical and Electronic Engineering, Nanyang Technological University, Nanyang Drive 637553, Singapore; Su H., Department of Biomedical Engineering, University of Florida, FL 32611, United States; Yang L., Department of Biomedical Engineering, University of Florida, FL 32611, United States, Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, 32611, United States","Efficient and robust cell detection serves as a critical prerequisite for many subsequent biomedical image analysis methods and computer-aided diagnosis (CAD). It remains a challenging task due to touching cells, inhomogeneous background noise, and large variations in cell sizes and shapes. In addition, the ever-increasing amount of available datasets and the high resolution of whole-slice scanned images pose a further demand for efficient processing algorithms. In this paper, we present a novel structured regression model based on a proposed fully residual convolutional neural network for efficient cell detection. For each testing image, our model learns to produce a dense proximity map that exhibits higher responses at locations near cell centers. Our method only requires a few training images with weak annotations (just one dot indicating the cell centroids). We have extensively evaluated our method using four different datasets, covering different microscopy staining methods (e.g., H & E or Ki-67 staining) or image acquisition techniques (e.g., bright-filed image or phase contrast). Experimental results demonstrate the superiority of our method over existing state of the art methods in terms of both detection accuracy and running time. © 2017","Biomedical image analysis; Cell detection; Deep learning; Structured regression","Algorithms; Bone Marrow Cells; Breast Neoplasms; Cytological Techniques; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Neural Networks (Computer); Neuroendocrine Tumors; Reproducibility of Results; Sensitivity and Specificity; Uterine Cervical Neoplasms; Cells; Computer aided analysis; Computer aided diagnosis; Cytology; Deep learning; Neural networks; Regression analysis; eosin; hematoxylin; Biomedical image analysis; Cell detection; Computer Aided Diagnosis(CAD); Convolutional neural network; Detection accuracy; Processing algorithms; State-of-the-art methods; Structured regression; Article; breast cancer; cell detection; controlled study; image analysis; microscopy; neuroendocrine tumor; phase contrast microscopy; priority journal; procedures concerning cells; staining; uterine cervix cancer; algorithm; artificial neural network; bone marrow cell; breast tumor; computer assisted diagnosis; cytology; female; human; pathology; procedures; reproducibility; sensitivity and specificity; uterine cervix tumor; Image analysis","","eosin, 17372-87-1, 51395-88-1, 548-26-5; hematoxylin, 517-28-2","","","National Institutes of Health, NIH; National Institute of Arthritis and Musculoskeletal and Skin Diseases, NIAMS, (R01AR065479)"," We acknowledge the authors of Kainz et al. (2015) and Arteta et al. (2012) for sharing their dataset. This research is supported by NIH grant R01 AR065479-02 .    ","Al-Kofahi Y., Lassoued W., Lee W., Roysam B., Improved automatic detection and segmentation of cell nuclei in histopathology images, Biomed. Eng., IEEE Trans., 57, 4, pp. 841-852, (2010); Ali S., Madabhushi A., An integrated region-, boundary-, shape-based active contour for multiple object overlap resolution in histological imagery, Med. Imaging, IEEE Trans., 31, 7, pp. 1448-1460, (2012); Arteta C., Lempitsky V., Noble J.A., Zisserman A., Learning to detect cells using non-overlapping extremal regions, Medical Image Computing and Computer-Assisted Intervention MICCAI 2012, 7510, pp. 348-356, (2012); Bastien F., Lamblin P., Pascanu R., Bergstra J., Goodfellow I.J., Bergeron A., Bouchard N., Bengio Y., Theano: new features and speed improvements, Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop, (2012); Bergstra J., Breuleux O., Bastien F., Lamblin P., Pascanu R., Desjardins G., Turian J., Warde-Farley D., Bengio Y., Theano: a CPU and GPU math expression compiler, Proceedings of the Python for Scientific Computing Conference (SciPy), (2010); Bernardis E., Yu S.X., Finding dots: segmentation as popping out regions from boundaries, CVPR, pp. 199-206, (2010); Bertelli L., Yu T., Vu D., Gokturk B., Kernelized structural SVM learning for supervised object segmentation, The 24th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2011, pp. 2153-2160, (2011); Byun J., Verardo M.R., Sumengen B., Lewis G., Manjunath B.S., Fisher S.K., Automated tool for the detection of cell nuclei in digital microscopic images: application to retinal images, Mol. Vis., 12, pp. 949-960, (2006); Chen L., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Deeplab: semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs, (2016); Chollet F., keras, (2015); Christ P.F., Elshaer M.E.A., Ettlinger F., Tatavarty S., Bickel M., Bilic P., Rempfler M., Armbruster M., Hofmann F., D'Anastasi M., Sommer W.H., Ahmadi S.-A., Menze B.H., Automatic Liver and Lesion Segmentation in CT Using Cascaded Fully Convolutional Neural Networks and 3D Conditional Random Fields, pp. 415-423, (2016); Ciresan D., Giusti A., Gambardella L.M., Schmidhuber J., Mitosis detection in breast cancer histology images with deep neural networks, Medical Image Computing and Computer-Assisted Intervention MICCAI 2013, 8150, pp. 411-418, (2013); Ciresan D.C., Giusti A., Gambardella L.M., Schmidhuber J., Deep neural networks segment neuronal membranes in electron microscopy images, 26th Annual Conference on Neural Information Processing Systems NIPS 2012., pp. 2852-2860, (2012); Clevert D.-A., Unterthiner T., Hochreiter S., Fast and accurate deep network learning by exponential linear units (elus), International Conference on Learning Representations, (2015); Cosatto E., Miller M., Graf H., Meyer J., Grading nuclear pleomorphism on histological micrographs, Pattern Recognition, 2008. ICPR 2008. 19th International Conference on, pp. 1-4, (2008); Cruz-Roa A., Arevalo-Ovalle J., Madabhushi A., Gonzalez-Osorio F., A deep learning architecture for image representation, visual interpretability and automated basal-cell carcinoma cancer detection, Medical Image Computing and Computer-Assisted Intervention MICCAI 2013, 8150, pp. 403-410, (2013); Cruz-Roa A.A., Ovalle J.E.A., Madabhushi A., Osorio F.A.G., A deep learning architecture for image representation, visual interpretability and automated basal-cell carcinoma cancer detection, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2013, pp. 403-410, (2013); Dhall D., Mertens R., Bresee C., Parakh R., Wang H.L., Li M., Dhall G., Colquhoun S.D., Ines D., Chung F., Yu R., Nissen N.N., Wolin E., Ki-67 proliferative index predicts progression-free survival of patients with well-differentiated ileal neuroendocrine tumors, Hum. Pathol., 43, pp. 489-495, (2012); Fakhry A., Zeng T., Ji S., Residual deconvolutional networks for brain electron microscopy image segmentation, IEEE Trans. Med. Imaging, 99, (2016); Gurcan M.N., Boucheron L.E., Can A., Madabhushi A., Rajpoot N.M., Yener B., Histopathological image analysis: a review, Biomed. Eng., IEEE Rev., 2, pp. 147-171, (2009); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, (2015); He K., Zhang X., Ren S., Sun J., Identity mappings in deep residual networks, Computer Vision–ECCV 2016, (2016); Irshad H., Automated mitosis detection in histopathology using morphological and multi-channel statistics features, J. Pathol. Inform., 4, (2013); Kainz P., Urschler M., Schulter S., Wohlhart P., Lepetit V., You should use regression to detect cells, Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015, 9351, pp. 276-283, (2015); Kong H., Gurcan M.N., Belkacem-Boussaid K., Partitioning histopathological images: an integrated framework for supervised color-texture segmentation and cell splitting, IEEE Trans. Med. Imaging, 30, 9, pp. 1661-1677, (2011); Laina I., Rupprecht C., Belagiannis V., Tombari F., Navab N., Deeper depth prediction with fully convolutional residual networks, 2016 International Conference on 3D Vision, 3DV 2016, Stanford, California, USA, (2016); LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-Based learning applied to document recognition, Proc. IEEE, 86, 11, pp. 2278-2324, (1998); Li R., Zhang W., Suk H.-I., Wang L., Li J., Shen D., Ji S., Deep learning based imaging data completion for improved brain disease diagnosis, Medical Image Computing and Computer-Assisted Intervention MICCAI 2014, 8675, pp. 305-312, (2014); Liao S., Gao Y., Oto A., Shen D., Representation learning: a unified deep learning framework for automatic prostate mr segmentation, Medical Image Computing and Computer-Assisted Intervention MICCAI 2013, 8150, pp. 254-261, (2013); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, CVPR (to appear), (2015); (2013); Noh H., Hong S., Han B., (2015); Parvin B., Yang Q., Han J., Chang H., Rydberg B., Barcellos-Hoff M.H., Iterative voting for inference of structural saliency and characterization of subcellular events, IEEE Trans. Image Process., 16, 3, pp. 615-623, (2007); Qi X., Xing F., Foran D.J., Yang L., Robust segmentation of overlapping cells in histopathology specimens using parallel seed detection and repulsive level set, IEEE Trans. Biomed. Eng., 59, 3, pp. 754-765, (2012); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional Networks for Biomedical Image Segmentation, pp. 234-241, (2015); Shah A., Kadam E., Shah H., Shinde S., Deep residual networks with exponential linear unit, CoRR, abs/1604.04112, (2016); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, CoRR, abs/1409.1556, (2014); Sirinukunwattana K., Ahmed Raza S.E., Tsang Y.-W., Snead D., Cree I., Rajpoot N., Patch-Based Techniques in Medical Imaging: First International Workshop, Patch-MI 2015, Held in Conjunction with MICCAI 2015, Munich, Germany, October 9, 2015, Revised Selected Papers, pp. 154-162, (2015); Sirinukunwattana K., Raza S., Tsang Y.W., Snead D., Cree I., Rajpoot N., Locality sensitive deep learning for detection and classification of nuclei in routine colon cancer histology images, IEEE Trans Med Imaging, PP, 99, (2016); Sironi A., Lepetit V., Fua P., Multiscale centerline detection by learning a scale-space distance transform, 2014  IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2014, Columbus, OH, USA, June 23–28, 2014, pp. 2697-2704, (2014); Su H., Xing F., Kong X., Xie Y., Zhang S., Yang L., Robust cell detection and segmentation in histopathological images using sparse reconstruction and stacked denoising autoencoders, Medical Image Computing and Computer-Assisted Intervention MICCAI 2015, 9351, pp. 383-390, (2015); Szegedy C., Ioffe S., Vanhoucke V., Alemi A.A., Inception-v4, inception-resnet and the impact of residual connections on learning, ICLR 2016 Workshop, (2016); Veta M., Pluim J., van Diest P., Viergever M., Breast cancer histopathology image analysis: a review, IEEE Trans. Biomed. Eng., 61, 5, pp. 1400-1411, (2014); Vink J.P., VAN Leeuwen M.B., van Deurzen C.H.M., de Haan G., Efficient nucleus detector in histopathology images, J. Microsc., 249, pp. 124-135, (2012); Wang Y., Sun Z., Liu C., Peng W., Zhang J., Mri image segmentation by fully convolutional networks, 2016 IEEE International Conference on Mechatronics and Automation, pp. 1697-1702, (2016); Xie S., Tu Z., Holistically-nested edge detection, Proceedings of the IEEE International Conference on Computer Vision, pp. 1395-1403, (2015); Xie W., Noble J.A., Zisserman A., Microscopy cell counting with fully convolutional regression networks, MICCAI 1st Workshop on Deep Learning in Medical Image Analysis, (2015); Xie Y., Kong X., Xing F., Liu F., Su H., Yang L., Deep voting: a robust approach toward nucleus localization in microscopy images, Medical Image Computing and Computer-Assisted Intervention MICCAI 2015, 9351, pp. 374-382, (2015); Xie Y., Xing F., Kong X., Su H., Yang L., Beyond classification: structured regression for robust cell detection using convolutional neural network, Medical Image Computing and Computer-Assisted Intervention -MICCAI 2015, 9351, pp. 358-365, (2015); Xing F., Su H., Yang L., An integrated framework for automatic ki-67 scoring in pancreatic neuroendocrine tumor, Medical Image Computing and Computer-Assisted Intervention -MICCAI 2013, pp. 436-443, (2013); Xing F., Xie Y., Yang L., An automatic learning-based framework for robust nucleus segmentation, Med. Imaging, IEEE Trans., PP, 99, (2015); Xing F., Yang L., Robust nucleus/cell detection and segmentation in digital pathology and microscopy images: a comprehensive review, Accepted to Biomedical Engineering, IEEE Reviews in, PP, 99, (2016); Xu J., Xiang L., Liu Q., Gilmore H., Wu J., Tang J., Madabhushi A., Stacked sparse autoencoder (ssae) for nuclei detection on breast cancer histopathology images, IEEE Trans. Med. Imaging, 35, 1, pp. 119-130, (2015); Yang J., Price B., Cohen S., Lee H., Yang M.-H., Object contour detection with a fully convolutional encoder-decoder network, Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on, (2016); Yang L., Tuzel O., Meer P., Foran D., Automatic image analysis of histopathology specimens using concave vertex graph, Medical Image Computing and Computer-Assisted Intervention MICCAI 2008, 5241, pp. 833-841, (2008); Zeiler M.D., ADADELTA: an adaptive learning rate method, CoRR, abs/1212.5701, (2012); Zhang C., Yarkony J., Hamprecht F.A., Cell detection and segmentation using correlation clustering, Medical Image Computing and Computer-Assisted Intervention -MICCAI 2014, 8673, pp. 9-16, (2014); Zheng S., Jayasumana S., Romera-Paredes B., Vineet V., Su Z., Du D., Huang C., Torr P.H.S., Conditional random fields as recurrent neural networks, ICCV, (2015)","Y. Xie; Department of Biomedical Engineering, University of Florida, FL 32611, United States; email: shampool@ufl.edu","","Elsevier B.V.","","","","","","13618415","","MIAEC","28797548","English","Med. Image Anal.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85026880496"
"Ashraf R.; Habib M.A.; Akram M.; Latif M.A.; Malik M.S.A.; Awais M.; Dar S.H.; Mahmood T.; Yasir M.; Abbas Z.","Ashraf, Rehan (56704783800); Habib, Muhammad Asif (35772504100); Akram, Muhammad (57217541926); Latif, Muhammad Ahsan (58583401200); Malik, Muhammad Sheraz Arshad (57505246800); Awais, Muhammad (57224215215); Dar, Saadat Hanif (57203841811); Mahmood, Toqeer (56081146500); Yasir, Muhammad (57215783658); Abbas, Zahoor (57217381928)","56704783800; 35772504100; 57217541926; 58583401200; 57505246800; 57224215215; 57203841811; 56081146500; 57215783658; 57217381928","Deep Convolution Neural Network for Big Data Medical Image Classification","2020","IEEE Access","8","","9104735","105659","105670","11","57","10.1109/ACCESS.2020.2998808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087166459&doi=10.1109%2fACCESS.2020.2998808&partnerID=40&md5=c58fd8faf01b060649a0a0b898d1a6dc","Department of Computer Science, National Textile University, Faisalabad, 37610, Pakistan; Department of Software Engineering, Balochistan University of Information Technology, Engineering and Management Sciences, Quetta, 87300, Pakistan; Department of Computer Science, University of Agriculture, Faisalabad, 38000, Pakistan; Department of Information Technology, Government College University Faisalabad, Faisalabad, 38000, Pakistan; Department of Software Engineering, Government College University Faisalabad, Faisalabad, 38000, Pakistan; Department of Software Engineering, Mirpur University of Science and Technology (MUST), Mirpur, 10250, Pakistan; Department of Computer Science, University of Engineering and Technology Lahore, Faisalabad, 38090, Pakistan","Ashraf R., Department of Computer Science, National Textile University, Faisalabad, 37610, Pakistan; Habib M.A., Department of Computer Science, National Textile University, Faisalabad, 37610, Pakistan; Akram M., Department of Software Engineering, Balochistan University of Information Technology, Engineering and Management Sciences, Quetta, 87300, Pakistan; Latif M.A., Department of Computer Science, University of Agriculture, Faisalabad, 38000, Pakistan; Malik M.S.A., Department of Information Technology, Government College University Faisalabad, Faisalabad, 38000, Pakistan; Awais M., Department of Software Engineering, Government College University Faisalabad, Faisalabad, 38000, Pakistan; Dar S.H., Department of Software Engineering, Mirpur University of Science and Technology (MUST), Mirpur, 10250, Pakistan; Mahmood T., Department of Computer Science, National Textile University, Faisalabad, 37610, Pakistan; Yasir M., Department of Computer Science, University of Engineering and Technology Lahore, Faisalabad, 38090, Pakistan; Abbas Z., Department of Computer Science, National Textile University, Faisalabad, 37610, Pakistan","Deep learning is one of the most unexpected machine learning techniques which is being used in many applications like image classification, image analysis, clinical archives and object recognition. With an extensive utilization of digital images as information in the hospitals, the archives of medical images are growing exponentially. Digital images play a vigorous role in predicting the patient disease intensity and there are vast applications of medical images in diagnosis and investigation. Due to recent developments in imaging technology, classifying medical images in an automatic way is an open research problem for researchers of computer vision. For classifying the medical images according to their relevant classes a most suitable classifier is most important. Image classification is beneficial to predict the appropriate class or category of unknown images. The less discriminating ability and domain-specific categorization are the main drawbacks of low-level features. A semantic gap that exists between features of low-level as machine understanding and features of human understanding as high-level perception. In this research, a novel image representation method is proposed where the algorithm is trained for classifying medical images by deep learning technique. A pre-trained deep convolution neural network method with the fine-tuned approach is applied to the last three layers of deep neural network. The results of the experiment exhibit that our method is best suited to classify various medical images for various body organs. In this manner, data can sum up to other medical classification applications which supports radiologist's efforts for improving diagnosis. © 2013 IEEE.","big data; biomedical image processing; convolution neural network; deep learning; image analysis; image enhancement; Medical image classification; pre-trained DCNN","Big data; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Learning algorithms; Learning systems; Medical imaging; Multilayer neural networks; Object recognition; Semantics; Convolution neural network; Discriminating abilities; Human understanding; Image representations; Learning techniques; Machine learning techniques; Machine understanding; Medical classification; Image classification","","","","","","","Zhu Q., Du B., Yan P., Boundary-weighted domain adaptive neural network for prostate MR image segmentation, IEEE Trans. Med. Imag., 39, 3, pp. 753-763, (2020); Zhu Q., Du B., Yan P., Lu H., Zhang L., Shape prior constrained PSO model for bladder wall MRI segmentation, Neurocomputing, 294, pp. 19-28, (2018); Zhu Q., Du B., Turkbey B., Choyke P., Yan P., Exploiting interslice correlation for MRI prostate image segmentation, from recursive neural networks aspect, Complexity, 2018, pp. 1-10, (2018); Kranthi Kumar K., Gopal T.V., A novel approach to self order feature reweighting in CBIR to reduce semantic gap using relevance feedback, Proc. Int. Conf. Circuits, Power Comput. Technol. (ICCPCT), pp. 1437-1442, (2014); Ashraf R., Baiwa K.B., Mahmood T., Content-based image retrieval by exploring bandletized regions through support vector machines, J. Inf. Sci. Eng., 32, 2, pp. 245-269, (2016); Wan J., Wang D., Hoi S.C.H., Wu P., Zhu J., Zhang Y., Li J., Deep learning for content-based image retrieval: A comprehensive study, Proc. ACM Int. Conf. Multimedia (MM) 2014, pp. 157-166; Shaukat F., Raja G., Ashraf R., Khalid S., Ahmad M., Ali A., Artificial neural network based classification of lung nodules in ct images using intensity, shape and texture features, J. Ambient Inte 11. Humanized Comput., 10, 10, pp. 4135-4149, (2019); Karpathy A., Toderici G., Shetty S., Leung T., Sukthankar R., Fei-Fei L., Large-scale video classification with convolutional neural networks, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 1725-1732, (2014); Wu G., Lu W., Gao G., Zhao C., Liu J., Regional deep learning model for visual tracking, Neurocomputing, 175, pp. 310-323, (2016); Hinton G., Deng L., Yu D., Dahl G.E., Mohamed A.-R., Jaitly N., Senior A., Vanhoucke V., Nguyen P., Sainath T.N., Kingsbury B., Deep neural networks for acoustic modeling in speech recognition, IEEE Signal Process. Mag., 29, 6, pp. 82-97, (2012); Zhou S., Chen Q., Wang X., Active deep learning method for semi-supervised sentiment classification, Neurocomputing, 120, pp. 536-546, (2013); Girshick R., Donahue J., Darrell T., Malik J., Rich feature hierarchies for accurate object detection and semantic segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun., pp. 580-587, (2014); Shi H.-Y., Pancreatic carcinosarcoma: First literature report on computed tomography imaging, World J. Gastroenterol, 21, 4, (2015); Zare M.R., Seng W.C., Mueen A., Automatic classification of medical X-ray images using a bag of visual words, IET Comput. Vis., 7, 2, pp. 105-114, (2013); Khan S., Yong S.-P., Deng J.D., Ensemble classification with modified SIFT descriptor for medical image modality, Proc. Int. Conf. Image Vis. Comput. New Zealand (IVCNZ), pp. 1-6, (2015); Cire§an D.C., Giusti A., Gambardella L.M., Schmidhuber J., Mitosis detection in breast cancer histology images with deep neural networks, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 411-418, (2013); Kanerva P., Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors, Cognit. Comput., 1, 2, pp. 139-159, (2009); Yilmaz O., Machine learning using cellular automata based feature expansion and reservoir computing, J. Cellular Automata, 10, pp. 435-472, (2015); Cheng D., Meng G., Cheng G., Pan C., SeNet: Structured edge network for Sea-Land segmentation, IEEE Geosci. Remote Sens. Lett., 14, 2, pp. 247-251, (2017); Chen P., Song Y., Yuan D., Liu Z., Feature fusion adversarial learning network for liver lesion classification, Proc. ACM Multimedia Asia ZZZ, Dec., pp. 1-7, (2019); Bengio Y., Lamblin P., Popovici D., Larochelle H., Greedy layer-wise training of deep networks, Proc. Adv. Neural Inf. Process. Syst., pp. 153-160, (2007); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., Laak Der Van M. W J.A., Van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Med. Image Anal, 42, pp. 60-88, (2017); Arroyo D.E., Visualizando Neuronas en Redes Neuronales Convolu-cionales, (2019); Al-Hadhrami S., Altuwaijri S., Alkharashi N., Ouni R., Deep classification technique for density counting, Proc. 2nd Int. Conf. Comput. Appl. Inf. Secur. (ICCAIS), pp. 1-6, (2019); Ashraf R., Ahmed M., Ahmad U., Habib M.A., Jabbar S., Naseer K., MDCBIR-MF: Multimedia data for content-based image retrieval by using multiple features, Multimedia Tools Appl., 79, pp. 1-27, (2018); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun., pp. 1-9, (2015); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) Jun., pp. 770-778, (2016); Ashraf R., Ahmed M., Jabbar S., Khalid S., Ahmad A., Din S., Jeon G., Content based image retrieval by using color descriptor and discrete wavelet transform, J. Med. Syst., 42, 3, (2018); Liu Y., Gadepalli K., Norouzi M., Dahl G.E., Kohlberger T., Boyko A., Venugopalan S., Timofeev A., Nelson P.Q., Corrado G.S., Hipp J.D., Peng L., Stumpe M.C., Detecting Cancer Metastases on Gigapixel Pathology Images, (2017); Esteva A., Kuprel B., Novoa R.A., Ko J., Swetter S.M., Blau H.M., Thrun S., Dermatologist-level classification of skin cancer with deep neural networks, Nature, 542, 7639, (2017); Kamnitsas K., Ledig C., Newcombe V.F.J., Simpson J.P., Kane A.D., Menon D.K., Rueckert D., Glocker B., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation, Med. Image Anal., 36, pp. 61-78, (2017); Ashraf R., Bashir K., Irtaza A., Mahmood M., Content based image retrieval using embedded neural networks with bandletized regions, Entropy, 17, 6, pp. 3552-3580, (2015); Moeskops P., Viergever M.A., Mendrik A.M., De Vries L.S., Benders M.J.N.L., Isgum I., Automatic segmentation of MR brain images with a convolutional neural network, IEEE Trans. Med. Imag., 35, 5, pp. 1252-1261, (2016); Prasoon A., Petersen K., Igel C., Lauze F., Dam E., Nielsen M., Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 246-253, (2013); Antony J., McGuinness K., O'Connor N.E., Moran K., Quantifying radiographic knee osteoarthritis severity using deep convolutional neural networks, Proc. 23rd Int. Conf. Pattern Recognit. (ICPR), pp. 1195-1200, (2016); Kim E., Corte-Real M., Baloch Z., A deep semantic mobile application for thyroid cytopathology, Med. Imag., Inform., Next Gener. Innov., Int. Soc. Opt. Photon., 9789, (2016); Brosch T., Tam R., Manifold learning of brain MRIs by deep learning, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 633-640, (2013); Plis S.M., Hjelm D.R., Salakhutdinov R., Allen E.A., Bockholt H.J., Long J.D., Johnson H.J., Paulsen J.S., Turner J.A., Calhoun V.D., Deep learning for neuroimaging: A validation study, Frontiers Neu-rosci, 8, (2014); Shin H.-C., Orton M.R., Collins D.J., Doran S.J., Leach M.O., Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data, IEEE Trans. Pattern Anal. Mach. Intell., 35, 8, pp. 1930-1943, (2013); Suk H.-I., Lee S.-W., Shen D., Hierarchical feature representation and multimodal fusion with deep learning for AD/MCI diagnosis, Neu-roImage, 101, pp. 569-582, (2014); Menegola A., Fornaciali M., Pires R., Avila S., Valle E., Towards Automated Melanoma Screening: Exploring Transfer Learning Schemes, (2016); Hoffman A.J., Singleton R.R., On moore graphs with diameters 2 and 3, Selected Papers of Alan J Hoffman: With Commentary, pp. 377-384, (2003); Payan A., Montana G., Predicting Alzheimer's Disease: A Neuroimaging Study with 3D Convolutional Neural Networks, (2015); Kawahara J., Brown C.J., Miller S.P., Booth B.G., Chau V., Grunau R.E., Zwicker J.G., Hamarneh G., BrainNetCNN: Convolutional neural networks for brain networks; towards predicting neurodevelopment, Neu-roImage, 146, pp. 1038-1049, (2017); Wang F., Jiang M., Qian C., Yang S., Li C., Zhang H., Wang X., Tang X., Residual attention network for image classification, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul., pp. 3156-3164, (2017); Shen W., Zhou M., Yang F., Yang C., Tian J., Multi-scale convolu-tional neural networks for lung nodule classification, Proc. Int. Conf. Inf. Process. Med. Imag, pp. 588-599, (2015); Kawahara J., Hamarneh G., Multi-resolution-tract cnn with hybrid pretrained and skin-lesion trained layers, Proc. Int. Workshop Mach. Learn. Med. Imag, pp. 164-171, (2016); Gao X., Lin S., Wong T.Y., Automatic feature learning to grade nuclear cataracts based on deep learning, IEEE Trans. Biomed. Eng., 62, 11, pp. 2693-2701, (2015); Nie D., Zhang H., Adeli E., Liu L., Shen D., 3D deep learning for multi-modal imaging-guided survival time prediction of brain tumor patients, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Inter-vent, pp. 212-220, (2016); Van Tulder G., De Bruijne M., Combining generative and discriminative representation learning for lung CT analysis with convolutional restricted Boltzmann machines, IEEE Trans. Med. Imag., 35, 5, pp. 1262-1272, (2016); Zhang Q., Xiao Y., Dai W., Suo J., Wang C., Shi J., Zheng H., Deep learning based classification of breast tumors with shear-wave elastogra-phy, Ultrasonics, 72, pp. 150-157, (2016); Kallenberg M., Petersen K., Nielsen M., Ng A.Y., Diao P., Igel C., Vachon C.M., Holland K., Winkel R.R., Karssemeijer N., Lillholm M., Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring, IEEE Trans. Med. Imag., 35, 5, pp. 1322-1331, (2016); Xu Y., Mo T., Feng Q., Zhong P., Lai M., Chang E.I.-C., Deep learning of feature representation with multiple instance learning for medical image analysis, Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), May, pp. 1626-1630, (2014); Soekhoe D., Putten Van Der P., Plaat A., On the impact of data set size in transfer learning using deep neural networks, Proc. Int. Symp. Intell. Data Anal, pp. 50-60, (2016); Lim K.J., Choi C.S., Yoon D.Y., Chang S.K., Kim K.K., Han H., Kim S.S., Lee J., Jeon Y.H., Computer-aided diagnosis for the differentiation of malignant from benign thyroid nodules on ultrasonography, Acad. Radiol., 15, 7, pp. 853-858, (2008); Savelonas M.A., Maroulis D.E., Iakovidis D.K., Dimitropoulos N., Computer-aided malignancy risk assessment of nodules in thyroid US images utilizing boundary descriptors, Proc. Panhellenic Conf. Infor-mat, pp. 157-160, (2008); Iakovidis D.K., Keramidas E.G., Maroulis D., Fusion of fuzzy statistical distributions for classification of thyroid ultrasound patterns, Artif. Intell. Med., 50, 1, pp. 33-41, (2010); Legakis I., Savelonas M.A., Maroulis D., Iakovidis D.K., Computer-based nodule malignancy risk assessment in thyroid ultrasound images, Int. J. Comput. Appl., 33, 1, pp. 29-35, (2011); Acharya U.R., Sree S.V., Swapna G., Gupta S., Molinari F., Garberoglio R., Witkowska A., Suri J.S., Effect of complex wavelet transform filter on thyroid tumor classification in three-dimensional ultrasound, Proc. Inst. Mech. Eng. H, J. Eng. Med., 227, 3, pp. 284-292, (2013)","M.A. Habib; Department of Computer Science, National Textile University, Faisalabad, 37610, Pakistan; email: drasif@ntu.edu.pk","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85087166459"
"Hamidinekoo A.; Denton E.; Rampun A.; Honnor K.; Zwiggelaar R.","Hamidinekoo, Azam (56568239100); Denton, Erika (55578429200); Rampun, Andrik (55785202900); Honnor, Kate (57201680128); Zwiggelaar, Reyer (6701923709)","56568239100; 55578429200; 55785202900; 57201680128; 6701923709","Deep learning in mammography and breast histology, an overview and future trends","2018","Medical Image Analysis","47","","","45","67","22","230","10.1016/j.media.2018.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045702232&doi=10.1016%2fj.media.2018.03.006&partnerID=40&md5=cb6ae23f2661ac7180281abecb6e371b","Department of Computer Science, Aberystwyth University, United Kingdom; Department of Radiology, Norfolk and Norwich University Hospital, United Kingdom; School of Computing, Ulster University, Coleraine, United Kingdom; Department of Histopathology/Cytopathology, Norfolk and Norwich University Hospital, United Kingdom","Hamidinekoo A., Department of Computer Science, Aberystwyth University, United Kingdom; Denton E., Department of Radiology, Norfolk and Norwich University Hospital, United Kingdom; Rampun A., School of Computing, Ulster University, Coleraine, United Kingdom; Honnor K., Department of Histopathology/Cytopathology, Norfolk and Norwich University Hospital, United Kingdom; Zwiggelaar R., Department of Computer Science, Aberystwyth University, United Kingdom","Recent improvements in biomedical image analysis using deep learning based neural networks could be exploited to enhance the performance of Computer Aided Diagnosis (CAD) systems. Considering the importance of breast cancer worldwide and the promising results reported by deep learning based methods in breast imaging, an overview of the recent state-of-the-art deep learning based CAD systems developed for mammography and breast histopathology images is presented. In this study, the relationship between mammography and histopathology phenotypes is described, which takes biological aspects into account. We propose a computer based breast cancer modelling approach: the Mammography–Histology–Phenotype–Linking–Model, which develops a mapping of features/phenotypes between mammographic abnormalities and their histopathological representation. Challenges are discussed along with the potential contribution of such a system to clinical decision making and treatment management. © 2018","Breast histopathology; Computer Aided Diagnosis; Deep learning; Mammography","Algorithms; Breast Neoplasms; Deep Learning; Diagnosis, Computer-Assisted; Female; Forecasting; Humans; Mammography; Neural Networks (Computer); Phenotype; Radiographic Image Interpretation, Computer-Assisted; Sensitivity and Specificity; Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Decision making; Diseases; Histology; Image enhancement; Mammography; Medical imaging; Biological aspects; Biomedical image analysis; Breast histopathology; Breast imaging; Clinical decision making; Computer Aided Diagnosis(CAD); Learning-based methods; Treatment management; Article; breast cancer; cancer screening; clinical decision making; computer assisted diagnosis; computer model; histopathology; human; image analysis; image processing; learning algorithm; mammography; phenotype; priority journal; algorithm; artificial neural network; breast tumor; diagnostic imaging; female; forecasting; pathology; procedures; sensitivity and specificity; Deep learning","","","","","","","Albarqouni S., Baur C., Achilles F., Belagiannis V., Demirci S., Navab N., Aggnet: Deep learning from crowds for mitosis detection in breast cancer histology images, IEEE Trans. Med. Imaging, 35, 5, pp. 1313-1321, (2016); (2016); AMIDA13, Assessment of mitosis detection algorithms, MICCAI Grand Challenge, (2017); Arevalo J., Gonzalez F.A., Ramos-Pollan R., Oliveira J.L., Lopez M.A.G., Convolutional neural networks for mammography mass lesion classification, IEEE 37th Annual International Conference of the Engineering in Medicine and Biology Society (EMBC), pp. 797-800, (2015); Arevalo J., Gonzalez F.A., Ramos-Pollan R., Oliveira J.L., Lopez M.A.G., Representation learning for mammography mass lesion classification with convolutional neural networks, Comput. Methods Programs Biomed., 127, pp. 248-257, (2016); Beck A.H., Sangoi A.R., Leung S., Marinelli R.J., Nielsen T.O., van de Vijver M.J., West R.B., van de Rijn M., Koller D., Systematic analysis of breast cancer morphology uncovers stromal features associated with survival, Sci. Transl. Med., 3, 108, (2011); Bejnordi B.E., Linz J., Glass B., Mullooly M., Gierach G.L., Sherman M.E., Karssemeijer N., van der Laak J., Beck A.H., (2017); Bekker A.J., Greenspan H., Goldberger J., A multi-view deep learning architecture for classification of breast microcalcifications, 13th International Symposium on Biomedical Imaging (ISBI), pp. 726-730, (2016); Bengio Y., Learning deep architectures for AI, Found. Trends® Mach. Learn., 2, 1, pp. 1-127, (2009); Bloom H., Richardson W., Histological grading and prognosis in breast cancer: a study of 1409 cases of which 359 have been followed for 15 years, Br.J. Cancer, 11, 3, pp. 359-377, (1957); Boyd N., Jensen H.M., Cooke G., Han H.L., Relationship between mammographic and histological risk factors for breast cancer, J. Natl. Cancer Inst., 84, 15, pp. 1170-1179, (1992); Boyd N.F., Martin L.J., Bronskill M., Yaffe M.J., Duric N., Minkin S., Breast tissue composition and susceptibility to breast cancer, J. Natl. Cancer Inst., 102, pp. 1224-1237, (2010); Boyer B., Balleyguier C., Granat O., Pharaboz C., CAD in questions/answers: review of the literature, Eur.Radiol., 69, 1, pp. 24-33, (2009); (2016); Britt K., Ingman W., Huo C., Chew G., Thompson E., The pathobiology of mammographic density, Cancer Biol. Res., 2, 1, (2014); Byng J.W., Boyd N., Fishell E., Jong R., Yaffe M.J., The quantitative analysis of mammographic densities, Phys. Med. Biol., 39, 10, (1994); (2016); (2017); Carneiro G., Nascimento J., Bradley A.P., Unregistered multiview mammogram analysis with pre-trained deep learning models, International Conference on Medical Image Computing and Computer-Assisted Intervention, 9351, pp. 652-660, (2015); Chan H.-P., Lo S.-C.B., Sahiner B., Lam K.L., Helvie M.A., Computer-aided detection of mammographic microcalcifications: pattern recognition with an artificial neural network, Med. Phys., 22, 10, pp. 1555-1567, (1995); Chen H., Dou Q., Wang X., Qin J., Heng P.-A., Mitosis detection in breast cancer histology images via deep cascaded networks, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pp. 1160-1166, (2016); Chen H., Wang X., Heng P.A., Automated mitosis detection with deep regression networks, 13th IEEE International Symposium on Biomedical Imaging (ISBI), pp. 1204-1207, (2016); Cheng H.-D., Cai X., Chen X., Hu L., Lou X., Computer-aided detection and classification of microcalcifications in mammograms: a survey, Pattern Recognit., 36, 12, pp. 2967-2991, (2003); Ciresan D., Giusti A., Gambardella L.M., Schmidhuber J., Deep neural networks segment neuronal membranes in electron microscopy images, Advances in Neural Information Processing Systems, pp. 2843-2851, (2012); Ciresan D., Meier U., Schmidhuber J., Multi-column deep neural networks for image classification, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3642-3649, (2012); Ciresan D.C., Giusti A., Gambardella L.M., Schmidhuber J., Mitosis detection in breast cancer histology images with deep neural networks, International Conference on Medical Image Computing and Computer-Assisted Intervention, 8150, pp. 411-418, (2013); Clark K., Vendt B., Smith K., Freymann J., Kirby J., Koppel P., Moore S., Phillips S., Maffitt D., Pringle M., Lawrence T., Prior F., The cancer imaging archive (TCIA): maintaining and operating a public information repository, J. Digit. Imaging, 26, 6, pp. 1045-1057, (2013); Cruz-Roa A., Basavanhally A., Gonzalez F., Gilmore H., Feldman M., Ganesan S., Shih N., Tomaszewski J., Madabhushi A., Automatic detection of invasive ductal carcinoma in whole slide images with convolutional neural networks, SPIE Medical Imaging, 9041, (2014); (2017); Dahl G.E., Sainath T.N., Hinton G.E., Improving deep neural networks for LVCSR using rectified linear units and dropout, 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 8609-8613, (2013); Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L., ImageNet: a large-scale hierarchical image database, IEEE Conference on Computer Vision and Pattern Recognition, CVPR, pp. 248-255, (2009); Dhungel N., Carneiro G., Bradley A.P., Automated mass detection in mammograms using cascaded deep learning and random forests, IEEE International Conference on Digital Image Computing: Techniques and Applications (DICTA), pp. 1-8, (2015); Dhungel N., Carneiro G., Bradley A.P., The automated learning of deep features for breast mass classification from mammograms, International Conference on Medical Image Computing and Computer-Assisted Intervention, 9901, pp. 106-114, (2016); (2017); Doi K., Computer-aided diagnosis in medical imaging: historical review, current status and future potential, Comput. Med. Imaging Graph., 31, 4, pp. 198-211, (2007); Donahue J., Jia Y., Vinyals O., Hoffman J., Zhang N., Tzeng E., Darrell T., DeCAF: a deep convolutional activation feature for generic visual recognition, International Conference on Machine Learning (ICML), pp. 647-655, (2014); D'Orsi C.J., ACR BI-RADS Atlas: Breast Imaging Reporting And Data System, (2013); Dos Santos C., Marshall P., Torresan R., Tinois E., Duarte G., Teixeira S., Abstract p4-01-04: immunohistochemical and histological features of mammographic dense and non-dense tissue in breast cancer patients, Cancer Res., 76, 4 Supplement, pp. P4-01, (2016); Dubrovina A., Kisilev P., Ginsburg B., Hashoul S., Kimmel R., Computational mammography using deep neural networks, Comput. Methods Biomech.Biomed. Eng., pp. 1-5, (2016); Dundar M.M., Badve S., Bilgin G., Raykar V., Jain R., Sertel O., Gurcan M.N., Computerized classification of intraductal breast lesions using histopathological images, IEEE Trans. Biomed.Eng., 58, 7, pp. 1977-1984, (2011); Elmore J.G., Jackson S.L., Abraham L., Miglioretti D.L., Carney P.A., Geller B.M., Yankaskas B.C., Kerlikowske K., Onega T., Rosenberg R.D., Sickles E.A., Buist D.S.M., Variability in interpretive performance at screening mammography and radiologists characteristics associated with accuracy, Radiology, 253, 3, pp. 641-651, (2009); Elston C.W., Ellis I., Pathological prognostic factors in breast cancer. I. The value of histological grade in breast cancer: experience from a large study with long-term follow-up, Histopathology, 19, 5, pp. 403-410, (1991); Fenton J.J., Abraham L., Taplin S.H., Geller B.M., Carney P.A., D'Orsi C., Elmore J.G., Barlow W.E., Consortium B.C.S., Effectiveness of computer-aided detection in community mammography practice, J. Natl. Cancer Inst., 103, 15, pp. 1152-1161, (2011); Fonseca P., Mendoza J., Wainer J., Ferrer J., Pinto J., Guerrero J., Castaneda B., Automatic breast density classification using a convolutional neural network architecture search procedure, SPIE Medical Imaging, 9414, (2015); Fotin S.V., Yin Y., Haldankar H., Hoffmeister J.W., Periaswamy S., Detection of soft tissue densities from digital breast tomosynthesis: comparison of conventional and deep learning approaches, SPIE Medical Imaging, 9785, (2016); Gastounioti A., Conant E.F., Kontos D., Beyond breast density: a review on the advancing role of parenchymal texture analysis in breast cancer risk assessment, Breast Cancer Res., 18, 1, pp. 91-103, (2016); Ghosh K., Brandt K.R., Reynolds C., Scott C.G., Pankratz V., Riehle D.L., Lingle W.L., Odogwu T., Radisky D.C., Visscher D.W., Ingle J.N., Hartmann L.C., Vachon C.M., Tissue composition of mammographically dense and non-dense breast tissue, Breast Cancer Res. Treat., 131, 1, pp. 267-275, (2012); Giger M.L., Medical imaging and computers in the diagnosis of breast cancer, SPIE, Photonic Innovations and Solutions for Complex Environments and Systems (PISCES) II, 918908, (2014); Giger M.L., Karssemeijer N., Schnabel J.A., Breast image analysis for risk assessment, detection, diagnosis, and treatment of cancer, Annu. Rev. Biomed. Eng., 15, pp. 327-357, (2013); Giusti A., Caccia C., Ciresari D.C., Schmidhuber J., Gambardella L.M., A comparison of algorithms and humans for mitosis detection, IEEE 11th International Symposium on Biomedical Imaging (ISBI), pp. 1360-1363, (2014); Glorot X., Bordes A., Bengio Y., Deep sparse rectifier neural networks, 14th International Conference on Artificial Intelligence and Statistics, 15, pp. 315-323, (2011); Goodfellow I., Bengio Y., Courville A., Deep Learning, (2016); Greenspan H., van Ginneken B., Summers R.M., Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique, IEEE Trans. Med. Imaging, 35, 5, pp. 1153-1159, (2016); Gurcan M.N., Boucheron L.E., Can A., Madabhushi A., Rajpoot N.M., Yener B., Histopathological image analysis: a review, IEEE Rev. Biomed. Eng., 2, pp. 147-171, (2009); Hamidinekoo A., Suhail Z., Qaiser T., Zwiggelaar R., Investigating the effect of various augmentations on the input data fed to a convolutional neural network for the task of mammographic mass classification, Annual Conference on Medical Image Understanding and Analysis, pp. 398-409, (2017); He W., Juette A., Denton E.R., Oliver A., Marti R., Zwiggelaar R., A review on automatic mammographic density and parenchymal segmentation, Int. J. Breast Cancer, 2015, (2015); Heath M., Bowyer K., Kopans D., Moore R., Kegelmeyer W.P., The digital database for screening mammography, Proceedings of the 5th International Workshop on Digital Mammography, pp. 212-218, (2001); Holland R., Hendriks J., Microcalcifications associated with ductal carcinoma in situ: mammographic-pathologic correlation, Seminars in Diagnostic Pathology, 11, pp. 181-192, (1994); Huynh B.Q., Li H., Giger M.L., Digital mammographic tumor classification using transfer learning from deep convolutional neural networks, J. Med. Imaging, 3, 3, (2016); ICPR2012, Contest, International Conference on Pattern Recognition. Tsukuba, Japan., (2017); Irshad H., Veillard A., Roux L., Racoceanu D., Methods for nuclei detection, segmentation, and classification in digital histopathology: a review- current status and future potential, IEEE Rev. Biomed. Eng., 7, pp. 97-114, (2014); Jamieson A.R., Drukker K., Giger M.L., Breast image feature learning with adaptive deconvolutional networks, SPIE Medical Imaging, 8315, (2012); Janowczyk A., Basavanhally A., Madabhushi A., Stain normalization using sparse autoencoders (StaNoSA): application to digital pathology, Comput. Med. Imaging Graph., 57, pp. 50-61, (2017); Janowczyk A., Doyle S., Gilmore H., Madabhushi A., A resolution adaptive deep hierarchical (RADHicaL) learning scheme applied to nuclear segmentation of digital pathology images, Comput. Methods Biomech. Biomed. Eng., pp. 1-7, (2016); Janowczyk A., Madabhushi A., Deep learning for digital pathology image analysis: acomprehensive tutorial with selected use cases, Journal of Pathology Informatics, (2016); Jia Y., Shelhamer E., Donahue J., Karayev S., Long J., Girshick R., Guadarrama S., Darrell T., Caffe: convolutional architecture for fast feature embedding, Proceedings of the 22nd ACM International Conference on Multimedia, pp. 675-678, (2014); Jiao Z., Gao X., Wang Y., Li J., A deep feature based framework for breast masses classification, Neurocomputing, 197, pp. 221-231, (2016); Kallenberg M., Petersen K., Nielsen M., Ng A.Y., Diao P., Igel C., Vachon C.M., Holland K., Winkel R.R., Karssemeijer N., Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring, IEEE Trans. Med.Imaging, 35, 5, pp. 1322-1331, (2016); Kooi T., Gubern-Merida A., Mordang J.-J., Mann R., Pijnappel R., Schuur K., den Heeten A., Karssemeijer N., A comparison between a deep convolutional neural network and radiologists for classifying regions of interest in mammography, International Workshop on Digital Mammography, 9699, pp. 51-56, (2016); Kooi T., Litjens G., van Ginneken B., Gubern-Merida A., Sanchez C.I., Mann R., den Heeten A., Karssemeijer N., Large scale deep learning for computer aided detection of mammographic lesions, Med. Image Anal., 35, pp. 303-312, (2017); Kopans D.B., The positive predictive value of mammography, Am. J. Roentgenol., 158, 3, pp. 521-526, (1992); Kothari S., Phan J.H., Stokes T.H., Wang M.D., Pathology imaging informatics for quantitative analysis of whole-slide images, Amer. Med. Inform.Assoc., 20, 6, pp. 1099-1108, (2013); Kowal M., Filipczuk P., Obuchowicz A., Korbicz J., Monczak R., Computer-aided diagnosis of breast cancer based on fine needle biopsy microscopic images, Comput. Biol. Med., 43, 10, pp. 1563-1572, (2013); Krizhevsky A., Hinton G., (2009); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Lamb P.M., Perry N.M., Vinnicombe S.J., Wells C.A., Correlation between ultrasound characteristics, mammographic findings and histological grade in patients with invasive ductal carcinoma of the breast, Clin. Radiol., 55, 1, pp. 40-44, (2000); Lazebnik S., Schmid C., Ponce J., Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), 2, pp. 2169-2178, (2006); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc. IEEE, 86, 11, pp. 2278-2324, (1998); LeCun Y., Kavukcuoglu K., Farabet C., Convolutional networks and applications in vision, Proceedings of IEEE International Symposium on Circuits and Systems (ISCAS), pp. 253-256, (2010); LeCun Y.A., Bottou L., Orr G.B., Muller K.-R., Efficient BackProp, Neural Networks: Tricks of the Trade, pp. 9-48, (2012); Levy D., Jain A., Breast mass classification from mammograms using deep convolutional neural networks, Computing Research Repository, (2016); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., van der Laak J.A., van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Med. Image Anal., 42, pp. 60-88, (2017); Litjens G., Sanchez C.I., Timofeeva N., Hermsen M., Nagtegaal I., Kovacs I., Hulsbergen-van de Kaa C., Bult P., van Ginneken B., van der Laak J., Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis, Sci. Rep., 6, (2016); Lopez M.G., Posada N., Moura D.C., Pollan R.R., Valiente J.M.F., Ortega C.S., Solar M., Diaz-Herrero G., Ramos I., Loureiro J., Fernandes T.C., Ferreira de Araujo B.M., BCDR: a breast cancer digital repository, 15th International Conference on Experimental Mechanics, (2012); Madabhushi A., Lee G., Image analysis and machine learning in digital pathology: challenges and opportunities, Med. Image Anal., 33, pp. 170-175, (2016); Malon C.D., Cosatto E., Classification of mitotic figures with convolutional neural networks and seeded blob features, Pathol. Inform., 4, 1, (2013); Matheus B.R.N., Schiabel H., Online mammographic images database for development and comparison of cad schemes, J.Digit. Imaging, 24, 3, pp. 500-506, (2011); Medsker L., Jain L.C., Recurrent Neural Networks, Design and Applications, (1999); (2017); MITOS-ATYPIA-14, Detection of mitosis and evaluation of nuclear atypia score in breast cancer histological images, The International Conference for Pattern Recognition (ICPR)., (2016); Moreira I.C., Amaral I., Domingues I., Cardoso A., Cardoso M.J., Cardoso J.S., INbreast: toward a full-field digital mammographic database, Acad. Radiol., 19, 2, pp. 236-248, (2012); Muhimmah I., Oliver A., Denton E.R., Pont J., Perez E., Zwiggelaar R., Comparison between Wolfe, Boyd, BI-RADS and Tabár based mammographic risk assessment, Lect. Notes Comput. Sci., 4046, (2006); Nair V., Hinton G.E., Rectified linear units improve Restricted Boltzmann Machines, Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 807-814, (2010); (2016); Neal L., Tortorelli C.L., Nassar A., Clinician's guide to imaging and pathologic findings in benign breast disease, Mayo Clinic Proceedings, 85, pp. 274-279, (2010); Ng A., Sparse autoencoder, CS294A Lecture Notes, 72, pp. 1-19, (2011); Oliver A., Freixenet J., Marti J., Perez E., Pont J., Denton E.R., Zwiggelaar R., A review of automatic mass detection and segmentation in mammographic images, Med. Image Anal., 14, 2, pp. 87-110, (2010); Oliver A., Freixenet J., Marti R., Zwiggelaar R., A comparison of breast tissue classification techniques, International Conference on Medical Image Computing and Computer-Assisted Intervention MICCAI, 4191, pp. 872-879, (2006); (2017); Pang J.-M.B., Byrne D.J., Takano E.A., Jene N., Petelin L., McKinley J., Poliness C., Saunders C., Taylor D., Mitchell G., Fox S.B., Breast tissue composition and immunophenotype and its relationship with mammographic density in women at high risk of breast cancer, PloS One, 10, 6, (2015); Petersen K., Chernoff K., Nielsen M., Ng A.Y., Breast density scoring with multiscale denoising autoencoders, Sparse Methods for Signal Reconstruction and Medical Image Analysis Workshop at MICCAI, (2012); Pinto N., Doukhan D., DiCarlo J.J., Cox D.D., A high-throughput screening approach to discovering good forms of biologically inspired visual representation, PLoS Comput. Biol., 5, 11, (2009); Rangayyan R.M., Ayres F.J., Desautels J.L., A review of computer-aided diagnosis of breast cancer: toward the detection of subtle signs, J. Frankl. Inst., 344, 3, pp. 312-348, (2007); Ranzato M., Poultney C., Chopra S., Cun Y.L., Efficient learning of sparse representations with an energy-based model, Advances in Neural Information Processing Systems, pp. 1137-1144, (2006); Romo-Bucheli D., Janowczyk A., Romero E., Gilmore H., Madabhushi A., Automated tubule nuclei quantification and correlation with oncotype DX risk categories in ER+ breast cancer whole slide images, SPIE Medical Imaging, (2016); Sahiner B., Chan H.-P., Petrick N., Wei D., Helvie M.A., Adler D.D., Goodsitt M.M., Classification of mass and normal breast tissue: a convolution neural network classifier with spatial domain and texture images, IEEE Trans. Med. Imaging, 15, 5, pp. 598-610, (1996); Salakhutdinov R., Hinton G.E., Deep Boltzmann Machines, in Proc. of The Twelfth International Conference on Artificial Intelligence and Statistics (AISTATS), 5, pp. 448-455, (2009); Samala R.K., Chan H.-P., Hadjiiski L., Helvie M.A., Wei J., Cha K., Mass detection in digital breast tomosynthesis: deep convolutional neural network with transfer learning from mammography, Med. Phys., 43, 12, pp. 6654-6666, (2016); Samala R.K., Chan H.-P., Hadjiiski L.M., Cha K., Helvie M.A., Deep-learning convolution neural network for computer-aided detection of microcalcifications in digital breast tomosynthesis, SPIE Medical Imaging 9785, 9785, pp. 1-7, (2016); Schmidhuber J., Deep learning in neural networks: an overview, Neural Netw., 61, pp. 85-117, (2015); Shin H.-C., Lu L., Kim L., Seff A., Yao J., Summers R.M., Interleaved text/image deep mining on a very large-scale radiology database, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1090-1099, (2015); Shin H.-C., Roth H.R., Gao M., Lu L., Xu Z., Nogues I., Yao J., Mollura D., Summers R.M., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning, IEEE Trans. Med. Imaging, 35, 5, pp. 1285-1298, (2016); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, International Conference on Learning Representations, (2014); Srivastava N., Hinton G.E., Krizhevsky A., Sutskever I., Salakhutdinov R., Dropout: a simple way to prevent neural networks from overfitting, J.Mach. Learn. Res., 15, 1, pp. 1929-1958, (2014); Stavros A.T., Thickman D., Rapp C.L., Dennis M.A., Parker S.H., Sisney G.A., Solid breast nodules: use of sonography to distinguish between benign and malignant lesions, Radiology, 196, 1, pp. 123-134, (1995); Stewart B.W., Kleihues P., World Cancer Report, (2014); Suckling J., Parker J., Dance D., Astley S., Hutt I., Boggis C., Ricketts I., Stamatakis E., Cerneaz N., Kok S., Et al., (2015); Sun W., Tseng T.-L.B., Zhang J., Qian W., Enhancing deep convolutional neural network scheme for breast cancer diagnosis with unlabeled data, Comput. Med. Imaging Graph., (2016); Sun X., Sandhu R., Figueroa J.D., Gierach G.L., Sherman M.E., Troester M.A., Benign breast tissue composition in breast cancer patients: association with risk factors, clinical variables, and gene expression, Cancer Epidemiol. Biomark.Prev., 23, 12, pp. 2810-2818, (2014); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Tabar L., Dean P.B., Breast Cancer-The Art and Science of Early Detection with Mammography, (2005); Tajbakhsh N., Shin J.Y., Gurudu S.R., Hurst R.T., Kendall C.B., Gotway M.B., Liang J., Convolutional neural networks for medical image analysis: Full training or fine tuning?, IEEE Trans. Med. Imaging, 35, 5, pp. 1299-1312, (2016); Tot T., Tabar L., The role of radiological–pathological correlation in diagnosing early breast cancer: the pathologists perspective, Virchows Arch., 458, 2, pp. 125-131, (2011); (2016); UK-Breast-Cancer, UK Breast Cancer Research Symposium, (2016); Van Diest P., Van Der Wall E., Baak J., Prognostic value of proliferation in invasive breast cancer: a review, Clin. Pathol., 57, 7, pp. 675-681, (2004); Veillard A., Kulikova M.S., Racoceanu D., Cell nuclei extraction from breast cancer histopathologyimages using colour, texture, scale and shape information, Diagn. Pathol., 8, 1, pp. 1-3, (2013); Veta M., van Diest P.J., Jiwa M., Al-Janabi S., Pluim J.P., Mitosis counting in breast cancer: object-level interobserver agreement and comparison to an automatic method, PloS One, 11, 8, (2016); Veta M., van Diest P.J., Pluim J.P., Cutting out the middleman: measuring nuclear area in histopathology slides without segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, 9901, pp. 632-639, (2016); Veta M., Pluim J.P., van Diest P.J., Viergever M.A., Breast cancer histopathology image analysis: a review, IEEE Trans. Biomed.Eng., 61, 5, pp. 1400-1411, (2014); Veta M., Van Diest P.J., Willems S.M., Wang H., Madabhushi A., Cruz-Roa A., Gonzalez F., Larsen A.B., Vestergaard J.S., Dahl A.B., Ciresan D.C., Schmidhuber J., Giusti A., Gambardella L.M., Tek F.B., Walter T., Wang C.-W., Kondo S., Matuszewski B.J., Precioso F., Snell V., Kittler J., de Campos T.E., Khan A.M., Rajpoot N.M., Arkoumani E., Lacle M.M., Viergever M.A., Pluim J.P., Assessment of algorithms for mitosis detection in breast cancer histopathology images, Med. Image Anal., 20, 1, pp. 237-248, (2015); Wang D., Khosla A., Gargeya R., Irshad H., Beck A., (2016); Wang H., Cruz-Roa A., Basavanhally A., Gilmore H., Shih N., Feldman M., Tomaszewski J., Gonzalez F., Madabhushi A., Cascaded ensemble of convolutional neural networks and handcrafted features for mitosis detection, SPIE Medical Imaging, 9041, (2014); Wang H., Cruz-Roa A., Basavanhally A., Gilmore H., Shih N., Feldman M., Tomaszewski J., Gonzalez F., Madabhushi A., Mitosis detection in breast cancer pathology images by combining handcrafted and convolutional neural network features, J. Med. Imaging, 1, 3, (2014); Wang J., Yang X., Cai H., Tan W., Jin C., Li L., Discrimination of breast cancer with microcalcifications on mammography by deep learning, Scient. Rep., 6, (2016); Wolfe J.N., Breast patterns as an index of risk for developing breast cancer, Am. J.Roentgenol., 126, 6, pp. 1130-1137, (1976); Xie Y., Xing F., Kong X., Su H., Yang L., Beyond classification: structured regression for robust cell detection using convolutional neural network, International Conference on Medical Image Computing and Computer-Assisted Intervention, 9351, pp. 358-365, (2015); Xing F., Xie Y., Yang L., An automatic learning-based framework for robust nucleus segmentation, IEEE Trans. Med. Imaging, 35, 2, pp. 550-566, (2016); Xu J., Luo X., Wang G., Gilmore H., Madabhushi A., A deep convolutional neural network for segmenting and classifying epithelial and stromal regions in histopathological images, Neurocomputing, 191, pp. 214-223, (2016); Xu J., Xiang L., Hang R., Wu J., Stacked sparse autoencoder (SSAE) based framework for nuclei patch classification on breast cancer histopathology, IEEE 11th International Symposium on Biomedical Imaging (ISBI), pp. 999-1002, (2014); Xu J., Xiang L., Liu Q., Gilmore H., Wu J., Tang J., Madabhushi A., Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images, IEEE Trans. Med. Imaging, 35, 1, pp. 119-130, (2016); Zeiler M.D., Taylor G.W., Fergus R., Adaptive deconvolutional networks for mid and high level feature learning, IEEE International Conference on Computer Vision, pp. 2018-2025, (2011)","A. Hamidinekoo; Department of Computer Science, Aberystwyth University, United Kingdom; email: azh2@aber.ac.uk","","Elsevier B.V.","","","","","","13618415","","MIAEC","29679847","English","Med. Image Anal.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85045702232"
"Arif M.; Ajesh F.; Shamsudheen S.; Geman O.; Izdrui D.; Vicoveanu D.","Arif, Muhammad (56452459100); Ajesh, F. (57217016287); Shamsudheen, Shermin (57223927301); Geman, Oana (53863372800); Izdrui, Diana (57223106792); Vicoveanu, Dragos (25522574300)","56452459100; 57217016287; 57223927301; 53863372800; 57223106792; 25522574300","Brain Tumor Detection and Classification by MRI Using Biologically Inspired Orthogonal Wavelet Transform and Deep Learning Techniques","2022","Journal of Healthcare Engineering","2022","","2693621","","","","85","10.1155/2022/2693621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123674522&doi=10.1155%2f2022%2f2693621&partnerID=40&md5=13187cc309127b2c3f702af6de30b723","Department of Computer Science and Information Technology, University of Lahore, Lahore, Pakistan; Department of Computer Science and Engineering, Sree Buddha College of Engineering, Kerala, Alappuzha, India; College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia; Neuroaesthetics Lab, Stefan Cel Mare University of Suceava, Suceava, Romania; Faculty of Electrical Engineering and Computer Science, Stefan Cel Mare University of Suceava, Suceava, Romania","Arif M., Department of Computer Science and Information Technology, University of Lahore, Lahore, Pakistan; Ajesh F., Department of Computer Science and Engineering, Sree Buddha College of Engineering, Kerala, Alappuzha, India; Shamsudheen S., College of Computer Science and Information Technology, Jazan University, Jazan, Saudi Arabia; Geman O., Neuroaesthetics Lab, Stefan Cel Mare University of Suceava, Suceava, Romania, Faculty of Electrical Engineering and Computer Science, Stefan Cel Mare University of Suceava, Suceava, Romania; Izdrui D., Faculty of Electrical Engineering and Computer Science, Stefan Cel Mare University of Suceava, Suceava, Romania; Vicoveanu D., Faculty of Electrical Engineering and Computer Science, Stefan Cel Mare University of Suceava, Suceava, Romania","Radiology is a broad subject that needs more knowledge and understanding of medical science to identify tumors accurately. The need for a tumor detection program, thus, overcomes the lack of qualified radiologists. Using magnetic resonance imaging, biomedical image processing makes it easier to detect and locate brain tumors. In this study, a segmentation and detection method for brain tumors was developed using images from the MRI sequence as an input image to identify the tumor area. This process is difficult due to the wide variety of tumor tissues in the presence of different patients, and, in most cases, the similarity within normal tissues makes the task difficult. The main goal is to classify the brain in the presence of a brain tumor or a healthy brain. The proposed system has been researched based on Berkeley's wavelet transformation (BWT) and deep learning classifier to improve performance and simplify the process of medical image segmentation. Significant features are extracted from each segmented tissue using the gray-level-co-occurrence matrix (GLCM) method, followed by a feature optimization using a genetic algorithm. The innovative final result of the approach implemented was assessed based on accuracy, sensitivity, specificity, coefficient of dice, Jaccard's coefficient, spatial overlap, AVME, and FoM.  © 2022 Muhammad Arif et al.","","Algorithms; Brain; Brain Neoplasms; Deep Learning; Humans; Magnetic Resonance Imaging; Wavelet Analysis; Biomimetics; Brain; Deep learning; Genetic algorithms; Histology; Image enhancement; Image segmentation; Learning systems; Medical imaging; Tumors; Wavelet transforms; Biologically-inspired; Brain tumors; Detection methods; Learning techniques; Medical science; MRI sequences; Orthogonal wavelet transforms; Segmentation methods; Tumor classification; Tumour detection; adult; Article; brain tumor; classification; classifier; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; feature extraction; genetic algorithm; human; image processing; image segmentation; major clinical study; nuclear magnetic resonance imaging; sensitivity and specificity; support vector machine; tumor diagnosis; wavelet transform; algorithm; brain; brain tumor; diagnostic imaging; nuclear magnetic resonance imaging; procedures; wavelet analysis; Magnetic resonance imaging","","","","","","","Dorairangaswamy M.A., A novel invisible and blind watermarking scheme for copyright protection of digital images, IJCSNS International Journal of Computer Science and Network Security, 9, 4, (2009); Kim W.-J., Lee J.K., Kim J.-H., Kwon K.-R., Block-based watermarking using random position key, IJCSNS International Journal of Computer Science and Network Security, 9, 2, (2009); Amato F., Lopez A., Pena-Mendez E.M., Vanhara P., Hampl A., Havel J., Artificial neural networks in medical diagnosis, Journal of Applied Biomedicine, 11, 2, pp. 47-58, (2013); Demirhan A., Toru M., Guler I., Segmentation of tumor and e along with healthy tissues of brain using wavelets and neural networks, IEEE Journal of Biomedical and Health Informatics, 19, 4, pp. 1451-1458, (2015); Madhukumar S., Santhiyakumari N., Evaluation of k-Means and fuzzy C-means segmentation on MR images of brain, The Egyptian Journal of Radiology and Nuclear Medicine, 46, 2, pp. 475-479, (2015); El-Melegy M.T., Mokhtar H.M., Tumor segmentation in brain MRI using a fuzzy approach with class center priors, EURASIP Journal on Image and Video Processing, 2014, (2014); Coatrieux G., Hui Huang H., Huazhong Shu H., Limin Luo L., Roux C., A watermarking-based medical image integrity control system and an image moment signature for tampering characterization, IEEE Journal of Biomedical and Health Informatics, 17, 6, pp. 1057-1067, (2013); Arif M., Wang G., Fast curvelet transform through genetic algorithm for multimodal medical image fusion, Soft Computing, 24, pp. 1815-1836, (2020); Lal S., Chandra M., Efficient algorithm for contrast enhancement of natural images, The International Arab Journal of Information Technology, 11, 1, pp. 95-102, (2014); Willmore B., Prenger R.J., Wu M.C.-K., Gallant J.L., The Berkeley wavelet transform: A biologically inspired orthogonal wavelet transform, Neural Computation, 20, 6, pp. 1537-1564, (2008); Yang X.-S., A new metaheuristic bat-inspired algorithm, Nature Inspired Cooperative Strategies for Optimization (NISCO 2010), pp. 65-74, (2010); Ali I., Direkoglu C., Sah M., Review of MRI-based Brain Tumor Image Segmentation Using Deep Learning Methods, pp. 29-30; Abdel-Maksoud E., Elmogy M., Al-Awadi R., Brain tumor segmentation based on a hybrid clustering technique, Egyptian Informatics Journal, 16, 1, pp. 71-81, (2015); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., Van Der Laak J.A.W.M., Van Ginneken B., Sanchez C.I., Sanchez C.I., A survey on deep learning in medical image analysis, Medical Image Analysis, 42, pp. 60-88, (2017); Devkota B., Alsadoon A., Prasad P.W.C., Singh A.K., Elchouemi A., Image Segmentation for Early Stage Brain Tumor Detection Using Mathematical Morphological Reconstruction; Glan D.G., Kumar S.S., Brain tumor detection and segmentation using a wrapper based genetic algorithm for optimized feature set, Cluster Computing, 22, 1, pp. 13369-13380, (2018); Willmore B., Prenger R.J., Wu M.C.-K., Gallant J.L., The Berkeley wavelet transform: A biologically inspired orthogonal wavelet transform, Neural Computation, 20, 6, pp. 1537-1564, (2008); Anjali R., Priya S., An efficient classifier for brain tumor classification, IJCSMC, 6, 8, pp. 40-48, (2017); Angulakshmi M., Lakshmi Priya G.G., Brain tumor segmentation from MRI using superpixels based spectral clustering, Journal of King Saud University-Computer and Information Sciences, 32, 10, pp. 1182-1193, (2018); Zahras D., Rustam Z., Cervical Cancer Risk Classification Based on Deep Convolutional Neural Network, pp. 149-153; Glan D.G., Kumar S.S., An improved tumor segmentation algorithm from T2 and FLAIR multimodality MRI brain images by support vector machine and genetic algorithm, Cogent Engineering, 5, 1, (2018); Mohsen H., El-Dahshan E.-S.A., El-Horbaty E.-S.M., Salem A.-B.M., Classification using deep learning neural networks for brain tumors, Future Computing and Informatics Journal, 3, 1, pp. 68-71, (2018); Vijila R.K., Joseph Jawhar S., Novel technology for lung tumor detection using nano image, IETE Journal of Research, 67, 5, pp. 1-15, (2021); Jinisha A.C., Rani T.S.S., Brain Tumor Classification Using SVM and Bag of Visual Word Classifier, pp. 1-6; Veeramuthu A., Meenakshi S., Priya Darsini V., Brain image classification using learning machine approach and brain structure analysis, Procedia Computer Science, 50, pp. 388-394, (2015); Kumar S., Dabas C., Sunila godara 'classification of brain MRI tumor images: A hybrid approach' information technology and quantitative management ITQM2017, Procedia Computer Science, 122, pp. 510-517, (2017); Khalil M., Ayad H., Adib A., Performance evaluation of feature extraction techniques in MR-brain image classification system, Procedia Computer Science, 127, pp. 218-225, (2018); Glan D.G., Kumar S.S., An optimized approach for SVM based segmentation of MR images of brain tumors, Journal of Advanced Research in Dynamical and Control Systems, 9, 8, pp. 80-87, (2017); Gonzalez-Villa S., Oliver A., Huo Y., Llado X., Landman B.A., Brain structure segmentation in the presence of multiple sclerosis lesions, NeuroImage: Clinica, 22, (2019); Mohsen H., El-Dahshan E.-S.A., El-Horbaty E.-S.M., Salem A.-B.M., Classification using deep learning neural networks for brain tumors, Future Computing and Informatics Journal, 3, 1, pp. 68-71, (2018); Masci J., Meier U., Ciresan D., Schmidhuber J., Gabriel F., Steel Defect Classification with Max-pooling Convolutional Neural Networks, pp. 1-6; Kurian S.M., Devaraj S.J., Vijayan V.P., Brain tumour detection by gamma DeNoised wavelet segmented entropy classifier, CMC-Computers, Materials & Continua, 69, 2, pp. 2093-2109, (2021); Javaid Q., Arif M., Talpur S., Segmentation and classification of calcification and hemorrhage in the brain using fuzzy C-mean and adaptive neuro-fuzzy inference system, Research Journal of Engineering Science, Technology and Innovation, 15, 1, pp. 50-63, (2016); Arif M., Wang G., Geman O., Chen J., Wang G., Bhuiyan M.Z.A., De Capitani Di Vimercati S., Ren Y., Medical image segmentation by combining adaptive artificial bee colony and wavelet packet decomposition, Dependability in Sensor, Cloud, and Big Data Systems and Applications. DependSys 2019, 1123, (2019); Arif M., Wang G., Balas V.E., Chen S., Wang G., El Saddik A., Lai X., Martinez Perez G., Choo K.K., Band segmentation and detection of DNA by using fast FuzzyC-mean and neuro adaptive fuzzy inference system, Smart City and Informatization. ISCI 2019, 1122, (2019); Albahli S., Rauf H.T., Arif M., Nafis M.T., Algosaibi A., Identification of thoracic diseases by exploiting deep neural networks, Computers, Materials & Continua, 66, 3, pp. 3139-3149, (2021)","M. Arif; Department of Computer Science and Information Technology, University of Lahore, Lahore, Pakistan; email: arifmuhammad36@hotmail.com; O. Geman; Neuroaesthetics Lab, Stefan Cel Mare University of Suceava, Suceava, Romania; email: oana.geman@usm.ro","","Hindawi Limited","","","","","","20402295","","","35047149","English","J. Healthc. Eng.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85123674522"
"Waly M.I.; Sikkandar M.Y.; Aboamer M.A.; Kadry S.; Thinnukool O.","Waly, Mohamed Ibrahim (57196075534); Sikkandar, Mohamed Yacin (57202716139); Aboamer, Mohamed Abdelkader (56073053400); Kadry, Seifedine (55906598300); Thinnukool, Orawit (56146494600)","57196075534; 57202716139; 56073053400; 55906598300; 56146494600","Optimal deep convolution neural network for cervical cancer diagnosis model","2022","Computers, Materials and Continua","70","2","","3297","3309","12","23","10.32604/cmc.2022.020713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115993107&doi=10.32604%2fcmc.2022.020713&partnerID=40&md5=1dafd35e4d4d7422b32fcedd812b6d64","Department of Medical Equipment Technology, College of Applied Medical Sciences, Majmaah University, Al Majmaah, 11952, Saudi Arabia; Faculty of Applied Computing and Technology, Noroff University College, Kristiansand, 4608, Norway; Research Group of Embedded Systems and Mobile Application in Health Science, College of Arts, Media and Technology, Chiang Mai University, Chiang Mai, 50200, Thailand","Waly M.I., Department of Medical Equipment Technology, College of Applied Medical Sciences, Majmaah University, Al Majmaah, 11952, Saudi Arabia; Sikkandar M.Y., Department of Medical Equipment Technology, College of Applied Medical Sciences, Majmaah University, Al Majmaah, 11952, Saudi Arabia; Aboamer M.A., Department of Medical Equipment Technology, College of Applied Medical Sciences, Majmaah University, Al Majmaah, 11952, Saudi Arabia; Kadry S., Faculty of Applied Computing and Technology, Noroff University College, Kristiansand, 4608, Norway; Thinnukool O., Research Group of Embedded Systems and Mobile Application in Health Science, College of Arts, Media and Technology, Chiang Mai University, Chiang Mai, 50200, Thailand","Biomedical imaging is an effective way of examining the internal organ of the human body and its diseases. An important kind of biomedical image is Pap smear image that is widely employed for cervical cancer diagnosis. Cervical cancer is a vital reason for increased women's mortality rate. Proper screening of pap smear images is essential to assist the earlier identification and diagnostic process of cervical cancer. Computer-aided systems for cancerous cell detection need to be developed using deep learning (DL) approaches. This study introduces an intelligent deep convolutional neural network for cervical cancer detection and classification (IDCNN-CDC) model using biomedical pap smear images. The proposed IDCNN-CDC model involves four major processes such as preprocessing, segmentation, feature extraction, and classification. Initially, the Gaussian filter (GF) technique is applied to enhance data through noise removal process in the Pap smear image. The Tsallis entropy technique with the dragonfly optimization (TE-DFO) algorithm determines the segmentation of an image to identify the diseased portions properly. The cell images are fed into the DL based SqueezeNet model to extract deep-learned features. Finally, the extracted features from SqueezeNet are applied to the weighted extreme learning machine (ELM) classification model to detect and classify the cervix cells. For experimental validation, the Herlev database is employed. The database was developed at Herlev University Hospital (Denmark). The experimental outcomes make sure that higher performance of the proposed technique interms of sensitivity, specificity, accuracy, and F-Score. © 2022 Tech Science Press. All rights reserved.","Biomedical images; Cervical cancer; Computer aided diagnosis; Deep learning; Herlev database; Pap smear images","Computer aided diagnosis; Computer aided instruction; Convolution; Convolutional neural networks; Database systems; Diseases; Feature extraction; Image enhancement; Image segmentation; Medical imaging; Biomedical images; Cancer classification; Cancer detection; Cancer diagnosis; Cervical cancers; Classification models; Deep learning; Detection models; Herlev database; Pap smear images; Deep neural networks","","","","","Majmaah University, MU, (R-2021-164)","Acknowledgement: The authors extend their appreciation to the Deanship of Scientific at Majmaah University for funding this study under Project number R-2021-164.","Garcia-Gonzalez D., Garcia-Silvente M., Aguirre E., A multiscale algorithm for nuclei extraction in pap smear images, Expert Systems with Applications, 64, 4, pp. 512-522, (2016); Shankar K., Perumal E., A novel hand-crafted with deep learning features based fusion model for COVID-19 diagnosis and classification using chest X-ray images, Complex & Intelligent Systems, 7, pp. 1277-1293, (2020); Riana D., Hidayanto A. N., Widyantoro D. H., Mengko T. L. R., Kalsoem O., Segmentation of overlapping cytoplasm and overlapped areas in pap smear images, 2017 8th Int. Conf. on Information, Intelligence, Systems & Applications, Larnaca, pp. 1-5, (2017); Sikkandar M. Y., Alrasheadi B. A., Prakash N. B., Hemalakshmi G. R., Mohanarathinam A., Et al., Deep learning based an automated skin lesion segmentation and intelligent classification model, Journal of Ambient Intelligence and Humanized Computing, 12, 3, pp. 3245-3255, (2021); Lakshmi G. A., Ravi S., Automated segmentation algorithm for cervical cell images by employing cuckoo search based ICM, Journal of Ambient Intelligence and Humanized Computing, 113, (2017); Shankar K., Zhang Y., Liu Y., Wu L., Chen C.-H., Hyperparameter tuning deep learning for diabetic retinopathy fundus image classification, IEEE Access, 8, pp. 118164-118173, (2020); Lakshmanaprabu S. K., Mohanty S. N., Shankar K., Arunkumar N., Ramirez G., Optimal deep learning model for classification of lung cancer on CT images, Future Generation Computer Systems, 92, 1, pp. 374-382, (2019); Topaloglu R. O., ICCAD-2016 CAD contest in pattern classification for integrated circuit design space analysis and benchmark suite, Proc. of the 35th Int. Conf. on Computer-Aided Design, pp. 1-4, (2016); Raj R. J. S., Shobana S. J., Pustokhina I. V., Pustokhin D. A., Gupta D., Et al., Optimal feature selection-based medical image classification using deep learning model in internet of medical things, IEEE Access, 8, pp. 58006-58017, (2020); Ghoneim A., Muhammad G., Hossain M. S., Cervical cancer classification using convolutional neural networks and extreme learning machines, Future Generation Computer Systems, 102, 2019, pp. 643-649; Adem K., Kilicarslan S., Comert O., Classification and diagnosis of cervical cancer with stacked autoencoder and softmax classification, Expert Systems with Applications, 115, 15, pp. 557-564, (2019); Dong N., Zhao L., Wu C. H., Chang J. F., Inception v3 based cervical cell classification combined with artificially extracted features, Applied Soft Computing, 93, 6, (2020); Perlin H. A., Lopes H. S., Extracting human attributes using a convolutional neural network approach, Pattern Recognition Letters, 68, 3, pp. 250-259, (2015); William W., Ware A., Basaza-Ejiri A. H., Obungoloch J., Cervical cancer classification from pap-smears using an enhanced fuzzy C-means algorithm, Informatics in Medicine Unlocked, 14, pp. 23-33, (2019); Alyafeai Z., Ghouti L., A fully-automated deep learning pipeline for cervical cancer classification, Expert Systems with Applications, 141, 6, (2020); Devi M. A., Sheeba J. I., Joseph K. S., Neutrosophic graph cut-based segmentation scheme for efficient cervical cancer detection, Journal of King Saud University-Computer and Information Sciences, pp. 1-9, (2018); William W., Ware A., Basaza-Ejiri A. H., Obungoloch J., A pap-smear analysis tool (PAT) for detection of cervical cancer from pap-smear images, BioMedical Engineering OnLine, 18, 1, (2019); Rajinikanth V., Satapathy S. C., Fernandes S. L., Nachiappan S., Entropy based segmentation of tumor from brain MR images-A study with teaching learning based optimization, Pattern Recognition Letters, 94, 1, pp. 87-95, (2017); Mirjalili S., Dragonfly algorithm: a new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems, Neural Computing and Applications, 27, 4, pp. 1053-1073, (2016); Aci C.I., Gulcan H., A modified dragonfly optimization algorithm for single-and multiobjective problems using brownian motion, Computational Intelligence and Neuroscience, 2019, 2, pp. 1-17, (2019); Pustokhina V., Pustokhin D. A., Nguyen P. T., Elhoseny M., Shankar K., Multi-objective rain optimization algorithm with WELM model for customer churn prediction in telecommunication sector, Complex & Intelligent Systems, 38, 12, (2021); Lu J., Song E., Ghoneim A., Alrashoud M., Machine learning for assisting cervical cancer diagnosis: An ensemble approach, Future Generation Computer Systems, 106, 6, pp. 199-205, (2020)","O. Thinnukool; Research Group of Embedded Systems and Mobile Application in Health Science, College of Arts, Media and Technology, Chiang Mai University, Chiang Mai, 50200, Thailand; email: orawit.t@cmu.ac.th","","Tech Science Press","","","","","","15462218","","","","English","Comput. Mater. Continua","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85115993107"
"Pietka E.; Gertych A.","Pietka, Ewa (6603704848); Gertych, Arkadiusz (7801318586)","6603704848; 7801318586","Advances in biomedical image processing","2021","Computerized Medical Imaging and Graphics","89","","101891","","","","3","10.1016/j.compmedimag.2021.101891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102633947&doi=10.1016%2fj.compmedimag.2021.101891&partnerID=40&md5=dc14c6ea9665445cdac379ec846b0ccc","Silesian University of Technology, Faculty of Biomedical Engineering, Zabrze, Roosevelta 40, Poland; Department of Surgery, Department of Pathology and Laboratory Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States","Pietka E., Silesian University of Technology, Faculty of Biomedical Engineering, Zabrze, Roosevelta 40, Poland; Gertych A., Department of Surgery, Department of Pathology and Laboratory Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, United States","[No abstract available]","","Image Processing, Computer-Assisted; abdominal viscera; Alzheimer disease; anatomical concepts; atopic dermatitis; biomedical engineering; classification; computer assisted tomography; convolutional neural network; data analysis; deep learning; diagnostic imaging; digital imaging; echography; Editorial; feature extraction; functional link artificial neural network; high frequency ultrasound; human; image processing; image segmentation; imaging algorithm; machine learning; mild cognitive impairment; multimodal imaging; nuclear magnetic resonance imaging; particle swarm optimization; priority journal; wound healing","","","","","","","87; 87; 87; 87; 87; 87; 87; 87; 87; 87; 87; 87; 87","E. Pietka; Department of Surgery, Department of Pathology and Laboratory Medicine, Cedars-Sinai Medical Center, Los Angeles, United States; email: ewa.pietka@polsl.pl","","Elsevier Ltd","","","","","","08956111","","CMIGE","33744791","English","Comput. Med. Imaging Graph.","Editorial","Final","","Scopus","2-s2.0-85102633947"
"Kar M.K.; Nath M.K.; Neog D.R.","Kar, Mithun Kumar (37087476200); Nath, Malaya Kumar (26423133700); Neog, Debanga Raj (37087579900)","37087476200; 26423133700; 37087579900","A Review on Progress in Semantic Image Segmentation and Its Application to Medical Images","2021","SN Computer Science","2","5","397","","","","29","10.1007/s42979-021-00784-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128319580&doi=10.1007%2fs42979-021-00784-5&partnerID=40&md5=98d28f4b102eba15a7f2b1f6ce0ee806","Department of Electronics and Communication Engineering, National Institute of Technology Puducherry, Karaikal, 609609, India; Toronto, Canada","Kar M.K., Department of Electronics and Communication Engineering, National Institute of Technology Puducherry, Karaikal, 609609, India; Nath M.K., Department of Electronics and Communication Engineering, National Institute of Technology Puducherry, Karaikal, 609609, India; Neog D.R., Toronto, Canada","Semantic image segmentation is a popular image segmentation technique where each pixel in an image is labeled with an object class. This technique has become a vital part of image analysis nowadays as it facilitates the description, categorization, and visualization of the regions of interest in an image. The recent developments in computer vision algorithms and the increasing availability of large datasets have made semantic image segmentation very popular in the field of computer vision. Motivated by the human visual system which can identify objects in a complex scene very efficiently, researchers are interested in building a model that can semantically segment an image into meaningful object classes. This paper reviews deep learning-based semantic segmentation techniques that use deep neural network architectures for image segmentation of biomedical images. We have provided a discussion on the fundamental concepts related to deep learning methods used in semantic segmentation for the benefit of readers. The standard datasets and existing deep network architectures used in both medical and non-medical fields are discussed with their significance. Finally, this paper concludes by discussing the challenges and future research directions in the field of deep learning-based semantic segmentation for applications in the medical field. © 2021, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.","Automated medical image analysis; Convolution neural network; Deep learning; Deep neural network; Recurrent neural network; Semantic segmentation","","","","","","National Institute of Technology Srinagar, NITSRI","This work is carried out at NIT Puducherry, Karaikal, India.","Fritsch Kuehnl J., Geiger A., A newperformance measure and evaluation benchmark for road detection algorithms, In: Proc. IEEE Int’l Conf. Intelligent Transportation Systems (ITSC)., pp. 9-18, (2013); Menze M., Geiger A., Object scene flow for autonomous vehicles. Computer Vision and Pattern Recognition, Proc. IEEE Int’l Conf, 2015, pp. 1-11; Cordts M., Omran M., Ramos S., Rehfeld T., Enzweiler M., Benenson R., Franke U., Roth S., Schiele B., The cityscapes dataset for semantic urban scene understanding, In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3213-3223, (2016); Huang C., Davis L., Townshend J., An assessment of support vector machines for land cover classification, In: Proc. IEEE Int’l Journal Remote Sensing, 23, 4, pp. 725-749, (2002); Oberweger M., Wohlhart P., Lepetit V., Hands Deep in Deep Learning for Hand Pose Estimation, pp. 1-10, (2015); Yoon Y., Jeon H.G., Yoo D., Lee J.Y., Kweon I.S., Learning a deep convolutional network for light-field image super resolution, In: Proceedings of the IEEE International Conference on Computer Vision Workshops, pp. 24-32, (2015); Kooi T., Litjens G., van Ginneken B., Gubern-Merida A., Sanchez C.I., Mann R., den Heeten A., Karssemeijer N., Large scale deep learning for computer aided detection of mammographic lesions, Med Image Anal., 35, pp. 302-312, (2016); Ghafoorian M., Karssemeijer N., Heskes T., van Uden I.W.M., de Leeuw F., Marchiori E., van Ginneken B., Platel B., Non-uniform patch sampling with deep convolutional neural networks for white matter hyper intensity segmentation, IEEE Int Symp Biomedical Imaging., pp. 1414-1417, (2016); Charbonnier J., van Rikxoort E., Setio A., Schaefer-Prokop C., van Ginneken B., Ciompi F., Improving airway segmentation in computed tomography using leak detection with convolutional networks, Med Image Anal., 36, pp. 52-60, (2017); Grinsven M.J., Hoyng C.B., Theelen T., Sanchez C.I., Fast convolutional neural network training using selective data sampling: Application to hemorrhage detection in color fundus images, In: Proc. IEEE Trans Med Imaging., 35, pp. 1273-1284, (2016); Karimi D., Samei G., Kesch C., Nir G., Salcudean S.E., Prostate segmentation in mri using a convolutional neural network architecture and training strategy based on statistical shape models, Int J Comput Assist Radiol Surg, 13, 8, pp. 1211-1219, (2018); Tran G.S., Nghiem T.P., Nguyen V.T., Luong C.M., Burie J.-C., Improving accuracy of lung nodule classification using deep learning with focal loss, Int’l J Healthcare Eng., pp. 1-9, (2019); Bejnordi B.E., Veta M., van Diest P.J., Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer, JAMA, 318, 22, pp. 2199-2210, (2017); Esteva A., Kuprel B., Novoa R.A., Ko J., Swetter S.M., Blau H.M., Thrun S., Dermatologist-level classification of skin cancer with deep neural networks, Proc Nat, 542, 7639, pp. 115-118, (2017); Yang W., Chen Y., Liu Y., Zhong L., Qin G., Lu Z., Feng Q., Chen W., Cascade of multi-scale convolutional neural networks for bone suppression of chest radiographs in gradient domain, Med Image Anal., 35, pp. 421-433, (2016); Litjens G., Kooi T., Bejnordi B.E., Arindra A., Setio A., Ciompi F., Ghafoorian M., van Der Laak J.A., van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Diagnostic Image Analysis Group, pp. 1-38, (2017); Hu K., Zhang Z., Niu X., Zhang Y., Cao C., Xiao F., Gao X., Retinal vessel segmentation of color fundus images using multiscale convolutional neural network with an improved cross-entropy loss function, J Neurocomput., 309, pp. 179-191, (2018); Chen X., Xu Y., Wong D.W.K., Wong T.Y., Liu J., Glaucoma detection based on deep convolutional neural network, Med Biol Soc: Proc. IEEE Int’l Conf, pp. 715-718, (2015); Havaei M., Davy A., Warde-Farley D., Et al., Brain tumor segmentation with deep neural networks, Med Image Anal., 35, pp. 18-31, (2017); Huynh B.Q., Li H., Giger M.L., Digital mammographic tumor classification using transfer learning from deep convolutional neural networks, Med Imaging, 3, 3, (2016); Kamnitsas K., Ledig C., Newcombe V.F., Simpson J.P., Kane A.D., Menon D.K., Rueckert D., Glocker B., Efficient multi-scale 3d CNN with fully connected CRF for accurate brain lesion segmentation, Proc Med Image Anal, 36, pp. 61-78, (2017); Kawahara J., Bentaieb A., Hamarneh G., Deep features to classify skin lesions, IEEE Int Symp Biomed Imaging., pp. 1397-1400, (2016); Akram S.U., Kannala J., Eklund L., Heikkila J., Cell segmentation proposal network for microscopy image analysis, Second International Workshop, DLMIA: Proc, pp. 21-29, (2016); Cohen A., Rivlin E., Shimshoni I., Sabo E., Memory based active contour algorithm using pixel-level classified images for colon crypt segmentation, Med Imaging Graph., 43, pp. 150-164, (2015); Thoma M., A survey of semantic segmentation, pp. 1-16, (2016); Guo Y., Liu Y., Georgiou T., Lew M.S., A review of semantic segmentation using deep neural networks, Int’l Journal of Multimedia Information Retrieval, pp. 787-790, (2018); Liu X., Deng Z., Yang Y., Recent progress in semantic image segmentation, Proc Artif Intell Rev, 52, 2, pp. 1089-1106, (2018); Goceri E., Challenges and recent solutions for image segmentation in the era of deep learning, Tools and Applications (IPTA): Proc.In Ninth Int’l Conference on Image Processing Theory., pp. 1-6, (2019); Taghanaki S.A., Abhishek K., Cohen J.P., Cohen-Adad J., Hamarneh G., Deep semantic segmentation of natural and medical images: a review, CoRR, 54, 1, pp. 137-178, (2019); Siddique I., Bajwa I., Naveed M., Choudhary M., Auto-matic functional brain mr image segmentation using region growing and seed pixel, . IEEE Int’l Conf. on Information and Communications Technology, pp. 1-12, (2006); Zhu S.C., Guo Y.W.C.E., Xu Z., Int’l Journal of Comput Vision, 62, pp. 121-143, (2005); Ho T.K., Random decision forests, Document Analysis and Recognition: Proc. IEEE Intl Conf, pp. 278-282, (1995); Plath N., Toussaint M., Nakajima S., Multiclass image segmentation using conditional random fields and global classification, In: Proceedings of the 26Th Annual International Conference on Machine Learning. (ACM, pp. 817-824, (2009); Cheng H., Jiang X., Sun Y., Wang J., Color image segmentation: advances and prospects, Pattern Recogn., 34, 12, pp. 2259-2281, (2001); Dalal N., Triggs B., Histograms of oriented gradients for human detection, Comput Vis Pattern Recogn, pp. 886-893, (2005); Lowe D., Distinctive image features from scale invariant keypoints, Int J Comput Vis, 60, pp. 91-110, (2004); Pietikainen M., Maenpaa T., Viertola J., Color texture classification with color histograms and local binary patterns, Workshop on Texture Analysis in Machine Vision, pp. 1-4, (2002); Bradski G., Pisarevsky V., Intel’s computer vision library: Applications in calibration, stereo segmentation, tracking, gesture, face and object recognition, . In: Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR, (2000); Chen H., Zheng Y., Park J.H., Heng P.A., Zhou S.K., Iterative multi-domain regularized deep learning for anatomical structure detection and segmentation from ultrasound images, Med Image Comput Assist Interv: Proc, 9901, pp. 487-495, (2016); Brox T., Bourdev L., Maji S., Malik J., Object segmentation by alignment of poselet activations to image contours, Computer Vision and Pattern Recognition: IEEE Intl Conf, pp. 2225-2232, (2011); Farag A., Lu L., Roth H.R., Liu J., Turkbey E., Summers R.M., A bottom-up approach for pancreas segmentation using cascaded superpixels and (Deep) image patch labeling, pp. 1-14, (2015); Saidin N., Ngah U.K., Sakim H.A.M., Siong D.N., Hoe M.K., Density based breast segmentation for sammograms using graph gut techniques, TENCON 2009, (2009); Adam A., Ioannidis C., Automatic road-sign detection and classification based on support vector machines and hog descriptors, Remote Sensing and Spatial Information Sciences: ISPRS Annals of the Photogrammetry., pp. 1-7, (2014); Yang M.Y., Forstner W., A hierarchical conditional random field model for labeling and classifying images of man-made scenes, pp. 196-203, (2011); Korc F., Forstner W., Etrims image database for interpreting images of man-made scenes; Shotton J., Winn J., Rother C., Criminisi A., . Textonboost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation, Computer Vision-Eccv, pp. 1-15, (2006); Vemulapalli R., Tuzel O., Liu M.-Y., Chellappa R., Gaussian conditional random field network for semantic segmentation, Computer Vision and Pattern Recognition: IEEE Intl Conf, pp. 3224-3233, (2015); Gulsrud T.O., Engan K., Hanstveit T., Watershed segmentation of detected masses in digital mammograms, In Proceedings of the IEEE Conference on Engineering in Medicine and Biology 27Th Annual Conference, pp. 3305-3307, (2005); Huang Y.L., Chen D.R., Watershed segmentation for breast tumor in 2D sonography, Ultrasound Med Bio, 30, pp. 625-632, (2004); Gomez W., Leija L., Pereira W.C.A., Infantosi A.F.C., Segmentation of breast, nodules on ultrasonographic images based on marke d-controlled watershed transform, Computación Y Sistemas: Proc, 14, pp. 165-174, (2010); Pan Z., Lu J., A bayes-based region-growing algorithm for medical image segmentation, Comput Sci Eng., 9, 4, pp. 32-38, (2007); Machine Learning: An Algorithmic Perspective, (2015); Chen L.C., Papandreou G., Kokkinos I., Murphy K., Yuille A., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs., 2016, pp. 834-848; Kim H., Hwang S., Scale-Invariant Feature Learning Using Deconvolutional Neural Networks for Weakly-Supervised Semantic Segmentation, pp. 1-17, (2016); Krizhevsky A., Sutskever I., Hinton G., Imagenet classification with deep convolutional neural networks, Adv Neural Inf Process Syst, pp. 1097-1105, (2012); Fukushima K., Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position, Biol Cybernet, 36, pp. 193-202, (1980); (2016); Lo S.-C., Chan H.-P., Lin J.-S., Li H., Freedman M.T., Mun S.K., Artificial convolution neural network for medical image pattern recognition, In: Proceedings Neural Networks, (1995); Yann L., Cortes C., Burges C.J., Mnist handwritten digit database, (2013); Long J., Shelhamer E., Darrell T. Fully convolutional networks for semantic segmentation. Computer Vision and Pattern Recognition: Proc, IEEE Int’l Conf, 79, 10, pp. 1337-1342, (2015); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 1-8, (2017); Caffe J.Y., An Open Source Convolutional Architecture for Fast Feature Embedding., (2013); Silberman N., Hoiem D., Kohli P., Fergus R., Indoor segmentation and support inference from rgbd images, European Conference on Computer Vision, pp. 746-760, (2012); Liu C., Yuen J., Torralba A., Nonparametric scene parsing: Label transfer via dense scene alignment. Computer Vision and Pattern Recognition: Proc, IEEE Intl Conf, pp. 1972-1979, (2009); Shelhamer E., Long J., Darrell T., Fully convolutional models for semantic segmentation, Pattern Analysis and Machine Intelligence: IEEE, pp. 1-12, (2016); Chen L.-C., Zhu Y., Papandreou G., Schroff F., Adam H., Encoder-decoder with atrous separable convolution for semantic image segmentation, (2018); Bengio Y., Learning deep architectures for ai, Foundations and trends in machine learning, (2009); Pinheiro P.H., Collobert R., Recurrent convolutional neural networks for scene parsing, pp. 1-14, (2013); Gould S., Fulton R., Koller D., Decomposing a scene into geometric and semantically consistent regions, In: IEEE 12Th International Conference on Computer Vision, pp. 1-8, (2009); Ren X., Malik J., Learning a classification model for segmentation, . In: Proceedings of the Ninth IEEE International Conference on Computer Vision, 2, pp. 1-10, (2003); Farabet C., Couprie C., Najman L., Lecun Y., Learning hierarchical features for scene labeling, Pattern Analysis and Machine Intelligence: IEEE, pp. 1-15, (2013); Sharma A., Tuzel O., Liu M.Y., Recursive context propagation network for semantic segmentation, NIPS, (2014); Hong S., Noh H., Han B., . Decoupled deep neural network for semi-supervised semantic segmentation, (2015); Lempitsky V., Vedaldi A., Zisserman A., A pylon model for semantic segmentation, In: Advances in Neural Information Processing Systems, (2011); Kallenberg M., Petersen K., Nielsen M., Ng A., Diao P., Igel C., Vachon C., Holland K., Karssemeijer N., Lillholm M., Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring, Proc IEEE Trans Med Imaging, 35, 5, pp. 1322-1331, (2016); Zhu X., Goldberg A., Introduction to semisupervised learning, Synthesis lectures on artificial intelligence and machine learning, 3, (2009); Roth H., Oda M., Shimizu N., Oda H., Hayashi Y., Kitasaka T., Fujiwara M., Misawa K., Mori K., Towards dense volumetric pancreas segmentation in ct using 3d fully convolutional networks, Medical Imaging, pp. 1-6, (2017); Vincent P., Larochelle H., Lajoie I., Bengio Y., Manzago P.A., Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion, J Mach Learn Res, (2010); Janowczyk A., Basavanhally A., Madabhushi A., Stain normalization using sparse autoencoders (Stanosa): Application to digital pathology, Proc: Comput Med Imaging Graph, 2016, pp. 3320-3328; Chen M., Shi X., Zhang Y., Wu D., Guizani M., Deep feature learning for medical image analysis with convolutional autoencoder neural network, IEEE Trans Big Data, pp. 1-10, (2016); Gondara L., Medical image denoising using convolutional denoising autoencoders, Proc. IEEE Int’l Conf. on Data Mining Workshops, pp. 242-246, (2016); Hinton G., A practical guide to training restricted boltzmann machines, UTML TR, pp. 2010-3003, (2010); Brosch T., Traboulsee A., Li D.K., Tam R., Deep learning of image features from unlabeled data for multiple sclerosis lesion segmentation, International Workshop on Machine Learning in Medical Imaging, pp. 117-124, (2014); Pereira S., Meier R., McKinley R., Wiest R., Alves V., Silva C.A., Reyes M., Enhancing interpretability of automatically extracted machine learning features: application to a rbm-random forest system on brain lesion segmentation, Med Image Anal., 44, pp. 228-244, (2018); Nahid A.-A., Mikaelian A., Kong Y., Histopathological breast-image classification with restricted boltzmann machine along with backpropagation, Biomed Res., 29, 10, pp. 2068-2077, (2018); Cao P., Liu X., Bao H., Yang J., Zhao D., Restricted boltzmann machines based oversampling and semi-supervised learning for false positive reduction in breast cad, Bio-Med Mater Eng., 26, s1, pp. S1541-S1547, (2015); Hinton G.E., Deep belief networks, Scholarpedia, 4, 5, (2009); Oquab M., Bottou L., Laptev I., Sivic J., Learning and transferring mid-level image representations using convolutional neural networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1717-1724, (2014); Shie C.K., Chuang C.-H., Chou C.-N., Wu M.-H., Chang E.Y., Transfer representation learning for medical image analysis, 37Th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 711-714, (2015); Yosinski J., Clune J., Bengio Y., Lipson H., How transferable are features in deep neural networks, ?. In: Advances in Neural Information Processing Systems, pp. 3320-3328, (2014); Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L., Imagenet: A large-scale hierarchical image database, Computer Vision and Pattern Recognition: Proc. IEEE Int’l Con, pp. 1-11, (2009); Singh S., Ho-Shon K., Karimi S., Hamey L., Modality classification and concept detection in medical images using deep transfer learning, International Conference on Image and Vision Computing, (IVCNZ), pp. 1-6, (2018); Luc P., Couprie C., Chintala S., Semantic segmentation using adversarial networks, Workshop on Adversarial Training, NIPS, pp. 1-9, (2016); Li Y., Qi H., Dai J., Ji X., Wei Y., Fully Convolutional Instance-Aware Semantic Segmentation., pp. 2359-2367, (2016); Dai J., He K., Sun J., Instance-Aware Semantic Segmentation via Multi-Task Network Cascades., pp. 3150-3158, (2015); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, pp. 1-14, (2014); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Visin F., Kastner K., Cho K., Matteucci M., Courville A.C., Bengio Y., Renet: A Recurrent Neural Network Based Alternative to Convolutional Networks, 2015, pp. 1-9; Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Computer Vision and Pattern Recognition: Proc. IEEE Intl Conf, (2015); Badrinarayanan V., Kendall A., Cipolla R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation, pp. 1-14, (2016); Zhao H., Shi J., Qi X., Wang X., Jia J., Pyramid scene parsing network, pp. 2881-2890, (2016); Kalesnykiene V., Kamarainen Jkvoutilainen R., Pietila J., Kalviainen H., Uusitalo H., Diaretdb1 diabetic retinopathy database and evaluation protocol., pp. 1-10, (2014); Porwal P., Pachade S., Kamble R., Kokare M., Deshmukh G., Sahasrabuddhe V., Meriaudeau F., Indian diabetic retinopathy image dataset (idrid): a database for diabetic retinopathy screening research, MDPI Data, 3, 3, (2018); Setio A.A.A., Jacobs C., Gelderblom J., van Ginneken B., Automatic detection of large pulmonary solid nodules in thoracic CT images, Med Phys., 42, 10, pp. 5642-5653, (2015); Cui S., Mao L., Jiang J., Liu C., Xiong S., Automatic semantic segmentation of brain gliomas from MRI images using a deep cascaded neural network, Hindawi J Healthcare Eng, pp. 1-14, (2018); Hein L.M., Mersmann S., Kondermann D., Bodenstedt S., Sanchez A., Stock C., Kenngott H.G., Eisenmann M., Speidel S., Can masses of non-experts train highly accurate image classifiers?, Proc. Medical Image Computing and Computer-Assisted Intervention-Miccai, pp. 438-445, (2014); Coelho L.P., Shariff A., Murphy R.F., Nuclear segmentation in microscope cell images: A hand segmented dataset and comparison of algorithms, In: Proc. IEEE Int’l Symposium on Biomedical Imaging from Nano to Macro, pp. 518-521, (2009); Sirinukunwattana K., Pluim J.P.W., Chen H., Qi X., Heng P., Guo Y.B., Wang L.Y., Matuszewski B.J., Bruni E., Sanchez U., Bohm A., Ronneberger O., Cheikh B.B., Racoceanu D., Kainz P., Pfeiffer M., Urschler M., Snead D.R.J., Rajpoot NM. Gland segmentation in colon histology images: The glas challenge contest, . Arxiv, (2016); Maska M., Ulman V., Svoboda D., Matula P., A benchmark for comparison of cell tracking algorithms, Proc Bioinform., 30, 11, pp. 1609-1617, (2014); Arteta C., Lempitsky V., Noble J., Zisserman A., Learning to detect cells using non-overlapping extremal regions, MICCAI 2012, Part I. LNCS, pp. 348-356, (2012); Kainz P., Urschler M., Schulter S., Wohlhart P., You should use regression to detect cells, MICCAI 2015, 9351, pp. 276-283, (2015); Wang X., Peng Y., Lu L., Lu Z., Bagheri M., Summers R., Chest x-ray: Hospital-scale chest x-ray database and benchmarks on weakly supervised classification and localization of common thorax diseases, Computer Vision and Pattern Recognition: IEEE Int’l Conf, pp. 3462-3471, (2017); Aew J., Pollard T., Berkowitz S., Greenbaum N., Lungreen M., Deng C., Mark R., Horng S., Mimic-Csr: A Large Database of Labeled Chest Radiographs, pp. 1-7, (2019); Shiraishi J., Katsuragawa S., Matsumoto T., Kobayashi T., Ichi Komatsu K., Matsui M., Fujita H., Kodera Y., Doi K., Development of a digital image database for chest radiographs with and without a lung nodule, Am J Roentgenol, 174, 1, pp. 71-74, (2000); van Ginneken B., Stegmann M., Loog M., Segmentation of anatomical structures in chest radiographs using supervised methods: a comparative study on a public database, Med Image Anal., 10, 1, pp. 19-40, (2006); Chilamkurthy S., Ghosh R., Tanamala S., Biviji M., Campeau N., Venugopal V., Mahajan V., Rao P., Warier P., Deep learning algorithms for detection of critical findings in head CT scans: A retrospective study, Proc. the Lancet., 932, pp. 2388-2396, (2018); Grammatikopoulou M., Flouty E., Kadkhodamohammadi A., Quellec G., Chow A., Nehme J., Luengo I., Stoyanov D., Cadis: Cataract dataset for image segmentation, pp. 1-8, (2019); Ye M., Giannarou S., Meining A., Yang G.-Z., Online tracking and retargeting with applications to optical biopsy in gastrointestinal endoscopic examinations, Med Image Anal., 30, pp. 144-157, (2015); Abadi M., Agarwal A., Barham P., Brevdo E., Chen Z., Citro C., Corrado G.S., Davis A., Dean J., Devin M., Tensorflow: Large-scale machine learning on heterogeneous distributed systems, (2016); Bastien F., Lamblin P., Pascanu R., Bergstra J., Goodfellow I., Bergeron A., Bouchard N., Warde-Farley D., Bengio Y., Theano: New features and speed improvements, Int J Mach Learn, 2012, pp. 1-10; Collobert R., Weston J., Karlen M., Natural Language Processing (Almost) from Scratch, 12, pp. 2493-2537, (2011); Chollet F., (2015); Chen T., Li M., Li Y., Lin M., Wang N., Wang M., Xiao T., Xu B., Zhang C., Zhang Z., Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems, pp. 1-6, (1995); Seide F., Agarwal A., Cntk: Microsoft’s pen-source deep-learning toolkit, (2016); Sharma A., Tuzel O., Jacobs D.W., Deep hierarchical parsing for semantic segmentation, Computer Vision and Pattern Recognition: IEEE Int’l Conf, pp. 530-538, (2015); Roth H.R., Shen C., Oda H., Oda M., Hayashi Y., Misawa K., Mori K., Deep learning and its application to medical image segmentation, Med Imaging., pp. 1-6, (2018); Smistad E., Lovstakken L., Vessel detection in ultrasound images using deep convolutional neural networks, Proceedings DLMIA. Vol. 10008 of Lect Notes Comput Sci, pp. 30-38, (2016); Tajbakhsh N., Shin J.Y., Gurudu S.R., Hurst R.T., Kendall C.B., Gotway M.B., Liang J., Convolutional neural networks for medical image analysis: Full training or fine tuning?, IEEE Trans Med Imaging., 35, 5, pp. 1299-1312, (2016); Zhoua X.-Y., Shena M., Rigab C., Yanga G.-Z., Lee S-L. Focal FCN: Towards small object segmentation with limited training data, . Arxiv, (2017); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, Proc. IEEE International Conference on Computer Vision, pp. 2980-2988, (2017); Zhoua X., Takayama R., Wang S., Hara T., Fujita H., Deep learning of the sectional appearances of 3d ct images for anatomical structure segmentation based on an FCN voting method, Med Phys, 44, 10, pp. 5221-5233, (2017); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-Net: Learning dense volumetric segmentation from sparse annotation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 424-432, (2016); Ahn B.B., The compact 3d convolutional neural network for medical images, (2017); Hammack D., Forecasting lung cancer diagnoses with deep learning, Data Science Bowl 2017 Technical Report, pp. 1-6, (2017); Jahangard S., Zangooei M.H., Shahedib M., U-Net based architecture for an improved multiresolution segmentation in medical images, Electric Eng Syst Sci, pp. 1-22, (2020); Lou A., Guan S., Loew M., DC-UNet: Rethinking the u-net architecture with dual channel efficient CNN for medical images segmentation, Electric Eng Syst Sci, pp. 1-16, (2020); Lei Y., Liu Y., Dong X., Tian S., Wang T., Jiang X., Higgins K., Beitler J.J., Yu D.S., Liu T., Curran W.J., Fang Y., Yang X., Automatic multi-organ segmentation in thorax CT images using u-net-gan, Proc.Spie Medical Imaging, (2019); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., Unet++: Redesigning skip connections to exploit multiscale features in image segmentation, IEEE Trans Med Imaging, 39, 6, pp. 1856-1867, (2020); Li X., Wang Y., Tang Q., Fan Z., Yu J., Dual unet for the segmentation of overlapping glioma nuclei, IEEE Access, 7, pp. 84040-84052, (2019); Yu L., Chen H., Dou Q., Qin J., Heng P.-A., Automated melanoma recognition in dermoscopy images via very deep residual networks, IEEE Trans Med Imaging., 36, 4, pp. 994-1004, (2016); Chen H., Dou Q., Yuvoxresnet L.P.-A., Deep voxelwise residual networks for volumetric brain segmentation, Neuroimage, 170, pp. 446-455, (2018); Cho K., van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning phrase representations using RNN encoder–decoder for statistical machine translation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1724-1734, (2014); Chen J., Yang L., Zhang Y., Alber M., Chen D.Z., Combining fully convolutional and recurrent neural networks for 3D biomedical image segmentation, 29Th Conference on Neural Information Processing Systems (NIPS 2016), pp. 1-9, (2016); Stollenga M.F., Byeon W., Liwicki M., Schmidhuber J., Parallel multi-dimensional lstm, with application to fast biomedical volumetric image segmentation, Arxiv:Abs/1506.07452., pp. 1-13, (2015); Poudel R.P.K., Lamata P., Montana G., Recurrent Fully Convolutional Neural Networks for Multi-Slice MRI Cardiac Segmentation, pp. 1-12, (2016); Radau P., Lu Y., Connelly K., Paul G., Dick A., Wright G., Evaluation Framework for Algorithms Segmenting Short Axis Cardiac MRI, (2009); Feng X., Yang J., Laine A.F., Angelini E.D., Discriminative localization in CNNs for weakly-supervised segmentation of pulmonary nodules, Arxiv:Abs/1707.01086, pp. 1-8, (2017); Gu Z., Cheng J., Fu H., Zhou K., Hao H., Zhao Y., Zhang T., Gao S., Liu J., Ce-net: Context encoder network for 2d medical image segmentation, IEEE Trans Med Imaging., 38, 10, pp. 2281-2292, (2019); Oktay O., Ferrante E., Kamnitsas K., Heinrich M., Bai W., Caballero J., Anatomically constrained neural networks (ACNN): application to cardiac image enhancement and segmentation, IEEE Trans Med Imaging, 37, 2, pp. 384-395, (2018); Alex V., Vaidhya K., Thirunavukkarasu S., Kesavadas C., Krishnamurthia G., Semisupervised learning using denoising autoencoders for brain lesion detection and segmentation, J Med Imaging., 4, 4, (2017); Yosinski J., Clune J., Bengio Y., Lipson H., How Transferable are Features in Deep Neural Networks?, pp. 1-9, (2014); Ravishankar H., Sudhakar P., Venkataramani R., Thiruvenkadam S., Annangi P., Babu N., Vaidya V., Understanding the mechanisms of deep transfer learning for medical images, Arxiv:Abs/1704.06040, pp. 1-8, (2017); Chen S., Ma K., Zheng Y., Med3d: Transfer learning for 3D medical image analysis., pp. 1-12, (2019); Xue Y., Xu T., Zhang H., Long L.R., Huang X., Segan: Adversarial network with multi-scale loss for medical image segmentation, pp. 1-9, (2017); Rezaei M., Yang H., Meinel C., Recurrent generative adversarial network for learning imbalanced medical image semantic segmentation, Multimed Tools Appl, 79, 21, pp. 15329-15348, (2019); Jiang F., Grigorev A., Rho S., Tian Z., Fu Y., Jifara W., Adil K., Liu S., Medical image semantic segmentation based on deep learning, Neural Computing in Next Generation Virtual Reality Technology, pp. 1257-1265, (2017); Cai J., Lu L., Zhang Z., Xing F., Yang L., Yin Q., Pancreas segmentation in MRI using graph-based decision fusion on convolutional neural networks, Med Image Comput Assist Interv, 9901, pp. 442-450, (2016); Thong W., Kadoury S., Piche N., Pal C.J., Convolutional networks for kidney segmentation in contrast-enhanced CT scans, Proceedings Computer Methods in Biomechanics and Biomedical Engineering: Imaging and Visualization, pp. 1-6, (2016); Lessmann N., Isgum I., Setio A.A., de Vos B.D., Ciompi F., de Jong P.A., Oudkerk M., Viergever Mali W.P.T.M.M.A., Ginneken B., Deep convolutional neural networks for automatic coronary calcium scoring in a screening study with low dose chest CT, Proc. Medical Imaging, 9785, pp. 1-6, (2016); Juan J., Gomez Valverde GF, Anton Alfonso. Automatic glaucoma classification using color fundus images based on convolutional neural networks and transfer learning, Proceedings Biomedical Optics Express, 10, 2, pp. 892-913, (2019); Li Z., Md Y., He S., Keel W., Chang Meng R.T., He M., Efficacy of a deep learning system for detecting glaucomatous optic neuropathy based on color fundus photographs, Proceedings American Academy of Opthulmology, 125, 8, pp. 1199-1206, (2018); Raghavendra U., Fujita H., Bhandary S.V., Gudigar A., Tan J.H., Acharya U.R., Deep convolution neural network for accurate diagnosis of glaucoma using digital fundus images, In: Proc. International Journal of Informatics and Computer Science Intelligent Systems Applications., 441, pp. 41-49, (2018); Dong F.L.Y.M.H., Yang G., Guo Y., Automatic brain tumor detection and segmentation using u-net based fully convolutional networks, Medical Image Understanding and Analysis, pp. 1-12, (2017); Dvorak P., Menze B., Structured prediction with convolutional neural networks for multimodal brain tumor segmentation. MICCAI-BRATS, Proc, pp. 13-24, (2015); Alansary A., Kamnitsas K., Davidson A., Khlebnikov R., Rajchl M., Malamateniou C., Rutherford M., Hajnal J.V., Glocker B., Rueckert D., Kainz B., Fast fully automatic segmentation of the human placenta from motion corrupted MIR, Med Image Computation Assist Interv: Proc, 9901, pp. 589-597, (2016); Gao Y., Maraci M.A., Noble J.A., Describing ultrasound video content using deep convolutional neural networks, : IEEE Int Symp Biomedical Imaging: Proc, pp. 787-790, (2016); Li Y., Ping W., Cancer metastasis detection with neural conditional random field, 1St Conference on Medical Imaging with Deep Learning (MIDL), pp. 1-9, (2018); Kraus O.Z., Ba J.L., Frey B.J., Classifying and segmenting microscopy images with deep multiple instance learning, Bioinformatics, 32, 12, pp. 152-159, (2016); Birenbaum A., Greenspan H., Longitudinal multiple sclerosis lesion segmentation using multi-view convolutional neural networks, Second International Workshop, pp. 58-67, (2016); Fotin S.V., Yin Y., Haldankar H., Hofmeister J.W., Periaswamy S., Detection of soft tissue densities from digital breast tomosynthesis: Comparison of conventional and deep learning approaches, Medical Imaging(Spie): Proc, 9785, pp. 1-6, (2016); Ramaswamy S., Truong K., Pulmonary Nodule Classification with Convolutional Neural Networks, (2016); Avendi M.R., Kheradvar A., Jafarkhani H., Automatic segmentation of the right ventricle from cardiac MRI using a learning-based approach, Magn Reson Med., 78, 6, pp. 2439-2448, (2016); Guo Y., Wu G., Commander L.A., Szary S., Jewells V., Lin W., Shent D., Segmenting hippocampus from infant brains by sparse patch matching with deep-learned features, International Conference on Medical Image Computing and Computer-Assisted Intervention, 7, pp. 87-93, (2014); Mansoor A., Cerrolaza J., Idrees R., Biggs E., Alsharid M., Avery R., Linguraru M.G., Deep learning guided partitioned shape model for anterior visual path- way segmentation, Imaging: IEEE Trans. Med, 35, 8, pp. 1856-1865, (2016); Su H., Xing F., Kong X., Xie Y., Zhang S., Yang L., Robust cell detection and segmentation in histopathological images using sparse reconstruction and stacked denoising autoencoders, Lecture Notes in Computer Science, 9351. Springer, 9351, pp. 383-390, (2018); Cai Y., Landis M., Laidley D.T., Kornecki A., Lum S.L.A., Multi-modal vertebrae recognition using transformed deep convolution network, Comput Med Imaging Graph, 51, pp. 11-19, (2016); Azizi S., Imani F., Ghavidel S., Tahmasebi A., Kwak J.T., Xu S., Turkbey B., Choyke P., Pinto P., Wood B., Mousavi P., Abolmaesumi P., Detection of prostate cancer using temporal sequences of ultrasound data: a large clinical feasibility study, Surgery, 11, 6, pp. 947-956, (2016); Shorten C., Khoshgoftaar T.M., A survey on image data augmentation for deep learning, J Big Data, 6, 60, (2019); Souly N., Spampinato C., Shah M., Semi Supervised Semantic Segmentation Using Generative Adversarial Network, 2017, pp. 5688-5696","M.K. Kar; Department of Electronics and Communication Engineering, National Institute of Technology Puducherry, Karaikal, 609609, India; email: mithunkar.iitg@gmail.com","","Springer","","","","","","2662995X","","","","English","SN COMPUT. SCI.","Review","Final","","Scopus","2-s2.0-85128319580"
"Cardoso I.; Almeida E.; Allende-Cid H.; Frery A.C.; Rangayyan R.M.; Azevedo-Marques P.M.; Ramos H.S.","Cardoso, Isadora (57191339334); Almeida, Eliana (8295156100); Allende-Cid, Hector (57208732887); Frery, Alejandro C. (7003561251); Rangayyan, Rangaraj M. (7005319550); Azevedo-Marques, Paulo M. (57218760488); Ramos, Heitor S. (25655377800)","57191339334; 8295156100; 57208732887; 7003561251; 7005319550; 57218760488; 25655377800","Analysis of Machine Learning Algorithms for Diagnosis of Diffuse Lung Diseases","2018","Methods of Information in Medicine","57","5-6","","272","279","7","12","10.1055/s-0039-1681086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062992252&doi=10.1055%2fs-0039-1681086&partnerID=40&md5=d012875b4843abe14c00b5e756e5098f","Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil; Escuela de Ingeniería Informatica, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile; Department of Electrical and Computer Engineering, Schulich School of Engineering, University of Calgary, Calgary, AB, Canada; Department of Internal Medicine, Ribeirão Preto Medical School, University of São Paulo, Ribeirão Preto, Brazil","Cardoso I., Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil; Almeida E., Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil; Allende-Cid H., Escuela de Ingeniería Informatica, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile; Frery A.C., Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil; Rangayyan R.M., Department of Electrical and Computer Engineering, Schulich School of Engineering, University of Calgary, Calgary, AB, Canada; Azevedo-Marques P.M., Department of Internal Medicine, Ribeirão Preto Medical School, University of São Paulo, Ribeirão Preto, Brazil; Ramos H.S., Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Av. Lourival Melo Mota, S/N, Maceió, Alagoas, 57072900, Brazil","Computational Intelligence Re-meets Medical Image Processing A Comparison of Some Nature-Inspired Optimization Metaheuristics Applied in Biomedical Image Registration Summary Background Diffuse lung diseases (DLDs) are a diverse group of pulmonary disorders, characterized by inflammation of lung tissue, which may lead to permanent loss of the ability to breathe and death. Distinguishing among these diseases is challenging to physicians due their wide variety and unknown causes. Computer-aided diagnosis (CAD) is a useful approach to improve diagnostic accuracy, by combining information provided by experts with Machine Learning (ML) methods. Objectives Exploring the potential of dimensionality reduction combined with ML methods for diagnosis of DLDs; improving the classification accuracy over state-of-the-art methods. Methods A data set composed of 3252 regions of interest (ROIs) was used, from which 28 features were extracted per ROI. We used Principal Component Analysis, Linear Discriminant Analysis, and Stepwise Selection - Forward, Backward, and Forward-Backward to reduce feature dimensionality. The feature subsets obtained were used as input to the following ML methods: Support Vector Machine, Gaussian Mixture Model, k-Nearest Neighbor, and Deep Feedforward Neural Network. We also applied a Deep Convolutional Neural Network directly to the ROIs. Results We achieved the maximum reduction from 28 to 5 dimensions using LDA. The best classification results were obtained by DFNN, with 99.60% of overall accuracy. Conclusions This work contributes to the analysis and selection of features that can efficiently characterize the DLDs studied. © 2018 Georg Thieme Verlag KG Stuttgart. New York.","Deep learning; diffuse lung diseases; dimensionality reduction; machine learning","Algorithms; Diagnosis, Computer-Assisted; Discriminant Analysis; Humans; Lung Diseases; Machine Learning; Principal Component Analysis; Time Factors; algorithm; computer assisted diagnosis; discriminant analysis; human; lung disease; machine learning; principal component analysis; time factor","","","","","SEFAZ-AL; Fondo Nacional de Desarrollo Científico y Tecnológico, FONDECYT, (11150248); Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq","This work was partially funded by Fapeal, CNPq, and SEFAZ-AL. The work of Héctor Allende-Cid was supported by the project FONDECYT Initiation into Research 11150248.","Raghu G., Chen S.Y., Yeh W.S., Li Q., Lee Y.C., Collard H.R., Idiopathic pulmonary fibrosis in US medicare beneficiaries aged 65 years and older: Incidence, prevalence, and survival, 2001-2011, Lancet Respir Med, 2, 7, pp. 566-572, (2014); Pereyra L., Rangayyan R., Ponciano-Silva M., Azevedo-Marques P., Fractal Analysis for Computer-aided Diagnosis of Diffuse Pulmonary Diseases in HRCT Images, pp. 1-5, (2014); Almeida E., Rangayyan R., Azevedo-Marques P., Gaussian Mixture Modeling for Statistical Analysis of Features of High-resolution CT Images of Diffuse Pulmonary Diseases, pp. 1-5, (2015); Kauczor H., Heitmann K., Heussel C., Marwede D., Uthmann T., Thelen M., Automatic detection and quantification of ground-glass opacities on high-resolution CT using multiple neural networks: Comparison with a density mask, AJR Am J Roentgenol, 175, 5, pp. 1329-1334, (2000); Uchiyama Y., Katsuragawa S., Abe H., Shiraishi J., Li F., Li Q., Zhang C.T., Suzuki K., Doi K., Quantitative computerized analysis of diffuse lung disease in high-resolution computed tomography, Med Phys, 30, 9, pp. 2440-2454, (2003); Goodfellow I., Bengio Y., Courville A., Deep Learning, (2016); Anthimopoulos M., Christodoulidis S., Ebner L., Christe A., Mougiakakou S., Lung pattern classification for interstitial lung diseases using a deep convolutional neural network, IEEE Trans Med Imag, 5, pp. 1207-1216, (2016); Christodoulidis S., Anthimopoulos M., Ebner L., Christe A., Mougiakakou S., Multisource transfer learning with convolutional neural networks for lung pattern analysis, IEEE Journal of Biomedical and Health Informatics, 21, 1, pp. 76-84, (2017); Shin H., Roth H., Gao M., Lu L., Xu Z., Nogues I., Yao J., Mollura D., Summers R., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning, IEEE Trans Med Imag, 35, 5, pp. 1285-1298, (2016); Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L., ImageNet: A Large-Scale Hierarchical Image Database; Hashimoto N., Suzuki K., Liu J., Hirano Y., Macahon H., Kido S., Deep Neural Network Convolution (NNC) for Three-class Classification of Diffuse Lung Disease Opacities in High-resolution CT (HRCT): Consolidation, Ground-glass Opacity (GGO), and Normal Opacity; Haralick R.M., Shanmugam K., Dinstein I., Textural features for image classification, IEEE Trans Syst, Man, Cybern Syst, 3, 6, pp. 610-621, (1973); Laws K.I., Rapid Texture Identification; Banik S., Rangayyan R.M., Desautels J., Detection of architectural distortion in prior mammograms, IEEE Trans Med Imag, 30, 2, pp. 279-294, (2011); Rangayyan R.M., Biomedical Image Analysis, (2004); Tan P., Steinbach M., Kumar V., Introduction to Data Mining, (2005); Zaki M.J., Meira W., Data Mining and Analysis: Fundamental Concepts and Algorithms, (2014); James G., Witten D., Hastie T., Tibshirani R., An Introduction to Statistical Learning: With Applications in R. Springer Texts in Statistics, (2013); Fraley C., Raftery A., Model-based clustering, discriminant analysis, and density estimation, J Am Stat Assoc, 97, pp. 611-631, (2000); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-scale Image Recognition, (2014); Zeiler M.D., ADADELTA: An Adaptive Learning Rate Method, (2012); Ruder S., An Overview of Gradient Descent Optimization Algorithms, (2016); Almeida E., Rangayyan R., Azevedo-Marques P., Fuzzy Membership Functions for Analysis of High-resolution CT Images of Diffuse Pulmonary Diseases","H.S. Ramos; Universidade Federal de Alagoas, Institute of Computing, Cidade Universitária, Maceió, Alagoas, Av. Lourival Melo Mota, S/N, 57072900, Brazil; email: heitor@laccan.ufal.br","","Georg Thieme Verlag","","","","","","00261270","","MIMCA","30875707","English","Methods Inf. Med.","Article","Final","","Scopus","2-s2.0-85062992252"
"Ke J.; Liu C.; Lu Y.; Jing N.; Liang X.; Jiang F.","Ke, Jing (57193131816); Liu, Changchang (59287406600); Lu, Yizhou (57200809307); Jing, Naifeng (35100372900); Liang, Xiaoyao (7401735951); Jiang, Fusong (56178389400)","57193131816; 59287406600; 57200809307; 35100372900; 7401735951; 56178389400","FIMIL: A high-throughput deep learning model for abnormality detection with weak annotation in microscopy images","2020","ACM International Conference Proceeding Series","","","a34","","","","1","10.1145/3373017.3373051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079848157&doi=10.1145%2f3373017.3373051&partnerID=40&md5=c3874c01d4cd33cc8e165d2d245df7af","Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Department of Micro-Nano Electronics, Shanghai Jiao Tong University, China; Department of Endocrinology and Metabolism, Shanghai Sixth People's Hospital, East Affiliated to Shanghai University of Medicine and Health Sciences, China","Ke J., Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Liu C., Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Lu Y., Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Jing N., Department of Micro-Nano Electronics, Shanghai Jiao Tong University, China; Liang X., Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Jiang F., Department of Endocrinology and Metabolism, Shanghai Sixth People's Hospital, East Affiliated to Shanghai University of Medicine and Health Sciences, China","Automatic computer-aided detection plays an important role in biomedical image analysis. Many studies have focused on weak supervised learning as annotation tasks are time-consuming and tedious. Compared with pixel-wise annotation by particular software on the scanned digital high-resolution images, an alternative method of marking out of suspicious regions on microscopy slides is significantly more convenient for pathologists. Additionally, with a focus on dysplasias in the central area, there is a high likelihood of the similar tissues to be found around in clusters. In this paper, for weak annotation on microscopy images, we propose an efficient Foveated Imaging based Multiple Instance Learning (FIMIL) framework to classify weakly-labeled microscopy images. The model also provides multi-scale algorithm for arbitrary image size, in which the patches with highest possibility to contain dysplasia are considered as ""fixation points"" in the image. The developed model combines deep convolutional neural networks (CNNs) with multiple instance learning (MIL) for dysplasias detection with only image-level labeling. The benchmark tests are carried out on the marked regions of 40x magnified whole-slide cytology images and the normal/abnormal label and their corresponding possibilities are predicted. Evaluated on the real-life clinical data, our proposed model shows high accuracy and efficiency by weakly-supervised learning. 1 © 2020 ACM.","foveated imaging; microscopy image; multiple instance learning; performance acceleration","Benchmarking; Computer aided analysis; Convolutional neural networks; Cytology; Deep neural networks; Image annotation; Learning systems; Supervised learning; Biomedical image analysis; Computer aided detection; Foveated imaging; High resolution image; Microscopy images; Multiple instance learning; Performance acceleration; Weakly supervised learning; Deep learning","","","","","Science and Technology and Economic Commission of Shanghai Pudong","∗Corresponding Author 1This work is funded by Science and Technology and Economic Commission of Shanghai Pudong New Area No.PKJ2019-Y03.","Barker J., Hoogi A., Depeursinge A., Rubin D.L., Automated classification of brain tumor type in whole-slide digital pathology images using local representative tiles, Medical Image Analysis, 30, pp. 60-71, (2016); Couture H.D., Marron J.S., Perou C.M., Troester M.A., Niethammer M., Multiple instance learning for heterogeneous images: Training a CNN for histopathology, Proc. MICCAI, (2018); Dundar M.M., Badve S., Raykar V.C., Jain R.K., Sertel O., Gurcan M.N., A multiple instance learning approach toward optimal classification of pathology slides, 2010 20th International Conference on Pattern Recognition., pp. 2732-2735, (2010); Jia Z., Huang X., I-Chao Chang E., Xu Y., Constrained deep weak supervision for histopathology image segmentation, IEEE Transactions on Medical Imaging, 36, pp. 2376-2388, (2017); Kandemir M., Hamprecht F.A., Computer-aided diagnosis from weak supervision: A benchmarking study, Computerized Medical Imaging and Graphics: The Official Journal of the Computerized Medical Imaging Society, 42, pp. 44-50, (2015); Kather J.N., Krisam J., Charoentong P., Luedde T., Herpel E., Weis C., Gaiser T., Marx A., Valous N.A., Ferber D., Et al., Predicting survival from colorectal cancer histology slides using deep learning: A retrospective multicenter study, PLoS Medicine, 16, 1, (2019); Kraus O.Z., Ba J.L., Frey B.J., Classifying and segmenting microscopy images with deep multiple instance learning, Bioinformatics, 32, 12, pp. i52-i59, (2016); Litjens G., Kooi T., Bejnordi B.E., Arindra A., Setio A., Ciompi F., Ghafoorian M., Laak Der Van J.A., Van Ginneken B., Sanchez C.I., A survey on deep learning in medical image analysis, Medical Image Analysis, 42, pp. 60-88, (2017); Maron O., Lozano-Perez T., A framework for multiple-instance learning, Advances in Neural Information Processing Systems., pp. 570-576, (1998); Pathak D., Shelhamer E., Long J., Darrell T., Fully Convolutional Multi-class Multiple Instance Learning, (2014); Pinheiro P.O., Collobert R., From image-level to pixel-level labeling with convolutional networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 1713-1721, (2015); Xu Y., Zhu J.-Y., Chang E., Tu Z., Multiple clustered instance learning for histopathology cancer image classification, segmentation and clustering, 2012 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, pp. 964-971, (2012); Xu Y., Zhu J., Eric I., Chang C., Lai M., Tu Z., Weakly supervised histopathology cancer image segmentation and classification, Medical Image Analysis, 18, 3, pp. 591-604, (2014); Zhang C., Platt J.C., Viola P.A., Multiple instance boosting for object detection, Advances in Neural Information Processing Systems., pp. 1417-1424, (2006); Zhang G., Yin J., Li Z., Su X., Li G., Zhang H., Automated skin biopsy histopathological image annotation using multiinstance representation and learning, BMC Medical Genomics, 6, 3, (2013); Zhang G., Yin J., Su X., Huang Y., Lao Y., Liang Z., Ou S., Zhang H., Augmenting multi-instance multilabel learning with sparse Bayesian models for skin biopsy image analysis, BioMed Research International, 2014, (2014)","J. Ke; Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; email: kejing@sjtu.edu.cn","","Association for Computing Machinery","The Computing Research and Education Association of Australasia (CORE)","2020 Australasian Computer Science Week Multiconference, ACSW 2020","3 February 2020 through 7 February 2020","Melbourne","157482","","978-145037697-6","","","English","ACM Int. Conf. Proc. Ser.","Conference paper","Final","","Scopus","2-s2.0-85079848157"
"Dhivya P.; Kumaresan T.; Subramanian P.; Gunasekaran K.; Kumar G.S.","Dhivya, P. (56448997200); Kumaresan, T. (56878942000); Subramanian, P. (57387323700); Gunasekaran, K. (57219427870); Kumar, G. Sathish (57217065933)","56448997200; 56878942000; 57387323700; 57219427870; 57217065933","HYBRID FIREFLY META OPTIMIZATION FOR BIO MEDICAL IMAGE PROCESSING USING DEEP LEARNING","2022","Journal of Pharmaceutical Negative Results","13","4","","1199","1209","10","0","10.47750/pnr.2022.13.04.169","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143281766&doi=10.47750%2fpnr.2022.13.04.169&partnerID=40&md5=03e21276b811afec63a51b88dbc89d27","Department of CSE, Bannari Amman Institute of Technology, Tamil Nadu, Erode, India; Department of AIDS, Bannari Amman Institute of Technology, Tamil Nadu, Erode, India; Department of AI, Saveetha School of Engineering, SIMATS, Tamil Nadu, Chennai, India; Department of DS, Sri Indu College of Engineering and Technology, Hyderabad, India; Department of CSE, Sri Krishna College of Engineering and Technology, Tamilnadu, Coimbatore, India","Dhivya P., Department of CSE, Bannari Amman Institute of Technology, Tamil Nadu, Erode, India; Kumaresan T., Department of AIDS, Bannari Amman Institute of Technology, Tamil Nadu, Erode, India; Subramanian P., Department of AI, Saveetha School of Engineering, SIMATS, Tamil Nadu, Chennai, India; Gunasekaran K., Department of DS, Sri Indu College of Engineering and Technology, Hyderabad, India; Kumar G.S., Department of CSE, Sri Krishna College of Engineering and Technology, Tamilnadu, Coimbatore, India","Signal and image processing is a part of biomedical science. In that, Biomedical image processing have a great value such as recognition, segmentation and classification for disease diagnosis. In one part of biomedical science, brain tumor classification is considered with Magnetic Resonance Images (MRI) images using state of art models. Initially, the Convolutional Neural Network (CNN), Fast Convolutional Neural Network (FCNN), U-Net and M-Net model was considered for classification. Further, the Hybrid Firefly Meta Optimization (HFMO) is proposed for the better prediction purpose. The proposed work has three phases like normalization with augmentation, deep attention segmentation and classification. In the first phase, data augmentation is applied to increase the scope of the dataset. In the second phase, a deep attention technique is applied to concentrate on hotspot in the image during segmentation. Finally, a hybrid firefly optimization is applied to enhance the performance of the model in convolution neural network by backtracking the process. The measuring parameters like Dice coefficient, Jaccard index, Positive Projected Value (PPV), True Positive Rate and False Positive Rate were evaluated. The comparative analysis of various state of art models with proposed classifier were demonstrated. Thus the proposed technique produces the training accuracy as 98.62%, testing accuracy as 95.31 % and 1 % of loss. © 2022 Wolters Kluwer Medknow Publications. All rights reserved.","Augmentation; Central Nervous System; Dice Coefficient,Firefly optimization; Jaccard Index; Meta Learning; MRI","Article; classification; classifier; comparative study; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic imaging; diagnostic test accuracy study; false negative result; false positive result; firefly algorithm; glioma; human; hypophysis tumor; image processing; image segmentation; meningioma; nuclear magnetic resonance imaging","","","","","","","Seetha J., Raja S.S., Brain tumor classification using convolutional neural networks, Biomedical & Pharmacology Journal, 11, 3, (2018); Abiwinanda N., Hanif M., Hesaputra S.T., Handayani A., Mengko T.R., Brain tumor classification using convolutional neural network, World congress on medical physics and biomedical engineering 2018, pp. 183-189, (2019); Kumar S., Dabas C., Godara S., Classification of brain MRI tumor images: a hybrid approach, Procedia computer science, 122, pp. 510-517, (2017); Amin J., Sharif M., Yasmin M., Fernandes S.L., A distinctive approach in brain tumor detection and classification using MRI, Pattern Recognition Letters, 139, pp. 118-127, (2020); Rathi V.P., Palani S., Brain tumor MRI image classification with feature selection and extraction using linear discriminant analysis, (2012); Tilahun1 SurafelLuleseged, Ong Hong Choon, Modified firefly algorithm, Journal of applied mathematics, (2012); Yang X. S., Firefly algorithms for multimodal optimization, Proceedings of the 5th International Conference on Stochastic Algorithms: Foundation and Applications (SAGA '09), vol. 5792 of Lecture notes in Computer Science, pp. 169-178, (2009); Yamanakkanavar Nagaraj, Et al., MRI Segmentation and Classification of Human Brain Using Deep Learning for Diagnosis of Alzheimer's disease: A Survey, Sensors (Basel, Switzerland), 20, (2020); Das A., Mohapatra S.K., Mohanty M.N., Design of deep ensemble classifier with fuzzy decision method for biomedical image classification, Applied Soft Computing, 115, (2022); Zhang Y., Dong Z., Wu L., Wang S., A hybrid method for MRI brain image classification, Expert Systems with Applications, 38, 8, pp. 10049-10053, (2011); Chaplot S., Patnaik L.M., Jagannathan N.R., Classification of magnetic resonance brain images using wavelets as input to support vector machine and neural network, Biomedical signal processing and control, 1, 1, pp. 86-92, (2006); Zhang Y., Dong Z., Liu A., Wang S., Ji G., Zhang Z., Yang J., Magnetic resonance brain image classification via stationary wavelet transform and generalized eigenvalue proximal support vector machine, Journal of Medical Imaging and Health Informatics, 5, 7, pp. 1395-1403, (2015); Anwar S.M., Majid M., Qayyum A., Awais M., Alnowami M., Khan M.K., Medical image analysis using convolutional neural networks: a review, Journal of medical systems, 42, 11, pp. 1-13, (2018); Bahadure N.B., Ray A.K., Thethi H.P., Image analysis for MRI based brain tumor detection and feature extraction using biologically inspired BWT and SVM, International journal of biomedical imaging, 2017, (2017); Pham D.L., Xu C., Prince J.L., Current methods in medical image segmentation, Annual review of biomedical engineering, 2, 1, pp. 315-337, (2000); Jothi G., Hybrid Tolerance Rough Set-Firefly based supervised feature selection for MRI brain tumor image classification, Applied Soft Computing, 46, pp. 639-651, (2016); Hemanth D.J., Anitha J., Modified Genetic Algorithm approaches for classification of abnormal Magnetic Resonance Brain tumour images, Applied Soft Computing, 75, pp. 21-28, (2019); Ortiz A., Gorriz J.M., Ramirez J., Salas-Gonzalez D., Llamas-Elvira J.M., Two fully-unsupervised methods for MR brain image segmentation using SOM-based strategies, Applied Soft Computing, 13, 5, pp. 2668-2682, (2013); Mukhopadhyay A., Maulik U., A multiobjective approach to MR brain image segmentation, Applied Soft Computing, 11, 1, pp. 872-880, (2011); Ren T., Wang H., Feng H., Xu C., Liu G., Ding P., Study on the improved fuzzy clustering algorithm and its application in brain image segmentation, Applied Soft Computing, 81, (2019); Zhang Y., Dong Z., Wu L., Wang S., A hybrid method for MRI brain image classification, Expert Systems with Applications, 38, 8, pp. 10049-10053, (2011); Karabatak M., Ince M.C., An expert system for detection of breast cancer based on association rules and neural network, Expert systems with Applications, 36, 2, pp. 3465-3469, (2009); Zhang Y.D., Wu L., An MR brain images classifier via principal component analysis and kernel support vector machine, Progress in Electromagnetics Research, 130, pp. 369-388, (2012)","P. Dhivya; Bannari Amman Institute of Technology, Erode, Tamil Nadu, India; email: dhivyasnsce@gmail.com","","ResearchTrentz Academy Publishing Education Services","","","","","","09769234","","","","English","J. Pharm. Negat. Results","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85143281766"
"Deleruyelle A.; Klein J.; Versari C.","Deleruyelle, Arnaud (57456693200); Klein, John (57199428576); Versari, Cristian (16647629300)","57456693200; 57199428576; 16647629300","SODA: SELF-ORGANIZING DATA AUGMENTATION IN DEEP NEURAL NETWORKS - APPLICATION TO BIOMEDICAL IMAGE SEGMENTATION TASKS","2022","ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","2022-May","","","6517","6521","4","0","10.1109/ICASSP43922.2022.9747744","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134063176&doi=10.1109%2fICASSP43922.2022.9747744&partnerID=40&md5=3a9bcf614616aa6c26f26e392bc89196","Univ. Lille, CNRS, Centrale Lille, UMR 9189, CRIStAL, Lille, F-59000, France","Deleruyelle A., Univ. Lille, CNRS, Centrale Lille, UMR 9189, CRIStAL, Lille, F-59000, France; Klein J., Univ. Lille, CNRS, Centrale Lille, UMR 9189, CRIStAL, Lille, F-59000, France; Versari C., Univ. Lille, CNRS, Centrale Lille, UMR 9189, CRIStAL, Lille, F-59000, France","In practice, data augmentation is assigned a predefined budget in terms of newly created samples per epoch. When using several types of data augmentation, the budget is usually uniformly distributed over the set of augmentations but one can wonder if this budget should not be allocated to each type in a more efficient way. This paper leverages online learning to allocate on the fly this budget as part of neural network training. This meta-algorithm can be run at almost no extra cost as it exploits gradient based signals to determine which type of data augmentation should be preferred. Experiments suggest that this strategy can save computation time and thus goes in the way of greener machine learning practices. © 2022 IEEE","data augmentation; deep learning; HEDGE; online learning; segmentation","Budget control; E-learning; Image segmentation; Biomedical image segmentation; Data augmentation; Deep learning; HEDGE; Neural network application; Neural networks trainings; On-the-fly; Online learning; Segmentation; Self-organising; Deep neural networks","","","","","GENCI-IDRIS","This work was performed using HPC resources from GENCI-IDRIS (Grant 2021-AD011011606R1).","Zhu X., Liu Y., Li J., Wan T., Qin Z., Emotion classification with data augmentation using generative adversarial networks, Pacific-Asia conference on knowledge discovery and data mining, pp. 349-360, (2018); Frid-Adar M.A.J.G.H.G.M., Klang E., Synthetic data augmentation using gan for improved liver lesion classification, International Symposium on Biomedical Imaging (ISBI 2018), (2018); Jackson P.T.G., Abarghouei A.A., Bonner S., Breckon T.P., Obara B., Style augmentation: data augmentation via style randomization, CVPR Workshops, pp. 83-92, (2019); Wang J., Perez L., Et al., The effectiveness of data augmentation in image classification using deep learning, Convolutional Neural Networks Vis. Recognit, 11, pp. 1-8, (2017); Inoue H., Data augmentation by pairing samples for images classification, (2018); Shorten C., Khoshgoftaar T.M., A survey on image data augmentation for deep learning, Journal of Big Data, 6, 1, pp. 1-48, (2019); Cubuk E.D., Zoph B., Mane D., Vasudevan V., Le Q.V., Autoaugment: Learning augmentation strategies from data, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), (2019); Huang Y., Li Y., Ye H., Li Z., Zhang Z., An asymptotically optimal multiarmed bandit algorithm and hyperparameter optimization, (2020); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Freund Y., Schapire R.E., A decision-theoretic generalization of on-line learning and an application to boosting, Journal of computer and system sciences, 55, 1, pp. 119-139, (1997); Cesa-Bianchi N., Lugosi G., Prediction, learning, and games, (2006); Liu A., Huang Z., Huang Z., Wang N., Direct differentiable augmentation search, IEEE Int. Conf. on Computer Vision (ICCV'21), pp. 12219-12228, (2021); Zheng Y., Zhang Z., Yan S., Zhang M., Deep autoaugment, Transformation, 3, (2021); Staal J., Abramoff M.D., Niemeijer M., Viergever M.A., Van Ginneken B., Ridge-based vessel segmentation in color images of the retina, IEEE transactions on medical imaging, 23, 4, pp. 501-509, (2004); Salsac A.-V., Deleruyelle A., Versari C., Klein J., Capsule: a dataset for the segmentation of a transparent and deformable capsule, (2021); Maska M., Ulman V., Svoboda D., Matula P., Matula P., Ederra C., Urbiola A., Espana T., Venkatesan S., Balak D.M.W., Et al., A benchmark for comparison of cell tracking algorithms, Bioinformatics, 30, 11, pp. 1609-1617, (2014)","","","Institute of Electrical and Electronics Engineers Inc.","Chinese and Oriental Languages Information Processing Society (COLPIS); Singapore Exhibition and Convention Bureau; The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen); The Institute of Electrical and Electronics Engineers Signal Processing Society","47th IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2022","23 May 2022 through 27 May 2022","Virtual, Online","179417","15206149","978-166540540-9","IPROD","","English","ICASSP IEEE Int Conf Acoust Speech Signal Process Proc","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85134063176"
"Subasi A.; Kapadnis M.N.; Bulbul A.K.","Subasi, Abdulhamit (8327241200); Kapadnis, Manav Nitin (57323545600); Bulbul, Ayse Kosal (57709399500)","8327241200; 57323545600; 57709399500","Alzheimer’s disease detection using artificial intelligence","2022","Augmenting Neurological Disorder Prediction and Rehabilitation Using Artificial Intelligence","","","","53","74","21","5","10.1016/B978-0-323-90037-9.00011-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130669432&doi=10.1016%2fB978-0-323-90037-9.00011-4&partnerID=40&md5=7730a86310b8d0a53bbba8083bffc6b5","Institute of Biomedicine, Faculty of Medicine, University of Turku, Turku, Finland; Department of Computer Science, College of Engineering, Effat University, Jeddah, Saudi Arabia; Department of Electrical Engineering, Indian Institute of Technology, Kharagpur, India","Subasi A., Institute of Biomedicine, Faculty of Medicine, University of Turku, Turku, Finland, Department of Computer Science, College of Engineering, Effat University, Jeddah, Saudi Arabia; Kapadnis M.N., Department of Electrical Engineering, Indian Institute of Technology, Kharagpur, India; Bulbul A.K., Institute of Biomedicine, Faculty of Medicine, University of Turku, Turku, Finland","Biomedical data relevant to several diseases are generally employed to diagnose precise physiological or pathological conditions. The objective of biomedical image analysis is exact modeling by using Artificial Intelligence (AI) algorithms to diagnose different diseases. Alzheimer’s disease (AD) is one of the most widespread dementia forms influencing the elderly people. On-time diagnosis of Alzheimer’s disease is crucial to discover innovative methods for AD treatment. AI is an efficient approach for AD detection since it can be utilized as a Computer-aided decision support systems approach in medical procedures and play a critical role to detect changes in the brain images to identify AD. This chapter presents the recent studies and advances in AI used for medical image analysis and image processing in AD detection. The main focus is to have a consistent but easy and quick model for automated AD detection relied on the application of AI methods. Hence, the focus will be on AI techniques for AD detection from brain images. Moreover, some of the AI techniques, which were utilized for AD detection is overviewed. Then a simple AD detection approach using deep learning models will be presented. The results show that CNN achieved a testing accuracy of 95.70% accuracy and a validation accuracy of 99.71% for the diagnosis of AD from brain MRI scans. The chapter will be completed with a review of the current state-of-the-art, a discussion of new trends and open challenges for potential investigation. © 2022 Elsevier Inc. All rights reserved.","Alzheimer’s disease detection; Artificial intelligence; Convolutional neural networks; Deep learning; Transfer learning","","","","","","","","Aggarwal C.C., Neural networks and deep learning, (2018); Albawi S., Mohammed T.A., Al-Zawi S., Understanding of a convolutional neural network, pp. 1-6, (2017); Albert M.S., Et al., The diagnosis of mild cognitive impairment due to Alzheimer’s disease: Recommendations from the National Institute on Aging-Alzheimer’s Association workgroups on diagnostic guidelines for Alzheimer’s disease, Focus (San Francisco, Calif.), 11, 1, pp. 96-106, (2013); Alpaydin E., Introduction to machine learning, (2014); 2020 Alzheimer’s disease facts and figures, Alzheimers Dement, 16, 3, pp. 391-460, (2020); Barakat N., Bradley A.P., Barakat M.N.H., Intelligible support vector machines for diagnosis of diabetes mellitus, IEEE Transactions on Information Technology in Biomedicine: A Publication of the IEEE Engineering in Medicine and Biology Society, 14, 4, pp. 1114-1120, (2010); Bateman R.J., Et al., Clinical and biomarker changes in dominantly inherited Alzheimer’s disease, The New England Journal of Medicine, 367, pp. 795-804, (2012); Bengio Y., Learning deep architectures for AI, Found. Trends® Mach. Learn., 2, 1, pp. 1-127, (2009); Biomarkers and surrogate endpoints: Preferred definitions and conceptual framework, Clinical Pharmacology and Therapeutics, 69, 3, pp. 89-95, (2001); Braak H., Thal D.R., Ghebremedhin E., Del Tredici K., Stages of the pathologic process in Alzheimer disease: Age categories from 1 to 100 years, Journal of Neuropathology and Experimental Neurology, 70, 11, pp. 960-969, (2011); Bringas S., Salomon S., Duque R., Lage C., Montana J.L., Alzheimer’s Disease stage identification using deep learning models, Journal of Biomedical Informatics, 109, (2020); Cabral C., Morgado P.M., Costa D.C., Silveira M., Predicting conversion from MCI to AD with FDG-PET brain images at different prodromal stages, Computers in Biology and Medicine, 58, pp. 101-109, (2015); Chen M., Yang J., Zhu X., Wang X., Liu M., Song J., Smart home 2.0: Innovative smart home system powered by botanical IoT and emotion detection, Mob. Netw. Appl., 22, 6, pp. 1159-1169, (2017); Chu C., Hsu A.-L., Chou K.-H., Bandettini P., Lin C., Does feature selection improve classification accuracy? Impact of sample size and feature selection on classification using anatomical magnetic resonance images, Neuroimage, 60, 1, pp. 59-70, (2012); Cras P., Kawai M., Lowery D., Gonzalez-DeWhitt P., Greenberg B., Perry G., Senile plaque neurites in Alzheimer disease accumulate amyloid precursor protein, Proc. Natl. Acad. Sci., 88, 17, pp. 7552-7556, (1991); Davatzikos C., Et al., Precision diagnostics based on machine learning-derived imaging signatures, Magnetic Resonance Imaging, 64, pp. 49-61, (2019); de Bruijne M., Machine learning approaches in medical image analysis: From detection to diagnosis, (2016); Deepika Nair M., Sinta M.S., Vidya M., A study on various deep learning algorithms to diagnose Alzheimer’s disease, Proceedings of the International Conference on ISMAC in Computational Vision and Bio-Engineering 2018 (ISMAC-CVB), 30, pp. 1705-1710, (2019); Dementia, (2021); Dickson D.W., The pathogenesis of senile plaques, Journal of Neuropathology and Experimental Neurology, 56, 4, pp. 321-339, (1997); Duraisamy B., Shanmugam J.V., Annamalai J., Alzheimer disease detection from structural MR images using FCM based weighted probabilistic neural network, Brain Imaging and Behavior, pp. 1-24, (2018); Feng C., Elazab A., Yang P., Wang T., Lei B., Xiao X., 3D Convolutional Neural Network and Stacked Bidirectional Recurrent Neural Network for Alzheimer’s Disease Diagnosis: First International Workshop, PRIME 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, pp. 138-146, (2018); Gao X.W., Hui R., A deep learning based approach to classification of CT brain images, pp. 28-31, (2016); Gauthier S., Scheltens P., Cummings J., Alzheimer’s Disease and Related Disorders, (2005); Ghosh S., Chandra A., Mudi R.K., A novel fuzzy pixel intensity correlation based segmentation algorithm for early detection of Alzheimer’s disease, Multimed. Tools Appl., pp. 1-25, (2018); Gordon B.A., Et al., Spatial patterns of neuroimaging biomarker change in individuals from families with autosomal dominant Alzheimer’s disease: A longitudinal study, Lancet Neurology, 17, 3, pp. 241-250, (2018); Guerrero R., Wolz R., Rao A., Rueckert D., Manifold population modeling as a neuro-imaging biomarker: Application to ADNI and ADNI-GO, Neuroimage, 94, pp. 275-286, (2014); Hall M., Witten I., Frank E., Data mining: Practical machine learning tools and techniques, (2011); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, pp. 770-778, (2016); Hinton G.E., Krizhevsky A., Sutskever I., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, 25, pp. 1106-1114, (2012); Hosseini-Asl E., Gimel'farb G., El-Baz A., Alzheimer’s disease diagnostics by a deeply supervised adaptable 3D convolutional network, (2016); Hosseini-Asl E., Keynto R., El-Baz A., Alzheimer’s Disease Diagnostics by Adaptation of 3D Convolutional Network, 2016 IEEE Int. Conf. Image Process. ICIP, pp. 126-130, (2016); Hu C., Ju R., Shen Y., Zhou P., Li Q., Clinical decision support for Alzheimer’s disease based on deep learning and brain network, 2016 IEEE Int. Conf. Commun. (ICC), Kuala Lumpur, Malaysia, pp. 1-6, (2016); Huda S., Yearwood J., Jelinek H.F., Hassan M.M., Fortino G., Buckland M., A hybrid feature selection with ensemble classification for imbalanced healthcare data: A case study for brain tumor diagnosis, IEEE Access, 4, pp. 9145-9154, (2016); Islam J., Zhang Y., A novel deep learning based multi-class classification method for Alzheimer’s disease detection using brain MRI data, Brain Informatics, 10654, pp. 213-222, (2017); Islam J., Zhang Y., Brain MRI analysis for Alzheimer’s disease diagnosis using an ensemble system of deep convolutional neural networks, Brain Inform, 5, 2, (2018); Islam J., Zhang Y., Disease Neuroimaging Initiative, Deep convolutional neural networks for automated diagnosis of Alzheimer’s disease and mild cognitive impairment using 3D brain MRI, pp. 359-369, (2018); Jack C.R., Et al., Introduction to the recommendations from the National Institute on Aging-Alzheimer’s Association workgroups on diagnostic guidelines for Alzheimer’s disease, Alzheimer’s & Dementia: The Journal of the Alzheimer’s Association, 7, 3, pp. 257-262, (2011); Jack C.R., Et al., Serial PIB and MRI in normal, mild cognitive impairment and Alzheimer’s disease: Implications for sequence of pathological events in Alzheimer’s disease, Brain, 132, 5, pp. 1355-1365, (2009); Jain D., Singh V., Feature selection and classification systems for chronic disease prediction: A review, Egypt. Inform. J., 19, 3, pp. 179-189, (2018); Jain R., Jain N., Aggarwal A., Hemanth D.J., Convolutional neural network based Alzheimer’s disease classification from magnetic resonance brain images, Cogn. Syst. Res., 57, pp. 147-159, (2019); Jie B., Zhang D., Gao W., Wang Q., Wee C.-Y., Shen D., Integration of network topological and connectivity properties for neuroimaging classification, IEEE Transactions on bio-medical Engineering, 61, 2, (2014); Ju R., Hu C., Li Q., Early Diagnosis of Alzheimer’s Disease Based on Resting-State Brain Networks and Deep Learning, IEEE/ACM Trans. Comput. Biol. Bioinform, (2017); Karasawa H., Liu C.L., Ohwada H., Deep 3D Convolutional Neural Network Architectures for Alzheimer’s Disease Diagnosis, Intelligent Information and Database Systems -10th Asian Conference, ACIIDS 2018, Proceedings, pp. 287-296, (2018); Lahmiri S., Shmuel A., Performance of machine learning methods applied to structural MRI and ADAS cognitive scores in diagnosing Alzheimer’s disease, Biomedical Signal Processing and Control, (2018); Lange C., Et al., Prediction of Alzheimer’s dementia in patients with amnestic mild cognitive impairment in clinical routine: Incremental value of biomarkers of neurodegeneration and brain amyloidosis added stepwise to cognitive status, Journal of Alzheimer’s Disease: JAD, 61, 1, pp. 373-388, (2018); Le Q.V., Et al., Building high-level features using large scale unsupervised learning, (2011); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, (2015); LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc. IEEE, 86, 11, pp. 2278-2324, (1998); Levine A.B., Schlosser C., Grewal J., Coope R., Jones S.J., Yip S., Rise of the machines: Advances in deep learning for cancer diagnosis, Trends Cancer, 5, 3, pp. 157-169, (2019); Li F., Liu M., Alzheimer’s disease diagnosis based on multiple cluster dense convolutional networks, Computerized Medical Imaging and Graphics: The Official Journal of the Computerized Medical Imaging Society, 70, pp. 101-110, (2018); Li F., Tran L., Thung K.-H., Ji S., Shen D., Li J., A robust deep model for improved classification of AD/MCI patients, IEEE J. Biomed. Health Inform., 19, 5, pp. 1610-1616, (2015); Litjens G., Et al., A survey on deep learning in medical image analysis, Medical Image Analysis, 42, pp. 60-88, (2017); Malathi D., Logesh R., Subramaniyaswamy V., Vijayakumar V., Sangaiah A.K., Hybrid reasoning-based privacy-aware disease prediction support system, Comput. Electr. Eng., 73, pp. 114-127, (2019); McKhann G.M., Et al., The diagnosis of dementia due to Alzheimer’s disease: Recommendations from the National Institute on Aging-Alzheimer’s Association workgroups on diagnostic guidelines for Alzheimer’s disease, Alzheimer’s & Dementia: The Journal of the Alzheimer’s Association, 7, 3, pp. 263-269, (2011); Nair M.D., Sinta M., Vidya M., A Study on Various Deep Learning Algorithms to Diagnose Alzheimer’s Disease, pp. 1705-1710, (2018); (2021); Pan S.J., Yang Q., A survey on transfer learning, IEEE Trans. Knowl. Data Eng., 22, 10, pp. 1345-1359, (2010); Payan A., Montana G., Predicting Alzheimer’s disease: A neuroimaging study with 3D convolutional neural networks, (2015); Purves D., Et al., Neuroscience, 4th Sunderland Mass Sinauer Xvii, 857, (2008); Reiman E.M., Et al., Brain imaging and fluid biomarker analysis in young adults at genetic risk for autosomal dominant Alzheimer’s disease in the presenilin 1 E280A kindred: A case-control study, Lancet Neurology, 11, 12, pp. 1048-1056, (2012); Sampath R., Indumathi J., Earlier detection of Alzheimer disease using N-fold cross validation approach, Journal of Medical Systems, 42, 11, (2018); Sarraf S., Tofighi G., Classification of alzheimer’s disease using fmri data and deep learning convolutional neural networks, (2016); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, (2014); Sperling R.A., Et al., Toward defining the preclinical stages of Alzheimer’s disease: Recommendations from the National Institute on Aging-Alzheimer’s Association workgroups on diagnostic guidelines for Alzheimer’s disease, Alzheimer’s & Dementia: The Journal of the Alzheimer’s Association, 7, 3, pp. 280-292, (2011); Springenberg J.T., A. Dosimer’s Association Alzheimers Dement, 8, 2, pp. 131-168, (2014); Ovitskiy T.B., Riedmiller M., Striving for simplicity: The all convolutional net; Subasi A., Use of artificial intelligence in Alzheimer’s disease detection, Artif. Intell. Precis. Health, pp. 257-278, (2020); Suk H.-I., Lee S.-W., Shen D., Hierarchical feature representation and multimodal fusion with deep learning for AD/MCI diagnosis, Neuroimage, 101, pp. 569-582, (2014); Suk H.-I., Lee S.-W., Shen D., Latent feature representation with stacked auto-encoder for AD/MCI diagnosis, Brain Structure & Function, 220, 2, pp. 841-859, (2015); Suk H.-I., Lee S.-W., Shen D., Deep sparse multi-task learning for feature selection in Alzheimer’s disease diagnosis, Brain Structure & Function, 221, 5, pp. 2569-2587, (2016); Suk H.-I., Shen D., Deep learning-based feature representation for AD/MCI classification, pp. 583-590, (2013); Tang H., Yao E., Tan G., Guo X., A fast and accurate 3d fine-tuning convolutional neural network for alzheimer’s disease diagnosis, in Artificial Intelligence, pp. 115-126, (2018); Thies W., Bleiler L., 2012 Alzheimer’s disease facts and figures Alzheimer’s Association, Alzheimer’s & Dementia: The Journal of the Alzheimer’s Association, 8, 2, pp. 131-168, (2012); Vasuki A., Govindaraju S., Deep neural networks for image classificationDeep Learning for Image Processing Applications, 31, (2017); Verma A.K., Pal S., Kumar S., Comparison of skin disease prediction by feature selection using ensemble data mining techniques, Inform. Med. Unlocked, 16, (2019); Vieira S., Pinaya W.H., Mechelli A., Using deep learning to investigate the neuroimaging correlates of psychiatric and neurological disorders: Methods and applications, Neuroscience and Biobehavioral Reviews, 74, pp. 58-75, (2017); Villemagne V.L., Et al., Amyloid β deposition, neurodegeneration, and cognitive decline in sporadic Alzheimer’s disease: A prospective cohort study, Lancet Neurology, 12, 4, pp. 357-367, (2013); Walker L.C., Aβ plaques, Free Neuropathol., 1, (2020); Wang H., Et al., Ensemble of 3D densely connected convolutional network for diagnosis of mild cognitive impairment and Alzheimer’s disease, Neurocomputing, 333, pp. 145-156, (2019); Wang S.-H., Phillips P., Sui Y., Liu B., Yang M., Cheng H., Classification of Alzheimer’s disease based on eight-layer convolutional neural network with leaky rectified linear unit and max pooling, Journal of Medical Systems, 42, 5, pp. 1-11, (2018); Zeiler M.D., Fergus R., Visualizing and understanding convolutional networks, pp. 818-833, (2014); Zhang D., Wang Y., Zhou L., Yuan H., Shen D., Multimodal classification of Alzheimer’s disease and mild cognitive impairment, Neuroimage, 55, 3, pp. 856-867, (2011)","","","Elsevier","","","","","","","978-032390037-9; 978-032388626-0","","","English","Augmenting Neurological Disorder Prediction and Rehabilitation Using Artificial Intelligence","Book chapter","Final","","Scopus","2-s2.0-85130669432"
"Escorcia-Gutierrez J.; Mansour R.F.; Beleño K.; Jiménez-Cabas J.; Pérez M.; Madera N.; Velasquez K.","Escorcia-Gutierrez, José (57191268293); Mansour, Romany F. (36960713000); Beleño, Kelvin (57410276900); Jiménez-Cabas, Javier (57202833550); Pérez, Meglys (59159121200); Madera, Natasha (57278705000); Velasquez, Kevin (57410862700)","57191268293; 36960713000; 57410276900; 57202833550; 59159121200; 57278705000; 57410862700","Automated Deep Learning Empowered Breast Cancer Diagnosis Using Biomedical Mammogram Images","2022","Computers, Materials and Continua","71","2","","4221","4235","14","34","10.32604/cmc.2022.022322","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122769222&doi=10.32604%2fcmc.2022.022322&partnerID=40&md5=3ae0821a195d4ca5af59d02370f64fa6","Electronics and Telecommunications Engineering Program, Universidad Autónoma del Caribe, Barranquilla, 08001, Colombia; Department of Mathematics, Faculty of Science, New Valley University, El-Kharga, 72511, Egypt; Mechatronics Engineering Program, Universidad Autónoma del Caribe, Barranquilla, 08001, Colombia; Department of Computational Science and Electronic, Universidad de la Costa, CUC, Barranquilla, 08001, Colombia","Escorcia-Gutierrez J., Electronics and Telecommunications Engineering Program, Universidad Autónoma del Caribe, Barranquilla, 08001, Colombia; Mansour R.F., Department of Mathematics, Faculty of Science, New Valley University, El-Kharga, 72511, Egypt; Beleño K., Mechatronics Engineering Program, Universidad Autónoma del Caribe, Barranquilla, 08001, Colombia; Jiménez-Cabas J., Department of Computational Science and Electronic, Universidad de la Costa, CUC, Barranquilla, 08001, Colombia; Pérez M., Electronics and Telecommunications Engineering Program, Universidad Autónoma del Caribe, Barranquilla, 08001, Colombia; Madera N., Electronics and Telecommunications Engineering Program, Universidad Autónoma del Caribe, Barranquilla, 08001, Colombia; Velasquez K., Electronics and Telecommunications Engineering Program, Universidad Autónoma del Caribe, Barranquilla, 08001, Colombia","Biomedical image processing is a hot research topic which helps to majorly assist the disease diagnostic process. At the same time, breast cancer becomes the deadliest disease among women and can be detected by the use of different imaging techniques. Digital mammograms can be used for the earlier identification and diagnostic of breast cancer to minimize the death rate. But the proper identification of breast cancer has mainly relied on the mammography findings and results to increased false positives. For resolving the issues of false positives of breast cancer diagnosis, this paper presents an automated deep learning based breast cancer diagnosis (ADL-BCD) model using digital mammograms. The goal of the ADL-BCD technique is to properly detect the existence of breast lesions using digital mammograms. The proposed model involves Gaussian filter based pre-processing and Tsallis entropy based image segmentation. In addition, Deep Convolutional Neural Network based Residual Network (ResNet 34) is applied for feature extraction purposes. Specifically, a hyper parameter tuning process using chimp optimization algorithm (COA) is applied to tune the parameters involved in ResNet 34 model. The wavelet neural network (WNN) is used for the classification of digital mammograms for the detection of breast cancer. The ADL-BCD method is evaluated using a benchmark dataset and the results are analyzed under several performance measures. The simulation outcome indicated that the ADL-BCD model outperforms the state of art methods in terms of different measures. © 2022 Tech Science Press. All rights reserved.","Breast cancer; Deep learning; Digital mammograms; Disease diagnosis; Resnet 34; Wavelet neural network","Benchmarking; Computer aided diagnosis; Convolutional neural networks; Deep neural networks; Diseases; E-learning; Image segmentation; X ray screens; Breast Cancer; Breast cancer diagnosis; Deep learning; Diagnosis model; Digital mammograms; Disease diagnosis; False positive; Neural-networks; Resnet 34; Wavelet neural network; Mammography","","","","","","","Lakshmanaprabu S. K., Mohanty S. N., Shankar K., Arunkumar N., Ramireze G., Optimal deep learning model for classification of lung cancer on CT images, Future Generation Computer Systems, 92, 1, pp. 374-382, (2019); Pustokhina I. V., Pustokhin D. A., Vaiyapuri T., Gupta D., Kumar S., Et al., An automated deep learning based anomaly detection in pedestrian walkways for vulnerable road users safety, Safety Science, 142, (2021); Shankar K., Perumal E., Tiwari P., Shorfuzzaman M., Gupta D., Deep learning and evolutionary intelligence with fusion-based feature extraction for detection of COVID-19 from chest X-ray images, Multimedia Systems, 66, 2, (2021); Pustokhina I. V., Pustokhin D. A., Pareek P. K., Gupta D., Khanna A., Et al., Energy-efficient cluster-based unmanned aerial vehicle networks with deep learning-based scene classification model, International Journal of Communication Systems, 34, 8, pp. 1-16, (2021); Vaiyapuri T., Mohanty S. N., Sivaram M., Pustokhina I. V., Pustokhin D. A., Et al., Automatic vehicle license plate recognition using optimal deep learning model, Computers, Materials & Continua, 67, 2, pp. 1881-1897, (2021); Mansour R. F., El Amraoui A., Nouaouri I., Diaz V. G., Gupta D., Et al., Artificial intelligence and internet of things enabled disease diagnosis model for smart healthcare systems, IEEE Access, 9, pp. 45137-45146, (2021); Li L., Sun L., Xue Y., Li S., Huang X., Et al., Fuzzy multilevel image thresholding based on improved coyote optimization algorithm, IEEE Access, 9, pp. 33595-33607, (2021); Mansour R. F., Gutierrez J. E., Gamarra M., Garcia V., Gupta D., Et al., Artificial intelligence with big data analytics-based brain intracranial hemorrhage e-diagnosis using CT images, Neural Computing and Applications, pp. 1-13, (2021); Mansour R. F., A robust deep neural network based breast cancer detection and classification, International Journal of Computational Intelligence and Applications, 19, 1, (2020); Mansour R. F., Evolutionary computing enriched ridge regression model for craniofacial reconstruction, Multimedia Tools and Applications, 79, 31, pp. 22065-22082, (2020); Zhang C., Zhao J., Niu J., Li D., New convolutional neural network model for screening and diagnosis of mammograms, PLoS ONE, 15, 8, (2020); Altaf M., A hybrid deep learning model for breast cancer diagnosis based on transfer learning and pulse-coupled neural networks, Mathematical Biosciences and Engineering, 18, 5, pp. 5029-5046, (2021); Yala A., Lehman C., Schuster T., Portnoi T., Barzilay R., A deep learning mammography-based model for improved breast cancer risk prediction, Radiology, 292, 1, pp. 60-66, (2019); Shen L., Margolies L. R., Rothstein J. H., Fluder E., McBride R., Et al., Deep learning to improve breast cancer detection on screening mammography, Scientific Reports, 9, 1, (2019); Kumar A., Mukherjee S., Luhach A. K., Deep learning with perspective modeling for early detection of malignancy in mammograms, Journal of Discrete Mathematical Sciences and Cryptography, 22, 4, pp. 627-643, (2019); Kaur P., Singh G., Kaur P., Intellectual detection and validation of automated mammogram breast cancer images by multi-class SVM using deep learning classification, Informatics in Medicine Unlocked, 16, 1, (2019); Aboutalib S. S., Mohamed A. A., Berg W. A., Zuley M. L., Sumkin J. H., Et al., Deep learning to distinguish recalled but benign mammography images in breast cancer screening, Clinical Cancer Research, 24, 23, pp. 5902-5909, (2018); Masni M. A. A., Antari M. A. A., Park J. M., Gi G., Kim T. Y., Et al., Simultaneous detection and classification of breast masses in digital mammograms via a deep learning YOLO-based CAD system, Computer Methods and Programs in Biomedicine, 157, 1, pp. 85-94, (2018); Al-antari M. A., Han S. M., Kim T. S., Evaluation of deep learning detection and classification towards computer-aided diagnosis of breast lesions in digital X-ray mammograms, Computer Methods and Programs in Biomedicine, 196, (2020); Punitha S., Amuthan A., Joseph K. S., Benign and malignant breast cancer segmentation using optimized region growing technique, Future Computing and Informatics Journal, 3, 2, pp. 348-358, (2018); Rajinikanth V., Satapathy S. C., Fernandes S. L., Nachiappan S., Entropy based segmentation of tumor from brain MR images–A study with teaching learning based optimization, Pattern Recognition Letters, 94, 1, pp. 87-95, (2017); Helwan A., Maaitah M. K. S., Abiyev R. H., Uzelaltinbulat S., Sonyel B., Deep learning based on residual networks for automatic sorting of bananas, Journal of Food Quality, 2021, pp. 1-11, (2021); Nahid A. A., Mehrabi M. A., Kong Y., Histopathological breast cancer image classification by deep neural network techniques guided by local clustering, BioMed Research International, 2018, pp. 1-20, (2018); Khishe M., Mosavi M. R., Classification of underwater acoustical dataset using neural network trained by chimp optimization algorithm, Applied Acoustics, 157, 13, (2020); Linhares L. L. S., Fontes A. I. R., Martins A. M., Araujo F. M. U., Silveira L. F. Q., Fuzzy wavelet neural network using a correntropy criterion for nonlinear system identification, Mathematical Problems in Engineering, 2015, 5, pp. 1-12, (2015); Dataset","J. Escorcia-Gutierrez; Electronics and Telecommunications Engineering Program, Universidad Autónoma del Caribe, Barranquilla, 08001, Colombia; email: jose.escorcia23@gmail.com","","Tech Science Press","","","","","","15462218","","","","English","Comput. Mater. Continua","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85122769222"
"Duhayyim M.A.; Malibari A.A.; Obayya M.; Nour M.K.; Salama A.S.; Eldesouki M.I.; Zamani A.S.; Rizwanullah M.","Duhayyim, Mesfer Al (57204360566); Malibari, Areej A. (6506143515); Obayya, Marwa (6505869929); Nour, Mohamed K. (56027613700); Salama, Ahmed S. (56480035100); Eldesouki, Mohamed I. (57581134200); Zamani, Abu Sarwar (57295189700); Rizwanullah, Mohammed (57263769000)","57204360566; 6506143515; 6505869929; 56027613700; 56480035100; 57581134200; 57295189700; 57263769000","Metaheuristic with Deep Learning Enabled Biomedical Bone Age Assessment and Classification Model","2022","Computers, Materials and Continua","73","3","","5473","5489","16","0","10.32604/cmc.2022.031976","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135077555&doi=10.32604%2fcmc.2022.031976&partnerID=40&md5=8f4b1016dcb8dd673d74cfec2064c5f6","Department of Computer Science, College of Sciences and Humanities-Aflaj, Prince Sattam bin Abdulaziz University, Saudi Arabia; Department of Industrial and Systems Engineering, College of Engineering, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Biomedical Engineering, College of Engineering, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Computer Sciences, College of Computing and Information System, Umm Al-Qura University, Saudi Arabia; Department of Electrical Engineering, Faculty of Engineering & Technology, Future University in Egypt, New Cairo, 11845, Egypt; Department of Information System, College of Computer Engineering and Sciences, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia; Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia","Duhayyim M.A., Department of Computer Science, College of Sciences and Humanities-Aflaj, Prince Sattam bin Abdulaziz University, Saudi Arabia; Malibari A.A., Department of Industrial and Systems Engineering, College of Engineering, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Obayya M., Department of Biomedical Engineering, College of Engineering, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Nour M.K., Department of Computer Sciences, College of Computing and Information System, Umm Al-Qura University, Saudi Arabia; Salama A.S., Department of Electrical Engineering, Faculty of Engineering & Technology, Future University in Egypt, New Cairo, 11845, Egypt; Eldesouki M.I., Department of Information System, College of Computer Engineering and Sciences, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia; Zamani A.S., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia; Rizwanullah M., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, AlKharj, Saudi Arabia","The skeletal bone age assessment (BAA) was extremely implemented in development prediction and auxiliary analysis of medicinal issues. X-ray images of hands were detected from the estimation of bone age, whereas the ossification centers of epiphysis and carpal bones are important regions. The typical skeletal BAA approaches remove these regions for predicting the bone age, however, few of them attain suitable efficacy or accuracy. Automatic BAA techniques with deep learning (DL) methods are reached the leading efficiency on manual and typical approaches. Therefore, this study introduces an intellectual skeletal bone age assessment and classification with the use of metaheuristic with deep learning (ISBAAC-MDL) model. The presented ISBAAC-MDL technique majorly focuses on the identification of bone age prediction and classification process. To attain this, the presented ISBAAC-MDL model derives a mask Region-related Convolutional Neural Network (Mask-RCNN) with MobileNet as baseline model to extract features. Followed by, the whale optimization algorithm (WOA) is implemented for hyperparameter tuning of the MobileNet method. At last, Deep Feed-Forward Module (DFFM) based age prediction and Radial Basis Function Neural Network (RBFNN) based stage classification approach is utilized. The experimental evaluation of the ISBAAC-MDL model is tested using benchmark dataset and the outcomes are assessed over distinct factors. The experimental outcomes reported the better performances of the ISBAAC-MDL model over recent approaches with maximum accuracy of 0.9920. © 2022 Tech Science Press. All rights reserved.","age prediction; Biomedical images; bone age assessment; computer vision; deep learning; image classification","Computer vision; Convolutional neural networks; Deep learning; Forecasting; Learning systems; Musculoskeletal system; Radial basis function networks; Age predictions; Assessment models; Biomedical images; Bone age; Bone age assessment; Classification models; Deep learning; Images classification; Learning models; Metaheuristic; Image classification","","","","","Deanship of Scientific Research at Umm Al-Qura University, (22UQU4310373DSR17)","Funding Statement: Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2022R151), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia. The authors would like to thank the Deanship of Scientific Research at Umm Al-Qura University for supporting this work by Grant Code: (22UQU4310373DSR17).","Nadeem M. W., Goh H. G., Ali A., Hussain M., Khan M. A., Et al., Bone age assessment empowered with deep learning: A survey, open research challenges and future directions, Diagnostics, 10, 10, (2020); Deshmukh S., Khaparde A., Faster region-convolutional neural network oriented feature learning with optimal trained recurrent neural network for bone age assessment for pediatrics, Biomedical Signal Processing and Control, 71, 12, (2022); Iglovikov V. I., Rakhlin A., Kalinin A. A., Shvets A. A., Paediatric bone age assessment using deep convolutional neural networks, Int. Workshop on Deep Learning in Medical Image Analysis, Int. Workshop on Multimodal Learning for Clinical Decision Support, DLMIA 2018, ML-CDS 2018: Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, Lecture Notes in Computer Science book series, 11045, pp. 300-308, (2018); Lee J. H., Kim K. G., Applying deep learning in medical images: The case of bone age estimation, Healthcare Informatics Research, 24, 1, (2018); Wang S., Shen Y., Zeng D., Hu Y., Bone age assessment using convolutional neural networks, 2018 Int. Conf. on Artificial Intelligence and Big Data (ICAIBD), pp. 175-178, (2018); Deshmukh S., Khaparde A., Multi-objective segmentation approach for bone age assessment using parameter tuning-based U-net architecture, Multimedia Tools and Applications, 81, 5, pp. 6755-6800, (2022); Zhao C., Han J., Jia Y., Fan L., Gou F., Versatile framework for medical image processing and analysis with application to automatic bone age assessment, Journal of Electrical and Computer Engineering, 2018, pp. 1-13, (2018); Mao K., Lu W., Wu K., Mao J., Dai G., Bone age assessment method based on fine-grained image classification using multiple regions of interest, Systems Science & Control Engineering, 10, 1, pp. 15-23, (2022); Mutasa S., Chang P. D., Shapiro C. R., Ayyala R., MABAL: A novel deep-learning architecture for machine-assisted bone age labeling, Journal of Digital Imaging, 31, 4, pp. 513-519, (2018); Lee B. D., Lee M. S., Automated bone age assessment using artificial intelligence: The future of bone age assessment, Korean Journal of Radiology, 22, 5, (2021); Bui T. D., Lee J. J., Shin J., Incorporated region detection and classification using deep convolutional networks for bone age assessment, Artificial Intelligence in Medicine, 97, 1, pp. 1-8, (2019); Son S. J., Song Y., Kim N., Do Y., Kwak N., Et al., TW3-based fully automated bone age assessment system using deep neural networks, IEEE Access, 7, pp. 33346-33358, (2019); Tong C., Liang B., Li J., Zheng Z., A deep automated skeletal bone age assessment model with heterogeneous features learning, Journal of Medical Systems, 42, 12, (2018); Liang B., Zhai Y., Tong C., Zhao J., Li J., Et al., A deep automated skeletal bone age assessment model via region-based convolutional neural network, Future Generation Computer Systems, 98, 3, pp. 54-59, (2019); Su L., Fu X., Hu Q., Generative adversarial network based data augmentation and gender-last training strategy with application to bone age assessment, Computer Methods and Programs in Biomedicine, 212, 5, (2021); Almasoud A. S., Hassine S. B. H., Wesabi F. N. A., Nour M. K., Hilal A. M., Et al., Automated multidocument biomedical text summarization using deep learning model, Computers, Materials & Continua, 71, 3, pp. 5799-5815, (2022); Poonia R., Gupta M., Abunadi I., Albraikan A., Al-Wesabi F., Et al., Intelligent diagnostic prediction and classification models for detection of kidney disease, Healthcare, 10, 2, (2022); Malibari A. A., Alshahrani R., Al-Wesabi F. N., Haj Hassine S. B., Alkhonaini M. A., Et al., Artificial intelligence based prostate cancer classification model using biomedical images, Computers, Materials & Continua, 72, 2, pp. 3799-3813, (2022); Malibari A. A., Al-Wesabi F. N., Obayya M., Alkhonaini M., Hamza M. A., Et al., Arithmetic optimization with Retinanet model for motor imagery classification on brain computer interface, Journal of Healthcare Engineering, 2022, 1, pp. 1-11, (2022); Palaniswamy T., Hyperparameter optimization based deep convolution neural network model for automated bone age assessment and classification, Displays, 73, 1, (2022); Srinivasu P. N., SivaSai J. G., Ijaz M. F., Bhoi A. K., Kim W., Et al., Classification of skin disease using deep learning neural networks with MobileNet V2 and LSTM, Sensors, 21, 8, (2021); Shankar K., Perumal E., Elhoseny M., Taher F., Gupta B. B., Et al., Synergic deep learning for smart health diagnosis of covid-19 for connected living and smart cities, ACM Transactions on Internet Technology, 22, 3, pp. 1-14, (2022); Gopi R., Muthusamy P., Suresh P., Kumar C. G. G. S., Pustokhina I. V., Et al., Optimal confidential mechanisms in smart city healthcare, Computers, Materials & Continua, 70, 3, pp. 4883-4896, (2022); Pustokhin D. A., Pustokhina I. V., Rani P., Kansal V., Elhoseny M., Et al., Optimal deep learning approaches and healthcare big data analytics for mobile networks toward 5G, Computers & Electrical Engineering, 95, 11, pp. 1-14, (2021); Chakraborty S., Saha A. K., Sharma S., Mirjalili S., Chakraborty R., A novel enhanced whale optimization algorithm for global optimization, Computers & Industrial Engineering, 153, 5, (2021); Atefinia R., Ahmadi M., Network intrusion detection using multi-architectural modular deep neural network, The Journal of Supercomputing, 77, 4, pp. 3571-3593, (2021); She C., Wang Z., Sun F., Liu P., Zhang L., Battery aging assessment for real-world electric buses based on incremental capacity analysis and radial basis function neural network, IEEE Transactions on Industrial Informatics, 16, 5, pp. 3345-3354, (2020); Spampinato C., Palazzo S., Giordano D., Aldinucci M., Leonardi R., Deep learning for automated skeletal bone age assessment in X-ray images, Medical Image Analysis, 36, pp. 41-51, (2017)","M.A. Duhayyim; Department of Computer Science, College of Sciences and Humanities-Aflaj, Prince Sattam bin Abdulaziz University, Saudi Arabia; email: m.alduhayyim@psau.edu.sa","","Tech Science Press","","","","","","15462218","","","","English","Comput. Mater. Continua","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85135077555"
"Pavone A.M.; Benfante V.; Stefano A.; Mamone G.; Milazzo M.; Di Pizza A.; Parenti R.; Maruzzelli L.; Miraglia R.; Comelli A.","Pavone, Anna Maria (57578504900); Benfante, Viviana (57211284401); Stefano, Alessandro (35794207900); Mamone, Giuseppe (17135015700); Milazzo, Mariapina (7005837543); Di Pizza, Ambra (57841731700); Parenti, Rosalba (57792357200); Maruzzelli, Luigi (23989257600); Miraglia, Roberto (23390480200); Comelli, Albert (57104982700)","57578504900; 57211284401; 35794207900; 17135015700; 7005837543; 57841731700; 57792357200; 23989257600; 23390480200; 57104982700","Automatic Liver Segmentation in Pre-TIPS Cirrhotic Patients: A Preliminary Step for Radiomics Studies","2022","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","13373 LNCS","","","408","418","10","1","10.1007/978-3-031-13321-3_36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135838559&doi=10.1007%2f978-3-031-13321-3_36&partnerID=40&md5=3e01e600c6ffbc8932fb8ce5fb41e578","Ri.MED Foundation, Via Bandiera 11, Palermo, 90133, Italy; Section of Physiology, Department of Biomedical and Biotechnological Sciences, University of Catania, Via S. Sofia n. 97, Torre Biologica,, Catania, 95123, Italy; Department of Health Promotion, Mother and Child Care, Internal Medicine and Medical Specialties, Molecular and Clinical Medicine, University of Palermo, Palermo, 90127, Italy; Institute of Molecular Bioimaging and Physiology, National Research Council (IBFM-CNR), Cefalù, 90015, Italy; Department of Diagnostic and Therapeutic Services, IRCCS-ISMETT (Mediterranean Institute for Transplantation and Advanced Specialized Therapies), Via Tricomi 5, Palermo, 90127, Italy","Pavone A.M., Ri.MED Foundation, Via Bandiera 11, Palermo, 90133, Italy, Section of Physiology, Department of Biomedical and Biotechnological Sciences, University of Catania, Via S. Sofia n. 97, Torre Biologica,, Catania, 95123, Italy; Benfante V., Ri.MED Foundation, Via Bandiera 11, Palermo, 90133, Italy, Department of Health Promotion, Mother and Child Care, Internal Medicine and Medical Specialties, Molecular and Clinical Medicine, University of Palermo, Palermo, 90127, Italy, Institute of Molecular Bioimaging and Physiology, National Research Council (IBFM-CNR), Cefalù, 90015, Italy; Stefano A., Institute of Molecular Bioimaging and Physiology, National Research Council (IBFM-CNR), Cefalù, 90015, Italy; Mamone G., Department of Diagnostic and Therapeutic Services, IRCCS-ISMETT (Mediterranean Institute for Transplantation and Advanced Specialized Therapies), Via Tricomi 5, Palermo, 90127, Italy; Milazzo M., Department of Diagnostic and Therapeutic Services, IRCCS-ISMETT (Mediterranean Institute for Transplantation and Advanced Specialized Therapies), Via Tricomi 5, Palermo, 90127, Italy; Di Pizza A., Department of Diagnostic and Therapeutic Services, IRCCS-ISMETT (Mediterranean Institute for Transplantation and Advanced Specialized Therapies), Via Tricomi 5, Palermo, 90127, Italy; Parenti R., Section of Physiology, Department of Biomedical and Biotechnological Sciences, University of Catania, Via S. Sofia n. 97, Torre Biologica,, Catania, 95123, Italy; Maruzzelli L., Department of Diagnostic and Therapeutic Services, IRCCS-ISMETT (Mediterranean Institute for Transplantation and Advanced Specialized Therapies), Via Tricomi 5, Palermo, 90127, Italy; Miraglia R., Department of Diagnostic and Therapeutic Services, IRCCS-ISMETT (Mediterranean Institute for Transplantation and Advanced Specialized Therapies), Via Tricomi 5, Palermo, 90127, Italy; Comelli A., Ri.MED Foundation, Via Bandiera 11, Palermo, 90133, Italy","The aim of this study is to present a deep learning (DL) algorithm for accurate liver delineation in high-resolution computed tomography (CT) images of pre-transjugular intrahepatic portosystemic shunt (TIPS) cirrhotic patients. In this way, we aim to improve the methodology performed by medical physicians in radiomics studies where the use of operator-independent segmentation methods is mandatory to correctly identify the target and to obtain accurate predictive models. Two DL models were investigated: UNet, the most widely used DL network for biomedical image segmentation, and the innovative customized efficient neural network (C-ENet). 111 patients with liver contrast-enhanced CT examinations before TIPS procedure were considered. The performance of the two DL networks was evaluated in terms of the similarity of their segmentations to the gold standard. The results show that C-ENet can be used to obtain accurate (dice similarity coefficient = 87.70%) segmentation of the liver region outperforming UNet (dice similarity coefficient = 85.33%). In conclusion, we demonstrated that DL can be efficiently applied to rapidly segment cirrhotic liver images, without any radiologist supervision, to produce user-independent results useful for subsequent radiomics studies. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","C-ENet; Cirrhosis; Deep learning; Liver; Segmentation; TIPS; UNet","Computerized tomography; Image segmentation; Medical imaging; Cirrhosis; Customized efficient neural network; Deep learning; Learning network; Liver segmentation; Neural-networks; Segmentation; Similarity coefficients; Transjugular intrahepatic portosystemic shunt; Unet; Deep learning","","","","","","","Roerecke M., Et al., Alcohol consumption and risk of liver cirrhosis: A systematic review and meta-analysis, Am. J. Gastroenterol., 114, pp. 1574-1586, (2019); Gines P., Krag A., Abraldes J.G., Sola E., Fabrellas N., Kamath P.S., Liver cirrhosis, Lancet, 398, pp. 1359-1376, (2021); Smith A.J., Baumgartner K., Bositis C.M., Cirrhosis: Diagnosis and management, Am. Fam. Physician, 100, 12, pp. 759-770, (2019); Fan Y., Li Y., Chu Y., Liu J., Cui L., Zhang D., Toll-like receptors recognize intestinal microbes in liver cirrhosis, Front. Immunol., 12, 99, (2021); Lai M., Afdhal N.H., Liver fibrosis determination, Gastroenterol. Clin. North Am., 48, pp. 281-289, (2019); de Wit K., Et al., Prevention of hepatic encephalopathy by administration of rifaximin and lactulose in patients with liver cirrhosis undergoing placement of a transjugular intrahepatic portosystemic shunt (TIPS): A multicentre randomised, double blind, placebo controlled t, BMJ Open Gastroenterol, (2020); Rajesh S., Et al., Transjugular intrahepatic portosystemic shunt in cirrhosis: An exhaustive critical update, World J. Gastroenterol., 26, pp. 5561-5596, (2020); Sun S.H., Et al., Predicting death or recurrence of portal hypertension symptoms after TIPS procedures, Eur. Radiol., 32, pp. 3346-3357, (2022); Salvaggio G., Et al., Deep learning network for segmentation of the prostate gland with median lobe enlargement in T2-weighted MR images: Comparison with manual segmentation method, Curr. Probl. Diagn. Radiol., (2021); Agnello L., Comelli A., Ardizzone E., Vitabile S., Unsupervised tissue classification of brain MR images for voxel-based morphometry analysis, Int. J. Imaging Syst. Technol., 26, pp. 136-150, (2016); Laudicella R., Et al., Artificial neural networks in cardiovascular diseases and its potential for clinical application in molecular imaging, Curr. Radiopharm., 14, pp. 209-219, (2020); Cutaia G., Et al., Radiomics and prostate MRI: Current role and future applications, J. Imaging, 7, (2021); Salvaggio G., Et al., Deep learning networks for automatic retroperitoneal sarcoma segmentation in computerized tomography, Appl. Sci., 12, (2022); Cuocolo R., Et al., Deep learning whole-gland and zonal prostate segmentation on a public MRI dataset, J. Magn. Reson. Imaging, 54, pp. 452-459, (2021); Chen C., Et al., Deep learning for cardiac image segmentation: A review, Front. Cardiovasc. Med., (2020); Choy G., Et al., Current applications and future impact of machine learning in radiology, Radiology, 288, pp. 318-328, (2018); Mitrea D., Badea R., Mitrea P., Brad S., Nedevschi S., Hepatocellular carcinoma automatic diagnosis within ceus and b-mode ultrasound images using advanced machine learning methods, Sensors, 21, 1-31, (2021); Zheng R., Et al., Feasibility of automatic detection of small hepatocellular carcinoma (≤2 cm) in cirrhotic liver based on pattern matching and deep learning, Phys. Med. Biol., 66, (2021); Perez A.A., Et al., Deep learning CT-based quantitative visualization tool for liver volume estimation: Defining normal and hepatomegaly, Radiology, 302, pp. 336-342, (2022); Stefano A., Comelli A., Customized efficient neural network for covid-19 infected region identification in CT images, J. Imaging., 7, (2021); Stefano A., Et al., Performance of radiomics features in the quantification of idiopathic pulmonary fibrosis from HRCT, Diagnostics 10, 306, 10, (2020); Paszke A., Chaurasia A., Kim S., Culurciello E., Enet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation, pp. 1-10, (2016); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, MICCAI 2015. LNCS, Vol. 9351, pp. 234-241, (2015); Salehi S.S.M., Erdogmus D., Gholipour A., Tversky loss function for image segmentation using 3D fully convolutional deep networks, MLMI 2017. LNCS, Vol. 10541, pp. 379-387, (2017); Alongi P., Et al., Radiomics analysis of 18F-Choline PET/CT in the prediction of disease outcome in high-risk prostate cancer: An explorative study on machine learning feature classification in 94 patients, Eur. Radiol., 31, 7, pp. 4595-4605, (2021); Comelli A., Stefano A., Benfante V., Russo G., Normal and abnormal tissue classification in positron emission tomography oncological studies, Pattern Recogn. Image Anal., 28, pp. 106-113, (2018); Hu Y., Et al., A prediction model for 30-day deaths of cirrhotic patients in intensive care unit hospitalization, Med. (United States)., 101, (2022); Groendahl A.R., Et al., A comparison of methods for fully automatic segmentation of tumors and involved nodes in PET/CT of head and neck cancers, Phys. Med. Biol., 66, (2021); Comelli A., Et al., Deep learning approach for the segmentation of aneurysmal ascending aorta, Biomed. Eng. Lett., 11, 1, pp. 15-24, (2020)","G. Mamone; Department of Diagnostic and Therapeutic Services, IRCCS-ISMETT (Mediterranean Institute for Transplantation and Advanced Specialized Therapies), Palermo, Via Tricomi 5, 90127, Italy; email: gmamone@ismett.edu","Mazzeo P.L.; Distante C.; Frontoni E.; Sclaroff S.","Springer Science and Business Media Deutschland GmbH","","21st International Conference on Image Analysis and Processing , ICIAP 2022","23 May 2022 through 27 May 2022","Lecce","281699","03029743","978-303113320-6","","","English","Lect. Notes Comput. Sci.","Conference paper","Final","","Scopus","2-s2.0-85135838559"
"Malibari A.A.; Alzahrani J.S.; Obayya M.; Negm N.; Al-Hagery M.A.; Salama A.S.; Hilal A.M.","Malibari, Areej A. (6506143515); Alzahrani, Jaber S. (57221867248); Obayya, Marwa (6505869929); Negm, Noha (57224513486); Al-Hagery, Mohammed Abdullah (57203986293); Salama, Ahmed S. (56480035100); Hilal, Anwer Mustafa (57202837434)","6506143515; 57221867248; 6505869929; 57224513486; 57203986293; 56480035100; 57202837434","Biomedical Osteosarcoma Image Classification Using Elephant Herd Optimization and Deep Learning","2022","Computers, Materials and Continua","73","3","","6443","6459","16","0","10.32604/cmc.2022.031324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135064194&doi=10.32604%2fcmc.2022.031324&partnerID=40&md5=06624d2d75c400bbb5175c7ed0816ad9","Department of Industrial and Systems Engineering, College of Engineering, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Industrial Engineering, College of Engineering at Alqunfudah, Umm Al-Qura University, Saudi Arabia; Department of Biomedical Engineering, College of Engineering, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Computer Science, College of Science and Art at Mahayil, King Khalid University, Saudi Arabia; Faculty of Science, Mathematics and Computer Science Department, Menoufia University, Egypt; Department of Computer Science, College of Computer, Qassim University, Saudi Arabia; Department of Electrical Engineering, Faculty of Engineering and Technology, Future University in Egypt, New Cairo, 11845, Egypt; Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, Saudi Arabia","Malibari A.A., Department of Industrial and Systems Engineering, College of Engineering, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Alzahrani J.S., Department of Industrial Engineering, College of Engineering at Alqunfudah, Umm Al-Qura University, Saudi Arabia; Obayya M., Department of Biomedical Engineering, College of Engineering, Princess Nourah Bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Negm N., Department of Computer Science, College of Science and Art at Mahayil, King Khalid University, Saudi Arabia, Faculty of Science, Mathematics and Computer Science Department, Menoufia University, Egypt; Al-Hagery M.A., Department of Computer Science, College of Computer, Qassim University, Saudi Arabia; Salama A.S., Department of Electrical Engineering, Faculty of Engineering and Technology, Future University in Egypt, New Cairo, 11845, Egypt; Hilal A.M., Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, Saudi Arabia","Osteosarcoma is a type of malignant bone tumor that is reported across the globe. Recent advancements in Machine Learning (ML) and Deep Learning (DL) models enable the detection and classification of malignancies in biomedical images. In this regard, the current study introduces a new Biomedical Osteosarcoma Image Classification using Elephant Herd Optimization and Deep Transfer Learning (BOIC-EHODTL) model. The presented BOIC-EHODTL model examines the biomedical images to diagnose distinct kinds of osteosarcoma. At the initial stage, Gabor Filter (GF) is applied as a pre-processing technique to get rid of the noise from images. In addition, Adam optimizer with MixNet model is also employed as a feature extraction technique to generate feature vectors. Then, EHO algorithm is utilized along with Adaptive Neuro-Fuzzy Classifier (ANFC) model for recognition and categorization of osteosarcoma. EHO algorithm is utilized to fine-tune the parameters involved in ANFC model which in turn helps in accomplishing improved classification results. The design of EHO with ANFC model for classification of osteosarcoma is the novelty of current study. In order to demonstrate the improved performance of BOIC-EHODTL model, a comprehensive comparison was conducted between the proposed and existing models upon benchmark dataset and the results confirmed the better performance of BOIC-EHODTL model over recent methodologies. © 2022 Tech Science Press. All rights reserved.","Biomedical imaging; deep transfer learning parameter tuning; fuzzy logic; osteosarcoma classification","Benchmarking; Deep learning; Fuzzy inference; Fuzzy neural networks; Gabor filters; Learning systems; Medical imaging; Biomedical imaging; Deep transfer learning parameter tuning; Fuzzy-Logic; Images classification; Learning parameters; Optimisations; Osteosarcoma classification; Osteosarcomas; Parameters tuning; Transfer learning; Image classification","","","","","Deanship of Scientific Research at Umm Al-Qura University, (22UQU4340237DSR16); Deanship of Scientific Research, King Faisal University, DSR, KFU, (42/43); Deanship of Scientific Research, King Faisal University, DSR, KFU","Funding Statement: The authors extend their appreciation to the Deanship of Scientific Research at King Khalid University for funding this work through Large Groups Project under grant number (42/43). Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2022R151), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia. The authors would like to thank the Deanship of Scientific Research at Umm Al-Qura University for supporting this work by Grant Code: (22UQU4340237DSR16).","Anisuzzaman D. M., Barzekar H., Tong L., Luo J., Yu Z., A deep learning study on osteosarcoma detection from histological images, Biomedical Signal Processing and Control, 69, 5, (2021); Mahore S., Bhole K., Rathod S., Machine learning approach to classify and predict different osteosarcoma types, 2021 8th Int. Conf. on Signal Processing and Integrated Networks (SPIN), pp. 641-645, (2021); Wang W., Huang X., Li J., Zhang P., Wang X., Detecting COVID-19 patients in X-ray images based on MAI-nets, International Journal of Computational Intelligence Systems, 14, 1, pp. 1607-1616, (2021); Gui Y., Zeng G., Joint learning of visual and spatial features for edit propagation from a single image, The Visual Computer, 36, 3, pp. 469-482, (2020); Wang W., Li Y. T., Zou T., Wang X., You J. Y., Et al., A novel image classification approach via Dense-MobileNet models, Mobile Information Systems, (2020); Zhou S. R., Yin J. P., Zhang J. M., Local binary pattern (LBP) and local phase quantization (LBQ) based on Gabor filter for face representation, Neurocomputing, 116, 6, pp. 260-264, (2013); Song Y., Zhang D., Tang Q., Tang S., Yang K., Local and nonlocal constraints for compressed sensing video and multi-view image recovery, Neurocomputing, 406, 2, pp. 34-48, (2020); Zhang D., Wang S., Li F., Tian S., Wang J., Et al., An efficient ECG denoising method based on empirical mode decomposition, sample entropy, and improved threshold function, Wireless Communications and Mobile Computing, 2020, 2, pp. 1-11, (2020); Zhang X. R., Sun X., Sun W., Xu T., Wang P. P., Deformation expression of soft tissue based on BP neural network, Intelligent Automation & Soft Computing, 32, 2, pp. 1041-1053, (2022); Zhang X. R., Zhang W. F., Sun W., Sun X. M., Jha S. K., A robust 3-D medical watermarking based on wavelet transform for data protection, Computer Systems Science & Engineering, 41, 3, pp. 1043-1056, (2022); Liu R., Pan D., Xu Y., Zeng H., He Z., Et al., A deep learning-machine learning fusion approach for the classification of benign, malignant, and intermediate bone tumors, European Radiology, 32, 2, pp. 1371-1383, (2022); Mohan B. C., Osteosarcoma classification using multilevel feature fusion and ensembles, 2021 IEEE 18th India Council Int. Conf. (INDICON), pp. 1-6, (2021); Badashah S. J., Basha S. S., Ahamed S. R., Subba Rao S. P. V., Fractional-harris hawks optimization-based generative adversarial network for osteosarcoma detection using renyi entropy-hybrid fusion, International Journal of Intelligent Systems, 36, 10, pp. 6007-6031, (2021); Bansal H., Dubey B., Goyanka P., Varshney S., Assessment of osteogenic sarcoma with histology images using deep learning, Machine Learning and Information Processing, Advances in Intelligent Systems and Computing Book Series, 1311, pp. 215-223, (2021); Malibari A. A., Alshahrani R., Al-Wesabi F. N., Haj Hassine S. B., Alkhonaini M. A., Et al., Artificial intelligence based prostate cancer classification model using biomedical images, Computers, Materials & Continua, 72, 2, pp. 3799-3813, (2022); Poonia R., Gupta M., Abunadi I., Albraikan A. A., Al-Wesabi F. N., Et al., Intelligent diagnostic prediction and classification models for detection of kidney disease, Healthcare, 10, 2, (2022); Almasoud A. S., Haj Hassine S. B., Al-Wesabi F. N., Nour M. K., Hilal A. M., Et al., Automated multidocument biomedical text summarization using deep learning model, Computers, Materials & Continua, 71, 3, pp. 5799-5815, (2022); Wang Y., Yan J., Yang Z., Zhao Y., Liu T., Optimizing GIS partial discharge pattern recognition in the ubiquitous power internet of things context: A MixNet deep learning model, International Journal of Electrical Power & Energy Systems, 125, 4, (2021); Zhang Z., Improved adam optimizer for deep neural networks, 2018 IEEE/ACM 26th Int. Symp. on Quality of Service (IWQoS), pp. 1-2, (2018); Rawat J., Singh A., Bhadauria H. S., Virmani J., Devgun J. S., Leukocyte classification using adaptive neuro-fuzzy inference system in microscopic blood images, Arabian Journal for Science and Engineering, 43, 12, pp. 7041-7058, (2018); Shankar K., Perumal E., Elhoseny M., Taher F., Gupta B. B., Et al., Synergic deep learning for smart health diagnosis of COVID-19 for connected living and smart cities, ACM Transactions on Internet Technology, 22, 3, pp. 1-14, (2022); Shankar K., Perumal E., Diaz V. G., Tiwari P., Gupta D., Et al., An optimal cascaded recurrent neural network for intelligent COVID-19 detection using Chest X-ray images, Applied Soft Computing, 113, pp. 1-13, (2021); Shankar K., Perumal E., Tiwari P., Shorfuzzaman M., Gupta D., Deep learning and evolutionary intelligence with fusion-based feature extraction for detection of COVID-19 from chest X-ray images, Multimedia Systems, 66, 2, (2021); Shankar K., Perumal E., A novel hand-crafted with deep learning features based fusion model for COVID-19 diagnosis and classification using chest X-ray images, Complex & Intelligent Systems, 7, pp. 1277-1293, (2020); Li J., Lei H., Alavi A. H., Wang G. G., Elephant herding optimization: Variants, hybrids, and applications, Mathematics, 8, 9, (2020); Leavey P., Sengupta A., Rakheja D., Daescu O., Arunachalam H. B., Et al., Osteosarcoma data from UT Southwestern/UT Dallas for viable and necrotic tumor assessment, Data set] The Cancer Imaging, (2019)","A.M. Hilal; Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam Bin Abdulaziz University, AlKharj, Saudi Arabia; email: a.hilal@psau.edu.sa","","Tech Science Press","","","","","","15462218","","","","English","Comput. Mater. Continua","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85135064194"
"Isler I.; Lisle C.; Rineer J.; Kelly P.; Turgut D.; Ricci J.; Bagci U.","Isler, Ilkin (57453663000); Lisle, Curtis (6602758735); Rineer, Justin (6504459710); Kelly, Patrick (56365080700); Turgut, Damla (6603176290); Ricci, Jacob (57247420600); Bagci, Ulas (24176491700)","57453663000; 6602758735; 6504459710; 56365080700; 6603176290; 57247420600; 24176491700","Enhancing Organ at Risk Segmentation with Improved Deep Neural Networks","2022","Progress in Biomedical Optics and Imaging - Proceedings of SPIE","12032","","1203233","","","","2","10.1117/12.2611498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131961819&doi=10.1117%2f12.2611498&partnerID=40&md5=86cf31b60bc4531c526d9e126d1a699e","Dept. of Computer Science, University of Central Florida, Orlando, FL, United States; KnowledgeVis LLC, Orlando, FL, United States; Dept. of Radiation Oncology, Orlando Health, Orlando, FL, United States; Dept. of Radiology and BME, Northwestern University, Chicago, IL, United States","Isler I., Dept. of Computer Science, University of Central Florida, Orlando, FL, United States; Lisle C., Dept. of Computer Science, University of Central Florida, Orlando, FL, United States, KnowledgeVis LLC, Orlando, FL, United States; Rineer J., Dept. of Radiation Oncology, Orlando Health, Orlando, FL, United States; Kelly P., Dept. of Radiation Oncology, Orlando Health, Orlando, FL, United States; Turgut D., Dept. of Computer Science, University of Central Florida, Orlando, FL, United States; Ricci J., Dept. of Radiation Oncology, Orlando Health, Orlando, FL, United States; Bagci U., Dept. of Computer Science, University of Central Florida, Orlando, FL, United States, Dept. of Radiology and BME, Northwestern University, Chicago, IL, United States","Organ at risk (OAR) segmentation is a crucial step for treatment planning and outcome determination in radiotherapy treatments of cancer patients. Several deep learning based segmentation algorithms have been developed in recent years, however, U-Net remains the de facto algorithm designed specifically for biomedical image segmentation and has spawned many variants with known weaknesses. In this study, our goal is to present simple architectural changes in U-Net to improve its accuracy and generalization properties. Unlike many other available studies evaluating their algorithms on single center data, we thoroughly evaluate several variations of U-Net as well as our proposed enhanced architecture on multiple data sets for an extensive and reliable study of the OAR segmentation problem. Our enhanced segmentation model includes (a)architectural changes in the loss function, (b)optimization framework, and (c)convolution type. Testing on three publicly available multi-object segmentation data sets, we achieved an average of 80% dice score compared to the baseline U-Net performance of 63%. © 2022 SPIE.","Generalization; Multi-object segmentation; Organ at risk segmentation; Radiation Oncology; U-Net","Bioinformatics; Computer aided diagnosis; Image segmentation; Medical imaging; Oncology; Radiotherapy; Architectural changes; Generalisation; Multi-object segmentation; Organ at risk segmentation; Organs at risks; Radiation oncology; Radiotherapy treatment; Treatment outcomes; Treatment planning; U-net; Deep neural networks","","","","","National Institutes of Health, NIH, (R01-CA240639, R01-CA246704)","This study greatly acknowledges the funding source: Florida Dept of Health (FDOH)-20K04. Dr. Bagci acknowledges the partial support by the NIH grants R01-CA246704 and R01-CA240639.","Gansler T., Ganz P. A., Grant M., Greene F. L., Johnstone P., Mahoney M., Newman L. A., Oh W. K., Thomas C. R., Thun M. J., Et al., Sixty years of ca: a cancer journal for clinicians, CA: a cancer journal for clinicians, 60, 6, pp. 345-350, (2010); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical image computing and computer-assisted intervention, pp. 234-241, (2015); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 3431-3440, (2015); Cicek O., Abdulkadir A., Lienkamp S. S., Brox T., Ronneberger O., 3d u-net: learning dense volumetric segmentation from sparse annotation, International conference on medical image computing and computer-assisted intervention, pp. 424-432, (2016); Kerfoot E., Clough J., Oksuz I., Lee J., King A. P., Schnabel J. A., Left-ventricle quantification using residual u-net, International Workshop on Statistical Atlases and Computational Models of the Heart, pp. 371-380, (2018); Zhou Z., Siddiquee M. M. R., Tajbakhsh N., Liang J., Unet++: A nested u-net architecture for medical image segmentation, Deep learning in medical image analysis and multimodal learning for clinical decision support, pp. 3-11, (2018); Smith L. N., Cyclical learning rates for training neural networks, 2017 IEEE winter conference on applications of computer vision (WACV), pp. 464-472, (2017); Tan M., Le Q., Efficientnet: Rethinking model scaling for convolutional neural networks, International Conference on Machine Learning, pp. 6105-6114, (2019); Babier A., Zhang B., Mahmood R., Moore K. L., Purdie T. G., McNiven A. L., Chan T. C., Openkbp: The open-access knowledge-based planning grand challenge, (2020); Raudaschl P. F., Zaffino P., Sharp G. C., Spadea M. F., Chen A., Dawant B. M., Albrecht T., Gass T., Langguth C., Luthi M., Et al., Evaluation of segmentation methods on head and neck ct: auto-segmentation challenge 2015, Medical physics, 44, 5, pp. 2020-2036, (2017); Aerts H. J., Velazquez E. R., Leijenaar R. T., Parmar C., Grossmann P., Carvalho S., Bussink J., Monshouwer R., Haibe-Kains B., Rietveld D., Et al., Decoding tumour phenotype by noninvasive imaging using a quantitative radiomics approach, Nature communications, 5, 1, pp. 1-9, (2014); Clark K., Vendt B., Smith K., Freymann J., Kirby J., Koppel P., Moore S., Phillips S., Maffitt D., Pringle M., Et al., The cancer imaging archive (tcia): maintaining and operating a public information repository, Journal of digital imaging, 26, 6, pp. 1045-1057, (2013); MONAI: Medical Open Network for AI, 3, (2020); Isensee F., Petersen J., Klein A., Zimmerer D., Jaeger P. F., Kohl S., Wasserthal J., Koehler G., Norajitra T., Wirkert S., Et al., nnu-net: Self-adapting framework for u-net-based medical image segmentation, (2018)","U. Bagci; Dept. of Computer Science, University of Central Florida, Orlando, United States; email: ulas.bagci@northwestern.edu","Colliot O.; Isgum I.; Landman B.A.; Loew M.H.","SPIE","Philips Healthcare; The Society of Photo-Optical Instrumentation Engineers (SPIE)","Medical Imaging 2022: Image Processing","21 March 2021 through 27 March 2021","Virtual, Online","179445","16057422","978-151064939-2","","","English","Progr. Biomed. Opt. Imaging Proc. SPIE","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85131961819"
"","","","14th International conference on Pattern Recognition and Information Processing, PRIP 2019","2019","Communications in Computer and Information Science","1055 CCIS","","","","","311","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076698019&partnerID=40&md5=d739f08078244e0340f18c86d8a47bbb","","","The proceedings contain 25 papers. The special focus in this conference is on Pattern Recognition and Information Processing. The topics include: Brands and Caps Labeling Recognition in Images Using Deep Learning; influence of Control Parameters and the Size of Biomedical Image Datasets on the Success of Adversarial Attacks; performance of Sequential Tests for Random Data Monitoring Under Distortion; equipment Condition Identification Based on Telemetry Signal Clustering; robots’ Vision Humanization Through Machine-Learning Based Artificial Visual Attention; automatic Analysis of Moving Particles by Total Internal Reflection Fluorescence Microscopy; fuzzy Morphological Filters for Processing of Printed Circuit Board Images; Detection of Bulbar Dysfunction in ALS Patients Based on Running Speech Test; thresholding Neural Network Image Enhancement Based on 2-D Non-separable Quaternionic Filter Bank; method of Creating the 3D Face Model of Character Based on Textures Maps Module; shadow Detection in Satellite Images by Computing Its Characteristics; nearest Convex Hull Classifier with Simplified Proximity Measurement; image Semantic Segmentation Based on Convolutional Neural Networks for Monitoring Agricultural Vegetation; reliability Analysis Based on Incompletely Specified Data; semantic-Based Linguistic Platform for Big Data Processing; cell Nuclei Counting and Segmentation for Histological Image Analysis; robust Person Tracking Algorithm Based on Convolutional Neural Network for Indoor Video Surveillance Systems; modeling of Intelligent Systems Architecture Based on the Brain Topology; temporal Convolutional and Recurrent Networks for Image Captioning; Video-Based Content Extraction Algorithm from Bank Cards for iOS Mobile Devices; FPGA Based Arbiter Physical Unclonable Function Implementation with Reduced Hardware Overhead; preface.","","","","","","","","","","","Ablameyko S.V.; Krasnoproshin V.V.; Lukashevich M.M.","Springer","","14th International conference on Pattern Recognition and Information Processing, PRIP 2019","21 May 2019 through 23 May 2019","Minsk","234449","18650929","978-303035429-9","","","English","Commun. Comput. Info. Sci.","Conference review","Final","","Scopus","2-s2.0-85076698019"
"Contreras G.; Pabon J.; Garcia H.; Rojas F.; Arguello H.","Contreras, Ghiordy (57422578400); Pabon, Jhon (57422727600); Garcia, Hans (57192275191); Rojas, Fernando (58625491200); Arguello, Henry (44061135000)","57422578400; 57422727600; 57192275191; 58625491200; 44061135000","Correction of Designed Compressive Spectral Imaging Measurements Using a Deep Learning-Based Method","2021","2021 22nd Symposium on Image, Signal Processing and Artificial Vision, STSIVA 2021 - Conference Proceedings","","","","","","","0","10.1109/STSIVA53688.2021.9592024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123319777&doi=10.1109%2fSTSIVA53688.2021.9592024&partnerID=40&md5=c67ee5a3b1b27a6fb2787f03ff39a407","Universidad Industrial de Santander, Dept. of Electrical Engineering, Bucaramanga, Colombia; Universidad Industrial de Santander, Dept. of Computer Science, Bucaramanga, Colombia","Contreras G., Universidad Industrial de Santander, Dept. of Electrical Engineering, Bucaramanga, Colombia; Pabon J., Universidad Industrial de Santander, Dept. of Computer Science, Bucaramanga, Colombia; Garcia H., Universidad Industrial de Santander, Dept. of Electrical Engineering, Bucaramanga, Colombia; Rojas F., Universidad Industrial de Santander, Dept. of Computer Science, Bucaramanga, Colombia; Arguello H., Universidad Industrial de Santander, Dept. of Computer Science, Bucaramanga, Colombia","Spectral imaging offers useful additional information to improve or expand imaging applications such as biomedical images, identification of cultures, and surveillance. These applications take advantage of features involved in a spectral scene captured using, for instance, the Coded Aperture Snapshot Spectral Imagers (CASSI), that naturally embodies the compressing sensing principles, whose potential is diminished because in practice, sensing matrix loses the ideal characteristics. This paper uses a deep learning based method in order to correct the real-compressed measurements and estimate the ideal-corrected measurements. The correction is estimated from a matrix form of compressed measurements, with the representation of compressed spatial dimensions and the number of projections captured as shots. The performance of the model is measured using peak signal-To-noise ratio, and the structural similarity index, upon the recovered data cube with the gradient projection for sparse reconstruction algorithm. The outcomes show how the deep learning-based method improves the quality in reconstruction against image ground truth when the noise is not concerning. © 2021 IEEE.","compressing sensing; convolutional neural network; cost function; deep learning; real calibration; Sensing matrix","Convolutional neural networks; Cost functions; Deep learning; Image enhancement; Matrix algebra; Signal to noise ratio; Compressing sensing; Convolutional neural network; Cost-function; Deep learning; Imaging measurements; Learning-based methods; matrix; Real calibration; Sensing matrix; Spectral imaging; Spectroscopy","","","","","","","Lu G., Fei B., Medical hyperspectral imaging: A review, Journal of Biomedical Optics, 19, 1, (2014); Sanchez K., Bacca J., Arevalo-Sanchez L., Arguello H., Castillo S., Classification of cocoa beans based on their level of fermentation using spectral information, TecnoLogicas, 24, 50, (2021); Bacca J., Gelvez T., Arguello H., Deep Coded Aperture Design: An End-To-end Approach for Computational Imaging Tasks, (2021); Marquez M., Rueda-Chacon H., Arguello H., Compressive spectral imaging via virtual side information, IEEE Transactions on Computational Imaging, 7, pp. 114-123, (2021); Bacca J., Fonseca Y., Arguello H., Compressive Spectral Image Reconstruction Using Deep Prior and Low-rank Tensor Representation, (2021); Garcia H., Correa C.V., Arguello H., Optimized sensing matrix for single pixel multi-resolution compressive spectral imaging, IEEE Transactions on Image Processing, 29, pp. 4243-4253, (2020); Ramirez J.M., Torre J.I.M., Arguello H., Feature fusion via dual-resolution compressive measurement matrix analysis for spectral image classification, Signal Processing: Image Communication, 90, (2021); Cao X., Yue T., Lin X., Lin S., Yuan X., Dai Q., Carin L., Brady D.J., Computational snapshot multispectral cameras: Toward dynamic capture of the spectral world, IEEE Signal Processing Magazine, 33, 5, pp. 95-108, (2016); Correa C.V., Arguello H., Arce G.R., Spatiotemporal blue noise coded aperture design for multi-shot compressive spectral imaging, JOSA A, 33, 12, pp. 2312-2322, (2016); Lopez C., Jacome R., Garcia H., Arguello H., Object classification using spectral images and deep learning, 2020 IEEE Colombian Conference on Applications of Computational Intelligence IEEE ColCACI, pp. 1-6, (2020); Garcia H., Marquez M., Arguello H., Super-resolution in compressive coded imaging systems via l2 l1 l2 minimization under a deep learning approach, 2020 Data Compression Conference (DCC, pp. 53-62, (2020); Gedalin D., Oiknine Y., Stern A., Deepcubenet: Reconstruction of spectrally compressive sensed hyperspectral images with deep neural networks, Optics Express, 27, 24, pp. 35811-35822, (2019); Bacca J., Galvis L., Arguello H., Coupled deep learning coded aperture design for compressive image classification, Optics Express, 28, 6, pp. 8528-8540, (2020); Marquez M., Meza P., Rojas F., Arguello H., Vera E., Snapshot compressive spectral depth imaging from coded aberrations, Opt. Express, 29, pp. 8142-8159, (2021); Wang L., Sun C., Fu Y., Kim M.H., Huang H., Hyperspectral image reconstruction using a deep spatial-spectral prior, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8032-8041, (2019); Arad B., Timofte R., Ben-Shahar O., Lin Y.-T., Finlayson G.D., Ntire 2020 challenge on spectral reconstruction from an rgb image, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, pp. 446-447, (2020)","H. Arguello; Universidad Industrial de Santander, Dept. of Computer Science, Bucaramanga, Colombia; email: henarfu@uis.edu.co","","Institute of Electrical and Electronics Engineers Inc.","Fundacion Universitaria Tecnologico Comfenalco; IEEE Colombia Section; IEEE Signal Processing Society Colombia Chapter; Universidad Antonio Narno; Universidad del Cauca; Universidad Tecnologica de Bolivar","22nd Symposium on Image, Signal Processing and Artificial Vision, STSIVA 2021","15 September 2021 through 17 September 2021","Popayan","174002","","978-166541668-9","","","English","Symp. Image, Signal Process. Artif. Vis., STSIVA - Conf. Proc.","Conference paper","Final","","Scopus","2-s2.0-85123319777"
"Gastounioti A.; Rathore S.; Maghsoudi O.H.; Conant E.F.; Kontos D.; Bakas S.","Gastounioti, Aimilia (36604342100); Rathore, Saima (55000220500); Maghsoudi, Omid Haji (56132015900); Conant, Emily F. (7004184822); Kontos, Despina (6602886901); Bakas, Spyridon (55366125000)","36604342100; 55000220500; 56132015900; 7004184822; 6602886901; 55366125000","Computational imaging applications in brain and breast cancer","2022","State of the Art in Neural Networks and their Applications: Volume 2","","","","29","45","16","0","10.1016/B978-0-12-819872-8.00009-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150132641&doi=10.1016%2fB978-0-12-819872-8.00009-4&partnerID=40&md5=7855fa8ac75bd120048c710dba93439a","Center for Biomedical Image Computing and Analytics, University of Pennsylvania, Philadelphia, PA, United States; Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Department of Pathology and Laboratory Medicine, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States","Gastounioti A., Center for Biomedical Image Computing and Analytics, University of Pennsylvania, Philadelphia, PA, United States, Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Rathore S., Center for Biomedical Image Computing and Analytics, University of Pennsylvania, Philadelphia, PA, United States, Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Maghsoudi O.H., Center for Biomedical Image Computing and Analytics, University of Pennsylvania, Philadelphia, PA, United States, Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Conant E.F., Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Kontos D., Center for Biomedical Image Computing and Analytics, University of Pennsylvania, Philadelphia, PA, United States, Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Bakas S., Center for Biomedical Image Computing and Analytics, University of Pennsylvania, Philadelphia, PA, United States, Department of Radiology, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States, Department of Pathology and Laboratory Medicine, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States","The rapid development of advanced computational algorithms from the domain of machine learning has shown promise for application in the clinical environment to (1) assist clinicians with tedious daily tasks and allow them to focus more on complex or urgent patient management, (2) offer second reads or opinions on tasks that require specialized training, as well as (3) assist in the training and education of new clinical experts. This chapter offers an overview of the state-of-the-art deep learning applications in the field of brain and breast cancer, as well as challenges and potential methods to improve the reproducibility of deep learning algorithms in biomedical image analysis of brain and breast cancer patients. The included references should not be considered as an exhaustive literature review but as studies serving as examples for the points made in this chapter. © 2023 Elsevier Inc. All rights reserved.","brain cancer; breast cancer; convolutional neural networks; Deep learning","","","","","","","","Niclou S.P., Gauging Heterogeneity in Primary Versus Recurrent Glioblastoma, (2015); O'Connor J.P., Rose C.J., Waterton J.C., Carano R.A., Parker G.J., Jackson A., Imaging intratumor heterogeneity: role in therapy response, resistance, and clinical outcome, Clin. Cancer Res., 21, 2, pp. 249-257, (2015); Fisher R., Pusztai L., Swanton C., Cancer heterogeneity: implications for targeted therapeutics, Br. J. Cancer, 108, 3, pp. 479-485, (2013); Zardavas D., Irrthum A., Swanton C., Piccart M., Clinical management of breast cancer heterogeneity, Nat. Rev. Clin. Oncol., 12, 7, (2015); Dagogo-Jack I., Shaw A.T., Tumour heterogeneity and resistance to cancer therapies, Nat. Rev. Clin. Oncol., 15, 2, (2018); McGranahan N., Swanton C., Biological and therapeutic impact of intratumor heterogeneity in cancer evolution, Cancer Cell, 27, 1, pp. 15-26, (2015); Therasse P., Arbuck S.G., Eisenhauer E.A., Wanders J., Kaplan R.S., Rubinstein L., Et al., New guidelines to evaluate the response to treatment in solid tumors, J. Natl Cancer Inst., 92, 3, pp. 205-216, (2000); Wen P.Y., Macdonald D.R., Reardon D.A., Cloughesy T.F., Sorensen A.G., Galanis E., Et al., Updated response assessment criteria for high-grade gliomas: response assessment in neuro-oncology working group, J. Clin. Oncol., 28, 11, pp. 1963-1972, (2010); Macdonald D.R., Cascino T.L., Schold S.C., Cairncross J.G., Response criteria for phase II studies of supratentorial malignant glioma, J. Clin. Oncol., 8, 7, pp. 1277-1280, (1990); Vos M., Uitdehaag B., Barkhof F., Heimans J., Baayen H., Boogerd W., Et al., Interobserver variability in the radiological assessment of response to chemotherapy in glioma, Neurology., 60, 5, pp. 826-830, (2003); Burnside E.S., Sickles E.A., Bassett L.W., Rubin D.L., Lee C.H., Ikeda D.M., Et al., The ACR BI-RADS® experience: learning from history, J. Am. Coll. Radiol., 6, 12, pp. 851-860, (2009); Bomers J.G., Barentsz J.O., Standardization of multiparametric prostate MR imaging using PI-RADS, BioMed. Res. Int., 2014, (2014); Kazerooni E.A., Armstrong M.R., Amorosa J.K., Hernandez D., Liebscher L.A., Nath H., Et al., ACR CT accreditation program and the lung cancer screening program designation, J. Am. Coll. Radiol., 12, 1, pp. 38-42, (2015); Zwanenburg A., Vallieres M., Abdalah M.A., Aerts H.J., Andrearczyk V., Apte A., Et al., The Image Biomarker Standardization Initiative: standardized quantitative radiomics for high-throughput image-based phenotyping, Radiology., (2020); Jaffe Imaging and Genomics: Is There a Synergy?:, (2012); Carol Proud M., Radiogenomics: the promise of personalized treatment in radiation oncology?, Clin. J. Oncol. Nurs., 18, 2, (2014); Rosenstein B.S., West C.M., Bentzen S.M., Alsner J., Andreassen C.N., Azria D., Et al., Radiogenomics: radiobiology enters the era of big data and team science, Int. J. Radiat. Oncol. Biol. Phys., 89, 4, pp. 709-713, (2014); Rutman A.M., Kuo M.D., Radiogenomics: creating a link between molecular diagnostics and diagnostic imaging, Eur. J. Radiol., 70, 2, pp. 232-241, (2009); Aerts H.J., The potential of radiomic-based phenotyping in precision medicine: a review, JAMA Oncol., 2, 12, pp. 1636-1642, (2016); Mazurowski M.A., Zhang J., Grimm L.J., Yoon S.C., Silber J.I., Radiogenomic analysis of breast cancer: luminal B molecular subtype is associated with enhancement dynamics at MR imaging, Radiology., 273, 2, pp. 365-372, (2014); Gill B.J., Pisapia D.J., Malone H.R., Goldstein H., Lei L., Sonabend A., Et al., MRI-localized biopsies reveal subtype-specific differences in molecular and cellular composition at the margins of glioblastoma, Proc. Natl. Acad. Sci., 111, 34, pp. 12550-12555, (2014); Li H., Zhu Y., Burnside E.S., Drukker K., Hoadley K.A., Fan C., Et al., MR imaging radiomics signatures for predicting the risk of breast cancer recurrence as given by research versions of MammaPrint, Oncotype DX, and PAM50 gene assays, Radiology., 281, 2, pp. 382-391, (2016); Kamnitsas K., Ledig C., Newcombe V.F., Simpson J.P., Kane A.D., Menon D.K., Et al., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation, Med. Image Anal., 36, pp. 61-78, (2017); Rao V., Sarabi M.S., Jaiswal A., Brain tumor segmentation with deep learning, Multimodal Brain Tumor Segmentation Challenge (BraTS), pp. 56-59, (2015); McCulloch W.S., Pitts W., A logical calculus of the ideas immanent in nervous activity, Bull. Math. Biophys, 5, 4, pp. 115-133, (1943); Kullback S., Leibler R.A., On information and sufficiency, Ann. Math. Stat., 22, 1, pp. 79-86, (1951); Havaei M., Davy A., Warde-Farley D., Biard A., Courville A., Bengio Y., Et al., Brain tumor segmentation with deep neural networks, Med. Image Anal., 35, pp. 18-31, (2017); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, (2015); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs, IEEE Trans. Pattern Anal. Mach. Intell., 40, 4, pp. 834-848, (2017); Liu Z., Li X., Luo P., Loy C.-C., Semantic image segmentation via deep parsing network, in: Proceedings of the IEEE International Conference on Computer Vision, (2015); Zhang S., Et al., Microstructure and electromechanical properties of carbon nanotube/poly (vinylidene fluoride—trifluoroethylene—chlorofluoroethylene) composites, physica status solidi (RRL)-Rapid Research Letters., 17, 15, (2005); Shaver M.M., Kohanteb P.A., Chiou C., Bardis M.D., Chantaduly C., Bota D., Et al., Optimizing neuro-oncology imaging: a review of deep learning approaches for glioma imaging, Cancers., 11, 6, (2019); Ge C., Gu I.Y., Jakola A.S., Yang J., Deep learning and multi-sensor fusion for glioma classification using multistream 2D convolutional networks, Conference Proceedings: Annual International Conference of the IEEE Engineering in Medicine and Biology Society IEEE Engineering in Medicine and Biology Society Annual Conference., pp. 5894-5897, (2018); Khawaldeh S., Pervaiz U., Rafiq A., Alkhawaldeh R.S., Noninvasive grading of glioma tumor using magnetic resonance imaging with convolutional neural networks, Appl. Sci., 8, 1, (2018); Sajjad M., Khan S., Muhammad K., Wu W., Ullah A., Baik S.W., Multi-grade brain tumor classification using deep CNN with extensive data augmentation, J. Comput. Sci., 30, pp. 174-182, (2019); Ozyurt F., Sert E., Avci E., Dogantekin E., Brain tumor detection based on convolutional neural network with neutrosophic expert maximum fuzzy sure entropy, Measurement, 147, (2019); Alqudah A.M., Alquraan H., Qasmieh I.A., Alqudah A., Al-Sharu W., Brain tumor classification using deep learning technique—a comparison between cropped, uncropped, and segmented lesion images with different sizes, Int. J. Adv. Trends Comp. Sci. Eng., 86, pp. 3684-3691, (2019); Macyszyn L., Akbari H., Pisapia J.M., Da X., Attiah M., Pigrish V., Et al., Imaging patterns predict patient survival and molecular subtype in glioblastoma via machine learning techniques, Neuro-oncology, 18, 3, pp. 417-425, (2015); Babcock S., Beverley J., Cowell L., Smith B., The infectious disease ontology in the age of COVID-19, (2020); Bakas S., Shukla G., Akbari H., Erus G., Sotiras A., Rathore S., Et al., Integrative radiomic analysis for pre-surgical prognostic stratification of glioblastoma patients: from advanced to basic MRI protocols, Medical Imaging 2020: Image-Guided Procedures, Robotic Interventions, (2020); Lao J., Chen Y., Li Z.C., Li Q., Zhang J., Liu J., Et al., A deep learning-based radiomics model for prediction of survival in glioblastoma multiforme, Sci. Rep., 7, 1, (2017); Hao J., Kim Y., Mallavarapu T., Oh J.H., Kang M., Interpretable deep neural network for cancer survival analysis by integrating genomic and clinical data, BMC Med. Genomics, 12, 10, (2019); Shukla G., Bakas S., Rathore S., Akbari H., Sotiras A., Davatzikos C., Radiomic features from multi-institutional glioblastoma MRI offer additive prognostic value to clinical and genomic markers: focus on TCGA-GBM collection, Int. J. Radiat. Oncol. Biol. Phys., 99, 2, pp. E107-E108, (2017); Nie D., Lu J., Zhang H., Adeli E., Wang J., Yu Z., Et al., Multi-channel 3D deep feature learning for survival time prediction of brain tumor patients using multi-modal neuroimages, Sci. Rep., 9, 1, (2019); Han W., Qin L., Bay C., Chen X., Yu K.-H., Miskin N., Et al., Deep transfer learning and radiomics feature prediction of survival of patients with high-grade gliomas, Am. J. Neuroradiol., (2019); Fathi Kazerooni A., Bakas S., Saligheh Rad H., Davatzikos C., Imaging signatures of glioblastoma molecular characteristics: a radiogenomics review, J. Magn. Reson. Imaging, (2019); Akkus Z., Ali I., Sedlar J., Agrawal J.P., Parney I.F., Giannini C., Et al., Predicting Deletion of Chromosomal Arms 1p/19q in Low-Grade Gliomas from MR Images Using Machine Intelligence, J. Digital Imaging, 30, 4, pp. 469-476, (2017); Li Z., Wang Y., Yu J., Guo Y., Cao W., Deep Learning based Radiomics (DLR) and its usage in noninvasive IDH1 prediction for low grade glioma, Sci. Rep., 7, 1, (2017); Liang S., Zhang R., Liang D., Song T., Ai T., Xia C., Et al., Multimodal 3D DenseNet for IDH genotype prediction in gliomas, Genes, 9, 8, (2018); Menze B.H., Jakab A., Bauer S., Kalpathy-Cramer J., Farahani K., Kirby J., Et al., The multimodal brain tumor image segmentation benchmark (BRATS), IEEE Trans. Med. Imaging, 34, 10, pp. 1993-2024, (2014); Bakas S., Akbari H., Sotiras A., Bilello M., Rozycki M., Kirby J., Et al., Segmentation labels and radiomic features for the pre-operative scans of the TCGA-LGG collection, Cancer Imaging Archive, (2017); Bakas S., Akbari H., Sotiras A., Bilello M., Rozycki M., Kirby J., Et al., Segmentation labels and radiomic features for the pre-operative scans of the TCGA-GBM collection, Cancer Imaging Archive, (2017); Bakas S., Akbari H., Sotiras A., Bilello M., Rozycki M., Kirby J.S., Et al., Advancing the cancer genome atlas glioma MRI collections with expert segmentation labels and radiomic features, Sci. Data, 4, (2017); Chang K., Bai H.X., Zhou H., Su C., Bi W.L., Agbodza E., Et al., Residual convolutional neural network for the determination of idh status in low- and high-grade gliomas from MR imaging, Clin. Cancer Res., 24, 5, pp. 1073-1081, (2018); Hegi M.E., Diserens A.C., Gorlia T., Hamou M.F., de Tribolet N., Weller M., Et al., MGMT gene silencing and benefit from temozolomide in glioblastoma, N. Engl. J. Med., 352, 10, pp. 997-1003, (2005); Korfiatis P., Kline T.L., Lachance D.H., Parney I.F., Buckner J.C., Erickson B.J., Residual deep convolutional neural network predicts MGMT methylation status, J. Digital Imaging, 30, 5, pp. 622-628, (2017); Chang P., Grinband J., Weinberg B.D., Bardis M., Khy M., Cadena G., Et al., Deep-learning convolutional neural networks accurately classify genetic mutations in gliomas, AJNR Am. J. Neuroradiol., 39, 7, pp. 1201-1207, (2018); Jang B.S., Jeon S.H., Kim I.H., Kim I.A., Prediction of pseudoprogression versus progression using machine learning algorithm in glioblastoma, Sci. Rep., 8, 1, (2018); Akbari H., Rathore S., Bakas S., Nasrallah M.P., Shukla G., Mamourian E., Et al., Histopathology-validated machine learning radiographic biomarker for noninvasive discrimination between true progression and pseudo-progression in glioblastoma, Cancer, (2020); McCormack V.A., dos Santos Silva I., Breast density and parenchymal patterns as markers of breast cancer risk: a meta-analysis, Cancer Epidemiol. Biomarkers Prev., 15, 6, pp. 1159-1169, (2006); Lehman C.D., Yala A., Schuster T., Dontchos B., Bahl M., Swanson K., Et al., Mammographic breast density assessment using deep learning: clinical implementation, Radiology, 290, 1, pp. 52-58, (2018); Dontchos B.N., Yala A., Barzilay R., Xiang J., Lehman C.D., External validation of a deep learning model for predicting mammographic breast density in routine clinical practice, Acad. Radiol., (2020); Mohamed A.A., Berg W.A., Peng H., Luo Y., Jankowitz R.C., Wu S., A deep learning method for classifying mammographic breast density categories, Med. Phys., 45, 1, pp. 314-321, (2018); Kallenberg M., Petersen K., Nielsen M., Ng A., Diao P., Igel C., Et al., Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring, IEEE Trans. Med. Imaging, 35, 5, pp. 1322-1331, (2016); Wu N., Geras K.J., Shen Y., Su J., Kim S.G., Kim E., Breast density classification with deep convolutional neural networks, in: 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), (2018); Yala A., Lehman C., Schuster T., Portnoi T., Barzilay R., A deep learning mammography-based model for improved breast cancer risk prediction, Radiology., (2019); Gastounioti A., Oustimov A., Hsieh M.-K., Pantalone L., Conant E.F., Kontos D., Using convolutional neural networks for enhanced capture of breast parenchymal complexity patterns associated with breast cancer risk, Acad. Radiol., (2018); Dembrower K., Liu Y., Azizpour H., Eklund M., Smith K., Lindholm P., Et al., Comparison of a deep learning risk score and standard mammographic density score for breast cancer risk prediction, Radiology., (2019); McKinney S.M., Sieniek M., Godbole V., Godwin J., Antropova N., Ashrafian H., Et al., International evaluation of an AI system for breast cancer screening, Nature., 577, 7788, pp. 89-94, (2020); Rodriguez-Ruiz A., Krupinski E., Mordang J.-J., Schilling K., Heywang-Kobrunner S.H., Sechopoulos I., Et al., Detection of breast cancer with mammography: effect of an artificial intelligence support system, Radiology., 290, 2, pp. 305-314, (2018); Kim H.-E., Kim H.H., Han B.-K., Kim K.H., Han K., Nam H., Et al., Changes in cancer detection and false-positive recall in mammography using artificial intelligence: a retrospective, multireader study, Lancet Digital Health, 2, 3, pp. e138-e148, (2020); Kyono T., Gilbert F.J., van der Schaar M., Improving workflow efficiency for mammography using machine learning, J. Am. Coll. Radiol., (2019); Rodriguez-Ruiz A., Lang K., Gubern-Merida A., Teuwen J., Broeders M., Gennaro G., Et al., Can we reduce the workload of mammographic screening by automatic identification of normal exams with artificial intelligence? A feasibility study, Eur. Radiol., pp. 1-8, (2019); Conant E.F., Toledano A.Y., Periaswamy S., Fotin S.V., Go J., Boatsman J.E., Et al., Improving accuracy and efficiency with concurrent use of artificial intelligence for digital breast tomosynthesis, Radiol. Artif. Intell., 1, 4, (2019); Oustimov A., Gastounioti A., Hsieh M.-K., Pantalone L., Conant E.F., Kontos D., Convolutional neural network approach for enhanced capture of breast parenchymal complexity patterns associated with breast cancer risk, SPIE Medical Imaging, (2017); D'Orsi C.J., ACR BI-RADS Atlas: Breast Imaging Reporting and Data System, (2013); Sprague B.L., Conant E.F., Onega T., Garcia M.P., Beaber E.F., Herschorn S.D., Et al., Variation in mammographic breast density assessments among radiologists in clinical practice: a multicenter observational study, Ann. Intern. Med., 165, 7, pp. 457-464, (2016); Rieke N., Hancox J., Li W., Milletari F., Roth H., Albarqouni S., Et al., The future of digital health with federated learning., (2020); Sheller M.J., Reina G.A., Edwards B., Martin J., Bakas S., Multi-institutional deep learning modeling without sharing patient data: A feasibility study on brain tumor segmentation, International MICCAI Brainlesion Workshop, (2018); Chang K., Balachandar N., Lam C., Yi D., Brown J., Beers A., Et al., Distributed deep learning networks among institutions for medical imaging, J. Am. Med. Inform. Assoc., 25, 8, pp. 945-954, (2018)","","","Elsevier","","","","","","","978-012819872-8; 978-012819912-1","","","English","State of the Art in Neural Networks and their Applications: Volume 2","Book chapter","Final","","Scopus","2-s2.0-85150132641"
"Pan Y.","Pan, Yangyi (57830222900)","57830222900","Influence of different image preprocessing methods on bone age prediction","2022","2022 3rd International Conference on Computer Vision, Image and Deep Learning and International Conference on Computer Engineering and Applications, CVIDL and ICCEA 2022","","","","632","636","4","0","10.1109/CVIDLICCEA56201.2022.9825218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135397871&doi=10.1109%2fCVIDLICCEA56201.2022.9825218&partnerID=40&md5=2e79d59ceaae582d689b0d5e84b4c727","Hohai University, China","Pan Y., Hohai University, China","In medical image recognition represented by bone age prediction, image samples need to be preprocessed to improve the quality of image samples and improve the learning efficiency of deep learning. This paper aims to compare the effects of different image preprocessing methods on the performance of the neural network. In this paper, the method of control experiment is used. Without pretreatment, the structure and framework of the neural network are controlled to remain unchanged, to make the conclusion more objective. This paper mainly discusses three pretreatment methods. 1 Conventional image filtering; 2. Use u-net network specially used for biomedical image segmentation to segment hand bones in X-ray; 3. The control group did not undergo image preprocessing. At the same time, this paper proposes to mark the gender of the owner of hand bone X-ray film in the form of a white background mark on the original image and control the gender weight by adjusting the size of the mark. U-net network preprocessing does not significantly improve the accuracy of the neural network, but this method makes the effect of deep neural network and shallow neural network almost the same, so it can be used as an effective method to prevent overfitting of neural networks. The main innovation of this paper is to explore the effectiveness of preprocessing algorithms in preventing the overfitting of medical image models by comparing the bone age prediction under various preprocessing methods. © 2022 IEEE.","bone age prediction; deep learning; grayscale histogram equalization; network lightweight; over-fitting; preprocessing; U-Net network","Equalizers; Forecasting; Image enhancement; Image recognition; Image segmentation; Medical imaging; X ray films; Age predictions; Bone age; Bone age prediction; Deep learning; Gray scale; Grayscale histogram equalization; Histogram equalizations; Net networks; Network lightweight; Overfitting; Preprocessing; U-net network; Deep neural networks","","","","","","","Ye S., Jing L., Yinlin X., Study on image preprocessing in bone age prediction of hand X-ray films [J], Journal of Nanjing Normal University (Engineering Technology Edition), 21, 2, pp. 54-59, (2021); Yang J., Weiguang C., Haijuan W., Hanrong D., Jungang H., Xiaohui J., Bin Y., Research progress of image-based automatic bone age evaluation algorithm and its application [J], Journal of xi'An University of Posts and Telecommunications, 26, 4, pp. 65-78, (2021); Jun G., Auxiliary evaluation technology of bone age based on convolutional neural network [J], Science and Technology Innovation, 4, pp. 53-55, (2021); Jiaqing W., Liye M., Junhua Z., Bone age evaluation of hand bone X-ray image based on deep learning [J], Computer Engineering, 47, 1, pp. 291-297, (2021); Zhihao T., Lijun L., Xupeng F., Huang Qingsong Residual network bone age assessment combined with efficient channel attention module [J], Photoelectron-Laser, 32, 3, pp. 331-338, (2021); Yan W., Aihua H., Dawei W., Yun S., Peng Yun Clinical application of artificial intelligence bone age evaluation system based on deep learning [J], China Medical Imaging Technology, 37, 1, pp. 104-107, (2021); Eng D.K., Khandwala N.B., Long J., Fefferman N.R., Lala S.V., Strubel N.A., Chen Yong Artificial intelligence algorithm improves radiologists' performance in bone age assessment: A prospective multicenter randomized controlled trial [J], International Journal of Medical Radiology, 45, 1, (2022); Weilong D., Tao L., Xiao D., Gu Y., Mao Keji Maturity level recognition of wrist bone image based on improved alexnet [J], Journal of Zhejiang University of Technology, 49, 6, pp. 614-622, (2021); Guangqian J., Hong L., Research progress of traditional methods, emerging methods and artificial intelligence methods in evaluating bone age [J], Chinese Journal of Interventional Imaging and Therapeutics, 16, 6, pp. 376-379, (2019)","Y. Pan; Hohai University, China; email: 1286299587@qq.com","","Institute of Electrical and Electronics Engineers Inc.","","3rd International Conference on Computer Vision, Image and Deep Learning and International Conference on Computer Engineering and Applications, CVIDL and ICCEA 2022","20 May 2022 through 22 May 2022","Virtual, Changchun","181070","","978-166545911-2","","","English","Int. Conf. Comput. Vis., Image Deep Learn. Int. Conf. Comput. Eng. Appl., CVIDL ICCEA","Conference paper","Final","","Scopus","2-s2.0-85135397871"
"Durkee M.S.; Abraham R.; Clark M.R.; Giger M.L.","Durkee, Madeleine S. (56677655800); Abraham, Rebecca (57215870962); Clark, Marcus R. (56664601700); Giger, Maryellen L. (7103040897)","56677655800; 57215870962; 56664601700; 7103040897","Artificial Intelligence and Cellular Segmentation in Tissue Microscopy Images","2021","American Journal of Pathology","191","10","","1693","1701","8","33","10.1016/j.ajpath.2021.05.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115163423&doi=10.1016%2fj.ajpath.2021.05.022&partnerID=40&md5=133006568dbba9637ee8804579e5d488","Department of Radiology and the Committee on Medical Physics, University of Chicago, Chicago, IL, United States; Department of Medicine, Section of Rheumatology and Gwen Knapp Center for Lupus and Immunology Research, University of Chicago, Chicago, IL, United States","Durkee M.S., Department of Radiology and the Committee on Medical Physics, University of Chicago, Chicago, IL, United States; Abraham R., Department of Medicine, Section of Rheumatology and Gwen Knapp Center for Lupus and Immunology Research, University of Chicago, Chicago, IL, United States; Clark M.R., Department of Medicine, Section of Rheumatology and Gwen Knapp Center for Lupus and Immunology Research, University of Chicago, Chicago, IL, United States; Giger M.L., Department of Radiology and the Committee on Medical Physics, University of Chicago, Chicago, IL, United States","With applications in object detection, image feature extraction, image classification, and image segmentation, artificial intelligence is facilitating high-throughput analysis of image data in a variety of biomedical imaging disciplines, ranging from radiology and pathology to cancer biology and immunology. Specifically, a growth in research on deep learning has led to the widespread application of computer-visualization techniques for analyzing and mining data from biomedical images. The availability of open-source software packages and the development of novel, trainable deep neural network architectures has led to increased accuracy in cell detection and segmentation algorithms. By automating cell segmentation, it is now possible to mine quantifiable cellular and spatio-cellular features from microscopy images, providing insight into the organization of cells in various pathologies. This mini-review provides an overview of the current state of the art in deep learning– and artificial intelligence–based methods of segmentation and data mining of cells in microscopy images of tissue. © 2021 American Society for Investigative Pathology","","Animals; Artificial Intelligence; Cells; Deep Learning; Humans; Image Processing, Computer-Assisted; Microscopy; Organ Specificity; artificial intelligence; artificial neural network; data mining; deep learning; deep neural network; generative adversarial network; high throughput analysis; human; image analysis; image processing; image quality; image segmentation; immunofluorescence; immunohistochemistry; microscopy; Review; selection bias; signal noise ratio; animal; antibody specificity; cells; cytology","","","CellProfiler; Ilastik; ImageJ, National Institute of Health, United States; QuPath","National Institute of Health, United States","Median Technologies; Mitsubishi; Riverain Technologies LLC; National Institutes of Health, NIH, (U19 AI082724); U.S. Department of Defense, DOD, (LR180083); National Institute of Allergy and Infectious Diseases, NIAID; National Institute of Arthritis and Musculoskeletal and Skin Diseases, NIAMS, (R01AR055646); University of Chicago; Medical Research Council, MRC, (R01 AI148705, R01 AR055646, U01 CA195564)","Funding text 1: Supported by National Institute of Allergy and Infectious Diseases ( NIH ) grants U19 AI082724 (M.R.C.) , R01 AR055646 (M.R.C.) , R01 AI148705 (M.R.C.) , and U01 CA195564 (M.L.G.) ; and US Department of Defense grant LR180083 (M.R.C.) . The content is the responsibility of the authors and does not necessarily represent the official views of the NIH. ; Funding text 2: Supported by National Institute of Allergy and Infectious Diseases (NIH) grants U19 AI082724 (M.R.C.), R01 AR055646 (M.R.C.), R01 AI148705 (M.R.C.), and U01 CA195564 (M.L.G.); and US Department of Defense grant LR180083 (M.R.C.). The content is the responsibility of the authors and does not necessarily represent the official views of the NIH. Disclosures: Maryellen L. Giger holds stock options in and receives royalties from Hologic, Inc.; holds equity in and is a co-founder of Quantitative Insights, Inc. (now, Qlarity Imaging); holds stock options in QView Medical, Inc.; and receives royalties from General Electric Company, Median Technologies, Riverain Technologies LLC, Mitsubishi, and Toshiba. It is the University of Chicago's conflict of interest policy that investigators disclose publicly actual or potential significant financial interests that would reasonably appear to be directly and significantly affected by the research activities.","Bansal G.J., Digital radiography. A comparison with modern conventional imaging, Postgrad Med J, 82, pp. 425-428, (2006); Giger M.L., Chan H.P., Boone J., Anniversary paper: history and status of CAD and quantitative image analysis: the role of medical physics and AAPM, Med Phys, 35, pp. 5799-5820, (2008); Wang H., Shang S., Long L., Hu R., Wu Y., Chen N., Zhang S., Cong F., Lin S., Biological image analysis using deep learning-based methods: literature review, Digit Med, 4, pp. 157-165, (2018); Gurcan M.N., Boucheron L.E., Can A., Madabhushi A., Rajpoot N.M., Yener B., Histopathological image analysis: a review, IEEE Rev Biomed Eng, 2, pp. 147-171, (2009); Xing F., Yang L., Robust nucleus/cell detection and segmentation in digital pathology and microscopy images: a comprehensive review, IEEE Rev Biomed Eng, 9, pp. 234-263, (2016); Bera K., Schalper K.A., Rimm D.L., Velcheti V., Madabhushi A., Artificial intelligence in digital pathology-new tools for diagnosis and precision oncology, Nat Rev Clin Oncol, 16, pp. 703-715, (2019); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, arXiv, (2014); Sahiner B., Pezeshk A., Hadjiiski L.M., Wang X., Drukker K., Cha K.H., Summers R.M., Giger M.L., Deep learning in medical imaging and radiation therapy, Med Phys, 46, pp. e1-e36, (2019); Tizhoosh H.R., Pantanowitz L., Artificial intelligence and digital pathology: challenges and opportunities, J Pathol Inform, 9, (2018); Cooper L.A.D., Carter A.B., Farris A.B., Wang F., Kong J., Gutman D.A., Widener P., Pan T.C., Cholleti S.R., Sharma A., TKurc T.M., Brat D.J., Saltz J.H., Digital pathology: data-intensive frontier in medical imaging, Proc IEEE Inst Electr Electron Eng, 100, pp. 991-1003, (2012); Radtke A.J., Kandov E., Lowekamp B., Speranza E., Chu C.J., Gola A., Thakur N., Shih R., Yao L., Yaniv Z.R., IBEX: a versatile multiplex optical imaging approach for deep phenotyping and spatial analysis of cells in complex tissues, Proc Natl Acad Sci U S A, 117, pp. 33455-33465, (2020); Tsujikawa T., Kumar S., Borkar R.N., Azimi V., Thibault G., Chang Y.H., Balter A., Kawashima R., Choe G., Sauer D., Quantitative multiplex immunohistochemistry reveals myeloid-inflamed tumor-immune complexity associated with poor prognosis, Cell Rep, 19, pp. 203-217, (2017); Goltsev Y., Samusik N., Kennedy-Darling J., Bhate S., Hale M., Vazquez G., Black S., Nolan G.P., Deep profiling of mouse splenic architecture with CODEX multiplexed imaging, Cell, 174, pp. 968-981.e15, (2018); Ronneberger O., Fischer P., Brox T., pp. 234-241; Yang L., Ghosh R.P., Franklin J.M., Chen S., You C., Narayan R.R., Melcher M.L., Liphardt J.T., NuSeT: a deep learning tool for reliably separating and analyzing crowded cells, PLoS Comput Biol, 16, (2020); Durkee M.S., Abraham R., Ai J., Veselits M., Clark M.R., Giger M.L., Quantifying the effects of biopsy fixation and staining panel design on automatic instance segmentation of immune cells in human lupus nephritis, J Biomed Opt, 26, pp. 1-17, (2021); de Bel T., Bokhorst J.-M., van der Laak J., Litjens G., Residual CycleGAN for robust domain transformation of histopathological tissue slides, Med Image Anal, 70, (2021); Keikhosravi A., Li B., Liu Y., Conklin M.W., Loeffler A.G., Eliceiri K.W., Non-disruptive collagen characterization in clinical histopathology using cross-modality image synthesis, Commun Biol, 3, (2020); Weigert M., Schmidt U., Boothe T., Muller A., Dibrov A., Jain A., Wilhelm B., Schmidt D., Broaddus C., Culley S., Rocha-Martins M., Segovia-Miranda F., Norden C., Henriques R., Zerial M., Solimena M., Rink J., Tomancak P., Royer L., Jug F., Myers E.W., Content-aware image restoration: pushing the limits of fluorescence microscopy, Nat Methods, 15, pp. 1090-1097, (2018); Falk T., Mai D., Bensch R., Cicek O., Abdulkadir A., Marrakchi Y., Bohm A., Deubner J., Jackel Z., Seiwald K., Dovzhenko A., Tietz O., Dal Bosco C., Walsh S., Saltukoglu D., Tay T.L., Prinz M., Palme K., Simons M., Diester I., Brox T., Ronneberger O., U-net: deep learning for cell counting, detection, and morphometry, Nat Methods, 16, pp. 67-70, (2019); Zhou Z., Rahman Siddiquee M.M., Tajbakhsh N., Liang J., UNet++: a nested U-net architecture for medical image segmentation, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pp. 3-11, (2018); Brennan D.J., Rexhepaj E., O'Brien S.L., McSherry E., O'Connor D.P., Fagan A., Culhane A.C., Higgins D.G., Jirstrom K., Millikan R.C., Altered cytoplasmic-to-nuclear ratio of survivin is a prognostic indicator in breast cancer, Clin Cancer Res, 14, pp. 2681-2689, (2008); Ren S., He K., Girshick R., Sun J., Faster R-CNN: towards real-time object detection with region proposal networks, IEEE, 39, pp. 1137-1149, (2017); He K., Gkioxari G., Dollar P., Girshick R., Mask R-CNN, pp. 2961-2969, (2017); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, pp. 2980-2988, (2017); Rodemerk J., Junker A., Chen B., Pierscianek D., Dammann P., Darkwah Oppong M., Radbruch A., Forsting M., Maderwald S., Quick H.H., Pathophysiology of intracranial aneurysms: Cox-2 expression, iron deposition in aneurysm wall, and correlation with magnetic resonance imaging, Stroke, 51, pp. 2505-2513, (2020); Rivenson Y., Wang H., Wei Z., de Haan K., Zhang Y., Wu Y., Gunaydin H., Zuckerman J.E., Chong T., Sisk A.E., Virtual histological staining of unlabelled tissue-autofluorescence images via deep learning, Nat Biomed Eng, 3, pp. 466-477, (2019); Carpenter A.E., Jones T.R., Lamprecht M.R., Clarke C., Kang I.H., Friman O., Guertin D.A., Chang J.H., Lindquist R.A., Moffat J., CellProfiler: image analysis software for identifying and quantifying cell phenotypes, Genome Biol, 7, pp. 1-11, (2006); McQuin C., Goodman A., Chernyshev V., Kamentsky L., Cimini B.A., Karhohs K.W., Doan M., Ding L., Rafelski S.M., Thirstrup D., CellProfiler 3.0: next-generation image processing for biology, PLoS Biol, 16, (2018); Sadanandan S.K., Ranefall P., Le Guyader S., Wahlby C., Automated training of deep convolutional neural networks for cell segmentation, Sci Rep, 7, pp. 1-7, (2017); Berg S., Kutra D., Kroeger T., Straehle C.N., Kausler B.X., Haubold C., Schiegg M., Ales J., Beier T., Rudy M., Ilastik: interactive machine learning for (bio) image analysis, Nat Methods, 16, pp. 1226-1232, (2019); McMahon N.P., Jones J.A., Kwon S., Chin K., Nederlof M.A., Gray J.W., Gibbs S.L., Oligonucleotide conjugated antibodies permit highly multiplexed immunofluorescence for future use in clinical histopathology, J Biomed Opt, 25, pp. 1-18, (2020); Rashid R., Gaglia G., Chen Y.-A., Lin J.-R., Du Z., Maliga Z., Schapiro D., Yapp C., Muhlich J., Sokolov A., Highly multiplexed immunofluorescence images and single-cell data of immune markers in tonsil and lung cancer, Sci Data, 6, pp. 1-10, (2019); Wills J.W., Robertson J., Summers H.D., Miniter M., Barnes C., Hewitt R.E., Keita A.V., Soderholm J.D., Rees P., Powell J.J., Image-based cell profiling enables quantitative tissue microscopy in gastroenterology, Cytometry A, 97, pp. 1222-1237, (2020); Schurch C.M., Bhate S.S., Barlow G.L., Phillips D.J., Noti L., Zlobec I., Chu P., Black S., Demeter J., McIlwain D.R., Coordinated cellular neighborhoods orchestrate antitumoral immunity at the colorectal cancer invasive front, Cell, 182, pp. 1341-1359, (2020); Bankhead P., Loughrey M.B., Fernandez J.A., Dombrowski Y., McArt D.G., Dunne P.D., McQuaid S., Gray R.T., Murray L.J., Coleman H.G., QuPath: open source software for digital pathology image analysis, Sci Rep, 7, pp. 1-7, (2017); Selvaraju R.R., Cogswell M., Das A., Vedantam R., Parikh D., Batra D., Grad-cam: visual explanations from deep networks via gradient-based localization, pp. 618-626, (2017); Faust K., Bala S., van Ommeren R., Portante A., Al Qawahmed R., Djuric U., Diamandis P., Intelligent feature engineering and ontological mapping of brain tumour histomorphologies by deep learning, Nat Mach Intell, 1, pp. 316-321, (2019); Diao J.A., Chui W.F., Wang J.K., Mitchell R.N., Rao S.K., Resnick M.B., Lahiri A., Maheshwari C., Glass B., Mountain V., Kerner J.K., Montalto M.C., Khosla A., Wapinski I.N., Beck A.H., Taylor-Weiner A., Elliott H.L., Dense, high-resolution mapping of cells and tissues from pathology images for the interpretable prediction of molecular phenotypes in cancer, bioRxiv, (2020); Nearchou I.P., Gwyther B.M., Georgiakakis E.C.T., Gavriel C.G., Lillard K., Kajiwara Y., Ueno H., Harrison D.J., Caie P.D., Spatial immune profiling of the colorectal tumor microenvironment predicts good outcome in stage II patients, NPJ Digit Med, 3, pp. 1-10, (2020); Lazarus J., Maj T., Smith J.J., Lanfranca M.P., Rao A., D'Angelica M.I., Delrosario L., Girgis A., Schukow C., Shia J., Spatial and phenotypic immune profiling of metastatic colon cancer, JCI Insight, 3, (2018); Wang H., Jiang Y., Li B., Cui Y., Li D., Li R., Single-cell spatial analysis of tumor and immune microenvironment on whole-slide image reveals hepatocellular carcinoma subtypes, Cancers, 12, (2020); Niethammer M., Borland D., Marron J.S., Woosley J., Thomas N.E., Appearance normalization of histology slides, Mach Learn Med Imaging, 6357, pp. 58-66, (2010); Bancroft J.D., Gamble M., Theory and Practice of Histological Techniques, (2008); Hoppin J.A., Tolbert P.E., Taylor J.A., Schroeder J.C., Holly E.A., Potential for selection bias with tumor tissue retrieval in molecular epidemiology studies, Ann Epidemiol, 12, pp. 1-6, (2002); Jiang H., Nachum O., Identifying and correcting label bias in machine learning, Proc Mach Learn Res, 108, pp. 702-712, (2020); Weinstein R.S., Graham A.R., Richter L.C., Barker G.P., Krupinski E.A., Lopez A.M., Erps K.A., Bhattacharyya A.K., Yagi Y., Gilbertson J.R., Overview of telepathology, virtual microscopy, and whole slide imaging: prospects for the future, Hum Pathol, 40, pp. 1057-1069, (2009); Rashidi H.H., Tran N.K., Betts E.V., Howell L.P., Green R., Artificial intelligence and machine learning in pathology: the present landscape of supervised methods, Acad Pathol, 6, (2019); Chen T., Kornblith S., Norouzi M., Hinton G., A simple framework for contrastive learning of visual representations, Proc Mach Learn Res, 119, pp. 1597-1607, (2020)","M.S. Durkee; Department of Radiology, University of Chicago, 5841 S. Maryland Ave, Chicago, IL, 60637, Department of Radiology, University of Chicago, Chicago, 5841 S. Maryland Ave., MC2026, 60637, United States; email: durkeems@uchicago.edu","","Elsevier Inc.","","","","","","00029440","","AJPAA","34129842","English","Am. J. Pathol.","Review","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85115163423"
"Schouten J.P.E.; Matek C.; Jacobs L.F.P.; Buck M.C.; Bošnački D.; Marr C.","Schouten, Jens P. E. (57222963224); Matek, Christian (55368586300); Jacobs, Luuk F. P. (57222959002); Buck, Michèle C. (57222016114); Bošnački, Dragan (6602212448); Marr, Carsten (10539477500)","57222963224; 55368586300; 57222959002; 57222016114; 6602212448; 10539477500","Tens of images can suffice to train neural networks for malignant leukocyte detection","2021","Scientific Reports","11","1","7995","","","","21","10.1038/s41598-021-86995-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104271125&doi=10.1038%2fs41598-021-86995-5&partnerID=40&md5=1e4d8774280e1317394d6c05afd480c8","Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Department of Internal Medicine III, University Hospital Munich, Ludwig-Maximilians-Universität München-Campus Großhadern, Munich, Germany; Department of Medicine III, Technische Universität München, Klinikum rechts der Isar, Munich, Germany","Schouten J.P.E., Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands, Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; Matek C., Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany, Department of Internal Medicine III, University Hospital Munich, Ludwig-Maximilians-Universität München-Campus Großhadern, Munich, Germany; Jacobs L.F.P., Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; Buck M.C., Department of Medicine III, Technische Universität München, Klinikum rechts der Isar, Munich, Germany; Bošnački D., Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; Marr C., Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany","Convolutional neural networks (CNNs) excel as powerful tools for biomedical image classification. It is commonly assumed that training CNNs requires large amounts of annotated data. This is a bottleneck in many medical applications where annotation relies on expert knowledge. Here, we analyze the binary classification performance of a CNN on two independent cytomorphology datasets as a function of training set size. Specifically, we train a sequential model to discriminate non-malignant leukocytes from blast cells, whose appearance in the peripheral blood is a hallmark of leukemia. We systematically vary training set size, finding that tens of training images suffice for a binary classification with an ROC-AUC over 90%. Saliency maps and layer-wise relevance propagation visualizations suggest that the network learns to increasingly focus on nuclear structures of leukocytes as the number of training images is increased. A low dimensional tSNE representation reveals that while the two classes are separated already for a few training images, the distinction between the classes becomes clearer when more training images are used. To evaluate the performance in a multi-class problem, we annotated single-cell images from a acute lymphoblastic leukemia dataset into six different hematopoietic classes. Multi-class prediction suggests that also here few single-cell images suffice if differences between morphological classes are large enough. The incorporation of deep learning algorithms into clinical practice has the potential to reduce variability and cost, democratize usage of expertise, and allow for early detection of disease onset and relapse. Our approach evaluates the performance of a deep learning based cytology classifier with respect to size and complexity of the training data and the classification task. © 2021, The Author(s).","","Databases as Topic; Humans; Image Processing, Computer-Assisted; Leukocytes; Lymphocytes; Neural Networks, Computer; data base; human; image processing; leukocyte; lymphocyte; pathology","","","","","Deutsche Jose Carreras-Leukämie Stiftung; German Science Foundation DFG, (SFB 1243); Horizon 2020 Framework Programme, H2020, (866411); European Research Council, ERC; Deutsche Forschungsgemeinschaft, DFG","We thank Natal van Riel and Katharina Goetze for supporting this study; Nikos Chlis for feedback on our CNN approach and Max Schmidt for feedback on the presentation; Labati et al. for providing the single-cell data. This work was supported by the German Science Foundation DFG within the Collaborative Research Center SFB 1243 “Cancer Evolution” with a research grant for MB. ChM gratefully acknowledges support from Deutsche Jose Carreras-Leukämie Stiftung. CM has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (Grant agreement No. 866411).","Terwilliger T., Abdul-Hay M., Acute lymphoblastic leukemia: A comprehensive review and 2017 update, Blood Cancer J., 7, (2017); Jabbour E., O'Brien S., Konopleva M., Kantarjian H., New insights into the pathophysiology and therapy of adult acute lymphoblastic leukemia, Cancer, 121, pp. 2517-2528, (2015); Hunger S.P., Mullighan C.G., Acute lymphoblastic leukemia in children, N. Engl. J. Med., 373, pp. 1541-1552, (2015); Kantarjian H., Et al., Blinatumomab versus chemotherapy for advanced acute lymphoblastic leukemia, N. Engl. J. Med., 376, pp. 836-847, (2017); Arber D.A., Et al., The 2016 revision to the World Health Organization classification of myeloid neoplasms and acute leukemia, Blood, 127, pp. 2391-2405, (2016); Fuchs T.J., Buhmann J.M., Computational pathology: Challenges and promises for tissue analysis, Comput. Med. Imaging Graph., 35, pp. 515-530, (2011); Esteva A., Et al., Dermatologist-level classification of skin cancer with deep neural networks, Nature, 542, pp. 115-118, (2017); Coudray N., Et al., Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning, Nat. Med., 24, pp. 1559-1567, (2018); Dey P., Lamba A., Kumari S., Marwaha N., Application of an artificial neural network in the prognosis of chronic myeloid leukemia, Anal. Quant. Cytol. Histol., 33, pp. 335-339, (2011); Matek C., Schwarz S., Spiekermann K., Marr C., Human-level recognition of blast cells in acute myeloid leukemia with convolutional neural networks, Nat. Mach. Intell., 1, pp. 538-544, (2019); Greenspan H., van Ginneken B., Summers R.M., Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique, IEEE Trans. Med. Imaging, 35, pp. 1153-1159, (2016); Willemink M.J., Et al., Preparing medical imaging data for machine learning, Radiology, 295, pp. 4-15, (2020); Shin H.-C., Et al., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning, IEEE Trans. Med. Imaging, 35, pp. 1285-1298, (2016); Cho J., Lee K., Shin E., Choy G., Do S., How Much Data is Needed to Train a Medical Image Deep Learning System to Achieve Necessary High Accuracy?, (2016); Labati R.D., Piuri V., Scotti F., All-IDB: The acute lymphoblastic leukemia image database for image processing, 2011 18Th IEEE International Conference on Image Processing, pp. 2045-2048, (2011); Chollet F., Deep Learning with Python, (2017); Matek C., Schwarz S., Spiekermann K., Marr C., Human-level recognition of blast cells in acute myeloid leukaemia with convolutional neural networks, Nat. Mach. Intell., 1, pp. 538-544, (2019); Simonyan K., Vedaldi A., Zisserman A., Deep inside convolutional networks: Visualising image classification models and saliency maps, ICLR., pp. 1-8, (2014); Kohlbrenner M., Et al., Towards best practice in explaining neural network decisions with LRP, 2020 Int. Joint Conf. Neural Netw. (IJCNN), (2020); van der Maaten L., Hinton G., Visualizing data using t-SNE, J. Mach. Learn. Res., 9, pp. 2579-2605, (2008); Matek C., Schwarz S., Marr C., Spiekermann K., A Single-cell Morphological Dataset of Leukocytes from AML Patients and Non-malignant Controls [Data set], The Cancer Imaging Archive., (2019); Krappe S., Wittenberg T., Haferlach T., Munzenmayer C., Automated morphological analysis of bone marrow cells in microscopic images for diagnosis of leukemia: Nucleus-plasma separation and cell classification using a hierarchical tree model of hematopoesis, Med. Imaging 2016 Comput. Aided Diagnosis, (2016); Basima C.T., Panicker J.R., Enhanced leucocyte classification for leukaemia detection, 2016 Int. Conf. Inf. Sci. (ICIS), (2016); Vogado L.H.S., Veras R.M.S., Araujo F.H.D., Silva R.R.V., Aires K.R.T., Leukemia diagnosis in blood slides using transfer learning in CNNs and SVM for classification, Eng. Appl. Artif. Intell., 72, pp. 415-422, (2018); Zhao J., Zhang M., Zhou Z., Chu J., Cao F., Automatic detection and classification of leukocytes using convolutional neural networks, Med. Biol. Eng. Comput., 55, pp. 1287-1301, (2017); Macawile M.J., Quinones V.V., Ballado A., Cruz J.D., Caya M.V., White blood cell classification and counting using convolutional neural network, 3Rd International Conference on Control and Robotics Engineering (ICCRE)., pp. 259-263, (2018); Kothari S., Et al., Removing batch effects from histopathological images for enhanced cancer diagnosis, IEEE J Biomed Health Inform, 18, pp. 765-772, (2014); Katharopoulos A., Fleuret F., Not all samples are created equal: Deep learning with importance sampling, International Conference on Machine Learning., pp. 2525-2534, (2018)","D. Bošnački; Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, Netherlands; email: D.Bosnacki@tue.nl; C. Marr; Institute of Computational Biology, Helmholtz Zentrum München-German Research Center for Environmental Health, Neuherberg, Germany; email: carsten.marr@helmholtz-muenchen.de","","Nature Research","","","","","","20452322","","","33846442","English","Sci. Rep.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85104271125"
"Behura A.","Behura, Aradhana (57216374591)","57216374591","Congruence of deep learning in biomedical engineering: Future prospects and challenges","2020","Handbook of Deep Learning in Biomedical Engineering: Techniques and Applications","","","","1","24","23","5","10.1016/B978-0-12-823014-5.00003-X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120533343&doi=10.1016%2fB978-0-12-823014-5.00003-X&partnerID=40&md5=cd6cccaedb7efa110557dcb904ca376b","Veer Surendra Sai University of Technology, Odisha, Burla, Sambalpur, India","Behura A., Veer Surendra Sai University of Technology, Odisha, Burla, Sambalpur, India","Deep learning models have opened up many prospects in medical images for achieving unprecedented performance, for example, classification of tissues and division or segmentation are a few medical outcomes. This chapter evaluates and describes the convolutional neural network (CNN) intended for characterization of tissue in clinical imaging, which is applied for segregating essential metastatic liver tumors from diffusion-weighted magnetic resonance imaging information. Advancement in the field of deep learning for normal pictures has provoked a surge of enthusiasm for applying comparative strategies to clinical images. Most of the initial attempts replaced the input of a deep CNN with medical images, which does not consider the basic contrasts between these two kinds of pictures. In particular, fine details are fundamental in clinical pictures, unlike regular images where coarse structures are very important. This distinction makes it difficult to utilize the current organized models created for common pictures, because they chip away at downscaled medical images to decrease the memory prerequisites. These subtleties are important to provide accurate detection. Furthermore, a medical test in clinical imaging regularly accompanies many perspectives, which must be intertwined to arrive at the right conclusion. A survey of deep learning is used for image classification, carotid ultrasound data investigations, cardiotocography, intravascular ultrasound reports, lung computed tomography reports, brain tumor prediction, coronavirus prediction (COVID-19) object detection, segmentation, breast cancer prediction, electrocardiogram signals, electroencephalograms, photoplethysmographic signal registration, psoriasis skin disease, as well as cancer detection. Concise summaries are delivered of trainings per application zone: pulmonary, musculoskeletal neuro, digital pathology, abdominal, retinal, breast, and cardiac. There are various types of deep learning techniques present to improve the accuracy of the medical dataset. Deep reinforcement learning, recursive neural network, multilayer perceptron, recurrent neural network, Boltzmann machine, and CNN are different types of deep learning techniques used to train the image and signal dataset. Generative adversarial network (GAN), autoencoder, and deep belief neural network are subcategories of unsupervised pretrained neural network. Some well-known architectural models of CNNs are ResNet (2015), VGGNet (2014), SqueezeNet (2016), GoogLeNet (2014), and ZFNet (2013) and are the visualization concept of the deconvolutional network; AlexNet (2012) and LeNet (Peng et al., 2009; Mitchell; Bengio, 2012; Dutkowski et al., 2015; Han et al., 2020 [16-20]) are basically used to train image datasets; the long short-term memory technique is used to train signalized datasets; and RHSBoost and genetically optimized neural network are used for efficient multiple classification of datasets. Dimensionality reduction, feature extraction, overfitting, underfitting, and normalization problems can be solved using various types of optimization algorithm. Image security is another important part, and by using an autoencoder, GAN network, and CNN we can prevent alteration in the medical image. Minor alteration of the medical image is very dangerous to patient life. By using deep learning and steganography, we can first compress as well as train the dataset, then security can be preserved after embedding of watermarks (which is a secret image visible to the human eye that cannot be altered; this steganography concept is called watermarking). © 2021 Elsevier Inc. All rights reserved.","Biomedical image and signal processing; Breast cancer; Deep learning; Image segmentation; Unsupervised feature learning","","","","","","","","Akolkar S., Secure Payment System Using Steganography and Visual Cryptography, (2016); Reddy R., The Process of Encoding and Decoding of Image Steganography Using LSB Algorithm, (2012); Baby D., Novel DWT Based Image Securing Method Using Steganography, (2014); Depart B., Steganography Methods and Some Application, (2009); Houssein H., An Image Steganography Algorithm Using HAAR Discrete Wavelet Transform with Advanced Encryption System, (2013); Wavelet Based Steganography Technique to Protect Household Confidential Information and Seal the Transmitted Smart Grid Reading, (2014); Srinivas M., Krishna Mohan C., Medical image indexing and retrieval using multi-feature extraction method, Proc. IEEE Int. Conf. on Computational Intelligence and Information Technology (CIIT) (Elsevier), Mumbai, (2013); Srinivas M., Krishna Mohan C., Efficient clustering approach using incremental and hierarchical clustering methods, Proc. IEEE Int. Conf. On International Joint Conference on Neural Networks (IJCNN), Barcelona, (2010); Guha T., Ward R., A sparse reconstruction based algorithm for image and video classification, Proc. IEEE Conf. on Acoustics, Speech and Signal Processing (ICASSP), pp. 3601-3604, (2012); Brezeale D., Cook D., Automatic video classification: A survey of the literature, IEEE Trans. Syst. Man Cybern. C App. Rev., 38, 3, pp. 416-430, (2008); Xiang M., Schonfeld D., Khokhar A.A., Video event classification and image segmentation based on non causal multidimensional hidden Markov models, IEEE Trans. Image Proc., 18, 6, pp. 1304-1313, (2009); Smeulder A.W.M., Worring M., Santini S., Gupta A., Jain R., Content based image retrieval at the end of the early years, IEEE Trans. Pattern Anal. Mach. Intell., 22, 12, pp. 1349-1380, (2000); Cai W., Feng D., Fulton R., Content-based retrieval of dynamic PET functional images, IEEE Trans. Inf. Technol. Biomed., 4, 2, pp. 152-158, (2000); Pourghassem H., Ghassemian H., Content based medical image classification using a new hierarchical merging scheme, Comput. Med. Imag. Graph., 32, 8, pp. 651-661, (2008); Krawczyk B., Schaefer G., Ensemble fusion methods for medical data classification, Proc. IEEE Int. Symposium. Neural Network Applications in Electrical Engineering (NEUREL), pp. 143-146, (2012); Peng F., Li L., Xu W., Liu W., Zhang J., Shao G., The identification of breast mass based on multi agent interactive information fusion method, Proc. of IEEE Int. Conf. Bioinformatics and Biomedical Engineering, 7, pp. 11-13, (2009); Mitchell T., Mach. Learn, 3; Bengio, Practical recommendations for gradient-based training of deep architectures, 2013. Training Recurrent Neural Networks, (2012); Dutkowski P., Linecker M., DeOliveira M.L., Mullhaupt B., Clavien P.A., Challenges to liver transplantation and strategies to improve outcomes, J. Gastroenterol., 148, pp. 307-323, (2015); Han G., Liu F., Tian Y., Wang H., Wang J., Wang Y., Detection of glucose concentration in a turbid medium using a stacked auto-encoder deep neural network, Infrared Phys. Technol., 105, (2020); Vukotic V., Chappelier V., Furon T., Are Deep Neural Networks good for blind image watermarking? 2018, IEEE International Workshop on Information Forensics and Security (WIFS), (2018); Kandi H., Mishra D., Gorthi S.R.K.S., Exploring the learning capabilities of convolutional neural networks for robust image watermarking, Comput. Secur., 65, pp. 247-268, (2017); Hafiz A.M., Bhat G.M., A survey of deep learning techniques for medical diagnosis, Adv. Intell. Syst. Comput., pp. 161-170, (2019); Siva Raja P.M., Rani A.V., Brain tumor classification using a hybrid deep autoencoder with Bayesian fuzzy clustering-based segmentation approach, Biocybern. Biomed. Eng., (2020); Havaei M., Davy A., Warde-Farley D., Biard A., Courville A., Bengio Y., Et al., Brain tumor segmentation with deep neural networks, Med. Image Anal., 35, pp. 18-31, (2017); Abdelaziz Ismael S.A., Mohammed A., Hefny H., An enhanced deep learning approach for brain cancer MRI images classification using residual networks, Artif. Intell. Med., (2019); Ghassemi N., Shoeibi A., Rouhani M., Deep neural network with generative adversarial networks pre-training for brain tumor classification based on MR images, Biomed. Signal Process Contr., 57, (2020); Amin J., Sharif M., Gul N., Yasmin M., Shad S.A., Brain tumor classification based on DWT fusion of MRI sequences using convolutional neural network, Pattern Recogn. Lett., (2019); Saba T., Sameh Mohamed A., El-Affendi M., Amin J., Sharif M., Brain tumor detection using fusion of hand crafted and deep learning features, Cognit. Syst. Res., (2019); Togacar M., Ergen B., Comert Z., BrainMRNet: Brain tumor detection using magnetic resonance images with a novel convolutional neural network model, Med. Hypotheses, (2019); Amin J., Sharif M., Gul N., Raza M., Anjum M.A., Nisar M.W., Et al., Brain tumor detection by using stacked autoencoders in deep learning, J. Med. Syst., 44, 2, (2019); Nema S., Dudhane A., Murala S., Naidu S., RescueNet: An unpaired GAN for brain tumor segmentation, Biomed. Signal Process Contr., 55, (2020); Geras K.J., Wolfson S., Shen Y., Wu N., Kim S., Kim E., Et al., High-resolution Breast Cancer Screening with Multi-View Deep Convolutional Neural Networks, (2017); Kallenberg M., Petersen K., Nielsen M., Ng A.Y., Diao P., Igel C., Et al., Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring, IEEE Trans. Med. Imaging, 35, 5, pp. 1322-1331, (2016); Haleem A., Javaid Vaishya M., Effects of COVID 19 pandemic in daily life, Curr. Med. Res. Pract., (2020)","","","Elsevier","","","","","","","978-012823014-5","","","English","Handb. of Deep Learning in Biomedical Engineering: Techniques and Applications","Book chapter","Final","","Scopus","2-s2.0-85120533343"
"McCann M.T.; Unser M.","McCann, M.T. (55617614400); Unser, M. (7102049045)","55617614400; 7102049045","Biomedical image reconstruction: From the foundations to deep neural networks","2019","Foundations and Trends in Signal Processing","13","3","","283","359","76","19","10.1561/2000000101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086604683&doi=10.1561%2f2000000101&partnerID=40&md5=7ff436fd7de566a2454876d2f4fb855e","Biomedical Imaging Group, Center for Biomedical Imaging, Signal Processing Core, EPFL, Lausanne, 1015, Switzerland; Biomedical Imaging Group, EPFL, Lausanne, 1015, Switzerland","McCann M.T., Biomedical Imaging Group, Center for Biomedical Imaging, Signal Processing Core, EPFL, Lausanne, 1015, Switzerland; Unser M., Biomedical Imaging Group, EPFL, Lausanne, 1015, Switzerland","This tutorial covers biomedical image reconstruction, from the foundational concepts of system modeling and direct reconstruction to modern sparsity and learning-based approaches. Imaging is a critical tool in biological research and medicine, and most imaging systems necessarily use an image reconstruction algorithm to create an image; the design of these algorithms has been a topic of research since at least the 1960's. In the last few years, machine learning-based approaches have shown impressive performance on image reconstruction problems, triggering a wave of enthusiasm and creativity around the paradigm of learning. Our goal is to unify this body of research, identifying common principles and reusable building blocks across decades and among diverse imaging modalities. We first describe system modeling, emphasizing how a few building blocks can be used to describe a broad range of imaging modalities. We then discuss reconstruction algorithms, grouping them into three broad generations. The first are the classical direct methods, including Tikhonov regularization; the second are the variational methods based on sparsity and the theory of compressive sensing; and the third are the learning-based (also called data-driven) methods, especially those using deep convolutional neural networks. There are strong links between these generations: classical (first-generation) methods appear as modules inside the latter two, and the former two are used to inspire new designs for learning-based (third-generation) methods. As a result, a solid understanding of all three generations is necessary for the design of state-of-the-art algorithms. © M. T. McCann and M. Unser (2019)","","Bioinformatics; Convolutional neural networks; Deep learning; Deep neural networks; Learning systems; Compressive sensing; Image reconstruction algorithm; Learning-based approach; Reconstruction algorithms; Reconstruction problems; State-of-the-art algorithms; Tikhonov regularization; Variational methods; Image reconstruction","","","","","European Union's Horizon 2020 Research and Innovation Program; Louis-Jeantet Foundations; University Hospitals of Geneva; Vaud University Hospital Centre; Horizon 2020 Framework Programme, H2020, (692726); European Research Council, ERC; École Polytechnique Fédérale de Lausanne, EPFL; Louis-Jeantet Foundation; Hôpitaux Universitaires de Genève, HUG; Université de Genève, UNIGE; Université de Lausanne, UNIL; Centre d'Imagerie BioMédicale, CIBM","Funding text 1: This work was made possible thanks to the CIBM Center for Biomedical Imaging, founded and supported by Vaud University Hospital Centre (CHUV), University of Lausanne (UNIL), Swiss Federal Institute of Technology Lausanne (EPFL), University of Geneva (UNIGE), University Hospitals of Geneva (HUG) and the Leenaards and the Louis-Jeantet Foundations and thanks to the European Research Council through the European Union’s Horizon 2020 Research and Innovation Program under Grant 692726, GlobalBioIm.; Funding text 2: This work was made possible thanks to the CIBM Center for Biomedical Imaging, founded and supported by Vaud University Hospital Centre (CHUV), University of Lausanne (UNIL), Swiss Federal Institute of Technology Lausanne (EPFL), University of Geneva (UNIGE), University Hospitals of Geneva (HUG) and the Leenaards and the Louis-Jeantet Foundations and thanks to the European Research Council through the European Union's Horizon 2020 Research and Innovation Program under Grant 692726, GlobalBioIm.","Adler J., Oktem O., Solving ill-posed inverse problems using iterative deep neural networks, Inverse Problems, 33, 12, (2017); Adler J., Oktem O., Learned Primal-Dual Reconstruction, IEEE Transactions on Medical Imaging, 37, 6, pp. 1322-1332, (2018); Aggarwal H. K., Mani M. P., Jacob M., MoDL: Model-Based Deep Learning Architecture for Inverse Problems, IEEE Transactions on Medical Imaging, 38, 2, pp. 394-405, (2019); Antun V., Renna F., Poon C., Adcock B., Hansen A. C., On instabilities of deep learning in image reconstruction - Does AI come at a cost?; Bailey D. L., Townsend D. W., Valk P. E., Maisey M. N., Positron Emission Tomography: Basic Sciences, (2005); Beck A., Teboulle M., A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems, SIAM Journal on Imaging Sciences, 2, 1, pp. 183-202, (2009); Benning M., Burger M., Modern regularization methods for inverse problems, Acta Numerica, 27, pp. 1-111, (2018); Born M., Wolf E., Bhatia A. B., Principles of Optics, (2002); Boublil D., Elad M., Shtok J., Zibulevsky M., Spatially-Adaptive Reconstruction in Computed Tomography Using Neural Networks, IEEE Transactions on Medical Imaging, 34, 7, pp. 1474-1485, (2015); Boyd S., Parikh N., Chu E., Peleato B., Eckstein J., Distributed optimization and statistical learning via the alternating direction method of multipliers, Foundations and Trends in Machine Learning, 3, 1, pp. 1-122, (2011); Boyd S., Vandenberghe L., Convex Optimization, (2004); Brezis H., Functional Analysis, Sobolev Spaces and Partial Differential Equations, (2010); Bristow H., Eriksson A., Lucey S., Fast Convolutional Sparse Coding, 2013 IEEE Conference on Computer Vision and Pattern Recognition, (2013); Buzzard G. T., Chan S. H., Sreehari S., Bouman C. A., Plug-and-Play Unplugged: Optimization-Free Reconstruction Using Consensus Equilibrium, SIAM Journal on Imaging Sciences, 11, 3, pp. 2001-2020, (2018); Cai C., Wang C., Zeng Y., Cai S., Liang D., Wu Y., Chen Z., Ding X., Zhong J., Single-shot T2 mapping using overlapping-echo detachment planar imaging and a deep convolutional neural network, Magnetic Resonance in Medicine, 80, 5, pp. 2202-2214, (2018); Candes E., Romberg J., Tao T., Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information, IEEE Transactions on Information Theory, 52, 2, pp. 489-509, (2006); Candes E., Braun N., Wakin M., Sparse signal and image recovery from compressive samples, 2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro, (2007); Candes E., Romberg J., Tao T., Stable signal recovery from incomplete and inaccurate measurements, Communications on Pure and Applied Mathematics, 59, 8, pp. 1207-1223, (2006); Censor Y., Finite series-expansion reconstruction methods, Proceedings of the IEEE, 71, 3, pp. 409-419, (1983); Chang J. H. R., Li C.-L., Poczos B., Kumar B. V. K. V., One Network to Solve Them All - Solving Linear Inverse Problems Using Deep Projection Models, 2017 IEEE International Conference on Computer Vision (ICCV), (2017); Chen H., Zhang Y., Kalra M. K., Lin F., Chen Y., Liao P., Zhou J., Wang G., Low-Dose CT With a Residual Encoder-Decoder Convolutional Neural Network, IEEE Trans. Med. Imag, 36, 12, pp. 2524-2535, (2017); Chen Y., Ranftl R., Pock T., Insights Into Analysis Operator Learning: From Patch-Based Sparse Models to Higher Order MRFs, IEEE Transactions on Image Processing, 23, 3, pp. 1060-1072, (2014); Ciak R., Shafei B., Steidl G., Homogeneous Penalizers and Constraints in Convex Image Restoration, Journal of Mathematical Imaging and Vision, 47, 3, pp. 210-230, (2012); Clark K., Vendt B., Smith K., Freymann J., Kirby J., Koppel P., Moore S., Phillips S., Maffitt D., Pringle M., Tarbox L., Prior F., The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository, Journal of Digital Imaging, 26, 6, pp. 1045-1057, (2013); Combettes P. L., Wajs V. R., Signal Recovery by Proximal Forward-Backward Splitting, Multiscale Modeling & Simulation, 4, 4, pp. 1168-1200, (2005); Dave A., Vadathya A. K., Subramanyam R., Baburajan R., Mitra K., Solving Inverse Computational Imaging Problems Using Deep Pixel-Level Prior, IEEE Transactions on Computational Imaging, 5, 1, pp. 37-51, (2019); Davidson M., MicroscopyU, (2001); Delaney A., Bresler Y., A fast and accurate Fourier algorithm for iterative parallel-beam tomography, IEEE Transactions on Image Processing, 5, 5, pp. 740-753, (1996); Diaspro A., van Zandvoort M. A. M. J., Super-Resolution Imaging in Biomedicine, (2016); Dong W., Wang P., Yin W., Shi G., Wu F., Lu X., Denoising Prior Driven Deep Neural Network for Image Restoration, IEEE Transactions on Pattern Analysis and Machine Intelligence, 41, 10, pp. 2305-2318, (2019); Donoho D. L., Compressed sensing, IEEE Transactions on Information Theory, 52, 4, pp. 1289-1306, (2006); Durairaj D. C., Krishna M. C., Murugesan R., A neural network approach for image reconstruction in electron magnetic resonance tomography, Computers in Biology and Medicine. QT Variability & Heart Rate Variability, 37, 10, pp. 1492-1501, (2007); Elad M., Deep, Deep Trouble, SIAM News, 50, 4, (2017); Elad M., Aharon M., Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries, IEEE Transactions on Image Processing, 15, 12, pp. 3736-3745, (2006); Elad M., Milanfar P., Rubinstein R., Analysis versus synthesis in signal priors, Inverse Problems, 23, 3, pp. 947-968, (2007); Engl H. W., Hanke M., Neubauer A., Neubauer G., Regularization of Inverse Problems, (1996); Eo T., Jun Y., Kim T., Jang J., Lee H.-J., Hwang D., KIKI-net: cross-domain convolutional neural networks for reconstructing undersampled magnetic resonance images, Magnetic Resonance in Medicine, 80, 5, pp. 2188-2201, (2018); Fessler J. A., Model-Based Image Reconstruction for MRI, IEEE Signal Processing Magazine, 27, 4, pp. 81-89, (2010); Frank J., Frank J., Electron Tomography, (2006); Ghani M. U., Karl W. C., Fast Enhanced CT Metal Artifact Reduction using Data Domain Deep Learning, IEEE Transactions on Computational Imaging, pp. 1-1, (2019); Gregor K., LeCun Y., Learning fast approximations of sparse coding, Proceedings of the 27th International Conference on International Conference on Machine Learning, (2010); Gribonval R., Nikolova M., On Bayesian estimation and proximity operators, Applied and Computational Harmonic Analysis, (2019); Gupta H., Jin K. H., Nguyen H. Q., McCann M. T., Unser M., CNN-Based Projected Gradient Descent for Consistent CT Image Reconstruction, IEEE Transactions on Medical Imaging, 37, 6, pp. 1440-1453, (2018); Gutman D. A., Khalilia M., Lee S., Nalisnik M., Mullen Z., Beezley J., Chittajallu D. R., Manthey D., Cooper L. A., The Digital Slide Archive: A Software Platform for Management, Integration, and Analysis of Histology for Cancer Research, Cancer Research, 77, 21, pp. e75-e78, (2017); Hammernik K., Knollc F., Machine learning for image reconstruction, Handbook of Medical Image Computing and Computer Assisted Intervention, (2019); He J., Yang Y., Wang Y., Zeng D., Bian Z., Zhang H., Sun J., Xu Z., Ma J., Optimizing a Parameterized Plug-and-Play ADMM for Iterative Low-Dose CT Reconstruction, IEEE Transactions on Medical Imaging, pp. 1-1, (2018); Hornik K., Approximation Capabilities of Multilayer Feedforward Networks, Neural Networks, 4, 2, pp. 251-257, (1991); Hyun C. M., Kim H. P., Lee S. M., Lee S., Seo J. K., Deep learning for undersampled MRI reconstruction, Physics in Medicine & Biology, 63, 13, (2018); Jin K. H., McCann M. T., Froustey E., Unser M., Deep Convolutional Neural Network for Inverse Problems in Imaging, IEEE Transactions on Image Processing, 26, 9, pp. 4509-4522, (2017); Johnson J., Alahi A., Fei-Fei L., Perceptual Losses for Real-Time Style Transfer and Super-Resolution, Computer Vision - ECCV 2016. Lecture Notes in Computer Science, pp. 694-711, (2016); Kak A., Slaney M., Principles of Computerized Tomographic Imaging, Classics in Applied Mathematics, (2001); Kamilov U. S., Mansour H., Learning Optimal Nonlinearities for Iterative Thresholding Algorithms, IEEE Signal Processing Letters, 23, 5, pp. 747-751, (2016); Kang E., Chang W., Yoo J., Ye J. C., Deep Convolutional Framelet Denosing for Low-Dose CT via Wavelet Residual Network, IEEE Transactions on Medical Imaging, 37, 6, pp. 1358-1369, (2018); Kang E., Koo H. J., Yang D. H., Seo J. B., Ye J. C., Cycle-consistent adversarial denoising network for multiphase coronary CT angiography, Medical Physics, 46, 2, pp. 550-562, (2018); Kim K. H., Do W.-J., Park S.-H., Improving resolution of MR images with an adversarial network incorporating images with different contrast, Medical Physics, 45, 7, pp. 3120-3131, (2018); Knoll F., Hammernik K., Kobler E., Pock T., Recht M. P., Sodickson D. K., Assessment of the generalization of learned image reconstruction and the potential for transfer learning, Magnetic Resonance in Medicine, (2018); Kobler E., Klatzer T., Hammernik K., Pock T., Variational Networks: Connecting Variational Methods and Deep Learning, Lecture Notes in Computer Science, pp. 281-293, (2017); Kundur D., Hatzinakos D., Blind image deconvolution, IEEE Signal Processing Magazine, 13, 3, pp. 43-64, (1996); Kunisch K., Pock T., A Bilevel Optimization Approach for Parameter Learning in Variational Models, SIAM Journal on Imaging Sciences, 6, 2, pp. 938-983, (2013); Lee S.-W., Mittra R., Fourier transform of a polygonal shape function and its application in electromagnetics, IEEE Transactions on Antennas and Propagation, 31, 1, pp. 99-103, (1983); Lewitt R., Reconstruction algorithms: Transform methods, Proceedings of the IEEE, 71, 3, pp. 390-408, (1983); Li Y., Li K., Zhang C., Montoya J., Chen G.-H., Learning to Reconstruct Computed Tomography Images Directly From Sinogram Data Under A Variety of Data Acquisition Conditions, IEEE Transactions on Medical Imaging, 38, 10, pp. 2469-2481, (2019); Liu Y., Zhang Y., Low-dose CT restoration via stacked sparse denoising autoencoders, Neurocomputing, 284, pp. 80-89, (2018); Lucas A., Iliadis M., Molina R., Katsaggelos A. K., Using Deep Neural Networks for Inverse Problems in Imaging: Beyond Analytical Methods, IEEE Signal Processing Magazine, 35, 1, pp. 20-36, (2018); Mallat S., A Wavelet Tour of Signal Processing, (2009); Mallat S., Understanding deep convolutional networks, Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374, 2065, (2016); Manton J. H., Amblard P.-O., A Primer on Reproducing Kernel Hilbert Spaces, Foundations and Trends in Signal Processing, 8, 1-2, pp. 1-126, (2015); McCann M. T., Jin K. H., Unser M., Convolutional Neural Networks for Inverse Problems in Imaging: A Review, IEEE Signal Processing Magazine, 34, 6, pp. 85-95, (2017); McCann M. T., Nilchian M., Stampanoni M., Unser M., Fast 3D reconstruction method for differential phase contrast X-ray CT, Optics Express, 24, 13, (2016); Mercier L., Maestro R. F. D., Petrecca K., Araujo D., Haegelen C., Collins D. L., Online database of clinical MR and ultrasound images of brain tumors, Medical Physics, 39, pp. 3253-3261, (2012); Mitchell T. M., Machine Learning, (1997); Monakhova K., Yurtsever J., Kuo G., Antipa N., Yanny K., Waller L., Learned reconstructions for practical mask-based lensless imaging, Optics Express, 27, 20, (2019); Nguyen H. Q., Bostan E., Unser M., Learning Convex Regularizers for Optimal Bayesian Denoising, IEEE Transactions on Signal Processing, 66, 4, pp. 1093-1105, (2018); Nikolova M., Model distortions in Bayesian MAP reconstruction, Inverse Problems and Imaging, 1, 2, pp. 399-422, (2007); Oppenheim A. V., Schafer R. W., Discrete-Time Signal Processing, (2009); Panin V., Kehren F., Michel C., Casey M., Fully 3-D PET reconstruction with system matrix derived from point source measurements, IEEE Transactions on Medical Imaging, 25, 7, pp. 907-921, (2006); Quan T. M., Nguyen-Duc T., Jeong W.-K., Compressed Sensing MRI Reconstruction Using a Generative Adversarial Network With a Cyclic Loss, IEEE Transactions on Medical Imaging, 37, 6, pp. 1488-1497, (2018); Raj A., Li Y., Bresler Y., GAN-based Projector for Faster Recovery in Compressed Sensing with Convergence Guarantees, (2019); Ramachandran G. N., Lakshminarayanan A. V., Three-dimensional Reconstruction from Radiographs and Electron Micrographs: Application of Convolutions instead of Fourier Transforms, Proceedings of the National Academy of Sciences, 68, 9, pp. 2236-2240, (1971); Rani M., Dhok S. B., Deshmukh R. B., A Systematic Review of Compressive Sensing: Concepts, Implementations and Applications, IEEE Access, 6, pp. 4875-4894, (2018); Ravishankar S., Ye J. C., Fessler J. A., Image Reconstruction: From Sparsity to Data-adaptive Methods and Machine Learning, Proc. IEEE, (2019); Rivenson Y., Gorocs Z., Gunaydin H., Zhang Y., Wang H., Ozcan A., Deep learning microscopy, Optica, 4, 11, (2017); Romano Y., Elad M., Milanfar P., The Little Engine That Could: Regularization by Denoising (RED), SIAM Journal on Imaging Sciences, 10, 4, pp. 1804-1844, (2017); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional Networks for Biomedical Image Segmentation, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2015, pp. 234-241, (2015); Rudin W., Real and Complex Analysis, (1986); Russakovsky O., Deng J., Su H., Krause J., Satheesh S., Ma S., Huang Z., Karpathy A., Khosla A., Bernstein M., Berg A. C., Fei-Fei L., ImageNet Large Scale Visual Recognition Challenge, International Journal of Computer Vision, 115, 3, pp. 211-252, (2015); Schlemper J., Caballero J., Hajnal J. V., Price A. N., Rueckert D., A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction, IEEE Transactions on Medical Imaging, 37, 2, pp. 491-503, (2018); Shan H., Padole A., Homayounieh F., Kruger U., Khera R. D., Nitiwarangkul C., Kalra M. K., Wang G., Competitive performance of a modularized deep neural network compared to commercial algorithms for low-dose CT image reconstruction, Nature Machine Intelligence, 1, 6, pp. 269-276, (2019); Shaw P. J., Rawlins D. J., The point-spread function of a confocal microscope: its measurement and use in deconvolution of 3-D data, Journal of Microscopy, 163, 2, pp. 151-165, (1991); Shepp L. A., Vardi Y., Maximum Likelihood Reconstruction for Emission Tomography, IEEE Transactions on Medical Imaging, 1, 2, pp. 113-122, (1982); Shewchuk J., An introduction to the conjugate gradient method without the agonizing pain, (1994); Soltani S., Andersen M. S., Hansen P. C., Tomographic image reconstruction using training images, Journal of Computational and Applied Mathematics, 313, pp. 243-258, (2017); Sun Y., Wohlberg B., Kamilov U. S., An Online Plug-and-Play Algorithm for Regularized Image Reconstruction, IEEE Transactions on Computational Imaging, 5, 3, pp. 395-408, (2019); Szegedy C., Zaremba W., Sutskever I., Bruna J., Erhan D., Goodfellow I., Fergus R., Intriguing properties of neural networks, International Conference on Learning Representations, (2014); Tosic I., Frossard P., Dictionary learning, IEEE Signal Processing Magazine, 28, 2, pp. 27-38, (2011); Unser M., Fageot J., Gupta H., Representer Theorems for Sparsity-Promoting `1 Regularization, IEEE Transactions on Information Theory, 62, 9, pp. 5167-5180, (2016); Unser M., Soubies E., Soulez F., McCann M., Donati L., GlobalBioIm: A Unifying Computational Framework for Solving Inverse Problems, Imaging and Applied Optics 2017, (2017); Unser M., Tafti P. D., An Introduction to Sparse Stochastic Processes, (2014); Vedaldi A., Lenc K., MatConvNet - Convolutional Neural Networks for MATLAB, Proceeding of the ACM Int. Conf. on Multimedia, (2015); Vetterli M., Kovacevic J., Goyal V., Foundations of Signal Processing, (2014); Vonesch C., Wang L., Shkolnisky Y., Singer A., Fast wavelet-based single-particle reconstruction in Cryo-EM, 2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro, (2011); Wang G., A Perspective on Deep Imaging, IEEE Access, 4, pp. 8914-8924, (2016); Wang G., Ye J. C., Mueller K., Fessler J. A., Image Reconstruction is a New Frontier of Machine Learning, IEEE Transactions on Medical Imaging, 37, 6, pp. 1289-1296, (2018); Webb A., Introduction to Biomedical Imaging, (2002); Wen B., Ravishankar S., Pfister L., Bresler Y., Transform Learning for Magnetic Resonance Image Reconstruction: From Model-based Learning to Building Neural Networks, (1903); Wipf D., Nagarajan S., Iterative Reweighted `1 and `2 Methods for Finding Sparse Solutions, IEEE Journal of Selected Topics in Signal Processing, 4, 2, pp. 317-329, (2010); Wolf E., Three-dimensional structure determination of semi-transparent objects from holographic data, Optics Communications, 1, 4, pp. 153-156, (1969); Wu D., Kim K., Fakhri G. E., Li Q., Iterative Low-Dose CT Reconstruction With Priors Trained by Artificial Neural Network, IEEE Transactions on Medical Imaging, 36, 12, pp. 2479-2486, (2017); Xu Q., Yu H., Mou X., Zhang L., Hsieh J., Wang G., Low-dose X-ray CT reconstruction via dictionary learning, IEEE Transactions on Medical Imaging, 31, 9, pp. 1682-1697, (2012); Yaghoobi M., Nam S., Gribonval R., Davies M. E., Constrained Overcomplete Analysis Operator Learning for Co-sparse Signal Modelling, IEEE Transactions on Signal Processing, 61, 9, pp. 2341-2355, (2013); Yang G., Yu S., Dong H., Slabaugh G., Dragotti P. L., Ye X., Liu F., Arridge S., Keegan J., Guo Y., Firmin D., DAGAN: Deep De-Aliasing Generative Adversarial Networks for Fast Compressed Sensing MRI Reconstruction, IEEE Transactions on Medical Imaging, 37, 6, pp. 1310-1321, (2018); Yang Q., Yan P., Zhang Y., Yu H., Shi Y., Mou X., Kalra M. K., Zhang Y., Sun L., Wang G., Low-Dose CT Image Denoising Using a Generative Adversarial Network With Wasserstein Distance and Perceptual Loss, IEEE Transactions on Medical Imaging, 37, 6, pp. 1348-1357, (2018); Zaharchuk G., Gong E., Wintermark M., Rubin D., Langlotz C., Deep Learning in Neuroradiology, American Journal of Neuroradiology, (2018); Zhao H., Gallo O., Frosio I., Kautz J., Loss Functions for Image Restoration With Neural Networks, IEEE Transactions on Computational Imaging, 3, 1, pp. 47-57, (2017); Zhou Y. T., Chellappa R., Vaid A., Jenkins B. K., Image restoration using a neural network, IEEE Transactions on Acoustics, Speech, and Signal Processing, 36, 7, pp. 1141-1151, (1988); Zhu B., Liu J. Z., Cauley S. F., Rosen B. R., Rosen M. S., Image reconstruction by domain-transform manifold learning, Nature, 555, 7697, pp. 487-492, (2018)","","","Now Publishers Inc","","","","","","19328346","","","","English","Found. Trends Signal Process.","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85086604683"
"","","","10th International Workshop on Clinical Image-Based Procedures, CLIP 2021, 2nd MICCAI Workshop on Distributed and Collaborative Learning, DCL 2021, 1st MICCAI Workshop, LL-COVID19, 1st Secure and Privacy-Preserving Machine Learning for Medical Imaging Workshop and Tutorial, PPML 2021, held in conjunction with 24th International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2021","2021","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12969 LNCS","","","","","188","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120670667&partnerID=40&md5=d2d8d0fe0bacf848b549c7c0113ca065","","","The proceedings contain 17 papers. The special focus in this conference is on Clinical Image-Based Procedures. The topics include: DCL preface; LL-COVID-19 preface; PPML preface; intestine Segmentation with Small Computational Cost for Diagnosis Assistance of Ileus and Intestinal Obstruction; multi-task Federated Learning for Heterogeneous Pancreas Segmentation; federated Learning in the Cloud for Analysis of Medical Images - Experience with Open Source Frameworks; on the Fairness of Swarm Learning in Skin Lesion Classification; Lessons Learned from the Development and Application of Medical Imaging-Based AI Technologies for Combating COVID-19: Why Discuss, What Next; The Role of Pleura and Adipose in Lung Ultrasound AI; DuCN: Dual-Children Network for Medical Diagnosis and Similar Case Recommendation Towards COVID-19; data Imputation and Reconstruction of Distributed Parkinson’s Disease Clinical Assessments: A Comparative Evaluation of Two Aggregation Algorithms; defending Medical Image Diagnostics Against Privacy Attacks Using Generative Methods: Application to Retinal Diagnostics; generation of Patient-Specific, Ligamentoskeletal, Finite Element Meshes for Scoliosis Correction Planning; Bayesian Graph Neural Networks for EEG-Based Emotion Recognition; ViTBIS: Vision Transformer for Biomedical Image Segmentation; Attention-Guided Pancreatic Duct Segmentation from Abdominal CT Volumes; development of the Next Generation Hand-Held Doppler with Waveform Phasicity Predictive Capabilities Using Deep Learning; learning from Mistakes: An Error-Driven Mechanism to Improve Segmentation Performance Based on Expert Feedback.","","","","","","","","","","","Oyarzun Laura C.; Cardoso M.J.; Rosen-Zvi M.; Kaissis G.; Linguraru M.G.; Shekhar R.; Wesarg S.; Erdt M.; Drechsler K.; Chen Y.; Albarqouni S.; Bakas S.; Landman B.; Rieke N.; Roth H.; Li X.; Xu D.; Gabrani M.; Konukoglu E.; Guindy M.; Rueckert D.; Ziller A.; Usynin D.; Passerat-Palmbach J.; Oyarzun Laura C.; Cardoso M.J.; Rosen-Zvi M.; Kaissis G.; Linguraru M.G.; Shekhar R.; Wesarg S.; Erdt M.; Drechsler K.; Chen Y.; Albarqouni S.; Bakas S.; Landman B.; Rieke N.; Roth H.; Li X.; Xu D.; Gabrani M.; Konukoglu E.; Guindy M.; Rueckert D.; Ziller A.; Usynin D.; Passerat-Palmbach J.","Springer Science and Business Media Deutschland GmbH","","10th International Workshop on Clinical Image-Based Procedures, CLIP 2021, 2nd MICCAI Workshop on Distributed and Collaborative Learning, DCL 2021, 1st MICCAI Workshop, LL-COVID19, 1st Secure and Privacy-Preserving Machine Learning for Medical Imaging Workshop and Tutorial, PPML 2021, held in conjunction with 24th International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2021","27 September 2021 through 1 October 2021","Virtual, Online","268689","03029743","978-303090873-7","","","English","Lect. Notes Comput. Sci.","Conference review","Final","","Scopus","2-s2.0-85120670667"
"Zhang R.; Guo Z.; Sun Y.; Lu Q.; Xu Z.; Yao Z.; Duan M.; Liu S.; Ren Y.; Huang L.; Zhou F.","Zhang, Ruochi (57196041167); Guo, Zhehao (57219109743); Sun, Yue (57221122033); Lu, Qi (57219110127); Xu, Zijian (57219109575); Yao, Zhaomin (57192304471); Duan, Meiyu (57212005263); Liu, Shuai (57200844289); Ren, Yanjiao (57201310055); Huang, Lan (55770288600); Zhou, Fengfeng (55634210800)","57196041167; 57219109743; 57221122033; 57219110127; 57219109575; 57192304471; 57212005263; 57200844289; 57201310055; 55770288600; 55634210800","COVID19XrayNet: A Two-Step Transfer Learning Model for the COVID-19 Detecting Problem Based on a Limited Number of Chest X-Ray Images","2020","Interdisciplinary Sciences – Computational Life Sciences","12","4","","555","565","10","53","10.1007/s12539-020-00393-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091267952&doi=10.1007%2fs12539-020-00393-5&partnerID=40&md5=0573121222167824ca5b815cf49aedb4","BioKnow Health Informatics Lab, College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China; School of Computing and Information, University of Pittsburgh, 135 N Bellefield Ave, Pittsburgh, 15213, PA, United States; College of Information Technology, Jilin Agricultural University, Changchun, 130118, Jilin, China","Zhang R., BioKnow Health Informatics Lab, College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China; Guo Z., School of Computing and Information, University of Pittsburgh, 135 N Bellefield Ave, Pittsburgh, 15213, PA, United States; Sun Y., School of Computing and Information, University of Pittsburgh, 135 N Bellefield Ave, Pittsburgh, 15213, PA, United States; Lu Q., School of Computing and Information, University of Pittsburgh, 135 N Bellefield Ave, Pittsburgh, 15213, PA, United States; Xu Z., School of Computing and Information, University of Pittsburgh, 135 N Bellefield Ave, Pittsburgh, 15213, PA, United States; Yao Z., BioKnow Health Informatics Lab, College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China; Duan M., BioKnow Health Informatics Lab, College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China; Liu S., BioKnow Health Informatics Lab, College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China; Ren Y., College of Information Technology, Jilin Agricultural University, Changchun, 130118, Jilin, China; Huang L., BioKnow Health Informatics Lab, College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China; Zhou F., BioKnow Health Informatics Lab, College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, Jilin, China","The novel coronavirus severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a major pandemic outbreak recently. Various diagnostic technologies have been under active development. The novel coronavirus disease (COVID-19) may induce pulmonary failures, and chest X-ray imaging becomes one of the major confirmed diagnostic technologies. The very limited number of publicly available samples has rendered the training of the deep neural networks unstable and inaccurate. This study proposed a two-step transfer learning pipeline and a deep residual network framework COVID19XrayNet for the COVID-19 detection problem based on chest X-ray images. COVID19XrayNet firstly tunes the transferred model on a large dataset of chest X-ray images, which is further tuned using a small dataset of annotated chest X-ray images. The final model achieved 0.9108 accuracy. The experimental data also suggested that the model may be improved with more training samples being released. Graphic abstract: COVID19XrayNet, a two-step transfer learning framework designed for biomedical images.[Figure not available: see fulltext.] © 2020, International Association of Scientists in the Interdisciplinary Areas.","COVID19XrayNet; Feature extraction layer (FEL); Feature smoothing layer (FSL); ResNet34; Two-step transfer learning","Algorithms; Betacoronavirus; Clinical Laboratory Techniques; Coronavirus; Coronavirus Infections; Databases, Factual; Datasets as Topic; Deep Learning; Humans; Lung; Machine Learning; Models, Biological; Neural Networks, Computer; Pandemics; Pneumonia; Pneumonia, Viral; Radiography; Reference Values; Tomography, X-Ray Computed; X-Rays; algorithm; Betacoronavirus; biological model; complication; Coronavirinae; Coronavirus infection; diagnostic imaging; factual database; human; information processing; laboratory technique; lung; machine learning; pandemic; pneumonia; procedures; radiography; reference value; virology; virus pneumonia; X ray; x-ray computed tomography","","","","","High Performance Computing Center of Jilin University; Jilin Provincial Key Laboratory of Big Data Intelligent Computing, (20180622002JC); Jilin University, JLU, (BMCPP-2018-001); Education Department of Jilin Province, (JJKH20180145KJ); Fundamental Research Funds for the Central Universities","This work was supported by the Jilin Provincial Key Laboratory of Big Data Intelligent Computing (20180622002JC), the Education Department of Jilin Province (JJKH20180145KJ), and the startup grant of the Jilin University. This work was also partially supported by the Bioknow MedAI Institute (BMCPP-2018-001), the High Performance Computing Center of Jilin University, and by the Fundamental Research Funds for the Central Universities, JLU. Acknowledgements ","Zhai P., Ding Y., Wu X., Long J., Zhong Y., Li Y., The epidemiology, diagnosis and treatment of COVID-19, Int J Antimicrob Agents, (2020); Zhou P., Yang X.L., Wang X.G., Hu B., Zhang L., Zhang W., Si H.R., Zhu Y., Li B., Huang C.L., Chen H.D., Chen J., Luo Y., Guo H., Jiang R.D., Liu M.Q., Chen Y., Shen X.R., Wang X., Zheng X.S., Zhao K., Chen Q.J., Deng F., Liu L.L., Yan B., Zhan F.X., Wang Y.Y., Xiao G.F., Shi Z.L., A pneumonia outbreak associated with a new coronavirus of probable bat origin, Nature, 579, 7798, pp. 270-273, (2020); Onder G., Rezza G., Brusaferro S., Case-fatality rate and characteristics of patients dying in relation to COVID-19 in Italy, JAMA, 323, 18, pp. 1775-1776, (2020); Weiss P., Murdoch D.R., Clinical course and mortality risk of severe COVID-19, Lancet, 395, 10229, pp. 1014-1015, (2020); Velavan T.P., Meyer C.G., The COVID-19 epidemic, Trop Med Int Health, 25, 3, pp. 278-280, (2020); Chu D.K.W., Pan Y., Cheng S.M.S., Hui K.P.Y., Krishnan P., Liu Y., Ng D.Y.M., Wan C.K.C., Yang P., Wang Q., Peiris M., Poon L.L.M., Molecular diagnosis of a novel coronavirus (2019-nCoV) causing an outbreak of pneumonia, Clin Chem, 66, 4, pp. 549-555, (2020); Li Z., Yi Y., Luo X., Xiong N., Liu Y., Li S., Sun R., Wang Y., Hu B., Chen W., Zhang Y., Wang J., Huang B., Lin Y., Yang J., Cai W., Wang X., Cheng J., Chen Z., Sun K., Pan W., Zhan Z., Chen L., Ye F., Development and clinical application of a rapid IgM-IgG combined antibody test for SARS-CoV-2 infection diagnosis, J Med Virol, (2020); Xie X., Zhong Z., Zhao W., Zheng C., Wang F., Liu J., Chest CT for typical 2019-nCoV pneumonia: relationship to negative RT-PCR testing, Radiology, (2020); Fang Y., Wang Z., Improving LBP features for gender classification, 2008 International Conference on Wavelet Analysis and Pattern Recognition, pp. 373-377, (2008); Satpathy A., Jiang X., Eng H.-L., Human detection by quadratic classification on subspace of extended histogram of gradients, IEEE Trans Image Process, 23, 1, pp. 287-297, (2013); Zhao R., Zhang R., Tang T., Feng X., Li J., Liu Y., Zhu R., Wang G., Li K., Zhou W., Yang Y., Wang Y., Ba Y., Zhang J., Liu Y., Zhou F., TriZ-a rotation-tolerant image feature and its application in endoscope-based disease diagnosis, Comput Biol Med, 99, pp. 182-190, (2018); Zhang R., Zhao R., Zhao X., Wu D., Zheng W., Feng X., Zhou F., pyHIVE, a health-related image visualization and engineering system using Python, BMC Bioinf, 19, 1, (2018); Kermany D.S., Goldbaum M., Cai W., Valentim C.C.S., Liang H., Baxter S.L., McKeown A., Yang G., Wu X., Yan F., Dong J., Prasadha M.K., Pei J., Ting M.Y.L., Zhu J., Li C., Hewett S., Dong J., Ziyar I., Shi A., Zhang R., Zheng L., Hou R., Shi W., Fu X., Duan Y., Huu V.A.N., Wen C., Zhang E.D., Zhang C.L., Li O., Wang X., Singer M.A., Sun X., Xu J., Tafreshi A., Lewis M.A., Xia H., Zhang K., Identifying medical diagnoses and treatable diseases by image-based deep learning, Cell, 172, 5, pp. 1122-1131, (2018); Cohen J.P., Morrison P., Dao L., COVID-19 Image Data Collection, (2020); Wang X., Peng Y., Lu L., Lu Z., Bagheri M., Summers R.M., Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2097-2106, (2017); Irvin J., Rajpurkar P., Ko M., Yu Y., Ciurea-Ilcus S., Chute C., Marklund H., Haghgoo B., Ball R., Shpanskaya K., Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison, Proceedings of the AAAI Conference on Artificial Intelligence, pp. 590-597, (2019); Johnson A.E., Pollard T.J., Berkowitz S.J., Greenbaum N.R., Lungren M.P., Deng C.-Y., Mark R.G., Horng S., MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports, Sci Data, (2019); Lawrence S., Giles C.L., Tsoi A.C., Back A.D., Face recognition: a convolutional neural-network approach, IEEE Trans Neural Netw, 8, 1, pp. 98-113, (1997); Lecun Y., Kavukcuoglu K., Farabet C., Convolutional networks and applications in vision, Proceedings of 2010 IEEE International Symposium on Circuits and Systems. IEEE, pp. 253-256, (2010); Frazao X., Alexandre L.A., Dropall: Generalization of two convolutional neural network regularization methods, International Conference Image Analysis and Recognition, pp. 282-289, (2014); Liu K., Kang G., Zhang N., Hou B., Breast cancer classification based on fully-connected layer first convolutional neural networks, IEEE Access, 6, pp. 23722-23732, (2018); Paszke A., Chaurasia A., Kim S., Culurciello E., Enet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation, (2016); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Ng H.-W., Nguyen V.D., Vonikakis V., Winkler S., Deep learning for emotion recognition on small datasets using transfer learning, Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, pp. 443-449, (2015); Hu B., Song R.-J., Wei X.-S., Yao Y., Hua X.-S., Liu Y., PyRetri: A PyTorch-based library for unsupervised image retrieval by Deep Convolutional Neural Networks, (2020); Yang H., Kim J.-Y., Kim H., Adhikari S.P., Guided soft attention network for classification of breast cancer histopathology images, IEEE Trans Med Imaging, (2019); Zhang Y., Chen C., Duan M., Liu S., Huang L., Zhou F., BioDog, biomarker detection for improving identification power of breast cancer histologic grade in methylomics, Epigenomics, 11, 15, pp. 1717-1732, (2019); Hao D., Peng J., Wang Y., Liu J., Zhou X., Zheng D., Evaluation of convolutional neural network for recognizing uterine contractions with electrohysterogram, Comput Biol Med, 113, (2019); McHugh M.L., Interrater reliability: the kappa statistic, Biochem Med (Zagreb), 22, 3, pp. 276-282, (2012)","F. Zhou; BioKnow Health Informatics Lab, College of Computer Science and Technology, Key Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, Changchun, 130012, China; email: FengfengZhou@gmail.com","","Springer Science and Business Media Deutschland GmbH","","","","","","19132751","","","32959234","English","Interdiscip. Sci. Comput. Life Sci.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85091267952"
"Davamani K.A.; Robin C.R.R.; Amudha S.; Anbarasi L.J.","Davamani, K. Anita (57210209037); Robin, C.R. Rene (57189274646); Amudha, S. (57217088432); Anbarasi, L. Jani (57222292455)","57210209037; 57189274646; 57217088432; 57222292455","Biomedical image segmentation by deep learning methods","2021","Computational Analysis and Deep Learning for Medical Care: Principles, Methods, and Applications","","","","131","154","23","11","10.1002/9781119785750.ch6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124250605&doi=10.1002%2f9781119785750.ch6&partnerID=40&md5=cc0abfe09b19cd3507ae7f3acb36ecff","Anna University, Chennai, India; Department of Computer Science and Engineering, Jerusalem College of Engineering, Chennai, India; Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, India; School of Computer Science and Engineering, VIT University, Chennai, India","Davamani K.A., Anna University, Chennai, India; Robin C.R.R., Department of Computer Science and Engineering, Jerusalem College of Engineering, Chennai, India; Amudha S., Department of Computer Science and Engineering, Bharath Institute of Higher Education and Research, Chennai, India; Anbarasi L.J., School of Computer Science and Engineering, VIT University, Chennai, India","Deep learning methods have been employed to predict and analyse various application in medical imaging. Deep Learning technology is a computational algorithm that learns by itself to demonstrate a desired behaviours. Neural network processes the input neurons according to the corresponding types of networks based on algorithm provided and passes it to the hidden layer. Finally, it outputs the result through output layer. Deep learning algorithms tend to be more useful in different applications. It plays important role in biomedical image segmentations such as identifying skin cancer, lung cancer, brain tumour, skin psoriasis, etc. Deep learning includes algorithms like Convolutional Neural Network (CNN), Restricted Boltzmann Machine (RBM), Generative Adversarial Network (GAN), Recurrent Neural Network (RNN), U-Net, V-net, Fully Convolutional Attention Network (FCANET), Docker- powered based deep learning, ResNet18, ResNet50, SqueezeNet and DenseNet-121 which processes on medical images and helps in identifying the defect in earlier stage by helping the physician to start the treatment process. This paper is about the review of deep learning algorithms using medical image segmentation. Future implementations can be performed through additional feature for the existing algorithm with better performance. © 2021 Scrivener Publishing LLC. All rights reserved.","Convolution neural network; Deep learning; Image processing; Image segmentation","","","","","","","","Haque I.R., Neubert J., Deep Learning approaches to biomedical image segmentation, Inf. Med. Unlocked, 18, (2020); Pal A., Chaturvedi A., Garain U., Chandra A., Chatterjee R., Severity grading of psoriatic plaques using deep CNN based multi-task learning,  international conference on pattern recognition, pp. 1478-1483, (2016); Wang G., A perspective on deep imaging, IEEE Access, 4, pp. 8914-8924, (2016); Henrique Schuindt da Silva F., Deep learning for Corpus Callosum segmentation in brain magnetic resonance images, (2018); Volkenandt T., Freitag S., Rauscher M., Machine learning powered image segmentation, Microsc. Microanal, 24, pp. 520-521, (2018); Isin A., Direkoglu C., Sah M., Review of MRI-based brain tumor image segmentation using deep learning methods, Proc. Comput. Sci, 102, pp. 317-324, (2016); Millioni R., Sbrignadello S., Tura A., Iori E., Murphy E., Tessari P., The inter- and intraoperator variability in manual spot segmentation and its effect on spot quantitation in two-dimensional electrophoresis analysis, Electrophoresis, 31, 10, pp. 1739-1742, (2010); Iglesias J.E., Globally optimal coupled surfaces for semi-automatic segmentation ofmedical images, Lect. Notes Comput. Sci. (including SubserLect Notes ArtifIntellLect Notes Bioinformatics), (2017); Fan J., Wang R., Li S., Zhang C., Automated cervical cell image segmentation using level set based active contour model, 2012 12th int. Conf. Control. Autom. Robot. Vision, 2012, pp. 877-882, (2012); Kim Y.J., Lee S.H., Park C.M., Kim K.G., Evaluation of semi-automatic segmentation methods for persistent ground glass nodules on thin-section CT scans, Healthc. Inform. Res, 22, 4, pp. 305-315, (2016); Roth H.R., Et al., Deep learning and its application to medical image segmentation, pp. 1-6, (2018); Zhou X., Et al., Performance evaluation of 2D and 3D deep learning approaches for automatic segmentation of multiple organs on CT images, Medical imaging 2018: Computer-Aided Diagnosis, (2018); Shen D., Wu G., Suk H.-I., Deep learning in medical image analysis, Annu. Rev. Biomed. Eng, 19, 1, pp. 221-248, (2017); Guo Y., Liu Y., Oerlemans A., Lao S., Wu S., Lew M.S., Deep learning for visual understanding: A review, Neurocomputing, 187, pp. 27-48, (2016); Garcia-Garcia A., Orts-Escolano S., Oprea S., Villena-Martinez V., Martinez-Gonzalez P., Garcia-Rodriguez J., A survey on deep learning techniques for image and video semantic segmentation, Appl. Soft Comput. J, 70, pp. 41-65, (2018); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Lect Notes ComputSci (including SubserLect Notes ArtifIntellLect Notes Bioinformatics), 9351, pp. 234-241, (2015); Milletari F., Navab N., Ahmadi S.A., V-Net: Fully convolutional neural networks for volumetric medical image segmentation, Proc. - 2016 4th int. Conf. 3D vision, 3DV, pp. 565-571, (2016); Csurka G., Larlus D., Perronnin F., What is a good evaluation measure for semantic segmentation?, BMVC 2013 - electron. Proc. Br. Mach. Vis. Conf, (2013); Xu Y., Wang Y., Yuan J., Cheng Q., Wang X., Carson P.L., Medical breast ultrasound image segmentation by machine learning, Ultrasonics, 91, 1-9, (2018); Chen H., Dou Q., Yu L., Qin J., Heng P.-A., VoxResNet: Deep voxelwise residual networks for brain segmentation from 3D MR images, Neuroimage, 170, pp. 446-455, (2017); Taha A.A., Hanbury A., Metrics for evaluating 3D medical image segmentation: Analysis, selection, and tool, BMC Med. Imaging, 15, (2015); Costa H., Foody G.M., Boyd D.S., Supervised methods of image segmentation accuracy assessment in land cover mapping, Remote Sens. Environ, 205, pp. 338-351, (2016); Chest X-ray NIHCC, (2017); Fotenos A.F., Snyder A.Z., Girton L.E., Morris J.C., Buckner R.L., Normative estimates of cross-sectional and longitudinal brain volume decline in aging and AD, Neurology, 64, 6, pp. 1032-1039, (2005); Dhungel N., Carneiro G., Bradley A.P., Deep learning and structured prediction forthe segmentation of mass in mammograms, Medical image computing and computer-assisted intervention -MICCAI 2015. MICCAI 2015. Lecture notes in computer science, 9349, pp. 605-612, (2015); Dou Q., Et al., 3D deeply supervised network for automated segmentation of volumetric medical images, Med. Image Anal, 41, pp. 40-54, (2017); Wang G., Et al., Interactive medical image segmentation using deep learning with image-specific fine tuning, IEEE Trans. Med. Imaging, 37, 7, pp. 1562-1573, (2018); Ngo T.A., Lu Z., Carneiro G., Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance, Med. Image Anal, 35, pp. 159-171, (2017); Milletari F., Et al., Hough-CNN: Deep learning for segmentation of deep brain regions in MRI and ultrasound, Comput. Vis. Image Und, 164, pp. 92-102, (2017); Jia Z., Huang X., Chang E.I.C., Xu Y., Constrained deep weak supervision for histopathology image segmentation, IEEE Trans. Med. Imaging, 36, 11, pp. 2376-2388, (2017); Zhao Z., Yang L., Zheng H., Guldner I.H., Zhang S., Chen D.Z., Deep learning based instance segmentation in 3D biomedical images using weak annotation, Lect. Notes Comput. Sci. (including SubserLect Notes ArtifIntellLect Notes Bioinformatics), (2018); Zeiler M.D., Fergus R., Visualizing and understanding convolutional networks, European conference on computer vision (ECCV), 2014, pp. 818-833, (2014); Caruana R., Multitask learning, Mach. Learn, 28, 1, pp. 41-75, (1997); Li S., Liu Z.-Q., Chan A.B., Heterogeneous multi-task learning for human pose estimation with deep convolutional neural network, Int. J. Comput. Vision, 113, 1, pp. 19-36, (2014); Yan Z., Zhan Y., Peng Z., Liao S., Shinagawa Y., Zhang S., Metaxas D., Zhou X., Multi-instance deep learning: Discover discriminative local anatomies for body part recognition, IEEE Trans. Med. Imaging, 35, 5, pp. 1332-1343, (2016); Katsevich A., An improved exact lteredbackprojection algorithm for spiral computed tomography, Adv. Appl. Math, 32, 4, pp. 681-697, (2004); McCollough C.H., Et al., Achieving routine submillisievert CT scanning: Report from the summit on management of radiation dose in CT, Radiology, 264, 2, (2012); Ravishankar S., Bresler Y., MR image reconstruction from highly undersampled k-space data by dictionary learning, IEEE Trans. Med. Imaging, 30, 5, (2011); Xu Q., Yu H., Mou X., Zhang L., Hsieh J., Wang G., Low-dose X-ray CT reconstruction via dictionary learning, IEEE Trans. Med. Imaging, 31, 9, (2012); Reduced lung-cancer mortality with low-dose computed tomographic screening, N. Engl. J. Med, 365, (2011); Badrinarayanan V., Kendall A., Cipolla R., SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation, (2015); Kucharsky Hiess R., Alter R., Sojoudi S., Et al., Corpus Callosum Area and Brain Volume in Autism Spectrum Disorder: Quantitative Analysis of Structural MRI from the ABIDE Database, J. Autism Dev. Disord, 45, 10, pp. 3107-3114, (2015); Bhalerao G.V., Sampathila N., K-means clustering approach for segmentation of corpus callosum from brain magnetic resonance images, International Conference on Circuits, Communication, Control and Computing, pp. 434-437, (2014); Meyer A., Multi-atlas Based Segmentation of Corpus Callosum on MRIs of Multiple Sclerosis Patients, Pattern Recognition: 36th German Conference, GCPR 2014, Munster, Germany, September 2-5, 2014, Proceedings, pp. 729-735, (2014); Siegel R., Ward E., Brawley O., Jemal A., Cancer statistics, 2011: The impact of eliminating socioeconomic and racial disparities on premature cancer deaths, CA Cancer J. Clin, 61, 4, pp. 212-236, (2011); Song J.S., Kim S.Y., Jo H.J., Lee K.K., Shin J.H., Shin S.N., Et al., The role and significance of biomarker for plasma GCSF in patients with primary lung cancer, Tuberc. Respir. Dis, 66, 6, pp. 444-450, (2009); Nakata M., Saeki H., Takata I., Segawa Y., Mogami H., Mandai K., Et al., Focal ground-glass opacity detected by low-dose helical CT, Chest, 121, 5, pp. 1464-1467, (2002); Park C.M., Goo J.M., Lee H.J., Lee C.H., Chun E.J., Im J.G., Nodular ground-glass opacity at thin-section CT: Histologic correlation and evaluation of change at follow-up, Radiographics, 27, 2, pp. 391-408, (2007); Roth H.R., Lu L., Lay N., Et al., Spatial aggregation of holistically-nested convolutional neural networks for automated pancreas localization and segmentation, (2017); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440, (2015); Lundervold A.S., Lundervold A., An overview of deep learning in medical imaging focusing on MRI, Z. Med. Phys, 29, pp. 102-127, (2019); Kadampur M.A., Al Riyaee S., Skin cancer detection: Applying a deep learning based model driven architecture in the cloud for classifying dermal cell images, Inform. Med. Unlocked, 18, (2020); Liua H., Xua J., Wub Y., Guoa Q., Ibragimovb B., Xing L., Learning Deconvolutional Deep Neural Network for High Resolution Medical Image Reconstruction, Inf. Sci, (2018); Ardakani A.A., Kanafi A.R., RajendraAcharya U., Khadem N., Mohammadi A., Application of deep learning technique to manage COVID-19 in routine clinical practice using CT images: Results of 10 convolutional neural networks, Comput. Biol. Med, 121, (2020); Minaeea S., Kafiehb R., Sonkac M., Yazdanid S., Soufi G.J., Deep-COVID: Predicting COVID-19 From Chest X-Ray Images Using Deep Transfer Learning, Med. Image Anal, 65, (2020); Kokil P., Sudharson S., Despeckling of clinical ultrasound images using deep residual learning, Comput. Methods Programs Biomed, 194, (2020); Pekala M., Joshi N., Alvin Liu T.Y., Bressler N.M., Cabrera DeBuc D., Burlina P., Deep Learning based Retinal OCT Segmentation, Comput. Biol. Med, 114, (2019); Lei B., Xia Z., Jiang F., Jiang X., Ge Z., Xu Y., Qin J., Chen S., Wang T., Wang S., Skin Lesion Segmentation via Generative Adversarial Networks with Dual Discriminators, Med. Image Anal, 64, (2020); Subrata S.A., Phuphaibul R., Grey M., Siripitayakunkit A., Piaseu N., Improving clinical outcomes of diabetic foot ulcers by the 3-month self- and family management support programs in Indonesia: A randomized controlled trial study, Diabetes Metab. Syndr.: Clin. Res. & Rev, 14, 5, pp. 857-863, (2020); Chenga J., Tianb S., Yua L., Lub H., Lv X., Fully convolutional attention network for biomedical image segmentation, Artif. Intell. Med, 107, (2020); Kwon Y., Won J.-H., Kim B.J., Paik M.C., Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation, Comput. Stat. Data Anal, 142, (2020); Anita Davamani K., Rene Robin C.R., Kamatchi S., Krithika S.R., Manisha P., Santhosh T., A novel sentiment analysis technique in disease classification, Adv. Environ. Biol, 11, (2020); Jayanthi S., Rene Robin C.R., A survey on different classification methods for microarray data analysis, Adv. Environ. Biol, 11, (2020); Murugan S., Muthu Kumar B., Amudha S., Classification and Prediction of Breast Cancer using Linear Regression, Decision Tree and Random Forest, 2017 International Conference on Current Trends in Computer, Electrical, Electronics and Communication (CTCEEC)","K.A. Davamani; Anna University, Chennai, India; email: anitadavamani@gmail.com","","wiley","","","","","","","978-111978575-0; 978-111978572-9","","","English","Comput. Anal. and Deep Learn. for Med. Care: Princ., Methods, and Appli.","Book chapter","Final","","Scopus","2-s2.0-85124250605"
"Greeshma K.V.; Viji Gripsy J.","Greeshma, K.V. (57207827443); Viji Gripsy, J. (56153136500)","57207827443; 56153136500","A Review on Classification and Retrieval of Biomedical Images Using Artificial Intelligence","2021","Internet of Things","","","","47","66","19","3","10.1007/978-3-030-75220-0_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113298343&doi=10.1007%2f978-3-030-75220-0_3&partnerID=40&md5=8a60c66169c30ef76a75dd4c257d5b3c","Department of Computer Science (UG), PSGR Krishnammal College for Women, Coimbatore, India","Greeshma K.V., Department of Computer Science (UG), PSGR Krishnammal College for Women, Coimbatore, India; Viji Gripsy J., Department of Computer Science (UG), PSGR Krishnammal College for Women, Coimbatore, India","Image retrieval and classification are the most prominent area of research in computer vision. Nowadays, bounteous medical images are generated through different types of medical imaging modalities in healthcare systems. It is often very difficult for researchers and doctors to access manage and retrieve images easily. The efficient and effective analysis and usage of heterogeneous biomedical images growing rapidly are a tedious task. Content-based image retrieval (CBIR) is one of the most widely used methods for automatic retrieval of images and widely used in medical images. Abundant research articles are published in different domain of applications related to CBIR and classification. The aim of this study is to provide a road map for researchers by exploring the various approaches, techniques, and algorithms used for medical image retrieval and classification. Feature extraction is the main subject for improving the performance of image classification and retrieval. Bag of visual words techniques and deep convolutional neural networks are widely used in content-based medical image retrieval (CBMIR). The state-of-the-art methods presented in this review are well suited to classify and retrieve multimodal medical images for different body organs. The methods include preprocessing of images, feature extraction, classification, and retrieval steps to develop an efficient biomedical image retrieval system. This chapter briefly reviews the various techniques used for biomedical images, and different methods adopted in classification and retrieval are focused. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Artificial intelligence; Bag of visual words; BoVW; CBIR; CBMIR; CNN; Content-based image retrieval; Content-based medical image retrieval; CT; Deep learning; Image classification; Internet of medical things; IoMT; IOT; Machine learning; MRI; Support vector machine","Biomedical signal processing; Classification (of information); Content based retrieval; Convolutional neural networks; Deep neural networks; Extraction; Feature extraction; Image classification; Image enhancement; Medical imaging; Automatic retrieval; Bag-of-visual-words; Content based medical image retrieval; Content-Based Image Retrieval; Effective analysis; Multimodal medical images; Preprocessing of image; State-of-the-art methods; Search engines","","","","","","","Greco L., Percannella G., Ritrovato P., Tortorella F., Vento M., Trends in IoT based solutions for health care: Moving AI to the edge, Pattern Recognition Letters, 135, pp. 346-353, (2020); Owais M., Arsalan M., Choi J., Park K.R., Effective diagnosis and treatment through content-based medical image retrieval (CBMIR) by using artificial intelligence, Journal of Clinical Medicine, 8, 4, (2019); Carvalho E.D., Antonio Filho O.C., Silva R.R., Araujo F.H., Diniz J.O., Silva A.C., Gattass M., Breast cancer diagnosis from histopathological images using textural features and CBIR, Artificial Intelligence in Medicine, 105, (2020); Wong K.K., Fortino G., Abbott D., Deep learning-based cardiovascular image diagnosis: A promising challenge, Future Generation Computer Systems, 110, pp. 802-811, (2020); Haripriya P., Porkodi R., Parallel deep convolutional neural network for content based medical image retrieval, Journal of Ambient Intelligence and Humanized, (2021); Haq N.F., Moradi M., Wang Z.J., A deep community based approach for large scale content based X-ray image retrieval, Medical Image Analysis, 68, (2020); Ismail W.N., Hassan M.M., Alsalamah H.A., Fortino G., CNN-based health model for regular health factors analysis in internet-of-medical things environment, IEEE Access, 8, pp. 52541-52549, (2020); Karimi D., Dou H., Warfield S.K., Gholipour A., Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis, Medical Image Analysis, 65, (2020); Kaur P., Singh R.K., A panoramic view of content-based medical image retrieval system, 2020 International Conference on Intelligent Engineering and Management (ICIEM), pp. 187-192, (2020); Khan S.R., Sikandar M., Almogren A., Din I.U., Guerrieri A., Fortino G., IoMT-based computational approach for detecting brain tumor, Future Generation Computer Systems, 109, pp. 360-367, (2020); Kumar A., Kim J., Cai W., Fulham M., Feng D., Content-based medical image retrieval: A survey of applications to multidimensional and multimodality data, Journal of Digital Imaging, 26, 6, pp. 1025-1039, (2013); Kumar M., Singh M., CBMIR: Content Based Medical Image Retrieval System Using Texture and Intensity for Eye Images, (2016); Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., Sanchez C.I., A survey on deep learning in medical image analysis, Medical Image Analysis, 42, pp. 60-88, (2017); Lowe D.G., Object recognition from local scale-invariant features, Proceedings of the Seventh IEEE International Conference on Computer Vision, 2, pp. 1150-1157, (1999); Muhammad K., Khan S., Del Ser J., de Albuquerque V.H.C., Deep learning for multigrade brain tumor classification in smart healthcare systems: A prospective survey, IEEE Transactions on Neural Networks and Learning Systems, (2020); Piccialli F., Di Somma V., Giampaolo F., Cuomo S., Fortino G., A survey on deep learning in medicine: Why, how and when?, Information Fusion, 66, pp. 111-137, (2021); Pilevar A.H., CBMIR: Content-based image retrieval algorithm for medical image databases, Journal of Medical Signals and Sensors, 1, 1, (2011); Greenspan H., Pinhas A.T., Medical image categorization and retrieval for PACS using the GMM-KL framework, IEEE Transactions on Information Technology in Biomedicine, 11, 2, pp. 190-202, (2007); Alinsaif S., Lang J., Texture features in the Shearlet domain for histopathological image classification, BMC Medical Informatics and Decision Making, 20, 14, pp. 1-19, (2020); Alroobaea R., Rubaiee S., Bourouis S., Bouguila N., Alsufyani A., Bayesian inference framework for bounded generalized Gaussian-based mixture model and its application to biomedical images classification, International Journal of Imaging Systems and Technology, 30, 1, pp. 18-30, (2020); Asnaoui K.E., Chawki Y., Idri A., Automated Methods for Detection and Classification Pneumonia Based on X-Ray Images Using Deep Learning. Arxiv Preprint Arxiv, 2003, (2020); Ciompi F., de Hoop B., van Riel S.J., Chung K., Scholten E.T., Oudkerk M., van Ginneken B., Automatic classification of pulmonary peri-fissural nodules in computed tomography using an ensemble of 2D views and a convolutional neural network out-of-the-box, Medical Image Analysis, 26, 1, pp. 195-202, (2015); Setio A.A.A., Ciompi F., Litjens G., Gerke P., Jacobs C., van Riel S.J., van Ginneken B., Pulmonary nodule detection in CT images: False positive reduction using multi-view convolutional networks, IEEE Transactions on Medical Imaging, 35, 5, pp. 1160-1169, (2016); van Tulder G., de Bruijne M., Combining generative and discriminative representation learning for lung CT analysis with convolutional restricted Boltzmann machines, IEEE Transactions on Medical Imaging, 35, 5, pp. 1262-1272, (2016); Anthimopoulos M., Christodoulidis S., Ebner L., Christe A., Mougiakakou S., Lung pattern classification for interstitial lung diseases using a deep convolutional neural network, IEEE Transactions on Medical Imaging, 35, 5, pp. 1207-1216, (2016); Yan Z., Zhan Y., Peng Z., Liao S., Shinagawa Y., Zhang S., Zhou X.S., Multi-instance deep learning: Discover discriminative local anatomies for bodypart recognition, IEEE Transactions on Medical Imaging, 35, 5, pp. 1332-1343, (2016); Dou Q., Chen H., Yu L., Zhao L., Qin J., Wang D., Heng P.A., Automatic detection of cerebral microbleeds from MR images via 3D convolutional neural networks, IEEE Transactions on Medical Imaging, 35, 5, pp. 1182-1195, (2016); Chowdhury M., Bulo S.R., Moreno R., Kundu M.K., Smedby O., An efficient radiographic image retrieval system using convolutional neural network, 2016 23Rd International Conference on Pattern Recognition (ICPR), pp. 3134-3139, (2016); Qayyum A., Anwar S.M., Awais M., Majid M., Medical image retrieval using deep convolutional neural network, Neurocomputing, 266, pp. 8-20, (2017); Scherer R., Ditzinger S., Computer Vision Methods for Fast Image Classification and Retrieval, (2020); Amini A., Chen W., Fortino G., Li Y., Pan Y., Wang M.D., Editorial special issue on “AI-driven informatics, sensing, imaging and big data analytics for fighting the COVID-19 pandemic”, IEEE Journal of Biomedical and Health Informatics, 24, 10, pp. 2731-2732, (2020); Ahmed A., Implementing relevance feedback for content-based medical image retrieval, IEEE Access, 8, pp. 79969-79976, (2020); Swapna T., Kunnan S., Content-Based Image Retrieval System for Bio-Medical Images; Camalan S., Niazi M.K.K., Moberly A.C., Teknos T., Essig G., Elmaraghy C., Gurcan M.N., OtoMatch: Content-based eardrum image retrieval using deep learning, Plos One, 15, 5, (2020); Fallahi A.R., Pooyan M., Mohammadnejad H., Application of morphological operations in human brain CT image with SVM, 2009 3Rd International Conference on Bioinformatics and Biomedical Engineering, pp. 1-4, (2009); Garg M., Dhiman G., A novel content based image retrieval approach for classification using glcm features and texture fused lbp variants, Neural Computing and Applications, 33, pp. 1311-1328, (2021); Quelhas P., Monay F., Odobez J.M., Gatica-Perez D., Tuytelaars T., A thousand words in a scene, IEEE Transactions on Pattern Analysis and Machine Intelligence, 29, 9, pp. 1575-1589, (2007); Nithya S., Shinelet G., Bio-medical image retrieval using SVM, International Journal of Advanced Research in Computer Engineering & Technology (IJARCET), 1, 10, pp. 14-18, (2012); Alhindi T.J., Kalra S., Ng K.H., Afrin A., Tizhoosh H.R., Comparing LBP, HOG and deep features for classification of histopathology images, 2018 International Joint Conference on Neural Networks (IJCNN), pp. 1-7, (2018); Greeshma K.V., Sreekumar K., Hyperparameter Optimization and Regularization on Fashion-Mnist Classification, (2019); Bansal D., Khanna K., Chhikara R., Dua R.K., Malhotra R., Classification of magnetic resonance images using bag of features for detecting dementia, Procedia Computer Science, 167, pp. 131-137, (2020); Greeshma K.V., Gripsy J.V., Image Classification Using HOG and LBP Feature Descriptors with SVM and CNN, (2020); Wang Z., Wu D., Gravina R., Fortino G., Jiang Y., Tang K., Kernel fusion based extreme learning machine for cross-location activity recognition, Information Fusion, 37, pp. 1-9, (2017); Bay H., Tuytelaars T., van Gool L., Surf: Speeded up robust features, European Conference on Computer Vision, pp. 404-417, (2006); Govindaraju S., Kumar G.P.R., A novel content based medical image retrieval using SURF features, Indian Journal of Science and Technology, 9, 20, pp. 1-8, (2016)","K.V. Greeshma; Department of Computer Science (UG), PSGR Krishnammal College for Women, Coimbatore, India; email: greeshmakv@gmail.com","","Springer Science and Business Media Deutschland GmbH","","","","","","21991073","","","","English","Internet Things","Book chapter","Final","","Scopus","2-s2.0-85113298343"
"Baum Z.M.C.; Hu Y.; Barratt D.C.","Baum, Zachary M. C. (6506021565); Hu, Yipeng (24512208500); Barratt, Dean C. (7005201740)","6506021565; 24512208500; 7005201740","Multimodality Biomedical Image Registration Using Free Point Transformer Networks","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12437 LNCS","","","116","125","9","7","10.1007/978-3-030-60334-2_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092739402&doi=10.1007%2f978-3-030-60334-2_12&partnerID=40&md5=8afaf86e10aa2821ae3b2c6801e94a7c","Centre for Medical Image Computing and Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom","Baum Z.M.C., Centre for Medical Image Computing and Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom; Hu Y., Centre for Medical Image Computing and Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom; Barratt D.C., Centre for Medical Image Computing and Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom","We describe a point-set registration algorithm based on a novel free point transformer (FPT) network, designed for points extracted from multimodal biomedical images for registration tasks, such as those frequently encountered in ultrasound-guided interventional procedures. FPT is constructed with a global feature extractor which accepts unordered source and target point-sets of variable size. The extracted features are conditioned by a shared multilayer perceptron point transformer module to predict a displacement vector for each source point, transforming it into the target space. The point transformer module assumes no vicinity or smoothness in predicting spatial transformation and, together with the global feature extractor, is trained in a data-driven fashion with an unsupervised loss function. In a multimodal registration task using prostate MR and sparsely acquired ultrasound images, FPT yields comparable or improved results over other rigid and non-rigid registration methods. This demonstrates the versatility of FPT to learn registration directly from real, clinical training data and to generalize to a challenging task, such as the interventional application presented. © 2020, Springer Nature Switzerland AG.","Deep-learning; Point-set registration; Prostate cancer","Bioinformatics; Computer aided analysis; Geometry; Image enhancement; Medical imaging; Metadata; Multilayer neural networks; Pediatrics; Ultrasonics; Vector spaces; Biomedical image registration; Clinical training; Displacement vectors; Interventional procedures; Multimodal registration; Nonrigid registration method; Point-set registrations; Spatial transformation; Image analysis","","","","","Centre for Interventional and Surgical Sciences, (203145Z/16/Z); Natural Sciences and Engineering Research Council of Canada, NSERC; University College London, UCL","Acknowledgments. Z. Baum is supported by the Natural Sciences and Engineering Research Council of Canada Postgraduate Scholarships-Doctoral Program, the University College London Overseas and Graduate Research Scholarships. This work is also supported by the Wellcome/EPSRC Centre for Interventional and Surgical Sciences (203145Z/16/Z).","Maintz J.B., Viergever M.A., A survey of medical image registration, Med. Image Anal., 2, 5, pp. 1-36, (1998); Costa D.N., Pedrosa I., Donato F., Roehrborn C.G., Rofsky N.M., MR imaging-transrectal US fusion for targeted prostate biopsies: Implication for diagnosis and clinical management, Radiographics, 35, 3, pp. 696-708, (2015); Puech P., Et al., Prostate cancer diagnosis: Multiparametric MR-targeted biopsy with cognitive and transrectal US-MR fusion guidance versus systematic biopsy – prospective multicenter study, Radiology, 268, 2, pp. 461-469, (2013); Lavaerts M., de Wever L., Vanhoutte E., de Keyzer F., Oyen R., TRUS-MR fusion biopsy of the prostate: Radiological and histological correlation, J. Belg. Soc. Radiol., 100, 1, pp. 1-9, (2016); Valerio M., Et al., Detection of clinically significant prostate cancer using magnetic resonance imaging-ultrasound fusion targeted biopsy: A systematic review, Eur. Radiol., 68, 1, pp. 8-19, (2015); Karnik V.V., Et al., Assessment of image registration accuracy in three-dimensional transrectal ultrasound guided prostate biopsy, Med. Phys., 37, 2, pp. 802-813, (2010); Hu Y., Et al., MR to ultrasound registration for image-guided prostate interventions, Med. Image Anal., 16, 3, pp. 687-703, (2012); de Silva T., Et al., 2D-3D rigid registration to compensate for prostate motion during 3D TRUS-guided biopsy, Med. Phys, 40, 2, pp. 022904-22911, (2013); Hu Y., Et al., Weakly-supervised convolutional neural networks for multimodal image registration, Med. Image Anal., 49, pp. 1-13, (2018); Zhang S., Jiang S., Yang Z., Liu R., 2D ultrasound and 3D MR image reconstruction of the prostate for brachytherapy surgical navigation, Med. (Balt.), 94, 40, (2015); Gilles D.J., Gardi L., de Silva T., Zhao S.R., Fenster A., Real-time registration of 3D to 2D ultrasound images for image-guided prostate biopsy, Med. Phys., 44, 9, pp. 4708-4723, (2017); van Sloun R.J.G., Et al., Deep learning for real-time, automatic, and scanner adapted prostate (Zone) segmentation of transrectal ultrasound, for example, magnetic resonance imaging-transrectal ultrasound fusion prostate biopsy, Eur. Urol. Focus., (2019); Ghavami N., Et al., Integration of spatial information in convolutional neural networks for automatic segmentation of intraoperative transrectal ultrasound images, J. Med. Imaging, 6, 1, (2018); Besl P.J., McKay N.D., A method for registration of 3-D shapes, IEEE Trans. Pattern Anal. Mach. Intell., 14, 2, pp. 239-256, (1992); Myronenko A., Song X., Point set registration: Coherent point drift, IEEE Trans. Pattern Anal. Mach. Intell., 32, 12, pp. 2262-2275, (2010); Jian B., Vemuri B.C., Robust point set registration using gaussian mixture models, IEEE Trans. Pattern Anal. Mach. Intell., 33, 8, pp. 1633-1645, (2010); Chui H., Rangarajan A., A new point matching algorithm for non-rigid registration, Comput. Vis. Image Underst., 89, 2-3, pp. 114-141, (2003); Aoki Y., Goforth H., Srivatsan R.A., Lucey S., PointNetLK: Robust and efficient point cloud registration using PointNet, The IEEE Conference on Computer Vision and Pattern Recognition, pp. 7163-7172, (2019); Qi C.R., Su H., Mo K., Guibas L.J., PointNet: Deep learning on point sets for 3D classification and segmentation, The IEEE Conference on Computer Vision and Pattern Recognition, pp. 652-660, (2017); Fan H., Su H., Guibas L.J., A point set generation network for 3D object reconstruction from a single image, The IEEE Conference on Computer Vision and Pattern Recognition, pp. 605-613, (2017); Wu Z., Et al., 3D ShapeNets: A deep representation for volumetric shapes, The IEEE Conference on Computer Vision and Pattern Recognition, pp. 1912-1920, (2015); Pan S.J., Yang Q., A survey on transfer learning, IEEE Trans. Knowl. Data Eng., 22, 10, pp. 1345-1359, (2010); Donaldson I., Et al., MP33-20 the smart target biopsy trial: A prospective paired blinded trial with randomization to compare visual-estimation and image-fusion targeted prosate biopsies, J. Urol., 197, 4, (2017); Wein W., Brunke S., Khamene A., Callstrom M.R., Navab N., Automatic ct-ultrasound registration for diagnostic imaging and image-guided intervention, Med. Image Anal., 12, 5, pp. 577-585, (2008); Gueziri H.-E., Drouin S., Yan C.X.B., Collins D.L., Toward real-time rigid registration of intra-operative ultrasound with preoperative ct images for lumbar spinal fusion surgery, Int. J. Comput. Assist. Radiol. Surg., 14, 11, pp. 1933-1943, (2019); Wein W., Roper B., Navab N., Automatic registration and fusion of ultrasound with ct for radiotherapy, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 303-311, (2005)","Z.M.C. Baum; Centre for Medical Image Computing and Wellcome/EPSRC Centre for Interventional and Surgical Sciences, University College London, London, United Kingdom; email: zachary.baum.19@ucl.ac.uk","Hu Y.; Licandro R.; Noble J.A.; Hutter J.; Melbourne A.; Aylward S.; Abaci Turk E.; Torrents Barrena J.; Torrents Barrena J.","Springer Science and Business Media Deutschland GmbH","","1st International Workshop on Advances in Simplifying Medical UltraSound, ASMUS 2020, and the 5th International Workshop on Perinatal, Preterm and Paediatric Image Analysis, PIPPI 2020, held in conjunction with the 23rd International Conference on Medical Image Computing and Computer-Assisted Intervention, MICCAI 2020","4 October 2020 through 8 October 2020","Lima","249639","03029743","978-303060333-5","","","English","Lect. Notes Comput. Sci.","Conference paper","Final","","Scopus","2-s2.0-85092739402"
"Larrazabal A.J.; Martínez C.; Glocker B.; Ferrante E.","Larrazabal, Agostina J. (57208260242); Martínez, César (8118083200); Glocker, Ben (23396784900); Ferrante, Enzo (55892013900)","57208260242; 8118083200; 23396784900; 55892013900","Post-DAE: Anatomically Plausible Segmentation via Post-Processing with Denoising Autoencoders","2020","IEEE Transactions on Medical Imaging","39","12","9126830","3813","3820","7","44","10.1109/TMI.2020.3005297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092739004&doi=10.1109%2fTMI.2020.3005297&partnerID=40&md5=2370e176dd25be3b12b72b563fed9c85","Institute for Signals, Systems, and Computational Intelligence, Sinc(i), Conicet, Universidad Nacional Del Litoral (UNL), Santa Fe, 3000, Argentina; Biomedical Image AnalysisGroup, Imperial College London, London, SW7 2AZ, United Kingdom","Larrazabal A.J., Institute for Signals, Systems, and Computational Intelligence, Sinc(i), Conicet, Universidad Nacional Del Litoral (UNL), Santa Fe, 3000, Argentina; Martínez C., Institute for Signals, Systems, and Computational Intelligence, Sinc(i), Conicet, Universidad Nacional Del Litoral (UNL), Santa Fe, 3000, Argentina; Glocker B., Biomedical Image AnalysisGroup, Imperial College London, London, SW7 2AZ, United Kingdom; Ferrante E., Institute for Signals, Systems, and Computational Intelligence, Sinc(i), Conicet, Universidad Nacional Del Litoral (UNL), Santa Fe, 3000, Argentina","We introduce Post-DAE, a post-processing method based on denoising autoencoders (DAE) to improve the anatomical plausibility of arbitrary biomedical image segmentation algorithms. Some of the most popular segmentation methods (e.g. based on convolutional neural networks or random forest classifiers) incorporate additional post-processing steps to ensure that the resulting masks fulfill expected connectivity constraints. These methods operate under the hypothesis that contiguous pixels with similar aspect should belong to the same class. Even if valid in general, this assumption does not consider more complex priors like topological restrictions or convexity, which cannot be easily incorporated into these methods. Post-DAE leverages the latest developments in manifold learning via denoising autoencoders. First, we learn a compact and non-linear embedding that represents the space of anatomically plausible segmentations. Then, given a segmentation mask obtained with an arbitrary method, we reconstruct its anatomically plausible version by projecting it onto the learnt manifold. The proposed method is trained using unpaired segmentation mask, what makes it independent of intensity information and image modality. We performed experiments in binary and multi-label segmentation of chest X-ray and cardiac magnetic resonance images. We show how erroneous and noisy segmentation masks can be improved using Post-DAE. With almost no additional computation cost, our method brings erroneous segmentations back to a feasible space. © 1982-2012 IEEE.","Anatomical segmentation; autoencoders; convolutional neural networks; learning representations; post-processing","Algorithms; Brain; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Bioinformatics; Convolutional neural networks; Decision trees; Image enhancement; Learning systems; Magnetic resonance; Magnetic resonance imaging; Processing; Biomedical image segmentation; Cardiac magnetic resonance images; Connectivity constraints; Intensity information; Latest development; Postprocessing methods; Random forest classifier; Segmentation methods; Article; cardiovascular magnetic resonance; deep learning; denoising autoencoder; human; image processing; image segmentation; quantitative analysis; random forest; segmentation algorithm; thorax radiography; algorithm; brain; diagnostic imaging; image processing; nuclear magnetic resonance imaging; Image segmentation","","","","","ANPyCT, (PICT 2016-0651, PICT 2018-03907); AXA Research Fund, AXA; Agencia Nacional de Promoción Científica y Tecnológica, ANPCyT; Universidad Nacional del Litoral, UNL, (CAID-PIC-50220140100084LI, CAID-PIC-50420150100098LI)","Manuscript received May 7, 2020; accepted June 22, 2020. Date of publication June 26, 2020; date of current version November 30, 2020. This work was supported in part by the Universidad Nacional del Litoral (UNL) under Grant CAID-PIC-50420150100098LI and Grant CAID-PIC-50220140100084LI, and in part by the Agencia Nacional de Promoción de la Investigación, el Desarrollo Tecnológico y la Inno-vación (ANPyCT) under Grant PICT 2016-0651 and Grant PICT 2018-03907. The work of Enzo Ferrante was supported by the AXA Research Fund through a grant. (Corresponding author: Enzo Ferrante.) Agostina J. Larrazabal, César Martínez, and Enzo Ferrante are with the Institute for Signals, Systems, and Computational Intelligence, sinc(i), CONICET, Universidad Nacional del Litoral (UNL), Santa Fe 3000, Argentina (e-mail: alarrazabal@sinc.unl.edu.ar; cmartinez@sinc.unl.edu.ar; eferrante@sinc.unl.edu.ar).","Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Proc. Miccai, pp. 234-241, (2015); Kamnitsas K., Et al., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation, Med. Image Anal., 36, pp. 61-78, (2017); Shakeri M., Et al., Sub-cortical brain structure segmentation using F-CNN'S, Proc. Ieee 13th Int. Symp. Biomed. Imag. (ISBI), pp. 269-272, (2016); BenTaieb A., Hamarneh G., Topology aware fully convolutional networks for histology gland segmentation, Proc. MICCAI., pp. 460-468, (2016); Breiman L., Random forests, Mach. Learn., 45, 1, pp. 5-32, (2001); Larrazabal A.J., Martinez C., Ferrante E., Anatomical priors for image segmentation via post-processing with denoising autoencoders, Proc. Miccai, pp. 585-593, (2019); Nosrati M.S., Hamarneh G., Incorporating Prior Knowledge in Medical Image Segmentation: A Survey, (2016); Oktay O., Et al., Anatomically constrained neural networks (ACNNs): Application to cardiac image enhancement and segmentation, Ieee Trans. Med. Imag., 37, 2, pp. 384-395, (2018); Ravishankar H., Venkataramani R., Thiruvenkadam S., Sudhakar P., Vaidya V., Learning and incorporating shape models for semantic segmentation, Proc. Miccai, pp. 203-211, (2017); Wachinger C., Brennan M., Sharp G., Golland P., On the importance of location and features for the patch-based segmentation of parotid glands, Proc. Miccai Workshop Image-Guided Adapt. Radiat. Therapy, pp. 1-8, (2014); Wachinger C., Reuter M., Klein T., DeepNAT: Deep convolutional neural network for segmenting neuroanatomy, NeuroImage, 170, pp. 434-445, (2018); Paragios N., Ferrante E., Glocker B., Komodakis N., Parisot S., Zacharaki E.I., Hyper-graphical models in biomedical image analysis, Med. Image Anal., 33, pp. 102-106, (2016); Dalca A.V., Guttag J., Sabuncu M.R., Anatomical priors in convolutional networks for unsupervised biomedical segmentation, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., pp. 9290-9299, (2018); Vincent P., Larochelle H., Lajoie I., Bengio Y., Manzagol P.-A., Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion, J. Mach. Learn. Res., 11, 12, pp. 3371-3408, (2010); Milletari F., Navab N., Ahmadi S.-A., V-net: Fully convolutional neural networks for volumetric medical image segmentation, Proc. 4th Int. Conf. 3D Vis. (3DV), pp. 565-571, (2016); Krahenbuhl P., Koltun V., Efficient inference in fully connected CRFs with Gaussian edge potentials, Proc. Nips, pp. 109-117, (2011); Chapelle O., Scholkopf B., Zien A., Semi-Supervised Learning., (2009); Pawlowski N., Et al., Unsupervised lesion detection in brain ct using Bayesian convolutional autoencoders, Proc. Midl, (2018); Uzunova H., Schultz S., Handels H., Ehrhardt J., Unsupervised pathology detection in medical images using conditional variational autoencoders, Int. J. Comput. Assist. Radiol. Surgery, 14, 3, pp. 451-461, (2019); Shiraishi J., Et al., Development of a digital image database for chest radiographs with and without a lung nodule: Receiver operating characteristic analysis of radiologists' detection of pulmonary nodules, Amer. J. Roentgenology, 174, 1, pp. 71-74, (2000); Radau P., Lu Y., Connelly K., Paul G., Dick A., Wright G., Evaluation framework for algorithms segmenting short axis cardiac MRI, Midas J., 49, (2009); Haralick R.M., Shanmugam K., Dinstein I., Textural features for image classification, Ieee Trans. Syst., Man, Cybern., SMC-3, 6, pp. 610-621, (1973); Glocker B., Zikic D., Konukoglu E., Haynor D.R., Criminisi A., Vertebrae localization in pathological spine CT via dense classification from sparse annotations, Proc. MICCAI., pp. 262-270, (2013); Frid-Adar M., Ben-Cohen A., Amer R., Greenspan H., Improving the segmentation of anatomical structures in chest radiographs using Unet with an imagenet pre-trained encoder, Image Analysis for Moving Organ, Breast, and Thoracic Images., pp. 159-168, (2018); Dai W., Dong N., Wang Z., Liang X., Zhang H., Xing E.P., SCAN: Structure correcting adversarial network for organ segmentation in chest X-rays, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support., pp. 263-273, (2018); Novikov A.A., Lenis D., Major D., Hladuvka J., Wimmer M., Buhler K., Fully convolutional architectures for multiclass segmentation in chest radiographs, Ieee Trans. Med. Imag., 37, 8, pp. 1865-1876, (2018); Mansilla L., Milone D.H., Ferrante E., Learning deformable registration of medical images with anatomical constraints, Neural Netw., 124, pp. 269-279, (2020); Zheng Q., Delingette H., Duchateau N., Ayache N., 3-D consistent and robust segmentation of cardiac images by deep learning with spatial propagation, Ieee Trans. Med. Imag., 37, 9, pp. 2137-2148, (2018); Curiale A.H., Colavecchia F.D., Mato G., Automatic quantification of the LV function and mass: A deep learning approach for cardiovascular MRI, Comput. Methods Programs Biomed., 169, pp. 37-50, (2019); Chen M., Fang L., Liu H., FR-NET: Focal loss constrained deep residual networks for segmentation of cardiac MRI, Proc. Ieee 16th Int. Symp. Biomed. Imag. (ISBI ), pp. 764-767, (2019); Stough J.V., DiPalma J., Ma Z., Fornwalt B.K., Haggerty C.M., Ventricular segmentation and quantitative assessment in cardiac MR using convolutional neural networks, Proc. Med. Imag., Biomed. Appl. Mol., Struct., Funct. Imag., (2018); Candemir S., Et al., Lung segmentation in chest radiographs using anatomical atlases with nonrigid registration, Ieee Trans. Med. Imag., 33, 2, pp. 577-590, (2014); Jaeger S., Et al., Automatic tuberculosis screening using chest radiographs, Ieee Trans. Med. Imag., 33, 2, pp. 233-245, (2014); Karargyris A., Et al., Combination of texture and shape features to detect pulmonary abnormalities in digital chest X-rays, Int. J. Comput. Assist. Radiol. Surg., 11, 1, pp. 99-106, (2016); Roulet N., Slezak D.F., Ferrante E., Joint learning of brain lesion and anatomy segmentation from heterogeneous datasets, Proc. Midl, pp. 401-413, (2019)","E. Ferrante; Institute for Signals, Systems, and Computational Intelligence, Sinc(i), Conicet, Universidad Nacional Del Litoral (UNL), Santa Fe, 3000, Argentina; email: eferrante@sinc.unl.edu.ar","","Institute of Electrical and Electronics Engineers Inc.","","","","","","02780062","","ITMID","32746125","English","IEEE Trans. Med. Imaging","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85092739004"
"Xing F.; Xie Y.; Su H.; Liu F.; Yang L.","Xing, Fuyong (38461688800); Xie, Yuanpu (56903340500); Su, Hai (44661704600); Liu, Fujun (55541334700); Yang, Lin (55771607100)","38461688800; 56903340500; 44661704600; 55541334700; 55771607100","Deep Learning in Microscopy Image Analysis: A Survey","2018","IEEE Transactions on Neural Networks and Learning Systems","29","10","8118310","4550","4568","18","280","10.1109/TNNLS.2017.2766168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035790459&doi=10.1109%2fTNNLS.2017.2766168&partnerID=40&md5=116e43fd3ab898ab2901ec2b8bfdb2a8","Department of Biostatistics and Informatics, Colorado School of Public Health, University of Colorado Denver, Denver, 80045, CO, United States; Department of Electrical and Computer Engineering, University of Florida, Gainesville, 32611, FL, United States; J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, 32611, FL, United States; Department of Electrical and Computer Engineering, J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, 32611, FL, United States","Xing F., Department of Biostatistics and Informatics, Colorado School of Public Health, University of Colorado Denver, Denver, 80045, CO, United States, Department of Electrical and Computer Engineering, University of Florida, Gainesville, 32611, FL, United States; Xie Y., J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, 32611, FL, United States; Su H., J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, 32611, FL, United States; Liu F., Department of Electrical and Computer Engineering, University of Florida, Gainesville, 32611, FL, United States; Yang L., Department of Electrical and Computer Engineering, J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, 32611, FL, United States","Computerized microscopy image analysis plays an important role in computer aided diagnosis and prognosis. Machine learning techniques have powered many aspects of medical investigation and clinical practice. Recently, deep learning is emerging as a leading machine learning tool in computer vision and has attracted considerable attention in biomedical image analysis. In this paper, we provide a snapshot of this fast-growing field, specifically for microscopy image analysis. We briefly introduce the popular deep neural networks and summarize current deep learning achievements in various tasks, such as detection, segmentation, and classification in microscopy image analysis. In particular, we explain the architectures and the principles of convolutional neural networks, fully convolutional networks, recurrent neural networks, stacked autoencoders, and deep belief networks, and interpret their formulations or modelings for specific tasks on various microscopy images. In addition, we discuss the open challenges and the potential trends of future research in microscopy image analysis using deep learning. © 2012 IEEE.","Classification; deep learning; detection; microscopy image analysis; segmentation","Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Image Processing, Computer-Assisted; Male; Microscopy; Neural Networks (Computer); Surveys and Questionnaires; Classification (of information); Computer aided analysis; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Error detection; Image segmentation; Learning systems; Medical imaging; Microscopic examination; Neural networks; Recurrent neural networks; Biomedical image analysis; Biomedical imaging; Convolutional networks; Convolutional neural network; Deep belief networks; Learning achievement; Machine learning techniques; Microscopy image analysis; algorithm; artificial neural network; computer assisted diagnosis; female; human; image processing; male; microscopy; procedures; questionnaire; Image analysis","","","","","","","Sommer C., Gerlich D.W., Machine learning in cell biology-Teaching computers to recognize phenotypes, J. Cell Sci, 126, 24, pp. 5529-5539, (2013); Wernick M.N., Yang Y., Brankov J.G., Yourganov G., Strother S.C., Machine learning in medical imaging, IEEE Signal Process. Mag, 27, 4, pp. 25-38, (2010); Nie L., Zhang L., Meng L., Song X., Chang X., Li X., Modeling disease progression via multisource multitask learners: A case study with alzheimers disease, IEEE Trans. Neural Netw. Learn. Syst, 28, 7, pp. 1508-1519, (2017); Grana M., Chyzhyk D., Image understanding applications of lattice autoassociative memories, IEEE Trans. Neural Netw. Learn. Syst, 27, 9, pp. 1920-1932, (2016); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, pp. 436-444, (2015); Goodfellow I., Bengio Y., Courville A., Deep Learning, (2016); Yuan Y., Mou L., Lu X., Scene recognition by manifold regularized deep learning architecture, IEEE Trans. Neural Netw. Learn. Syst, 26, 10, pp. 2222-2233, (2015); Chalasani R., Principe J.C., Context dependent encoding using convolutional dynamic networks, IEEE Trans. Neural Netw. Learn. Syst, 26, 9, pp. 1992-2004, (2015); Deng L., Yu D., Deep learning: Methods and applications, Found. Trends Signal Process, 3, 3-4, pp. 197-387, (2014); Siniscalchi S.M., Salerno V.M., Adaptation to new microphones using artificial neural networks with trainable activation functions, IEEE Trans. Neural Netw. Learn. Syst., 28, 8, pp. 1959-1965, (2017); Xing F., Yang L., Robust nucleus/cell detection and segmentation in digital pathology and microscopy images: A comprehensive review, IEEE Rev. Biomed. Eng, 9, pp. 234-263, (2016); Min S., Lee B., Yoon S., Deep learning in bioinformatics, Briefings Bioinform, 18, 5, pp. 851-869, (2017); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Proc. Adv. Neural Inf. Process. Syst, pp. 1097-1105, (2012); Hinton G., Et al., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups, IEEE Signal Process. Mag, 29, 6, pp. 82-97, (2012); Arganda-Carreras I., Et al., Crowdsourcing the creation of image segmentation algorithms for connectomics, Frontiers Neuroanatomy, 9, (2015); Veta M., Et al., Assessment of algorithms for mitosis detection in breast cancer histopathology images, Med. Image Anal, 20, 1, pp. 237-248, (2015); Ma J., Sheridan R.P., Liaw A., Dahl G.E., Svetnik V., Deep neural nets as a method for quantitative structure-Activity relationships, J. Chem. Inf. Model, 55, 2, pp. 263-274, (2015); LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc IEEE, 86, 11, pp. 2278-2324, (1998); Girshick R., Donahue J., Darrell T., Malik J., Rich feature hierarchies for accurate object detection and semantic segmentation, Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 580-587, (2014); Girshick R., Fast R-CNN, Proc IEEE Int. Conf. Comput. Vis, pp. 1440-1448, (2015); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3431-3440, (2015); Greenspan H., Van Ginneken B., Summers R.M., Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique, IEEE Trans. Med. Imag, 35, 5, pp. 1153-1159, (2016); LeCun Y., Kavukcuoglu K., Farabet C., Convolutional networks and applications in vision, Proc IEEE Int. Symp. Circuits Syst, pp. 253-256, (2010); Lee H., Grosse R., Ranganath R., Ng A.Y., Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations, Proc. 26th Int. Conf. Mach. Learn, pp. 609-616, (2009); Lee H., Grosse R., Ranganath R., Ng A.Y., Unsupervised learning of hierarchical representations with convolutional deep belief networks, Commun ACM, 54, 10, pp. 95-103, (2011); Schmidhuber J., Deep learning in neural networks: An overview, Neural Netw, 61, pp. 85-117, (2015); Nielsen M.A., Neural Networks and Deep Learning, (2015); Arel I., Rose D.C., Karnowski T.P., Deep machine learning-A new frontier in artificial intelligence research [research frontier], IEEE Comput. Intell. Mag, 5, 4, pp. 13-18, (2010); Bengio Y., Learning deep architectures for AI, Found. Trends Mach. Learn, 2, 1, pp. 1-127, (2009); Bengio Y., Courville A., Vincent P., Representation learning: A review and new perspectives, IEEE Trans. Pattern Anal. Mach. Intell, 35, 8, pp. 1798-1828, (2013); Litjens G., Et al., Anchez A survey on deep learning in medical image analysis, Med. Image Anal, 42, pp. 60-88, (2017); Gurcan M.N., Boucheron L.E., Can A., Madabushi A., Rajpoot N.M., Yener B., Histopathological image analysis: A review, IEEE Rev. Biomed. Eng, 2, pp. 147-171, (2009); McCann M.T., Ozolek J.A., Castro C.A., Parvin B., Kovacevic J., Automated histology analysis: Opportunities for signal processing, IEEE Signal Process. Mag, 32, 1, pp. 78-87, (2015); Veta M., Pluim J., Van Diest P., Viergever M., Breast cancer histopathology image analysis: A review, IEEE Trans. Biomed. Eng, 61, 5, pp. 1400-1411, (2014); Irshad H., Veillard A., Roux L., Racoceanu D., Methods for nuclei detection, segmentation, and classification in digital histopathology: A review-Current status and future potential, IEEE Rev. Biomed. Eng, 7, pp. 97-114, (2014); Veta M., Van Diest P.J., Pluim J.P.W., Cutting out the middleman: Measuring nuclear area in histopathology slides without segmentation, Proc. 19th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 632-639, (2016); Xu Z., Huang J., Detecting 10, 000 cells in one second, Proc. 19th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 676-684, (2016); Ciresan D.C., Giusti A., Gambardella L.M., Schmidhuber J., Mitosis detection in breast cancer histology images with deep neural networks, Proc. 16th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, 8150, pp. 411-418, (2013); Xing F., Xie Y., Yang L., An automatic learning-based framework for robust nucleus segmentation, IEEE Trans. Med. Imag, 35, 2, pp. 550-566, (2016); Liu F., Yang L., A novel cell detection method using deep convolutional neural network and maximum-weight independent set, Proc. 18th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, 9351, pp. 349-357, (2015); Xie Y., Xing F., Kong X., Yang L., Beyond classification: Structured regression for robust cell detection using convolutional neural network, Proc. 18th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, 9351, pp. 358-365, (2015); Xie W., Noble J.A., Zisserman A., Microscopy cell counting with fully convolutional regression networks, Proc. 1st Workshop Deep Learn. Med. Image Anal. (MICCAI), pp. 1-8, (2015); Xie Y., Kong X., Xing F., Liu F., Su H., Yang L., Deep voting: A robust approach toward nucleus localization in microscopy images, Proc. 18th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, 9351, pp. 374-382, (2015); Albarqouni S., Baur C., Achilles F., Belagiannis V., Demirci S., Navab N., AggNet: Deep learning from crowds for mitosis detection in breast cancer histology images, IEEE Trans. Med. Imag, 35, 5, pp. 1313-1321, (2016); Xu J., Et al., Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images, IEEE Trans. Med. Imag, 35, 1, pp. 119-130, (2016); Razavian A.S., Azizpour H., Sullivan J., Carlsson S., CNN features off-The-shelf: An astounding baseline for recognition, Proc IEEE Conf. Comput. Vis. Pattern Recognit. Workshops, pp. 512-519, (2014); Tajbakhsh N., Et al., Convolutional neural networks for medical image analysis: Full training or fine tuning?, IEEE Trans. Med. Imag, 35, 5, pp. 1299-1312, (2016); Wu J., Leng C., Wang Y., Hu Q., Cheng J., Quantized convolutional neural networks for mobile devices, Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 4820-4828, (2016); Cong J., Xiao B., Minimizing computation in convolutional neural networks, Proc. 24th Int. Conf. Artif. Neural Netw. Artif. Neural Netw. Mach. Learn. (ICANN), pp. 281-290, (2014); Goodfellow I.J., Warde-Farley D., Mirza M., Courville A., Bengio Y., Maxout networks, Proc. 30th Int. Conf. Int. Conf. Mach. Learn, 28, pp. III1319-III1327, (2013); Graves A., Fernandez S., Schmidhuber J., Multi-dimensional recurrent neural networks, Proc. 17th Int. Conf. Artif. Neural Netw, pp. 549-558, (2007); Graves A., Schmidhuber J., Offline handwriting recognition with multidimensional recurrent neural networks, Proc. Adv. Neural Inf. Process. Syst, pp. 545-552, (2009); Byeon W., Breuel T.M., Raue F., Liwicki M., Scene labeling with LSTM recurrent neural networks, Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3547-3555, (2015); Xie Y., Zhang Z., Sapkota M., Yang L., Spatial clockwork recurrent neural network for muscle perimysium segmentation, Proc. 19th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, 9901, pp. 185-193, (2016); Roux L., Et al., Mitosis detection in breast cancer histological images an ICPR 2012 contest, J. Pathol. Inform, 4, 1, pp. 1-8, (2013); Xing F., Yang L., Fast cell segmentation using scalable sparse manifold learning and affine transform-Approximated active contour, Proc. 18th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, 9351, pp. 332-339, (2015); Xing F., Shi X., Zhang Z., Cai J., Xie Y., Yang L., Transfer shape modeling towards high-Throughput microscopy image segmentation, Proc. 19th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent. (MICCAI), 9902, pp. 183-190, (2016); Mao Y., Yin Z., Schober J.M., Iteratively training classifiers for circulating tumor cell detection, Proc IEEE 12th Int. Symp. Biomed. Imag, pp. 190-194, (2015); Wang J., MacKenzie J.D., Ramachandran R., Chen D.Z., Neutrophils identification by deep learning and Voronoi diagram of clusters, Proc. 18th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 226-233, (2015); Dong B., Shao L., Da Costa M., Bandmann O., Frangi A.F., Deep learning for automatic cell detection in wide-field microscopy zebrafish images, Proc IEEE 12th Int. Symp. Biomed. Imag, pp. 772-776, (2015); Shkolyar A., Gefen A., Benayahu D., Greenspan H., Automatic detection of cell divisions (mitosis) in live-imaging microscopy images using convolutional neural networks, Proc. 37th Annu. Int. Conf IEEE Eng. Med. Biol. Soc, pp. 743-746, (2015); Sirinukunwattana K., Raza S.E.A., Tsang Y.-W., Snead D.R.J., Cree I.A., Rajpoot N.M., Locality sensitive deep learning for detection and classification of nuclei in routine colon cancer histology images, IEEE Trans. Med. Imag, 35, 5, pp. 1196-1206, (2016); Lempitsky V., Zisserman A., Learning to count objects in images, Proc. Adv. Neural Inf. Process. Syst, pp. 1324-1332, (2010); Van Grinsven M.J.J.P., Van Ginneken B., Hoyng C.B., Theelen T., Sanchez C.I., Fast convolutional neural network training using selective data sampling: Application to hemorrhage detection in color fundus images, IEEE Trans. Med. Imag, 35, 5, pp. 1273-1284, (2016); Meijering E., Cell segmentation: 50 years down the road, IEEE Signal Process. Mag, 29, 5, pp. 140-145, (2012); Ciresan D., Giusti A., Gambardella L.M., Schmidhuber J., Deep neural networks segment neuronal membranes in electron microscopy images, Proc. Adv. Neural Inf. Process. Syst, pp. 2843-2851, (2012); Fakhry A., Peng H., Ji S., Deep models for brain em image segmentation: Novel insights and improved performance, Bioinformtics, 32, 15, pp. 2352-2358, (2016); Liu T., Seyedhosseini M., Ellisman M., Tasdizen T., Watershed merge forest classification for electron microscopy image stack segmentation, Proc IEEE Int. Conf. Image Process, pp. 4069-4073, (2013); Ning F., Delhomme D., LeCun Y., Piano F., Bottou L., Barbano P.E., Toward automatic phenotyping of developing embryos from videos, IEEE Trans. Image Process, 14, 9, pp. 1360-1371, (2005); Song Y., Zhang L., Chen S., Ni D., Lei B., Wang T., Accurate segmentation of cervical cytoplasm and nuclei based on multiscale convolutional network and graph partitioning, IEEE Trans. Biomed. Eng, 62, 10, pp. 2421-2433, (2015); Boykov Y., Kolmogorov V., An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision, IEEE Trans. Pattern Anal. Mach. Intell, 26, 9, pp. 1124-1137, (2004); Su H., Liu F., Xie Y., Xing F., Meyyappan S., Yang L., Region segmentation in histopathological breast cancer images using deep convolutional neural network, Proc IEEE 12th Int. Symp. Biomed. Imag, pp. 55-58, (2015); Sapkota M., Xing F., Su H., Yang L., Automatic muscle perimysium annotation using deep convolutional neural network, Proc IEEE 12th Int. Symp. Biomed. Imag, pp. 205-208, (2015); Su H., Xing F., Kong X., Xie Y., Zhang S., Yang L., Robust cell detection and segmentation in histopathological images using sparse reconstruction and stacked denoising autoencoders, Proc. 18th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, 9351, pp. 383-390, (2015); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Proc. 18th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, 9351, pp. 234-241, (2015); Dosovitskiy A., Springenberg J.T., Riedmiller M., Brox T., Discriminative unsupervised feature learning with convolutional neural networks, Proc. Adv. Neural Inf. Process. Syst, pp. 766-774, (2014); Maska M., Et al., A benchmark for comparison of cell tracking algorithms, Bioinformatics, 30, 11, pp. 1609-1617, (2014); Chen H., Qi X., Cheng J., Heng P.A., Deep contextual networks for neuronal structure segmentation, Proc. 13th AAAI Conf. Artif. Intell, pp. 1167-1173, (2016); Bengio Y., Lamblin P., Popovici D., Larochelle H., Greedy layerwise training of deep networks, Proc. Adv. Neural Inf. Process. Syst, 19, pp. 153-160, (2007); Lee C.Y., Xie S., Gallagher P.W., Zhang Z., Tu Z., Deeplysupervised nets, Proc. 18th Int. Conf. Artif. Intell. Statist, pp. 562-570, (2015); Li J., Mei X., Prokhorov D., Tao D., Deep neural network for structural prediction and lane detection in traffic scene, IEEE Trans. Neural Netw. Learn. Syst, 28, 3, pp. 690-703, (2017); Deng Y., Bao F., Kong Y., Ren Z., Dai Q., Deep direct reinforcement learning for financial signal representation and trading, IEEE Trans. Neural Netw. Learn. Syst, 28, 3, pp. 653-664, (2017); Zhang Y., Yamaguchi R., Imoto S., Miyano S., Sequence-specific bias correction for RNA-seq data using recurrent neural networks, BMC Genomics, 18, 1, pp. 1-6, (2017); Hochreiter S., Heusel M., Obermayer K., Fast model-based protein homology detection without alignment, Bioinformatics, 23, 14, pp. 1728-1736, (2007); Davidson P.R., Jones R.D., Peiris M.T.R., EEG-based lapse detection with high temporal resolution, IEEE Trans. Biomed. Eng, 54, 5, pp. 832-839, (2007); Stollenga M.F., Byeon W., Liwicki M., Schmidhuber J., Parallel multi-dimensional lstm, with application to fast biomedical volumetric image segmentation, Proc. Adv. Neural Inf. Process. Syst, 28, pp. 2980-2988, (2015); Koutnik J., Greff K., Gomez F., Schmidhuber J., A clockwork RNN, Proc. 31st Int. Conf. Mach. Learn, 32, pp. 1863-1871, (2014); Hochreiter S., Schmidhuber J., Long short-Term memory, Neural Comput, 9, 8, pp. 1735-1780, (1997); Vincent P., Larochelle H., Lajoie I., Bengio Y., Manzagol P.-A., Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion, J. Mach. Learn. Res, 11, 12, pp. 3371-3408, (2010); Ranzato M., Boureau Y., LeCun Y., Sparse feature learning for deep belief networks, Proc. Adv. Neural Inf. Process. Syst, 20, pp. 1185-1192, (2007); Gao Z., Wang L., Zhou L., Zhang J., HEp-2 cell image classification with deep convolutional neural networks, IEEE J. Biomed. Health Inform, 21, 2, pp. 416-428, (2017); Chen C.L., Et al., Deep learning in label-free cell classification, Sci. Rep, 6, (2016); Carneiro G., Peng T., Bayer C., Navab N., Weakly-supervised structured output learning with flexible and latent graphs using highorder loss functions, Proc IEEE Int. Conf. Comput. Vis, pp. 648-656, (2015); Xu Y., Jia Z., Ai Y., Zhang F., Lai M., Chang E.I.-C., Deep convolutional activation features for large scale brain tumor histopathology image classification and segmentation, Proc IEEE Int. Conf. Acoust., Speech Signal Process, pp. 947-951, (2015); Russakovsky O., Et al., ImageNet large scale visual recognition challenge, Int. J. Comput. Vis, 115, 3, pp. 211-252, (2015); Boureau Y.-L., Ponce J., LeCun Y., A theoretical analysis of feature pooling in visual recognition, Proc. 27th Int. Conf. Mach. Learn, pp. 1-8, (2010); Xu Y., Mo T., Feng Q., Zhong P., Lai M., Chang E.I.-C., Deep learning of feature representation with multiple instance learning for medical image analysis, Proc IEEE Int. Conf. Acoust., Speech Signal Process, pp. 1626-1630, (2014); Maron O., Lozano-Perez T., A framework for multiple-instance learning, Proc. Adv. Neural Inf. Process. Syst, 10, pp. 570-576, (1998); Viola P.A., Platt J.C., Zhang C., Multiple instance boosting for object detection, Proc. Adv. Neural Inf. Process. Syst, 18, pp. 1417-1426, (2007); Cruz-Roa A.A., Ovalle J.E.A., Madabhushi A., Osorio F.A.G., A deep learning architecture for image representation, visual interpretability and automated basal-cell carcinoma cancer detection, Proc. 16th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 403-410, (2013); Kavukcuoglu K., Ranzato M., LeCun Y., Fast Inference in Sparse Coding Algorithms with Applications to Object Recognition, (2010); Chang H., Nayak N., Spellman P.T., Parvin B., Characterization of tissue histopathology via predictive sparse decomposition and spatial pyramid matching, Proc. 16th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 91-98, (2013); Chang H., Zhou Y., Spellman P., Parvin B., Stacked predictive sparse coding for classification of distinct regions of tumor histopathology, Proc IEEE Int. Conf. Comput. Vis, pp. 169-176, (2013); Pati Y.C., Rezaiifar R., Krishnaprasad P.S., Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition, Proc. Conf. Rec. 27th Asilomar Conf. Signals, Syst. Comput, 1, pp. 40-44, (1993); Nitta T., Resolution of singularities introduced by hierarchical structure in deep neural networks, IEEE Trans. Neural Netw. Learn. Syst, 28, 10, pp. 2282-2293, (2017); Bianchini M., Scarselli F., On the complexity of neural network classifiers: A comparison between shallow and deep architectures, IEEE Trans. Neural Netw. Learn. Syst, 25, 8, pp. 1553-1565, (2014); Szymanski L., McCane B., Deep networks are effective encoders of periodicity, IEEE Trans. Neural Netw. Learn. Syst, 25, 10, pp. 1816-1827, (2014); Le Roux N., Bengio Y., Representational power of restricted Boltzmann machines and deep belief networks, Neural Comput, 20, 6, pp. 1631-1649, (2008); Sutskever I., Hinton G.E., Deep, narrow sigmoid belief networks are universal approximators, Neural Comput, 20, 11, pp. 2629-2636, (2008); Chang C.-H., Deep and shallow architecture of multilayer neural networks, IEEE Trans. Neural Netw. Learn. Syst, 26, 10, pp. 2477-2486, (2015); Brahma P.P., Wu D., She Y., Why deep learning works: A manifold disentanglement perspective, IEEE Trans. Neural Netw. Learn. Syst, 27, 10, pp. 1997-2008, (2016); Shao L., Wu D., Li X., Learning deep and wide: A spectral method for learning deep networks, IEEE Trans. Neural Netw. Learn. Syst, 25, 12, pp. 2303-2308, (2014); Li J., Zhang T., Luo W., Yang J., Yuan X.-T., Zhang J., Sparseness analysis in the pretraining of deep neural networks, IEEE Trans. Neural Netw. Learn. Syst, 28, 6, pp. 1425-1438, (2017); Gong M., Liu J., Li H., Cai Q., Su L., A multiobjective sparse feature learning model for deep neural networks, IEEE Trans. Neural Netw. Learn. Syst, 26, 12, pp. 3263-3277, (2015); Erhan D., Courville A., Bengio Y., Understanding Representations Learned in Deep Architectures, (2010); Szegedy C., Et al., Intriguing Properties of Neural Networks, (2014); Mahendran A., Vedaldi A., Understanding deep image representations by inverting them, Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 5188-5196, (2015); Zeiler M.D., Fergus R., Visualizing and understanding convolutional networks, Proc. 13th Eur. Conf. Comput. Vis. (ECCV), pp. 818-833, (2014); Simonyan K., Vedaldi A., Zisserman A., Deep inside convolutional networks: Visualising image classification models and saliency maps, Proc. Int. Conf. Learn. Represent. Workshop, pp. 1-8, (2014); Bach S., Binder A., Montavon G., Klauschen F., Moller K.-R., Samek W., On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation, PLoS ONE, 10, 7, (2015); Samek W., Binder A., Montavon G., Lapuschkin S., Moller K.-R., Evaluating the visualization of what a deep neural network has learned, IEEE Trans. Neural Netw. Learn. Syst, 28, 11, pp. 2660-2673, (2017); Le Q.V., Ngiam J., Coates A., Lahiri A., Prochnow B., Ng A.Y., On optimization methods for deep learning, Proc. 28th Int. Conf. Mach. Learn, pp. 265-272, (2011); Jia Y., Et al., Caffe: Convolutional Architecture for Fast Feature Embedding, (2014); Theano: A Python Framework for Fast Computation of Mathematical Expressions, (2016); Abadi M., Et al., TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. Accessed, (2015); Collobert R., Kavukcuoglu K., Farabet C., Torch7: A MATLABlike environment for machine learning, Proc. BigLearn, NIPS Workshop, pp. 1-6, (2011); Dean J., Et al., Large scale distributed deep networks, Proc. Adv. Neural Inf. Process. Syst, 25, pp. 1223-1231, (2012); Raina R., Madhavan A., Ng A.Y., Large-scale deep unsupervised learning using graphics processors, Proc. 26th Annu. Int. Conf. Mach. Learn, pp. 873-880, (2009); Li M., Et al., Scaling distributed machine learning with the parameter server, Proc. 11th USENIX Symp. Oper. Syst. Design Implement, pp. 583-598, (2014); Recht B., Re C., Wright S., Niu F., Hogwild: A lock-free approach to parallelizing stochastic gradient descent, Proc. Adv. Neural Inf. Process. Syst, 24, pp. 693-701, (2011); Coates A., Huval B., Wang T., Wu D.J., Ng A.Y., Catanzaro B., Deep learning with COTS HPC systems, Proc. 30th Int. Conf. Mach. Learn, pp. 1337-1345, (2013); Nickolls J., Buck I., Garland M., Skadron K., Scalable parallel programming with CUDA, Queue, 6, 2, pp. 40-53, (2008); Chetlur S., Et al., CuDNN: Efficient Primitives for Deep Learning, (2014); Young S., Lu J., Holleman J., Arel I., On the impact of approximate computation in an analog DeSTIN architecture, IEEE Trans. Neural Netw. Learn. Syst, 25, 5, pp. 934-946, (2014); Farabet C., Poulet C., LeCun Y., An FPGA-based stream processor for embedded real-Time vision with convolutional networks, Proc IEEE 12th Int. Conf. Comput. Vis. Workshops, pp. 878-885, (2009); Yan C., Et al., Efficient parallel framework for HEVC motion estimation on many-core processors, IEEE Trans. Circuits Syst. Video Technol, 24, 12, pp. 2077-2089, (2014); Yan C., Et al., A highly parallel framework for HEVC coding unit partitioning tree decision on many-core processors, IEEE Signal Process. Lett, 21, 5, pp. 573-576, (2014); Yan C., Zhang Y., Dai F., Wang X., Li L., Dai Q., Parallel deblocking filter for HEVC on many-core processor, Electron. Lett, 50, 5, pp. 367-368, (2014); Yan C., Zhang Y., Dai F., Zhang J., Li L., Dai Q., Efficient parallel HEVC intra-prediction on many-core processor, Electron. Lett, 50, 11, pp. 805-806, (2014); Yan C., Zhang Y., Dai F., Li L., Highly parallel framework for HEVC motion estimation on many-core platform, Proc. Data Compress. Conf DCC, pp. 63-72, (2013); Lacey G., Taylor G.W., Areibi S., Deep Learning on FPGAS: Past, Present, and Future, (2016); Dundar A., Jin J., Martini B., Culurciello E., Embedded streaming deep neural networks accelerator with applications, IEEE Trans. Neural Netw. Learn. Syst, 28, 7, pp. 1572-1583, (2017); Cox C.E., Blanz W.E., GANGLION-A fast field-programmable gate array implementation of a connectionist classifier, IEEE J. Solid-State Circuits, 27, 3, pp. 288-299, (1992); Paul K., Rajopadhye S., Back-propagation algorithm achieving 5 GOPS on the Virtex-E, FPGA Implementations of Neural Networks, pp. 137-165, (2006); Ovtcharov K., Ruwase O., Kim J.-Y., Fowers J., Strauss K., Chung E.S., Accelerating Deep Convolutional Neural Networks Using Specialized Hardware, (2015); Zhang C., Li P., Sun G., Guan Y., Xiao B., Cong J., Optimizing FPGA-based accelerator design for deep convolutional neural networks, Proc ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays (FPGA), pp. 161-170, (2015); Qiu J., Et al., Going deeper with embedded FPGA platform for convolutional neural network, Proc ACM/SIGDA Int. Symp. Field-Programmable Gate Arrays (FPGA), pp. 26-35, (2016); Farabet C., Martini B., Akselrod P., Talay S., LeCun Y., Culurciello E., Hardware accelerated convolutional neural networks for synthetic vision systems, Proc IEEE Int. Symp. Circuits Syst, pp. 257-260, (2010); Reagen B., Et al., Minerva: Enabling low-power, highly-Accurate deep neural network accelerators, Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit, pp. 267-278, (2016); Chen Y.-H., Krishna T., Emer J.S., Sze V., Eyeriss: An energyefficient reconfigurable accelerator for deep convolutional neural networks, IEEE Int. Solid-State Circuits Conf. (ISSCC) Dig. Tech. Papers, pp. 262-263, (2016); Stromatias E., Neil D., Galluppi F., Pfeiffer M., Liu S.-C., Furber S., Scalable energy-efficient, low-latency implementations of trained spiking deep belief networks on SpiNNaker, Proc. Int. Joint Conf. Neural Netw, pp. 1-8, (2015); Han S., Et al., EIE: Efficient inference engine on compressed deep neural network, Proc. ACM/IEEE 43rd Annu. Int. Symp. Comput. Archit, pp. 243-254, (2016); Tensor Processing Unit, (2016); Krishna R., Et al., Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations, (2016); Shin H.-C., Lu L., Kim L., Seff A., Yao J., Summers R.M., Interleaved text/image deep mining on a large-scale radiology database for automated image interpretation, J. Mach. Learn. Res, 17, 1, pp. 3729-3759, (2016); Geman D., Geman S., Hallonquist N., Younes L., Visual Turing test for computer vision systems, Proc. Nat. Acad. Sci. USA, 112, 12, pp. 3618-3623, (2015); Malinowski M., Fritz M., A multi-world approach to question answering about real-world scenes based on uncertain input, Proc. Adv. Neural Inf. Process. Syst, 27, pp. 1682-1690, (2014); Tu K., Meng M., Lee M.W., Choe T.E., Zhu S.-C., Joint video and text parsing for understanding events and answering queries, IEEE Multimedia, 21, 2, pp. 42-70, (2014); Antol S., Et al., VQA: Visual question answering, Proc IEEE Int. Conf. Comput. Vis, pp. 2425-2433, (2015); Malinowski M., Rohrbach M., Fritz M., Ask your neurons: A neural-based approach to answering questions about images, Proc IEEE Int. Conf. Comput. Vis, pp. 1-9, (2015); Madabhushi A., Lee G., Image analysis and machine learning in digital pathology: Challenges and opportunities, Med. Image Anal, 33, pp. 170-175, (2016); Kothari S., Phan J.H., Stokes T.H., Wang M.D., Pathology imaging informatics for quantitative analysis of whole-slide images, J. Amer. Med. Inform. Assoc, 20, 6, pp. 1099-1108, (2013); Wu H.-S., Et al., Restoration of distorted colour microscopic images from transverse chromatic aberration of imperfect lenses, J. Microsc, 241, 2, pp. 125-131, (2011); Khan A.M., Rajpoot N., Treanor D., Magee D., A nonlinear mapping approach to stain normalization in digital histopathology images using image-specific color deconvolution, IEEE Trans. Biomed. Eng, 61, 6, pp. 1729-1738, (2014); Kothari S., Phan J.H., Wang M.D., Scale normalization of histopathological images for batch invariant cancer diagnostic models, Proc. Annu. Int. Conf IEEE Eng. Med. Biol. Soc., pp. 4406-4409, (2012); Bejnordi B.E., Et al., Stain specific standardization of whole-slide histopathological images, IEEE Trans. Med. Imag, 35, 2, pp. 404-415, (2016); Janowczyk A., Basavanhally A., Madabhushi A., Stain normalization using sparse AutoEncoders (StaNoSA): Application to digital pathology, Comput. Med. Imag. Graph, 57, pp. 50-61, (2017); Ciompi F., Et al., The importance of stain normalization in colorectal tissue classification with convolutional networks, Proc IEEE 14th Int. Symp. Biomed. Imag, pp. 160-163, (2017); Xing F., Yang L., Robust selection-based sparse shape model for lung cancer image segmentation, Proc. Int. Conf. Med. Image Comput. Comput. Assist. Intervent. (MICCAI), 8151, pp. 404-412, (2013); The Cancer Genome Altas, (2017); Lonsdale J., Et al., The genotype-Tissue expression (GTEx) project, Nature Genet, 45, 6, pp. 580-585, (2013); Ciresan D., Meier U., Schmidhuber J., Multi-column deep neural networks for image classification, Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3642-3649, (2012); Weese J., Lorenz C., Four challenges in medical image analysis from an industrial perspective, Med. Image Anal, 33, pp. 44-49, (2016); Howe J., The rise of crowdsourcing, Wired Mag, 14, 6, pp. 1-4, (2006); Estelles-Arolas E., Gonzalez-Ladron-De-Guevara F., Towards an integrated crowdsourcing definition, J. Inf. Sci, 38, 2, pp. 189-200, (2012); Hinton G.E., Osindero S., Teh Y.-W., A fast learning algorithm for deep belief nets, Neural Comput, 18, 7, pp. 1527-1554, (2006); Erhan D., Bengio Y., Courville A., Manzagol P.-A., Vincent P., Bengio S., Why does unsupervised pre-Training help deep learning?, J. Mach. Learn. Res, 11, pp. 625-660, (2010); Hinton G.E., Salakhutdinov R.R., Reducing the dimensionality of data with neural networks, Science, 313, 5786, pp. 504-507, (2006); Hou W., Gao X., Tao D., Li X., Blind image quality assessment via deep learning, IEEE Trans. Neural Netw. Learn. Syst, 26, 6, pp. 1275-1286, (2015); Stuhlsatz A., Lippel J., Zielke T., Feature extraction with deep neural networks by a generalized discriminant analysis, IEEE Trans. Neural Netw. Learn. Syst, 23, 4, pp. 596-608, (2012); Goh H., Thome N., Cord M., Lim J.-H., Learning deep hierarchical visual feature coding, IEEE Trans. Neural Netw. Learn. Syst, 25, 12, pp. 2212-2225, (2014); Yosinski J., Clune J., Bengio Y., Lipson H., How transferable are features in deep neural networks?, Proc. Adv. Neural Inf. Process. Syst, 27, pp. 3320-3328, (2014); Shin H.-C., Et al., Deep convolutional neural networks for computeraided detection: CNN architectures, dataset characteristics and transfer learning, IEEE Trans. Med. Imag, 35, 5, pp. 1285-1298, (2016); Freund Y., Seung H.S., Shamir E., Tishby N., Selective sampling using the query by committee algorithm, Mach. Learn, 28, 2, pp. 133-168, (1997); Lin M., Tang K., Yao X., Dynamic sampling approach to training neural networks for multiclass imbalance classification, IEEE Trans. Neural Netw. Learn. Syst, 24, 4, pp. 647-660, (2013); Elkan C., The foundations of cost-sensitive learning, Proc. 17th Int. Joint Conf. Artif. Intell, 2, pp. 973-978, (2001); Kukar M., Kononenko I., Cost-sensitive learning with neural networks, Proc. 13th Eur. Conf. Artif. Intell, pp. 445-449, (1998); Zhou Z.-H., Liu X.-Y., Training cost-sensitive neural networks with methods addressing the class imbalance problem, IEEE Trans. Knowl. Data Eng, 18, 1, pp. 63-77, (2006); Castro C.L., Braga A.P., Novel cost-sensitive approach to improve the multilayer perceptron performance on imbalanced data, IEEE Trans. Neural Netw. Learn. Syst, 24, 6, pp. 888-899, (2013); He H., Garcia E.A., Learning from imbalanced data, IEEE Trans. Knowl. Data Eng, 21, 9, pp. 1263-1284, (2009); He H., Ma Y., Imbalanced Learning: Foundations, Algorithms, and Applications, (2013); Paech D.C., Et al., A systematic review of the interobserver variability for histology in the differentiation between squamous and nonsquamous non-small cell lung cancer, J. Thoracic Oncol, 6, 1, pp. 55-63, (2011); Hou L., Samaras D., Kurc T.M., Gao Y., Davis J.E., Saltz J.H., Patch-based convolutional neural network for whole slide tissue image classification, Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 2424-2433, (2016); Korbar B., Et al., Deep learning for classification of colorectal polyps on whole-slide images, J. Pathol. Inform, 8, 1, (2017); Zhu X., Yao J., Zhu F., Huang J., WSISA: Making survival prediction from whole slide histopathological images, Proc IEEE Conf. Comput. Vis. Pattern Recognit, pp. 7234-7242, (2017); Ward A.D., Et al., Prostate: Registration of digital histopathologic images to in vivo MR images acquired by using endorectal receive coil, Radiol, 263, 3, pp. 856-864, (2012); Savage R.S., Yuan Y., Predicting chemoinsensitivity in breast cancer with omics/digital pathology data fusion, Roy. Soc. Open Sci, 3, 2, (2016)","F. Xing; Department of Biostatistics and Informatics, Colorado School of Public Health, University of Colorado Denver, Denver, 80045, United States; email: fuyong.xing@ucdenver.edu","","Institute of Electrical and Electronics Engineers Inc.","","","","","","2162237X","","","29989994","English","IEEE Trans. Neural Networks Learn. Sys.","Article","Final","","Scopus","2-s2.0-85035790459"
"Abunadi I.; Senan E.M.","Abunadi, Ibrahim (57189636917); Senan, Ebrahim Mohammed (57222957501)","57189636917; 57222957501","Deep learning and machine learning techniques of diagnosis dermoscopy images for early detection of skin diseases","2021","Electronics (Switzerland)","10","24","3158","","","","46","10.3390/electronics10243158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121285366&doi=10.3390%2felectronics10243158&partnerID=40&md5=936d2ea8f1d49477b6cd71aec8feb454","Department of Information Systems, College of Computer and Information Sciences, Prince Sultan University, Riyadh, 11586, Saudi Arabia; Department of Computer Science & Information Technology, Dr. Babasaheb Ambedkar, Marathwada University, Aurangabad, 431004, India","Abunadi I., Department of Information Systems, College of Computer and Information Sciences, Prince Sultan University, Riyadh, 11586, Saudi Arabia; Senan E.M., Department of Computer Science & Information Technology, Dr. Babasaheb Ambedkar, Marathwada University, Aurangabad, 431004, India","With the increasing incidence of severe skin diseases, such as skin cancer, endoscopic medical imaging has become urgent for revealing the internal and hidden tissues under the skin. Diagnostic information to help doctors make an accurate diagnosis is provided by endoscopy devices. Nonetheless, most skin diseases have similar features, which make it challenging for dermatologists to diagnose patients accurately. Therefore, machine and deep learning techniques can have a critical role in diagnosing dermatoscopy images and in the accurate early detection of skin diseases. In this study, systems for the early detection of skin lesions were developed. The performance of the machine learning and deep learning was evaluated on two datasets (e.g., the International Skin Imaging Collaboration (ISIC 2018) and Pedro Hispano (PH2)). First, the proposed system was based on hybrid features that were extracted by three algorithms: local binary pattern (LBP), gray level co-occurrence matrix (GLCM), and wavelet transform (DWT). Such features were then integrated into a feature vector and classified using artificial neural network (ANN) and feedforward neural network (FFNN) classifiers. The FFNN and ANN classifiers achieved superior results compared to the other methods. Accuracy rates of 95.24% for diagnosing the ISIC 2018 dataset and 97.91% for diagnosing the PH2 dataset were achieved using the FFNN algorithm. Second, convolutional neural networks (CNNs) (e.g., ResNet-50 and AlexNet models) were applied to diagnose skin diseases using the transfer learning method. It was found that the ResNet-50 model fared better than AlexNet. Accuracy rates of 90% for diagnosing the ISIC 2018 dataset and 95.8% for the PH2 dataset were reached using the ResNet-50 model. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Biomedical image processing; Deep learning; Dermoscopy images; Machine learning; Melanoma; Skin diseases","","","","","","Prince Sultan University, PSU","Funding: This research has been funded by Prince Sultan University, Saudi Arabia.","Rosenbaum S., Health Cares. Nation, 22, (2008); Proksch E., Brandner J.M., Jensen J.M., The skin: An indispensable barrier, Exp. Dermatol, 17, pp. 1063-1072, (2008); Sakuma T.H., Maibach H.I., Oily skin: An overview, Ski. Pharmacol. Physiol, 25, pp. 227-235, (2012); Nasir M., Khan M.A., Sharif M., Javed M.Y., Saba T., Ali H., Tariq J., Melanoma Detection and Classification using Computerized Analysis of Dermoscopic Systems: A Review, Curr. Med. Imaging Former. Curr. Med. Imaging Rev, 16, pp. 794-822, (2019); Saba T., Khan M.A., Rehman A., Marie-Sainte S.L., Region Extraction and Classification of Skin Cancer: A Heterogeneous framework of Deep CNN Features Fusion and Reduction, J. Med. Syst, 43, (2019); Nasir M., Khan M.A., Sharif M., Lali I.U., Saba T., Iqbal T., An improved strategy for skin lesion detection and classification using uniform segmentation and feature selection based approach, Microsc. Res. Tech, 81, pp. 528-543, (2018); Zhang B., Zhou X., Luo Y., Zhang H., Yang H., Ma J., Ma L., Opportunities and Challenges: Classification of Skin Disease Based on Deep Learning, Chin. J. Mech. Eng, 34, (2021); Herman C., Emerging technologies for the detection of melanoma: Achieving better outcomes, Clin. Cosmet. Investig. Dermatol, 5, (2012); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, pp. 436-444, (2015); Khan M.A., Muhammad K., Sharif M., Albuquerque V.H.C., Multi-Class Skin Lesion Detection and Classification via Teledermatology, IEEE J. Biomed. Health Inform, 25, pp. 4267-4275, (2021); Khan M.A., Zhang Y.D., Sharif M., Akram T., Pixels to Classes: Intelligent Learning Framework for Multiclass Skin Lesion Localization and Classification, Comput. Electr. Eng, 90, (2021); Qin Z., Liu Z., Zhu P., Xue Y., A GAN-based image synthesis method for skin lesion classification, Comput. Methods Programs Biomed, 195, (2020); Tschandl P., Sinz C., Kittler H., Domain-specific classification-pretrained fully convolutional network encoders for skin lesion segmentation, Comput. Biol. Med, 104, pp. 111-116, (2019); Sreelatha T., Subramanyam M.V., Prasad M.G., Early detection of skin cancer using melanoma segmentation technique, J. Med Syst, 43, (2019); Chatterjee S., Dey D., Munshi S., Integration of morphological preprocessing and fractal based feature extraction with recursive feature elimination for skin lesion types classification, Comput. Methods Programs Biomed, 178, pp. 201-218, (2019); Al-Masni M.A., Kim D.H., Kim T.S., Multiple skin lesions diagnostics via integrated deep convolutional networks for segmentation and classification, Comput. Methods Programs Biomed, 190, (2020); Alzubaidi L., Al-Amidie M., Al-Asadi A., Humaidi A.J., Al-Shamma O., Fadhel M.A., Zhang J., Santamaria J., Duan Y., Novel Transfer Learning Approach for Medical Imaging with Limited Labeled Data, Cancers, 13, (2021); Liu Y.P., Wang Z., Li Z., Li J., Li T., Chen P., Liang R., Multiscale ensemble of convolutional neural networks for skin lesion classification, IET Image Process, 15, pp. 2309-2318, (2021); Ding S., Zheng J., Liu Z., Zheng Y., Chen Y., Xu X., Lu J., Xie J., High-resolution dermoscopy image synthesis with conditional generative adversarial networks, Biomed. Signal Process. Control, 64, (2021); Surowka G., Ogorzalek M., Wavelet-based logistic discriminator of dermoscopy images, Expert Syst. Appl, 167, (2021); Iqbal I., Younus M., Walayat K., Kakar M.U., Ma J., Automated multi-class classification of skin lesions through deep convolutional neural network with dermoscopic images, Comput. Med. Imaging Graph, 88, (2021); Sikkandar M.Y., Alrasheadi B.A., Prakash N.B., Hemalakshmi G.R., Mohanarathinam A., Shankar K., Deep learning based an automated skin lesion segmentation and intelligent classification model, J. Ambient Intell. Humaniz. Comput, 12, pp. 3245-3255, (2021); Ali M.S., Miah M.S., Haque J., Rahman M.M., Islam M.K., An enhanced technique of skin cancer classify cation using deep convolutional neural network with transfer learning models, Mach. Learn. Appl, 5, (2021); Kim D., Hong B.W., Unsupervised Feature Elimination via Generative Adversarial Networks: Application to Hair Removal in Melanoma Classification, IEEE Access, 9, pp. 42610-42620, (2021); Tyagi A., Mehra R., An optimized CNN based intelligent prognostics model for disease prediction and classification from Dermoscopy images, Multimed. Tools Appl, 79, pp. 26817-26835, (2020); Ahmad B., Jun S., Palade V., You Q., Mao L., Zhongjie M., Improving Skin Cancer Classification Using Heavy-Tailed Student T-Distribution in Generative Adversarial Networks (TED-GAN), Diagnostics, 11, 11, (2021); Molina-Molina E.O., Solorza-Calderon S., Alvarez-Borrego J., Classification of dermoscopy skin lesion color-images using fractal-deep learning features, Appl. Sci, 10, (2020); Adegun A.A., Viriri S., FCN-based DenseNet framework for automated detection and classification of skin lesions in dermoscopy images, IEEE Access, 8, pp. 150377-150396, (2020); Khan M.A., Akram T., Sharif M., Kadry S., Nam Y., Computer Decision Support System for Skin Cancer Localization and Classification, Comput. Mater. Contin, 68, pp. 1041-1064, (2021); Khan M.A., Muhammad K., Sharif M., Akram T., Kadry S., Intelligent fusion-assisted skin lesion localization and classification for smart healthcare, Neural Comput. Appl, 20, pp. 1-16, (2021); Khan M.A., Sharif M., Akram T., Kadry S., Hsu C.H., A two-stream deep neural network-based intelligent system for complex skin cancer types classification, Int. J. Intell. Syst, (2021); Khan M.A., Sharif M., Akram T., Damasevicius R., Maskeliunas R., Skin Lesion Segmentation and Multiclass Classification Using Deep Learning Features and Improved Moth Flame Optimization, Diagnostics, 11, (2021); Tschandl P., Rinner C., Apalla Z., Argenziano G., Codella N., Halpern A., Kittler H., Human–computer collaboration for skin cancer recognition, Nat. Med, 26, pp. 1229-1234, (2020); Automatic Computer-Based Diagnosis System for Dermoscopy Images; Kiani K., Sharafat A.R., E-shaver: An improved DullRazor® for digitally removing dark and light-colored hairs in dermoscopic images, Comput. Biol. Med, 41, pp. 139-145, (2011); Senan E.M., Jadhav M.E., Kadam A., Classification of PH2 Images for Early Detection of Skin Diseases, Proceedings of the 2021 6th International Conference for Convergence in Technology (I2CT), pp. 1-7, (2021); Senan E.M., Jadhav M.E., Techniques for the Detection of Skin Lesions in PH 2 Dermoscopy Images Using Local Binary Pattern (LBP), Proceedings of the International Conference on Recent Trends in Image Processing and Pattern Recognition, pp. 14-25, (2020); Livieris I.E., Improving the Classification Efficiency of an ANN Utilizing a New Training Methodology, Informatics, 6, (2019); Huang M.L., Chou Y.C., Combining a gravitational search algorithm, particle swarm optimization, and fuzzy rules to improve the classification performance of a feed-forward neural network, Comput. Methods Programs Biomed, 180, (2019); Jahnavi M., Introduction to Neural Networks, Advant. Appl, (2021); Alsaade F.W., Aldhyani T.H., Al-Adhaileh M.H., Developing a Recognition System for Diagnosing Melanoma Skin Lesions Using Artificial Intelligence Algorithms, Comput. Math. Methods Med, 2021, (2021); Acharya U.R., Oh S.L., Hagiwara Y., Tan J.H., Adam M., Gertych A., San Tan R., A deep convolutional neural network model to classify heartbeats, Comput. Biol. Med, 89, pp. 389-396, (2017); Agarap A.F., Deep Learning Using Rectified Linear Units (ReLU); Mohammed B.A., Senan E.M., Rassem T.H., Makbol N.M., Alanazi A.A., Al-Mekhlafi Z.G., Almurayziq T.S., Ghaleb F.A., Multi-Method Analysis of Medical Records and MRI Images for Early Diagnosis of Dementia and Alzheimer’s Disease Based on Deep Learning and Hybrid Methods, Electronics, 10, (2021); Senan E.M., Fawaz W.A., Mohammed I.A., Theyazn H.H., Mosleh H.A., Classification of histopathological images for early detection of breast cancer using deep learning, J. Appl. Sci. Eng, 24, pp. 323-329, (2021); Senan E.M., Al-Adhaileh M.H., Alsaade F.W., Aldhyani T.H., Alqarni A.A., Alsharif N., Uddin M.I., Alahmadi A.H., E Jadhav M., Alzahrani M.Y., Diagnosis of Chronic Kidney Disease Using Effective Classification Algorithms and Recursive Feature Elimination Techniques, J. Healthc. Eng, 2021, (2021); Pathan S., Prabhu K.G., Siddalingaswamy P.C., Automated detection of melanocytes related pigmented skin lesions: A clinical framework, Biomed. Signal Process. Control, 51, pp. 59-72, (2019); Parmar B., Talati B., Automated Melanoma Types and Stages Classification for dermoscopy images, Proceedings of the 2019 Innovations in Power and Advanced Computing Technologies (i-PACT), 2019, (2019); Jianu S.R.S., Ichim L., Popescu D., Automatic Diagnosis of Skin Cancer Using Neural Networks, Proceedings of the 2019 11th International Symposium on Advanced Topics in Electrical Engineering, pp. 1-4, (2019); Oliveira R.B., Pereira A.S., Tavares J.M.R., Computational diagnosis of skin lesions from dermoscopic images using combined features, Neural Comput. Appl, 31, pp. 6091-6111, (2018); Srinivasu P.N., SivaSai J.G., Ijaz M.F., Bhoi A.K., Kim W., Kang J.J., Classification of Skin Disease Using Deep Learning Neural Networks with MobileNet V2 and LSTM, Sensors, 21, (2021); Gong A., Yao X., Lin W., Classification for Dermoscopy Images Using Convolutional Neural Networks Based on the Ensemble of Individual Advantage and Group Decision, IEEE Access, 8, pp. 155337-155351, (2020); Reisinho J., Coimbra M., Renna F., Deep Convolutional Neural Network Ensembles for Multi-Classification of Skin Lesions from Dermoscopic and Clinical Images, Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, 2020, pp. 1940-1943, (2020)","I. Abunadi; Department of Information Systems, College of Computer and Information Sciences, Prince Sultan University, Riyadh, 11586, Saudi Arabia; email: iabunadi@psu.edu.sa; E.M. Senan; Department of Computer Science & Information Technology, Dr. Babasaheb Ambedkar, Marathwada University, Aurangabad, 431004, India; email: Senan1710@gmail.com","","MDPI","","","","","","20799292","","","","English","Electronics (Switzerland)","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85121285366"
"Zeng C.; Nan Y.; Xu F.; Lei Q.; Li F.; Chen T.; Liang S.; Hou X.; Lv B.; Liang D.; Luo W.; Lv C.; Li X.; Xie G.; Liu Z.","Zeng, Caihong (57202571023); Nan, Yang (57217028826); Xu, Feng (56527573800); Lei, Qunjuan (57215660069); Li, Fengyi (57217029448); Chen, Tingyu (57208481340); Liang, Shaoshan (55173691300); Hou, Xiaoshuai (56982264100); Lv, Bin (58717185000); Liang, Dandan (57188857554); Luo, WeiLi (57217735405); Lv, Chuanfeng (57216090925); Li, Xiang (56044095900); Xie, Guotong (14042931500); Liu, Zhihong (56118017700)","57202571023; 57217028826; 56527573800; 57215660069; 57217029448; 57208481340; 55173691300; 56982264100; 58717185000; 57188857554; 57217735405; 57216090925; 56044095900; 14042931500; 56118017700","Identification of glomerular lesions and intrinsic glomerular cell types in kidney diseases via deep learning","2020","Journal of Pathology","252","1","","53","64","11","56","10.1002/path.5491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087566915&doi=10.1002%2fpath.5491&partnerID=40&md5=1a9dfe409d8733da80f37831df2f0886","National Clinical Research Center of Kidney Diseases, Jinling Hospital, Nanjing University School of Medicine, Nanjing, China; Ping An Healthcare Technology, Shang Hai, China","Zeng C., National Clinical Research Center of Kidney Diseases, Jinling Hospital, Nanjing University School of Medicine, Nanjing, China; Nan Y., Ping An Healthcare Technology, Shang Hai, China; Xu F., National Clinical Research Center of Kidney Diseases, Jinling Hospital, Nanjing University School of Medicine, Nanjing, China; Lei Q., National Clinical Research Center of Kidney Diseases, Jinling Hospital, Nanjing University School of Medicine, Nanjing, China; Li F., Ping An Healthcare Technology, Shang Hai, China; Chen T., National Clinical Research Center of Kidney Diseases, Jinling Hospital, Nanjing University School of Medicine, Nanjing, China; Liang S., National Clinical Research Center of Kidney Diseases, Jinling Hospital, Nanjing University School of Medicine, Nanjing, China; Hou X., Ping An Healthcare Technology, Shang Hai, China; Lv B., Ping An Healthcare Technology, Shang Hai, China; Liang D., National Clinical Research Center of Kidney Diseases, Jinling Hospital, Nanjing University School of Medicine, Nanjing, China; Luo W., Ping An Healthcare Technology, Shang Hai, China; Lv C., Ping An Healthcare Technology, Shang Hai, China; Li X., Ping An Healthcare Technology, Shang Hai, China; Xie G., Ping An Healthcare Technology, Shang Hai, China; Liu Z., National Clinical Research Center of Kidney Diseases, Jinling Hospital, Nanjing University School of Medicine, Nanjing, China","Identification of glomerular lesions and structures is a key point for pathological diagnosis, treatment instructions, and prognosis evaluation in kidney diseases. These time-consuming tasks require a more accurate and reproducible quantitative analysis method. We established derivation and validation cohorts composed of 400 Chinese patients with immunoglobulin A nephropathy (IgAN) retrospectively. Deep convolutional neural networks and biomedical image processing algorithms were implemented to locate glomeruli, identify glomerular lesions (global and segmental glomerular sclerosis, crescent, and none of the above), identify and quantify different intrinsic glomerular cells, and assess a network-based mesangial hypercellularity score in periodic acid–Schiff (PAS)-stained slides. Our framework achieved 93.1% average precision and 94.9% average recall for location of glomeruli, and a total Cohen's kappa of 0.912 [95% confidence interval (CI), 0.892–0.932] for glomerular lesion classification. The evaluation of global, segmental glomerular sclerosis, and crescents achieved Cohen's kappa values of 1.0, 0.776, 0.861, and 95% CI of (1.0, 1.0), (0.727, 0.825), (0.824, 0.898), respectively. The well-designed neural network can identify three kinds of intrinsic glomerular cells with 92.2% accuracy, surpassing the about 5–11% average accuracy of junior pathologists. Statistical interpretation shows that there was a significant difference (P value < 0.0001) between this analytic renal pathology system (ARPS) and four junior pathologists for identifying mesangial and endothelial cells, while that for podocytes was similar, with P value = 0.0602. In addition, this study indicated that the ratio of mesangial cells, endothelial cells, and podocytes within glomeruli from IgAN was 0.41:0.36:0.23, and the performance of mesangial score assessment reached a Cohen's kappa of 0.42 and 95% CI (0.18, 0.69). The proposed computer-aided diagnosis system has feasibility for quantitative analysis and auxiliary recognition of glomerular pathological features. © 2020 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of Pathological Society of Great Britain and Ireland. © 2020 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of Pathological Society of Great Britain and Ireland.","computational pathology; glomerular lesion classification; IgAN; intrinsic glomerular cells identification; mesangial hypercellularity score assessment","Adult; Deep Learning; Diagnosis, Computer-Assisted; Female; Glomerulonephritis, IGA; Humans; Kidney Diseases; Kidney Glomerulus; Male; Mesangial Cells; Neural Networks, Computer; Podocytes; adult; Article; cellular distribution; Chinese; cohort analysis; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; feasibility study; female; focal glomerulosclerosis; glomerular structure; glomerulopathy; glomerulus epithelium cell; histopathology; human; human tissue; imaging algorithm; immunoglobulin A nephropathy; major clinical study; male; mesangium cell; pathologist; periodic acid Schiff stain; podocyte; priority journal; quantitative analysis; rapidly progressive glomerulonephritis; retrospective study; sensitivity and specificity; validation study; computer assisted diagnosis; glomerulus; immunoglobulin A nephropathy; kidney disease; mesangium cell; pathology; podocyte","","","","","Science, Technology and Education of Jiangsu Province Medical Key Talent, (ZDRCA2016098); National Natural Science Foundation of China, NSFC, (81570644); National Natural Science Foundation of China, NSFC; National Key Research and Development Program of China, NKRDPC, (2016YFC0901202); National Key Research and Development Program of China, NKRDPC","We thank Tao Jingli, Wang Huichao, ZouYun, Liu Li, Li He, Song Yashan, Sun Jing, Tang Wen, Jiang Linglin, and Li Li for pathological annotation work. This research was funded by the National Key Research and Development Program of China (2016YFC0901202), the National Natural Science Foundation of China (81570644), and the Project of Invigorating Health Care through Science, Technology and Education of Jiangsu Province Medical Key Talent (ZDRCA2016098). ","Zhang L., Wang F., Wang L., Wang W., Et al., Prevalence of chronic kidney disease in China: a cross-sectional survey, The Lancet, 379, pp. 815-822, (2012); Eckhardt K.-U., Coresh J., Devuyst O., Et al., Evolving importance of kidney disease: from subspecialty to global health burden, Lancet, 382, pp. 158-169, (2013); Magistroni R., D'Agati V.D., Appel G.B., Et al., New developments in the genetics, pathogenesis, and therapy of IgA nephropathy, Kidney Int, 88, pp. 974-989, (2015); Wyatt R.J., Julian B.A., IgA nephropathy, N Engl J Med, 368, pp. 2402-2414, (2013); Sethi S., Haas M., Markowitz G.S., Et al., Mayo Clinic/Renal Pathology Society consensus report on pathologic classification, diagnosis, and reporting of GN, J Am Soc Nephrol, 27, (2016); Haas M., Verhave J.C., Liu Z.-H., Et al., A multicenter study of the predictive value of crescents in IgA nephropathy, J Am Soc Nephrol, 28, pp. 691-701, (2017); Alamartine E., Sauron C., Laurent B., Et al., The use of the Oxford classification of IgA nephropathy to predict renal survival, Clin J Am Soc Nephrol, 6, pp. 2384-2388, (2011); Bellur S.S., Lepeytre F., Vorobyeva O., Et al., Evidence from the Oxford Classification cohort supports the clinical value of subclassification of focal segmental glomerulosclerosis in IgA nephropathy, Kidney Int, 91, pp. 235-243, (2017); Cattran D.C., Rosanna C., Terence H.C., Et al., The Oxford classification of IgA nephropathy: rationale, clinicopathological correlations, and classification, Kidney Int, 76, pp. 534-545, (2009); Herzenberg A.M., Fogo A.B., Reich H.N., Et al., Validation of the Oxford classification of IgA nephropathy, Kidney Int, 80, pp. 310-317, (2011); Shi S.-F., Wang S.-X., Jiang L., Et al., Pathologic predictors of renal outcome and therapeutic efficacy in IgA nephropathy: validation of the Oxford classification, Clin J Am Soc Nephrol, 6, pp. 2175-2184, (2011); Trimarchi H., Barratt J., Cattran D.C., Et al., Oxford Classification of IgA nephropathy 2016: an update from the IgA Nephropathy Classification Working Group, Kidney Int, 91, pp. 1014-1021, (2017); Zeng C.-H., Le W., Ni Z., Et al., A multicenter application and evaluation of the Oxford classification of IgA nephropathy in adult Chinese patients, Am J Kidney Dis, 60, pp. 812-820, (2012); Temerinac-Ott M., Forestier G., Schmitz J., Et al., Detection of glomeruli in renal pathology by mutual comparison of multiple staining modalities, Proceedings of the 10th International Symposium on Image and Signal Processing and Analysis, pp. 19-24, (2017); Kato T., Relator R., Ngouv H., Et al., Segmental HOG: new descriptor for glomerulus detection in kidney microscopy image, BMC Bioinformatics, 16, (2015); Maree R., Dallongeville S., Olivo-Marin J.-C., Et al., An approach for detection of glomeruli in multisite digital pathology, 2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI), pp. 1033-1036, (2016); Gadermayr M., Dombrowski A., Klinkhammer B.M., Et al., CNN cascades for segmenting sparse objects in gigapixel whole slide images, Comput Med Imaging Graph, 71, pp. 40-48, (2019); Gallego J., Pedraza A., Lopez S., Et al., Glomerulus classification and detection based on convolutional neural networks, J Imaging, 4, (2018); Sheehan S., Mawe S., Cianciolo R.E., Et al., Detection and classification of novel renal histologic phenotypes using deep neural networks, Am J Pathol, 189, pp. 1786-1796, (2019); Bukowy J.D., Dayton A., Cloutier D., Et al., Region-based convolutional neural nets for localization of glomeruli in trichrome-stained whole kidney sections, J Am Soc Nephrol, 29, pp. 2081-2088, (2018); Bueno G., Fernandez-Carrobles M.M., Gonzalez-Lopez L., Et al., Glomerulosclerosis identification in whole slide images using semantic segmentation, Comput Methods Programs Biomed, 184, (2020); Sarder P., Ginley B., Tomaszewski J.E., Automated renal histopathology: digital extraction and quantification of renal pathology, Medical Imaging 2016: Digital Pathology, (2016); Ginley B., Lutnick B., Jen K.-Y., Et al., Computational segmentation and classification of diabetic glomerulosclerosis, J Am Soc Nephrol, 30, pp. 1953-1967, (2019); Simon O., Yacoub R., Jain S., Et al., Multi-radial LBP features as a tool for rapid glomerular detection and assessment in whole slide histopathology images, Sci Rep, 8, (2018); Hermsen M., de Bel T., den Boer M., Et al., Deep learning-based histopathologic assessment of kidney tissue, J Am Soc Nephrol, 30, pp. 1968-1979, (2019); He K., Gkioxari G., Dollar P., Et al.; Tian Z., Shen C., Chen H., Et al., FCOS: fully convolutional one-stage object detection, International Conference on Computer Vision, pp. 9627-9636, (2019); Marsh J.N., Matlock M., Kudose S., Et al., Deep learning global glomerulosclerosis in transplant kidney frozen sections, IEEE Trans Med Imaging, 37, pp. 2718-2728, (2018); Kannan S., Morgan L.A., Liang B., Et al., Segmentation of glomeruli within trichrome images using deep learning, Kidney Int Rep, 4, pp. 955-962, (2019); Barros G.O., Navarro B., Duarte A., Et al., PathoSpotter-K: a computational tool for the automatic identification of glomerular lesions in histological images of kidneys, Sci Rep, 7, (2017); Chagas P., Souza L., Araujo I., Et al., Classification of glomerular hypercellularity using convolutional features and support vector machine, Artif Intell Med, 103, (2020); Jayapandian C., Chen Y., Janowczyk A., Et al., Deep learning based detection of normal and globally sclerotic glomeruli on whole slide images from the NEPTUNE renal biopsies with HE, PAS, trichrome and silver staining, Lab Invest, 32, pp. 16-17, (2019); Ronneberger O., Fischer P., Brox T.; Norman B., Pedoia V., Majumdar S., Use of 2D U-net convolutional neural networks for automated cartilage and meniscus segmentation of knee MR imaging data to determine relaxometry and morphometry, Radiology, 288, pp. 177-185, (2018); Venhuizen F.G., van Ginneken B., Liefers B., Et al., Robust total retina thickness segmentation in optical coherence tomography images using convolutional neural networks, Biomed Opt Express, 8, pp. 3292-3316, (2017); Huang G., Liu Z., Van Der Maaten L., Et al., Densely connected convolutional networks, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4700-4708, (2017); Cao Y., Xu J., Lin S., Et al., GCNet: non-local networks meet squeeze-excitation networks and beyond, arXiv, (2019); Milletari F., Navab N., Ahmadi S.-A., V-net: fully convolutional neural networks for volumetric medical image segmentation, 2016 Fourth International Conference on 3D Vision (3DV), pp. 565-571, (2016); Roberts I.S.D., Cook H.T., Et al., The Oxford classification of IgA nephropathy: pathology definitions, correlations, and reproducibility, Kidney Int, 76, pp. 546-556, (2009); Oktay O., Schlemper J., Folgoc L.L., Et al., Attention U-net: learning where to look for the pancreas, arXiv, (2018); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput, 9, pp. 1735-1780, (1997); Steffes M.W., Schmidt D., McCrery R., Et al., Glomerular cell number in normal subjects and in type 1 diabetic patients, Kidney Int, 59, pp. 2104-2113, (2001); Coppo R., Troyanov S., Bellur S., Et al., Validation of the Oxford classification of IgA nephropathy in cohorts with different presentations and treatments, Kidney Int, 86, pp. 828-836, (2014); Wang Z., Bovik A.C., Sheikh H.R., Et al., Image quality assessment: from error visibility to structural similarity, IEEE Trans Image Process, 13, pp. 600-612, (2004); Huang G., Liu Z., Weinberger K.Q., Et al., Densely connected convolutional networks, arXiv, (2016); Ginley B., Tomaszewski J.E., Sarder P., Automatic computational labeling of glomerular textural boundaries, Proc SPIE 10140, Medical Imaging 2017: Digital Pathology, (2017); Hu J., Shen L., Sun G., Squeeze-and-excitation networks, The IEEE Conference on Computer Vision and Pattern Recognition, pp. 7132-7141, (2018); Lian S., Luo Z., Zhong Z., Et al., Attention guided U-Net for accurate iris segmentation, J Vis Commun Image Represent, 56, pp. 296-304, (2018); Glorot X., Bengio Y., Understanding the difficulty of training deep feedforward neural networks, Proceedings of the 13th International Conference on Artificial Intelligence and Statistics, pp. 249-256, (2010); Kingma D.P., Ba J., Adam: a method for stochastic optimization, arXiv, (2014)","Z. Liu; National Clinical Research Center of Kidney Diseases, Jinling Hospital, Nanjing University School of Medicine, Nanjing, China; email: liuzhihong@nju.edu.cn","","John Wiley and Sons Ltd","","","","","","00223417","","JPTLA","32542677","English","J. Pathol.","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85087566915"
"Mergin A.A.; Premi M.S.G.","Mergin, A. Ancy (57202237260); Premi, M. S. Godwin (36809617400)","57202237260; 36809617400","Convolutional Neural Networks (CNN) with Quantum-Behaved Particle Swarm Optimization (QPSO)-Based Medical Image Fusion","2022","International Journal of Image and Graphics","","","2340005","","","","3","10.1142/S0219467823400053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136595001&doi=10.1142%2fS0219467823400053&partnerID=40&md5=cab94aca071858a08e6ef09a744c0f3f","Department of Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, India; Department of Electronics and Communication Engineering, Sathyabama Institute of Science and Technology, Chennai, India","Mergin A.A., Department of Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, India; Premi M.S.G., Department of Electronics and Communication Engineering, Sathyabama Institute of Science and Technology, Chennai, India","Medical imaging fusion is the process of combining pictures from various imaging modalities to create a single image that may be used in clinical settings. Robust methods for merging image data from several modalities are being developed in the field of multimodal medical imaging. Deep learning (DL) has been widely researched in two areas: pattern recognition and image processing. We will demonstrate a multimodal image fusion with DL implementation that considers the characteristics of medical diagnostic imaging as well as the demands of clinical practice. For the past three years, pixel-level picture fusion has been a hot topic. This paper proposes a new multimodal medical picture fusion technique for a wide range of medical diagnostic challenges. Image fusion is crucial in biomedical research and clinical diagnostics for biomedical image processing and therapy planning. The most convincing argument for fusion is obtaining a significant amount of critical information from the input photographs. We show how a well-organized multimodal medical image fusion technique can be utilized to integrate computed tomography (CT) and magnetic resonance imaging (MRI) data in this study. Using convolutional neural networks (CNNs), the quantum-behaved particle swarm optimization (QPSO) algorithm was used to create a method for integrating multimodal medical pictures. In order to improve the overall quality and efficiency of QPSO, it was chosen to add the metrics of image entropy, standard deviation, average gradient (AG), spatial frequency (SF), and visual information fidelity (VIF). In experiments, multimodal medical images are utilized to evaluate a variety of parameters, including performance and algorithm stability. When compared to the other possibilities, the recommended technique outperformed them in the evaluations. On a range of quantitative metrics, this method outperforms the alternatives.  © 2023 World Scientific Publishing Company.","Convolutional neural networks (CNN); image entropy (EN); image fusion; MRI; QPSO; visual information fidelity (VIF)","","","","","","","","Rajalingam B., Priya R., A novel approach for multimodal medical image fusion using hybrid fusion algorithms for disease analysis, Int. J. Pure Appl. Math, 117, 15, pp. 599-619, (2017); Vasan D., Alazab M., Wassan S., Safaei B., Zheng Q., Image-based malware classiffication using ensemble of CNN architectures (IMCEC), Comput. Secur, 92, (2020); Chao-ben D., She-sheng G., Multi-focus image fusion with the all convolutional neural network, Optoelectron. Lett, 14, 1, pp. 71-75, (2018); Xinzheng X., Shana D., Guanying W., Jiang X., Multimodal medical image fusion using PCNN optimized by the QPSO algorithm, Appl. Soft Comput, 46, pp. 588-595, (2016); Zhaobin W., Shuai W., Ying Z., Yide M., Review of image fusion based on pulsecoupled neural network, Arch. Comput. Methods Eng, 23, pp. 659-671, (2016); El-Hoseny H. M., El Rabaie E. M., Elrahman W. A., Abd El-Samie F. E., Medical image fusion techniques based on combined discrete transform domains, 34th National Radio Science Conf. (NRSC), pp. 471-480, (2017); Srinivasa Rao D., Seetha M., Krishna Prasad M. H. M., Comparison of fuzzy and neuro fuzzy image fusion techniques and its applications, Int. J. Comput. Appl, 43, 20, pp. 0975-8887, (2012); Xingbin L., Wenbo M., Huiqian D., Structure tensor and nonsubsampled sheasrlet transform based algorithm for CT and MRI image fusion, Neurocomputing, 235, pp. 131-139, (2017); Rajkumar S., Bardhan P., Akkireddy S. K., Munshi C., CT and MRI image fusion based on wavelet transform and neuro-fuzzy concepts with quantitative analysis, 2014 Int. Conf. Electronics and Communication Systems (ICECS), pp. 1-6, (2014); Liu Y., Chen X., Cheng J., Peng H., A medical image fusion method based on convolutional neural networks, 2017 20th Int. Conf. Information Fusion (Fusion), pp. 1-7, (2017); Gomathi S., Kalaavathi B., Multimodal medical image fusion in non-subsampled contourlet transform domain, Circuits Syst, 7, 8, pp. 1598-1610, (2016); Narasimha Murthy K. N., Kusuma J., Fusion of medical image using STSVD, Proc. 5th Int. Conf. Frontiers in Intelligent Computing: Theory and Applications, Advances in Intelligent Systems and Computing, 516, (2017); Darwish S. M., Multi-level fuzzy contourlet-based image fusion for medical applications, IET Image Process, 7, 7, pp. 694-700, (2013); Das S., Kundu M. K., A neuro-fuzzy approach for medical image fusion, IEEE Trans. Biomed. Eng, 60, 12, pp. 3347-3353, (2013); Kavitha C. T., Chellamuthu C., Multimodal medical image fusion based on integer wavelet transform and neuro-fuzzy, 2010 Int. Conf. Signal and Image Processing, pp. 296-300, (2010); Meenu M., Sharma R., A novel method of multimodal medical image fusion using fuzzy transform, J. Vis. Commun. Image Represent, 40, pp. 197-217, (2016); Wang Z., Wang S., Zhu Y., Yide M., Review of image fusion based on pulse-coupled neural network, Arch. Comput. Methods in Eng, 23, pp. 659-671, (2016); Karthikeyan C., Ramadoss B., Comparative analysis of similarity measure performance for multimodality image fusion using DTCWT and SOFM with various medical image fusion techniques, Indian J. Sci. Technol, 9, 22, pp. 1-6, (2016); Chavan S. S., Abhishek M., Talbar S. N., Subhash D., Meenakshi T., Anil D., Nonsubsampled rotated complex wavelet transform (NSRC_WT) for medical image fusion related to clinical aspects in neurocysticercosis, Comput. Biol. Med, 81, 1, pp. 64-78, (2017); Chen J. H., Shu M. C., Cao R, Hsu S. C., Lu J. C., A self organizing map optimization based image recognition and processing model for bridge crack inspection, Autom. Constr, 73, pp. 58-66, (2017); Liu J., Tang Z., Gui W., Liu W., Xu P., Zhu J., Application of statistical modeling of image spatial structures to automated visual inspection of product quality, J. Process. Control, 44, pp. 23-40, (2016); Ko C. N., Jau Y. M., Jeng J. T., Parameter estimation of chaotic dynamical systems using quantum-behaved particle swarm optimization based on hybrid evolution, J. Inf. Sci. Eng, 31, 2, pp. 675-689, (2015); Udhaya Suriya T. S., Rangarajan P., Brain tumour detection using discrete wavelet transform based medical image fusion, Biomed. Res, 28, 2, pp. 684-688, (2017); Zhao W., Lu H., Medical image fusion and denoising with alternating sequential filter and adaptive fractional order total variation, IEEE Trans. Instrum. Meas, 66, 9, pp. 2283-2294, (2017); Venkatrao P. H., Damodar S. S., HWFusion: Holoentropy and SP-whale optimization-based fusion model for magnetic resonance imaging multimodal image fusion, IET Image Process, 12, 4, pp. 572-581, (2018); Meher B., Agrawal S., Panda R., Abraham A., A survey on region based image fusion methods, Inf. Fusion, 48, pp. 119-132, (2019); Dilmaghani M. S., Daneshvar S., Dousty M., A new MRI and PET image fusion algorithm based on BEMD and IHS methods, 2017 Iranian Conf. Electrical Engineering (ICEE), pp. 118-121, (2017); Kamalraj R., Kumar M. R., Rao V. C. S., Anand R., Singh H., Interpretable filter based convolutional neural network (IF-CNN) for glucose prediction and classification using PD-SS algorithm, Measurement, 183, (2021); Kavitha T., Mathai P. P., Karthikeyan C., Ashok M., Kohar R., Avanija J., Neelakandan S., Deep learning based capsule neural network model for breast cancer diagnosis using mammogram images, Interdiscip. Sci. Comput. Life Sci, 14, pp. 113-129, (2022); Reshma G., Al-Atroshi C., Nassa V. K., Geetha B. T., Sunitha G., Galety M. G., Neelakandan S., Deep learning-based skin lesion diagnosis model using dermoscopic images, Intell. Autom. Soft Comput, 31, 1, pp. 621-634, (2022); Huang C., Et al., A new pulse coupled neural network (PCNN) for brain medical image fusion empowered by shuffled frog leaping algorithm, Front. Neurosci, 13, (2019)","A.A. Mergin; Department of Computer Science and Engineering, Sathyabama Institute of Science and Technology, Chennai, India; email: ancymergin@gmail.com","","World Scientific","","","","","","02194678","","","","English","Intl. J. Image Graphics","Article","Article in press","","Scopus","2-s2.0-85136595001"
"Kamrul Hasan S.M.; Linte C.A.","Kamrul Hasan, S.M. (57188664990); Linte, Cristian A. (57202997616)","57188664990; 57202997616","A Modified U-Net Convolutional Network Featuring a Nearest-neighbor Re-sampling-based Elastic-Transformation for Brain Tissue Characterization and Segmentation","2018","2018 IEEE Western New York Image and Signal Processing Workshop, WNYISPW 2018","","","8576421","","","","37","10.1109/WNYIPW.2018.8576421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060302593&doi=10.1109%2fWNYIPW.2018.8576421&partnerID=40&md5=fa5af0a5b01453035d8474470fe52b2e","Chester F. Carlson Center for Imaging Science, United States; Biomedical Engineering Biomedical Modeling, Visualization and Image-guided Navigation Lab, Rochester Institute of Technology, Rochester, NY, United States","Kamrul Hasan S.M., Chester F. Carlson Center for Imaging Science, United States; Linte C.A., Chester F. Carlson Center for Imaging Science, United States, Biomedical Engineering Biomedical Modeling, Visualization and Image-guided Navigation Lab, Rochester Institute of Technology, Rochester, NY, United States","The detection and segmentation of brain tumors from Magnetic Resonance Imaging (MRI) is a very challenging task, despite the availability of modern medical image processing tools. Neuro-radiologists still diagnose deadly brain cancers such as even glioblastoma using manual segmentation. This approach is not only tedious, but also highly variable, featuring limited accuracy and precision, and hence raising the need for more robust, automated techniques. Deep learning methods such as the U-Net deep convolutional neural networks have been widely used in biomedical image segmentation. Although this model was demonstrated to yield desirable results on the BRATS 2015 dataset by using a pixel-wise segmentation map of the input image as an auto-encoder, which assures best segmentation accuracy, the output only showed limited accuracy and robustness for a number of cases. The goal of this work was to improve the U-net model by replacing the de-convolution component with an up-sampled by the Nearest-neighbor algorithm and also employing an elastic transformation to augment the training dataset to render the model more robust, especially for the segmentation of low-grade tumors. The proposed Nearest-Neighbor Re-sampling Based Elastic-Transformed (NNRET) U-net Deep CNN framework has been trained on 285 glioma patients BRATS 2017 MR dataset available through the MICCAI 2017 grand challenge. The framework has been tested on 146 patients using Dice similarity coefficient (DSC) Intersection over Union (IoU) performance metrics and outweighed the classic U-net model. © 2018 IEEE.","Brain tissue segmentation; deep convolutional networks; modified U-net; nearest-neighbor interpolation","Brain; Convolution; Deep neural networks; Magnetic resonance imaging; Medical imaging; Neural networks; Tumors; Biomedical image segmentation; Brain tissue segmentations; Convolutional networks; Deep convolutional neural networks; Magnetic Resonance Imaging (MRI); modified U-net; Nearest neighbor algorithm; Nearest neighbor interpolation; Image segmentation","","","","","","","Kohler B.A., Ward E., McCarthy B.J., Schymura M.J., Ries L.A., Eheman C., Jemal A., Anderson R.N., Ajani U.A., Edwards B.K., Annual report to the nation on the status of cancer, 1975-2007, featuring tumors of the brain and other nervous system, Journal of the National Cancer Institute, 103, 9, pp. 714-736, (2011); Soltaninejad M., Yang G., Lambrou T., Allinson N., Jones T.L., Barrick T.R., Howe F.A., Ye X., Automated brain tumour detection and segmentation using superpixel-based extremely randomized trees in flair mri, International Journal of Computer Assisted Radiology and Surgery, 12, 2, pp. 183-203, (2017); Ciresan D., Giusti A., Gambardella L.M., Schmidhuber J., Deep neural networks segment neuronal membranes in electron microscopy images, Advances in Neural Information Processing Systems, pp. 2843-2851, (2012); Isensee F., Kickingereder P., Wick W., Bendszus M., Maier-Hein K.H., Brain tumor segmentation and radiomics survival prediction: Contribution to the brats 2017 challenge, International MICCAI Brainlesion Workshop, pp. 287-297, (2017); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Dong H., Yang G., Liu F., Mo Y., Guo Y., Automatic brain tumor detection and segmentation using u-net based fully convolutional networks, Annual Conference on Medical Image Understanding and Analysis, pp. 506-517, (2017); Radford A., Metz L., Chintala S., Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, (2015); Bakas S., Akbari H., Sotiras A., Bilello M., Rozycki M., Kirby J.S., Freymann J.B., Farahani K., Davatzikos C., Advancing the cancer genome atlas glioma mri collections with expert segmentation labels and radiomic features, Scientific Data, 4, (2017); Bakas S., Akbari H., Sotiras A., Bilello M., Rozycki M., Kirby J., Freymann J., Farahani K., Davatzikos C., Segmentation labels and radiomic features for the pre-operative scans of the tcga-lgg collection, The Cancer Imaging Archive, (2017); Dong C., Loy C.C., Tang X., Accelerating the super-resolution convolutional neural network, European Conference on Computer Vision, pp. 391-407, (2016); Dong C., Loy C.C., He K., Tang X., Image super-resolution using deep convolutional networks, IEEE Transactions on Pattern Analysis and Machine Intelligence, 38, 2, pp. 295-307, (2016)","","","Institute of Electrical and Electronics Engineers Inc.","","2018 IEEE Western New York Image and Signal Processing Workshop, WNYISPW 2018","5 October 2018","Rochester","143707","","978-172810255-9","","","English","IEEE Western New York Image Signal Process. Workshop, WNYISPW","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85060302593"
"Alassaf A.; Sikkandar M.Y.","Alassaf, Ahmad (57191228351); Sikkandar, Mohamed Yacin (57202716139)","57191228351; 57202716139","Intelligent Deep Transfer Learning Based Malaria Parasite Detection and Classification Model Using Biomedical Image","2022","Computers, Materials and Continua","72","3","","5273","5285","12","7","10.32604/cmc.2022.025577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128662756&doi=10.32604%2fcmc.2022.025577&partnerID=40&md5=10a96545be2818f071bdb082445ac197","Department of Medical Equipment Technology, College of Applied Medical Sciences, Majmaah University, Al Majmaah, 11952, Saudi Arabia","Alassaf A., Department of Medical Equipment Technology, College of Applied Medical Sciences, Majmaah University, Al Majmaah, 11952, Saudi Arabia; Sikkandar M.Y., Department of Medical Equipment Technology, College of Applied Medical Sciences, Majmaah University, Al Majmaah, 11952, Saudi Arabia","Malaria is a severe disease caused by Plasmodium parasites, which can be detected through blood smear images. The early identification of the disease can effectively reduce the severity rate. Deep learning (DL) models can be widely employed to analyze biomedical images, thereby minimizing the misclassification rate. With this objective, this study developed an intelligent deep-transfer-learning-based malaria parasite detection and classification (IDTL-MPDC) model on blood smear images. The proposed IDTL-MPDC technique aims to effectively determine the presence ofmalarial parasites in blood smear images. In addition, the IDTL-MPDC technique derives median filtering (MF) as a pre-processing step. In addition, a residual neural network (Res2Net) model was employed for the extraction of feature vectors, and its hyperparameters were optimally adjusted using the differential evolution (DE) algorithm. The k-nearest neighbor (KNN) classifier was used to assign appropriate classes to the blood smear images. The optimal selection of Res2Net hyperparameters by the DE model helps achieve enhanced classification outcomes. A wide range of simulation analyses of the IDTL-MPDC technique are carried out using a benchmark dataset, and its performance seems to be highly accurate (95.86%), highly sensitive (95.82%), highly specific (95.98%), with a high F1 score (95.69%), and high precision (95.86%), and it has been proven to be better than the other existing methods. © 2022 Tech Science Press. All rights reserved.","biomedical images; blood smear images; Computer-aided diagnosis; deep learning; malaria parasites","Benchmarking; Blood; Computer aided diagnosis; Computer aided instruction; Deep learning; Evolutionary algorithms; Image classification; Median filters; Nearest neighbor search; Biomedical images; Blood smear image; Blood smears; Classification models; Classification technique; Deep learning; Detection models; Hyper-parameter; Malaria parasite; Transfer learning; Diseases","","","","","Majmaah University, MU, (R-2022-76)","Acknowledgement: The authors extend their appreciation to the Deanship of Scientific Research at Majmaah University for funding this study under project number R-2022-76.","(2019); Masanja I.M., McMorrow M. L., Maganga M. B., Sumari D., Udhayakumar V., Et al., Quality assurance of malaria rapid diagnostic tests used for routine patient care in rural Tanzania: Microscopy versus realtime polymerase chain reaction, Malaria Journal, 14, 1, (2015); Poostchi M., Silamut K., Maude R. J., Jaeger S., Thoma G., Image analysis and machine learning for detecting malaria, Translational Research, 194, pp. 36-55, (2018); Obeagu E. I., Uo C., Is E., Malaria rapid diagnostic test (RDTs), Annals of Clinical & Laboratory Science, 6, 4, pp. 1-3, (2018); Mathison B. A., Pritt B. S., Update on malaria diagnostics and test utilization, Journal of Clinical Microbiology, 55, 7, pp. 2009-2017, (2017); Rajaraman S., Antani S. K., Poostchi M., Silamut K., Hossain M. A., Et al., Pre-trained convolutional neural networks as feature extractors toward improved malaria parasite detection in thin blood smear images, PeerJ, 6, (2018); Quinn J. A., Nakasi R., Mugagga P. K., Byanyima P., Lubega W., Et al., Deep convolutional neural networks for microscopy-based point of care diagnostics, Proc. of the Machine Learning for Healthcare Conf, 56, pp. 271-281, (2016); Yang D., Subramanian G., Duan J., Gao S., Bai L., Et al., A portable image-based cytometer for rapid malaria detection and quantification, PLoS ONE, 12, 6, (2017); Arco J. E., Gorriz J. M., Ramirez J., Alvarez I., Puntonet C. G., Digital image analysis for automatic enumeration of malaria parasites using morphological operations, Expert Systems with Applications, 42, 6, pp. 3041-3047, (2015); Bibin D., Nair M. S., Punitha P., Malaria parasite detection fromperipheral blood smear images using deep belief networks, IEEE Access, 5, pp. 9099-9108, (2017); Chakradeo K., Delves M., Titarenko S., Malaria parasite detection using deep learning methods, International Journal of Computer and Information Engineering, 15, 2, pp. 175-182, (2021); Fuhad K. M. F., Tuba J. F., Sarker M. R. A., Momen S., Mohammed N., Et al., Deep learning based automaticmalaria parasite detection fromblood smear and its smartphone based application, Diagnostics, 10, 5, (2020); Shah D., Kawale K., Shah M., Randive S., Mapari R., Malaria parasite detection using deep learning: (Beneficial to humankind), 2020 4th Int. Conf. on Intelligent Computing and Control Systems (ICICCS), pp. 984-988, (2020); Li S., Du Z., Meng X., Zhang Y., Multi-stage malaria parasite recognition by deep learning, GigaScience, 10, 6, (2021); Rahman A., Zunair H., Reme T. R., Rahman M. S., Mahdy M. R. C., A comparative analysis of deep learning architectures on high variation malaria parasite classification dataset, Tissue and Cell, 69, (2021); Swastika W., Kristianti G. M., Widodo R. B., Effective preprocessed thin blood smear images to improve malaria parasite detection using deep learning, Journal of Physics: Conference Series, 1869, 1, (2021); Xu Z., Sheykhahmad F. R., Ghadimi N., Razmjooy N., Computer-aided diagnosis of skin cancer based on soft computing techniques, Open Medicine, 15, 1, pp. 860-871, (2020); Gao S., Cheng M., Zhao K., Zhang X., Yang M., Et al., Res2net:Anewmulti-scale backbone architecture, IEEE Transactions on Pattern Analysis and Machine Intelligence, 43, 2, pp. 652-662, (2021); Saha S. K., Ghoshal S. P., Kar R., Mandal D., Cat swarm optimization algorithm for optimal linear phase fir filter design, ISA Transactions, 52, 6, pp. 781-794, (2013); Hassanat A. B., Abbadi M. A., Altarawneh G. A., Alhasanat A. A., Solving the problem of the K parameter in the KNN classifier using an ensemble learning approach, International Journal of Computer Science and Information Security, 12, 8, pp. 33-39, (2014); Maqsood A., Farid M. S., Khan M. H., Grzegorzek M., Deep malaria parasite detection in thin blood smear microscopic images, Applied Sciences, 11, 5, (2021)","M.Y. Sikkandar; Department of Medical Equipment Technology, College of Applied Medical Sciences, Majmaah University, Al Majmaah, 11952, Saudi Arabia; email: m.sikkandar@mu.edu.sa","","Tech Science Press","","","","","","15462218","","","","English","Comput. Mater. Continua","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85128662756"
"Onofrey J.A.; Staib L.H.; Huang X.; Zhang F.; Papademetris X.; Metaxas D.; Rueckert D.; Duncan J.S.","Onofrey, John A. (55823011300); Staib, Lawrence H. (7005557159); Huang, Xiaojie (55500290600); Zhang, Fan (57199243418); Papademetris, Xenophon (6602197282); Metaxas, Dimitris (7006359060); Rueckert, Daniel (7004895812); Duncan, James S. (57203363835)","55823011300; 7005557159; 55500290600; 57199243418; 6602197282; 7006359060; 7004895812; 57203363835","Sparse Data-Driven Learning for Effective and Efficient Biomedical Image Segmentation","2020","Annual Review of Biomedical Engineering","22","","","127","153","26","5","10.1146/annurev-bioeng-060418-052147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086052462&doi=10.1146%2fannurev-bioeng-060418-052147&partnerID=40&md5=3b2a39eb9a6e2673471e12f4a78eb877","Department of Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, 06520, CT, United States; Department of Urology, Yale School of Medicine, New Haven, 06520, CT, United States; Department of Biomedical Engineering, Yale University, New Haven, 06520, CT, United States; Department of Computer Science, Rutgers University, Piscataway, 08854, NJ, United States; Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Citadel Securities, Chicago, 60603, IL, United States","Onofrey J.A., Department of Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, 06520, CT, United States, Department of Urology, Yale School of Medicine, New Haven, 06520, CT, United States; Staib L.H., Department of Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, 06520, CT, United States, Department of Biomedical Engineering, Yale University, New Haven, 06520, CT, United States; Huang X., Department of Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, 06520, CT, United States, Citadel Securities, Chicago, 60603, IL, United States; Zhang F., Department of Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, 06520, CT, United States; Papademetris X., Department of Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, 06520, CT, United States, Department of Biomedical Engineering, Yale University, New Haven, 06520, CT, United States; Metaxas D., Department of Computer Science, Rutgers University, Piscataway, 08854, NJ, United States; Rueckert D., Department of Computing, Imperial College London, London, SW7 2AZ, United Kingdom; Duncan J.S., Department of Radiology and Biomedical Imaging, Yale School of Medicine, New Haven, 06520, CT, United States, Department of Biomedical Engineering, Yale University, New Haven, 06520, CT, United States","Sparsity is a powerful concept to exploit for high-dimensional machine learning and associated representational and computational efficiency. Sparsity is well suited for medical image segmentation. We present a selection of techniques that incorporate sparsity, including strategies based on dictionary learning and deep learning, that are aimed at medical image segmentation and related quantification. © 2020 by Annual Reviews. All rights reserved.","dictionary learning; image representation; image segmentation; machine learning; medical image analysis; Sparsity","Algorithms; Animals; Brain; Deep Learning; Dogs; Echocardiography; Heart Ventricles; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Models, Theoretical; Neural Networks, Computer; Tomography, X-Ray Computed; Computational efficiency; Deep learning; Medical image processing; Biomedical image segmentation; Dictionary learning; High-dimensional; Sparse data; deep learning; image analysis; image segmentation; review; algorithm; animal; brain; diagnostic imaging; dog; echocardiography; heart ventricle; human; image processing; machine learning; procedures; theoretical model; three-dimensional imaging; x-ray computed tomography; Image segmentation","","","","","National Institutes of Health, NIH, (R01CA206180, R41CA224888); National Institutes of Health, NIH; National Heart, Lung, and Blood Institute, NHLBI, (R01HL121226); National Heart, Lung, and Blood Institute, NHLBI","The writing of this review was supported in part by National Institutes of Health grants R41CA224888, R01HL121226, and R01CA206180.","Zhang Z, Xu Y, Yang J, Li X, Zhang D., A survey of sparse representation: algorithms and applications, IEEE Access, 3, pp. 490-530, (2015); Li S, Yin H, Fang L., Group-sparse representation with dictionary learning for medical image denoising and fusion, IEEE Trans. Biomed. Eng, 59, pp. 3450-3459, (2012); Ma L, Moisan L, Yu J, Zeng T., A dictionary learning approach for Poisson image deblurring, IEEE Trans. Med. Imaging, 32, pp. 1277-1289, (2013); Nayak N, Chang H, Borowsky A, Spellman P, Parvin B., Classifcation of tumor histopathology via sparse feature learning, Proceedings of the 10th IEEE International Symposium on Biomedical Imaging, pp. 410-413, (2013); Onofrey JA, Oksuz I, Sarkar S, Venkataraman R, Staib LH, Papademetris X., MRI-TRUS image synthesis with application to image-guided prostate intervention, Proceedings of the International Workshop on Simulation and Synthesis in Medical Imaging, pp. 157-166, (2016); Huang X, Dione DP, Compas CB, Papademetris X, Lin BA, Et al., Contour tracking in echocar-diographic sequences via sparse representation and dictionary learning, Med. Image Anal, 18, pp. 253-271, (2014); Fang R, Chen T, Metaxas D, Sanelli P, Zhang S., Sparsity techniques in medical imaging, Comput. Med. Imaging Graph, 46, (2015); Brill AB, Price RR, McClain WJ, Landay MW, Proceedings of the 5th International Conference on Information Processing in Medical Imaging, (1977); Sklansky J., Boundary detection in medical radiography, Digital Processing of Biomedical Images, pp. 307-322, (1976); Duda RO, Hart PE, Stork DG., Pattern Classifcation, (2012); Ballard DH, Brown CM., Computer Vision, (1982); Pham D, Xu C, Prince J., Current methods in medical image segmentation, Annu. Rev. Biomed. Eng, 2, pp. 315-337, (2000); Ashburner J, Friston KJ., Unifed segmentation, NeuroImage, 26, pp. 839-851, (2005); Zhang Y, Brady M, Smith S., Segmentation of brain MR images through a hidden Markov random feld model and the expectation-maximization algorithm, IEEE Trans. Med. Imaging, 20, pp. 45-57, (2001); Van Leemput K, Maes F, Vandermeulen D, Suetens P., Automated model-based tissue classifcation of MR images of the brain, IEEE Trans. Med. Imaging, 18, pp. 897-908, (1999); Roy S, Carass A, Bazin PL, Prince JL., A Rician mixture model classifcation algorithm for magnetic resonance images, Proceedings of the 2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro, pp. 406-409, (2009); Pham DL., Spatial models for fuzzy clustering, Comput. Vis. Image Underst, 84, pp. 285-297, (2001); Bai W, Shi W, Ledig C, Rueckert D., Multi-atlas segmentation with augmented features for cardiac MR images, Med. Image Anal, 19, pp. 98-109, (2015); Couprie C, Grady L, Najman L, Talbot H., Power watershed: a unifying graph-based optimization framework, IEEE Trans. Pattern Anal. Mach. Intell, 33, pp. 1384-1399, (2011); Roy S, Carass A, Prince J., A compressed sensing approach for MR tissue contrast synthesis, Inf. Process. Med. Imaging, 22, pp. 371-383, (2011); Wang Z, Donoghue C, Rueckert D., Patch-based segmentation without registration: application to knee MRI, Proceedings of the International Workshop on Machine Learning in Medical Imaging, pp. 98-105, (2013); Staib LH, Duncan JS., Boundary fnding with parametrically deformable models, IEEE Trans. Pattern Anal. Mach. Intell, 14, pp. 1061-1075, (1992); Chakraborty A, Staib LH, Duncan JS., Deformable boundary fnding in medical images by integrating gradient and region information, IEEE Trans. Med. Imaging, 15, pp. 859-870, (1996); Cootes TF, Taylor CJ, Cooper DH, Graham J., Active shape models-their training and application, Comput. Vis. Image Underst, 61, pp. 38-59, (1995); Cootes TF, Edwards G, Taylor C., Active appearance models, IEEE Trans. Pattern Anal. Mach. Intell, 23, pp. 681-685, (2001); Cortes C, Vapnik V., Support-vector networks, Mach. Learn, 20, pp. 273-297, (1995); Breiman L., Random forests, Mach. Learn, 45, pp. 5-32, (2001); Shen D, Wu G, Suk HI., Deep learning in medical image analysis, Annu. Rev. Biomed. Eng, 19, pp. 221-248, (2017); Marimont RB, Shapiro MB., Nearest neighbour searches and the curse of dimensionality, IMA J. Appl. Math, 24, pp. 59-70, (1979); Chen C, Ozolek J, Wang W, Rohde G., A pixel classifcation system for segmenting biomedical images using intensity neighborhoods and dimension reduction, Proceedings of the IEEE International Symposium on Biomedical Imaging: From Nano to Macro, pp. 1649-1652, (2011); Baraniuk RG, Candes E, Elad M, Ma Y., Applications of sparse representation and compressive sensing, Proc. IEEE, 98, pp. 906-909, (2010); Wright J, Yang A, Ganesh A, Sastry S, Ma Y., Robust face recognition via sparse representation, IEEE Trans. Pattern Anal. Mach. Intell, 31, pp. 210-227, (2009); Huang K, Aviyente S., Sparse representation for signal classifcation, Proceedings of Advances in Neural Information Processing Systems 19 (NIPS 2006), pp. 609-616, (2006); Mairal J, Leordeanu M, Bach F, Hebert M, Ponce J., Discriminative sparse image models for class-specifc edge detection and image interpretation, Proceedings of the 2008 European Conference on Computer Vision, pp. 43-56, (2008); Peyre G., Sparse modeling of textures, J. Math. Imaging Vis, 34, pp. 17-31, (2009); Skretting K, Husoy JH., Texture classifcation using sparse frame-based representations, EURASIP J. Appl. Signal Process, 2006, (2006); Wright J, Ma Y, Mairal J, Sapiro G, Huang T, Yan S., Sparse representation for computer vision and pattern recognition, Proc. IEEE, 98, pp. 1031-1044, (2010); Candes E, Romberg J, Tao T., Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information, IEEE Trans. Inf. Theory, 52, pp. 489-509, (2006); Rodriguez F, Sapiro G., Sparse representations for image classifcation: learning discriminative and re-constructive non-parametric dictionaries, (2007); Zhang S, Zhan Y, Dewan M, Huang J, Metaxas DN, Zhou XS., Towards robust and effective shape modeling: sparse shape composition, Med. Image Anal, 16, pp. 265-277, (2012); Zhang S, Zhan Y, Metaxas DN., Deformable segmentation via sparse representation and dictionary learning, Med. Image Anal, 16, pp. 1385-1396, (2012); Zhang S, Zhan Y, Zhou Y, Uzunbas MG, Metaxas DN., Shape prior modeling using sparse representation and online dictionary learning, Proceedings of the 15th Annual Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI2012), pp. 435-442, (2012); Shi W, Zhuang X, Pizarro L, Bai W, Wang H, Et al., Registration using sparse free-form deformations, Proceedings of the 15th Annual Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2012), pp. 659-666, (2012); Wee CY, Yap PT, Zhang D, Wang L, Shen D., Constrained sparse functional connectivity networks for MCI classifcation, Proceedings of the 15th Annual Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2012), pp. 212-219, (2012); Davis G, Mallat S, Avellaneda M., Adaptive greedy approximations, Constr. Approx, 13, pp. 57-98, (1997); Mallat S, Zhang Z., Matching pursuits with time-frequency dictionaries, IEEE Trans. Signal Process, 41, pp. 3397-3415, (1993); Pati YC, Rezaiifar R, Krishnaprasad PS., Orthogonal matching pursuit: recursive function approx-imation with applications to wavelet decomposition, Proceedings of the 27th Annual Asilomar Conference on Signals, Systems, and Computers, pp. 40-44, (1993); Davis GM, Mallat SG, Zhang Z., Adaptive time-frequency decompositions, Opt. Eng, 33, pp. 2183-2191, (1994); Tropp J., Greed is good: algorithmic results for sparse approximation, IEEE Trans. Inf. Theory, 50, pp. 2231-2242, (2004); Starck J, Elad M, Donoho D., Image decomposition via the combination of sparse representations and a variational approach, IEEE Trans. Image Proc, 14, pp. 1570-1582, (2005); Donoho DL., For most large underdetermined systems of linear equations the minimal 1-norm solution is also the sparsest solution, Commun. Pure Appl. Math, 59, pp. 797-829, (2006); Liao S, Gao Y, Lian J, Shen D., Sparse patch-based label propagation for accurate prostate localization in CT images, IEEE Trans. Med. Imaging, 32, pp. 419-434, (2013); Tibshirani R., Regression shrinkage and selection via the lasso, J. R. Stat. Soc. B, 58, pp. 267-288, (1996); Zou H, Hastie T., Regularization and variable selection via the elastic net, J. R. Stat. Soc. B, 67, pp. 301-320, (2005); Aharon M, Elad M, Bruckstein A., K-SVD: an algorithm for designing overcomplete dictionaries for sparse representation, IEEE Trans. Signal Process, 54, pp. 4311-4322, (2006); Engan K, Aase S, Husoy J., Frame based signal compression using method of optimal directions (MOD), Proceedings of the 1999 IEEE International Symposium on Circuits and Systems (ISCAS), 4, pp. 1-4, (1999); Mairal J, Bach F, Ponce J, Sapiro G., Online dictionary learning for sparse coding, Proceedings of the 26th International Conference on Machine Learning, pp. 689-696, (2009); Tropp JA, Gilbert AC., Signal recovery from random measurements via orthogonal matching pursuit, IEEE Trans. Inf. Theory, 53, pp. 4655-4666, (2007); Mairal J, Bach F, Ponce J, Sapiro G, Zisserman A., Discriminative learned dictionaries for local image analysis, Proceedings of the 2008 IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, (2008); Glorot X, Bordes A, Bengio Y., Deep sparse rectifer neural networks, J.Mach. Learn. Res, 15, pp. 315-323, (2011); Narang S, Diamos GF, Sengupta S, Elsen E., Exploring sparsity in recurrent neural networks, (2017); Shi S, Chu X., Speeding up convolutional neural networks by exploiting the sparsity of rectifer units, (2017); Ng A., Sparse autoencoder, (2011); Le QV, Coates A, Prochnow B, Ng AY., On optimization methods for deep learning, J. Mach. Learn. Res, 15, pp. 265-272, (2011); Scardapane S, Comminiello D, Hussain A, Uncini A., Group sparse regularization for deep neural networks, Neurocomputing, 241, pp. 81-89, (2017); Xu J, Xiang L, Liu Q, Gilmore H, Wu J, Et al., Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images, IEEE Trans. Med. Imaging, 35, pp. 119-130, (2015); Liu B, Wang M, Foroosh H, Tappen M, Penksy M., Sparse convolutional neural networks, Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition, pp. 806-814, (2015); Srivastava N, Hinton G, Krizhevsky A, Sutskever I, Salakhutdinov R., Dropout: a simple way to prevent neural networks from overftting, J. Mach. Learn. Res, 15, pp. 1929-1958, (2014); Papyan V, Romano Y, Elad M., Convolutional neural networks analyzed via convolutional sparse coding, J. Mach. Learn. Res, 18, pp. 1-52, (2017); Poultney C, Chopra S, Le Cun Y., Effcient learning of sparse representations with an energy-based model, Proceedings of Advances in Neural Information Processing Systems 20 (NIPS 2007), pp. 1137-1144, (2007); Ben-Cohen A, Klang E, Kerpel A, Konen E, Amitai MM, Greenspan H., Fully convolutional network and sparsity-based dictionary learning for liver lesion detection in CT examinations, Neurocomput-ing, 275, pp. 1585-1594, (2018); Huang X, Lin BA, Compas CB, Sinusas AJ, Staib LH, Duncan JS., Segmentation of left ventricles from echocardiographic sequences via sparse appearance representation, Proceedings of the 2012 IEEE Workshop on Mathematical Methods in Biomedical Image Analysis, pp. 305-312, (2012); Huang X, Dione DP, Compas CB, Papademetris X, Lin BA, Et al., A dynamical appearance model based on multiscale sparse representation: segmentation of the left ventricle from 4D echocardiography, Proceedings of the 15th Annual Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2012), pp. 58-65, (2012); Huang X, Dione DP, Lin BA, Bregasi A, Sinusas AJ, Duncan JS., Segmentation of 4D echocardio-graphy using stochastic online dictionary learning, Proceedings of the 16th Annual Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2013), pp. 57-65, (2013); Onofrey JA, Staib LH, Papademetris X., Segmenting the brain surface from CT images with ar-tifacts using locally-oriented appearance and dictionary learning, IEEE Trans. Med. Imaging, 38, pp. 596-607, (2018); Tong T, Wolz R, Coupe P, Hijnal J, Rueckert D, Et al., Segmentation of MR images via discriminative dictionary learning and sparse coding: application to hippocampus labeling, NeuroImage, 76, pp. 11-23, (2013); Roy S, He Q, Sweeney E, Carass A, Reich D, Et al., Subject-specifc sparse dictionary learning for atlas-based brain MRI segmentation, IEEE J. Biomed. Health Inform, 19, pp. 1598-1609, (2015); Zhang F, Yang J, Nezami N, Laage-gaupp F, Chapiro J, Et al., Liver tissue classifcation using an auto-context-based deep neural network with a multi-phase training framework, Proceedings of the 4th International Workshop on Patch-Based Techniques in Medical Imaging, pp. 59-66, (2018); Amini A, Duncan J., Pointwise tracking of left-ventricular motion, Proc. IEEE Workshop Vis. Motion, 1, pp. 294-299, (1991); McEachen JC, Nehorai A, Duncan JS., Multiframe temporal estimation of cardiac nonrigid motion, IEEE Trans. Image Proc, 9, pp. 651-665, (2000); Compas C, Wong E, Huang X, Sampath S, Pal P, Et al., Radial basis functions for combining shape and speckle tracking in 4D echocardiography, IEEE Trans. Med. Imaging, 33, pp. 1275-1289, (2014); Mairal J, Sapiro G, Elad M., Learning multiscale sparse representations for image and video restoration, Multiscale Model. Simul, 7, pp. 214-241, (2008); Freund Y, Schapire R., A decision-theoretic generalization of on-line learning and an application to boosting, J. Comput. Syst. Sci, 55, pp. 119-139, (1997); Sarti A, Corsi C, Mazzini E, Lamberti C., Maximum likelihood segmentation of ultrasound images with Rayleigh distribution, IEEE Trans. Ultrason. Ferroelectr. Freq. Control, 52, pp. 947-960, (2005); Zhu Y, Papademetris X, Sinusas A, Duncan J., Segmentation of the left ventricle from cardiac MR images using a subject-specifc dynamical model, IEEE Trans. Med. Imaging, 29, pp. 669-687, (2010); Studholme C, Novotny E, Zubal I, Duncan J., Estimating tissue deformation between functional images induced by intracranial electrode implantation using anatomical MRI, NeuroImage, 13, pp. 561-576, (2001); Skrinjar O, Spencer D, Duncan J., Brain shift modeling for use in neurosurgery, Proceedings of the 1st International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 1998), pp. 641-649, (1998); Skrinjar O, Duncan J., Real time 3D brain shift compensation, Proceedings of the Biennial Inter national Conference on Information Processing in Medical Imaging, pp. 42-55, (1999); Skrinjar O, Nabavi A, Duncan J., Model-driven brain shift compensation, Med. Image Anal, 6, pp. 361-373, (2002); Chui H, Rangarajan A., A new point matching algorithm for non-rigid registration, Comput. Vis. Image Underst, 89, pp. 114-141, (2003); Myronenko A, Song X., Point set registration: coherent point drift, IEEE Trans. Pattern Anal. Mach. Intell, 32, pp. 2262-2275, (2010); Smith SM., Fast robust automated brain extraction, Hum. Brain Mapp, 17, pp. 143-155, (2002); Zhang Q, Li B., Discriminative K-SVD for dictionary learning in face recognition, Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 2691-2698, (2010); Jack CR, Bernstein MA, Fox NC, Thompson P, Alexander G, Et al., The Alzheimer's Disease Neuroimaging Initiative (ADNI): MRI methods, J. Magn. Reson. Imaging, 27, pp. 685-691, (2008); Mazziotta J, Toga A, Evans A, Fox P, Lancaster J, Et al., A probabilistic atlas and reference system for the human brain: International Consortium for Brain Mapping (ICBM), Philos. Trans. R. Soc. B, 356, pp. 1293-1322, (2001); Coupe P, Manjn J, Fonov V, Pruessner J, Robles M, Collins D., Patch-based segmentation using expert priors: application to hippocampus and ventricle segmentation, NeuroImage, 54, pp. 940-954, (2011); Nyul LG, Udupa JK., On standardizing the MR image intensity scale, Magn. Reson. Med, 42, pp. 1072-1081, (1999); Zhang S, Zhan Y, Dewan M, Huang J, Metaxas D., Towards robust and effective shape modeling: sparse shape composition, Med. Image Anal, 16, pp. 265-277, (2012); Wang G, Zhang S, Xie H, Metaxas D, Gu L., A homotopy-based sparse representation for fast and accurate shape prior modeling in liver surgical planning, Med. Image Anal, 19, pp. 176-186, (2015); Shen D, Davatzikos C., An adaptive-focus deformable model using statistical and geometric infor-mation, IEEE Trans. Pattern Anal. Mach. Intell, 22, pp. 906-913, (2000); Zhan Y, Shen D., Deformable segmentation of 3D ultrasound prostate images using statistical texture matching method, IEEE Trans. Med. Imaging, 25, pp. 256-272, (2006); Bookstein F., Principal warps: thin-plate splines and the decomposition of deformations, IEEE Trans. Pattern Anal. Mach. Intell, 11, pp. 567-585, (1989); Ronneberger O, Fischer P, Brox T., U-net: convolutional networks for biomedical image seg-mentation, Proceedings of the 18th Annual Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2015), pp. 234-241, (2015); Raza A, Sood GK., Hepatocellular carcinoma review: current treatment, and evidence-based medicine, World J. Gastroenterol, 20, pp. 4115-4127, (2014); Raoul JL, Sangro B, Forner A, Mazzaferro V, Piscaglia F, Et al., Evolving strategies for the management of intermediate-stage hepatocellular carcinoma: available evidence and expert opinion on the use of transarterial chemoembolization, Cancer Treat. Rev, 37, pp. 212-220, (2011); Tu Z, Bai X., Auto-context and its application to high-level vision tasks and 3D brain image segmentation, IEEE Trans. Pattern Anal. Mach. Intell, 32, pp. 1744-1757, (2010); Treilhard J, Smolka S, Staib L, Chapiro J, Lin M, Et al., Liver tissue classifcation in patients with hepatocellular carcinoma by fusing structured and rotationally invariant context representation, Proceedings of the 20th Annual Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2017), pp. 81-88, (2017); Christ PF, Elshaer MEA, Ettlinger F, Tatavarty S, Bickel M, Et al., Automatic liver and lesion segmentation in CT using cascaded fully convolutional neural networks and 3D conditional random felds, Proceedings of the 19th Annual Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2016), pp. 415-423, (2016); Li W, Jia F, Hu Q., Automatic segmentation of liver tumor in CT images with deep convolutional neural networks, J. Comput. Commun, 3, pp. 146-151, (2015); Papademetris X, Jackowski MP, Rajeevan N, DiStasio M, Okuda H, Et al., BioImage Suite: an integrated medical image analysis suite: an update, Insight J, 2006, (2006)","","","Annual Reviews Inc.","","","","","","15239829","","ARBEF","32169002","English","Annu. Rev. Biomed. Eng.","Review","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85086052462"
"Anusha C.; Avadhani P.S.","Anusha, Chamarty (57211622942); Avadhani, P.S. (57204399665)","57211622942; 57204399665","Optimal accuracy zone identification in object detection technique-a learning rate methodology","2019","International Journal of Engineering and Advanced Technology","9","1","","6470","6476","6","3","10.35940/ijeat.A2258.109119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074655906&doi=10.35940%2fijeat.A2258.109119&partnerID=40&md5=00034cb65b7b053da8703fb28736ad43","Andhra University College of Engineering, Andhra University, Visakhapatnam, AP, India","Anusha C., Andhra University College of Engineering, Andhra University, Visakhapatnam, AP, India; Avadhani P.S., Andhra University College of Engineering, Andhra University, Visakhapatnam, AP, India","In the recent past, Deep Learning models [1] are predominantly being used in Object Detection algorithms due to their accurate Image Recognition capability. These models extract features from the input images and videos [2] for identification of objects present in them. Various applications of these models include Image Processing, Video analysis, Speech Recognition, Biomedical Image Analysis, Biometric Recognition, Iris Recognition, National Security applications, Cyber Security, Natural Language Processing [3], Weather Forecasting applications, Renewable Energy Generation Scheduling etc. These models utilize the concept of Convolutional Neural Network (CNN) [3], which constitutes several layers of artificial neurons. The accuracy of Deep Learning models [1] depends on various parameters such as ‘Learning-rate’, ‘Training batch size’, ‘Validation batch size’, ‘Activation Function’, ‘Drop-out rate’ etc. These parameters are known as Hyper-Parameters. Object detection accuracy depends on selection of Hyper-parameters and these in-turn decides the optimum accuracy. Hence, finding the best values for these parameters is a challenging task. Fine-Tuning is a process used for selection of a suitable Hyper-Parameter value for improvement of object detection accuracy. Selection of an inappropriate Hyper-Parameter value, leads to Over-Fitting or Under-Fitting of data. Over-Fitting is a case, when training data is larger than the required, which results in learning noise and inaccurate object detection. Under-fitting is a case, when the model is unable to capture the trend of the data and which leads to more erroneous results in testing or training data. In this paper, a balance between Over-fitting and Under-fitting is achieved by varying the ‘Learning rate’ of various Deep Learning models. Four Deep Learning Models such as VGG16, VGG19, InceptionV3 and Xception are considered in this paper for analysis purpose. The best zone of Learning-rate for each model, in respect of maximum Object Detection accuracy, is analyzed. In this paper a dataset of 70 object classes is taken and the prediction accuracy is analyzed by changing the ‘Learning-rate’ and keeping the rest of the Hyper-Parameters constant. This paper mainly concentrates on the impact of ‘Learning-rate’ on accuracy and identifies an optimum accuracy zone in Object Detection. © BEIESP.","Convolution neural network; Deep learning; Hyper-parameter; InceptionV3; Learning-rate; Object detection; VGG-16; VGG-19; Xception","","","","","","","","Anusha C., Avadhani P.S., Object Detection Using Deep Learning, International Journal of Computer Applications, 182, 32, pp. 18-22, (2018); Le Cun Y., Bengio Y., Hinton G., Deep Learning, Nature, 521, 7553, pp. 436-444, (2015); Girshick R., Donahue J., Darrell T., Malik J., Region based Convolutional Networks for Accurate Object Detection and Segmentation, IEEE Transactions on Pattern Analysis and Machine Intelligence, 38, pp. 142-158, (2016); Peace I., Uzoma A.O., Abasiamaita S., Effect of Learning Rate on Artificial Neural Network in Machine Learning, International Journal of Engineering Research & Technology (IJERT), 4, 2, (2015); Peng J.-X., Li K., Irwin G.W., A New Jacobian Matrix for Optimal Learning of Single-Layer Neural Networks, IEEE Transactions on Neural Networks, 19, 1, pp. 119-129, (2008); Anusha C., Avadhani P.S., Fine-Tuning Convolutional Neural Network Models for improvement of Object Detection Accuracy, International Journal of Engineering and Advanced Technology, 8, 5, (2019); Zhang X., Yan F., Zhuang Y., Hu H., Bu C., Using an Ensemble of Incrementally Fine-Tuned CNNs for Cross-Domain Object Category Recognition, In IEEE Access, 7, pp. 33822-33833, (2019); Zhao Z.-Q., Zheng P., Xu S.-T., Wu X., Object Detection with Deep Learning: A Review, (2019); Gu J., Wang Z., Kuen J., Ma L., Shahroudy A., Shuai B., Liu T., Wang X., Wangcai G., Chen T., Recent Advances in Convolutional Neural Networks, Pattern Recognition, 77, pp. 354-377, (2018); Girshick R., Fast R-CNN, (2015); Wilson D.R., Martinez T.R., The need for small learning rates on large problems, In IEEE Conference on International Joint Conference on Neural Networks, (2001); Son H.J., Trafails T.B., Richman M.B., Determination of the optimal batch size in incremental approaches: An application to tornado detection, In IEEE International Joint Conference on Neural Networks, (2005); Krizhevsky A., Sutskever L., Hinton G.E., ImagNet Classification with Deep Convolutional Neural Network”, The Conference on Neural Information Processing Systems, (2012); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, In International Conference on Learning Representations, (2015); Christian Szegedy W.L., Yangqingjia P.S., Scott Reed D., Dumitruerhan V.V., Rabinovich A., Going Deeper with Convolutions, In the Conference on Computer Vision and Pattern Recognition, (2015); Francois C., Deep Learning with Depthwise Seperable Convolutions”, The Conference on Computer Vision and Pattern Recognition, (2017); Matthew D., Zeiler, Rob Fergus, “Visualizing and Understanding Convolutional Networks”, Arxiv, (2013)","","","Blue Eyes Intelligence Engineering and Sciences Publication","","","","","","22498958","","","","English","Int. J. Eng. Adv. Technol.","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85074655906"
"Azran A.; Schclar A.; Saabni R.","Azran, Adi (57234967700); Schclar, Alon (8319691800); Saabni, Raid (35198993400)","57234967700; 8319691800; 35198993400","Text line extraction using deep learning and minimal sub seams","2021","DocEng 2021 - Proceedings of the 2021 ACM Symposium on Document Engineering","","","3474941","","","","1","10.1145/3469096.3474941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113610367&doi=10.1145%2f3469096.3474941&partnerID=40&md5=c41fc70ea9926e11e979de88c2cd9cdf","School of Computer Science, The Academic College of Tel-Aviv, Tel-Aviv Yaffo, Yaffo, Israel","Azran A., School of Computer Science, The Academic College of Tel-Aviv, Tel-Aviv Yaffo, Yaffo, Israel; Schclar A., School of Computer Science, The Academic College of Tel-Aviv, Tel-Aviv Yaffo, Yaffo, Israel; Saabni R., School of Computer Science, The Academic College of Tel-Aviv, Tel-Aviv Yaffo, Yaffo, Israel","Accurate text line extraction is a vital prerequisite for efficient and successful text recognition systems ranging from keywords/phrases searching to complete conversion to text. In many cases, the proposed algorithms target binary pre-processed versions of the image, which may cause insufficient results due to poor quality document images. Recently, more papers present solutions that work directly on gray-level images [1,2,7,12,15]. In this paper, we present a novel robust, and efficient algorithm to extract text-lines directly from gray-level document images. The proposed approach uses a combination of two variants of Convolutional Neural Network (CNNs), followed by minimal energy seam extraction. The first ConvNet is a modified version of the autoencoder used for biomedical image segmentation [8]. The second is a deep convolutional Neural Network, working on overlapping vertical slices of the original image. The two variants are combined to one neural net after re-attaching the resulting slices of the second net. The merged results of the two nets are used as a preprocessed image to obtain an energy map for a second phase. In the second step, we use the algorithm presented in [2], to track minimal energy sub-seams accumulated to perform a full local minimal/maximal separating and medial seam defining the text baselines and the text line regions. We have tested our approach on multi-lingual various datasets written at a range of image quality based on the ICDAR datasets.  © 2021 ACM.","convolutional neural networks; historical document image analysis; image processing; line extraction; local projection profile; minimal seams; seam carving; text line extraction","Character recognition; Convolution; Convolutional neural networks; Deep neural networks; Digital image storage; Extraction; Image segmentation; Biomedical image segmentation; Document images; Gray level image; Minimal energy; Original images; Text recognition; Text-line extractions; Vertical slices; Deep learning","","","","","","","Saabni R., El-Sana J., Language-independent text lines extraction using seam carving, Document Analysis and Recognition (ICDAR), pp. 563-568, (2011); Saabni R., Robust and efficient text-line extraction by local minimal sub-seams, Iscsic '18: The 2nd International Symposium on Computer Science and Intelligent, (2018); Saabni R., Asi A., El-Sana J., Text line extraction for historical document images, Pattern Recognition Letters, pp. 23-33, (2014); Nikolaou N., Makridis M., Gatos B., Stamatopoulos N., Papamarkos N., Segmentation of historical machine-printed documents using adaptive run length smoothing and skeleton segmentation paths, Image and Vision Computing, pp. 590-604, (2010); Soullard Y., Kermorvant C., Chatelain Cl., Paquet T., Fully Convolutional Network with Dilated Convolutions for Handwritten Text Line Segmentation, (2013); Baechler M., Liwicki M., Ingold R., Text line extraction using dmlp classifiers for historical manuscripts, The 12th International Conference on Document Analysis and Recognition, pp. 1029-1033, (2013); Gruning T., Leifert G., Strauss T., Michael J., Labahn R., A two stage method for text line detection in historical documents, International Journal on Document Analysis and Recognition (IJDAR), 22, 3, pp. 285-302, (2019); Ronneberger O., Fischer P., Thomas Brox: U-Net: Convolutional Networks for Biomedical Image Segmentation, (2015); Stamatopoulos N., Gatos B., Louloudis G., Pal U., Alaei A., Icdar 2013 handwriting segmentation contest, 2013 12th International Conference on Document Analysis and Recognition, pp. 1402-1406, (2013); Diem M., Kleber F., Fiel S., Gruning T., Gatos B., Cbad: Icdar2017 competition on baseline detection, The 14th Iapr International Conference on Document Analysis and Recognition, pp. 1355-1360, (2017); Markus D., Florian K., Robert S., Basilis G., CBAD: ICDAR2019 Competition on Baseline Detection, 2019, pp. 1494-1498, (2019); Barakat B.K., El-Sana J., Rabaev I., The pinkasdataset, The 15th International Conference on Document Analysis and Recognition, pp. 732-737, (2019); He K., Gkioxari G., Dollar P., Girshick R., Mask r-cnn, Proceedings of the Ieee International Conference on Computer Vision, pp. 2961-2969, (2017); Kurar Barakat B., Droby A., Alasam R., Madi B., Rabaev I., Shammes R., El-Sana J., Unsupervised deep learning for text line segmentation, The 25th International Conference on Pattern Recognition (ICPR), pp. 3651-3656, (2020); Renton G., Chatelain C., Adam S., Kermorvant C., Paquet T., Handwritten text line segmentation using fully convolutional network, The 14th Iapr International Conference on Document Analysis and Recognition (ICDAR), pp. 5-9, (2017); Saabni R.M., El-Sana J.A., Keywords image retrieval in historical handwritten arabic documents, Journal of Electronic Imaging, 22, 1, pp. 1-9, (2013); Saabni R., Bronstein A., Fast key-word searching via embedding and active-dtw, 2011 International Conference on Document Analysis and Recognition, pp. 68-72, (2011)","","","Association for Computing Machinery, Inc","ACM SIGWEB","21st ACM Symposium on Document Engineering, DocEng 2021","24 August 2021 through 27 August 2021","Virtual, Online","171225","","978-145038596-1","","","English","DocEng - Proc. ACM Symp. Doc. Eng.","Conference paper","Final","","Scopus","2-s2.0-85113610367"
"Guo K.; Wu J.; Wan W.; Li L.; Wang T.; Zhu X.; Qu L.","Guo, Kaixuan (57215183906); Wu, Jun (57266847900); Wan, Wan (57285346200); Li, Longfei (57223305256); Wang, Tao (58736748500); Zhu, Xingliang (57215524940); Qu, Lei (36175185400)","57215183906; 57266847900; 57285346200; 57223305256; 58736748500; 57215524940; 36175185400","Biomedical image segmentation based on classification supervision","2021","ACM International Conference Proceeding Series","","","","22","27","5","0","10.1145/3473258.3473262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121702646&doi=10.1145%2f3473258.3473262&partnerID=40&md5=bc8916f30d4067e7b93d1ddfecd0f51f","School of Electronics and Information Engineering, Anhui University, 111 Jiulong Road, Hefei, China","Guo K., School of Electronics and Information Engineering, Anhui University, 111 Jiulong Road, Hefei, China; Wu J., School of Electronics and Information Engineering, Anhui University, 111 Jiulong Road, Hefei, China; Wan W., School of Electronics and Information Engineering, Anhui University, 111 Jiulong Road, Hefei, China; Li L., School of Electronics and Information Engineering, Anhui University, 111 Jiulong Road, Hefei, China; Wang T., School of Electronics and Information Engineering, Anhui University, 111 Jiulong Road, Hefei, China; Zhu X., School of Electronics and Information Engineering, Anhui University, 111 Jiulong Road, Hefei, China; Qu L., School of Electronics and Information Engineering, Anhui University, 111 Jiulong Road, Hefei, China","Convolutional neural networks (CNN) has been widely used in the biomedical image segmentation (BIS) for their remarkable feature representation capability. However, there are often segmentation errors and missing segmentation problems in biomedical image segmentation based on deep learning. In this paper, we propose a full convolutional neural network, which is assisted by classification supervision based on segmentation network. The algorithm first obtains a segmentation result through a basic segmentation network. Then a Classification Supervision Module (CSM) is designed to enable the network to judge whether each slicer contains lesions from the perspective of classification. In this way we allow the network to take advantage of more global information. Experimental results on several available databases demonstrate the effectiveness and advancement of the proposed method.  © 2021 ACM.","Biomedical image; Classification supervision; Convolutional neural network; Image segmentation","Convolution; Convolutional neural networks; Deep learning; Image classification; Biomedical image segmentation; Biomedical images; Classification supervision; Convolutional neural network; Feature representation; Global informations; Images segmentations; Segmentation error; Segmentation results; Image segmentation","","","","","University Synergy Innovation Program of Anhui Province, (GXXT-2019-008); National Natural Science Foundation of China, NSFC, (61871411, 61901003); Natural Science Foundation of Anhui Province, (1908085QF255)","This research was funded by the National Natural Science Foundation of China (61871411 and 61901003), the Anhui Provincial Natural Science Foundation (1908085QF255), and The University Synergy Innovation Program of Anhui Province (GXXT-2019-008). And the authors acknowledge the High-performance Computing Platform of Anhui University for providing computing resources.","Siegel R.L., Miller K.D., Goding Sauer A., Fedewa S.A., Butterly L.F., Anderson J.C., Jemal A., Colorectal cancer statistics, 2020, CA: a Cancer Journal for Clinicians, (2020); Releasing of the white paper on medical imaging artificial intelligence in china, Chinese Medical Sciences Journal, 34, 2, (2019); Minaee S., Boykov Y., Porikli F., Plaza A., Kehtarnavaz N., Terzopoulos D., Image Segmentation Using Deep Learning: A Survey, (2020); Ciresan D., Giusti A., Gambardella L.M., Schmidhuber J., Deep neural networks segment neuronal membranes in electron microscopy images, Advances in Neural Information Processing Systems, 25, pp. 2843-2851, (2012); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, 39, pp. 3431-3440, (2015); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Miccai, 9351, pp. 234-241, (2015); Liu H., Shen X., Shang F., Wang F., Cu-net: Cascaded unet with loss weighted sampling for brain tumor segmentation, MBIA/MFCA@MICCAI, pp. 102-111, (2019); Seo H., Huang C., Bassenne M., Xiao R., Xing L., Modified u-net (mu-net) with incorporation of object-dependent high level features for improved liver and liver-tumor segmentation in ct images, Ieee Transactions on Medical Imaging, 39, 5, pp. 1316-1325, (2020); Chen L.C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Semantic image segmentation with deep convolutional nets and fully connected crfs, CoRR, (2015); Chen L.C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs, Ieee Transactions on Pattern Analysis and Machine Intelligence, 40, 4, pp. 834-848, (2018); Chen L.C., Papandreou G., Schroff F., Adam H., Rethinking Atrous Convolution for Semantic Image Segmentation, (2017); Liu S., Qi L., Qin H., Shi J., Jia J., Path aggregation network for instance segmentation, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8759-8768, (2018); Abdulkadir A., Lienkamp S.S., Et al., 3d u-net: Learning dense volumetric segmentation from sparse annotation, Miccai, (2016); Chen W., Liu B., Peng S., Sun J., Qiao X., S3d-unet: Separable 3d u-net for brain tumor segmentation, Miccai Brainlesion Workshop, (2018); Nuechterlein N., Mehta S., 3D-ESPNet with Pyramidal Refinement for Volumetric Brain Tumor Image Segmentation, Miccai Brainlesion Workshop, (2018); Wang Q., Shi Y., Suk H.I., Et al., Machine Learning in Medical Imaging Volume 10541 || 3D U-net with Multi-level Deep Supervision: Fully Automatic Segmentation of Proximal Femur in 3D Mr Images[J], pp. 274-282, (2017); Chen C., Liu X., Ding M., Et al., 3d dilated multi-fiber network for real-time brain tumor segmentation in mri[c], International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 184-192, (2019); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Et al., Unet++: A nested u-net architecture for medical image segmentation, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support: 4th International Workshop, Dlmia 2018, and 8th International Workshop, ML-CDS 2018, Held in Conjunction with Miccai 2018, pp. 3-11, (2018); Huang H., Lin L., Feng Tong R., Et al., Unet 3+: A full-scale connected unet for medical image segmentation, Icassp 2020 - 2020 Ieee International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1055-1059, (2020)","","","Association for Computing Machinery","","13th International Conference on Bioinformatics and Biomedical Technology, ICBBT 2021","21 May 2021 through 23 May 2021","Xi'an","175425","","978-145038965-5","","","English","ACM Int. Conf. Proc. Ser.","Conference paper","Final","","Scopus","2-s2.0-85121702646"
"Račić L.; Popović T.; Čakić S.; Šandi S.","Račić, Luka (57223008261); Popović, Tomo (7006324784); Čakić, Stevan (57216726692); Šandi, Stevan (57193401703)","57223008261; 7006324784; 57216726692; 57193401703","Pneumonia Detection Using Deep Learning Based on Convolutional Neural Network","2021","2021 25th International Conference on Information Technology, IT 2021","","","9390137","","","","49","10.1109/IT51528.2021.9390137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104431624&doi=10.1109%2fIT51528.2021.9390137&partnerID=40&md5=220b902e2ad99c28a98cb623fc75984f","University of Donja Gorica, Faculty for Information Systems and Technologies, Oktoih 1, Podgorica, 81000, Montenegro","Račić L., University of Donja Gorica, Faculty for Information Systems and Technologies, Oktoih 1, Podgorica, 81000, Montenegro; Popović T., University of Donja Gorica, Faculty for Information Systems and Technologies, Oktoih 1, Podgorica, 81000, Montenegro; Čakić S., University of Donja Gorica, Faculty for Information Systems and Technologies, Oktoih 1, Podgorica, 81000, Montenegro; Šandi S., University of Donja Gorica, Faculty for Information Systems and Technologies, Oktoih 1, Podgorica, 81000, Montenegro","Artificial intelligence has found its use in various fields during the course of its development, especially in recent years with the enormous increase in available data. Its main task is to assist making better, faster and more reliable decisions. Artificial intelligence and machine learning are increasingly finding their application in medicine. This is especially true for medical fields that utilize various types of biomedical images and where diagnostic procedures rely on collecting and processing a large number of digital images. The application of machine learning in processing of medical images helps with consistency and boosts accuracy in reporting. This paper describes the use of machine learning algorithms to process chest X-ray images in order to support the decision making process in determining the correct diagnosis. Specifically, the research is focused on the use of deep learning algorithm based on convolutional neural network in order to build a processing model. This model has the task to help with a classification problem that is detecting whether a chest X-ray shows changes consistent with pneumonia or not, and classifying the X-ray images in two groups depending on the detection results.  © 2021 IEEE.","artificial intelligence; artificial intelligence; convolutional neural network; deep learning; image processing; convolutional neural network; deep learning; image processing, machine learning; machine learning; pneumonia detection; pneumonia detection","Convolution; Convolutional neural networks; Decision making; Deep learning; Diagnosis; Learning systems; Medical image processing; Biomedical images; Chest X-ray image; Chest x-rays; Decision making process; Diagnostic procedure; Digital image; Medical fields; Processing model; Learning algorithms","","","","","","","Haenlein M., Kaplan A., A brief history of artificial intelligence: On the past, present, and future of artificial intelligence, California Management Review, 61, 4, pp. 5-14, (2019); Kaul V., Enslin S., Gross S.A., The history of artificial intelligence in medicine, Gastrointestinal Endoscopy, (2020); Minsky M., Papert S.A., Perceptrons: An Introduction to Computational Geometry, (1969); Esteva A., Et al., A guide to deep learning in healthcare, Nature Medicine, 25, 1, pp. 24-29, (2019); Ravi D., Et al., Deep learning for health informatics, IEEE Journal of Biomedical and Health Informatics, 21, 1, pp. 4-21, (2017); Yang Y.J., Bang C.S., Application of artificial intelligence in gastroenterology, World Journal of Gastroenterolology, 25, 2019, pp. 1666-1683, (2019); Hosny A., Parmar C., Quackenbush J., Schwartz L.H., Aerts H.J.W.L., Artificial intelligence in radiology, Nature Reviews. Cancer, 18, 8, pp. 500-510, (2018); Johnson K.W., Et al., Artificial intelligence in cardiology, Journal of the American College of Cardiology, 71, 23, pp. 2668-2679, (2018); Perisic V.N., Jankovic B., Pedrijatrija Za Studente Medicine, (2010); Chen N., Et al., Epidemiological and clinical characteristics of 99 cases of 2019 novel coronavirus pneumonia in Wuhan, China: A descriptive study, The Lancet, 395, pp. 507-513, (2020); Kermany D., Zhang K., Goldbaum M., Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification, (2018); Gonzalez R.C., Woods R.E., Digital Image Processing, (2007); Geron A., Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, (2019); (2020); Varshni D., Thakral K., Agarwal L., Nijhawan R., Mittal A., Pneumonia detection using CNN based feature extraction, 2019 IEEE International Conf. On Electrical, Computer and Communication Technologies (ICECCT), pp. 1-7, (2019); Sirish Kaushik V., Et al., Pneumonia detection using convolutional neural networks (CNNs), Proceedings of First International Conference on Computing, Communications, and Cyber-Security (IC4S 2019). Lecture Notes in Networks and Systems, 121","","","Institute of Electrical and Electronics Engineers Inc.","","25th International Conference on Information Technology, IT 2021","16 February 2021 through 20 February 2021","Zabljak","168281","","978-172819103-4","","","English","Int. Conf. Inf. Technol., IT","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85104431624"
"Ali M.; Gilani S.O.; Waris A.; Zafar K.; Jamil M.","Ali, Mahnoor (57221004265); Gilani, Syed Omer (57194679489); Waris, Asim (54894010500); Zafar, Kashan (57215656557); Jamil, Mohsin (57616931600)","57221004265; 57194679489; 54894010500; 57215656557; 57616931600","Brain Tumour Image Segmentation Using Deep Networks","2020","IEEE Access","8","","9171998","153589","153598","9","85","10.1109/ACCESS.2020.3018160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090585705&doi=10.1109%2fACCESS.2020.3018160&partnerID=40&md5=5d761bd6584806739c5d451e25b10e58","Department of Biomedical Engineering and Sciences, School of Mechanical and Manufacturing Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Department of Electrical and Computer Engineering, Memorial University of Newfoundland, St. John's, NL A1B, Canada","Ali M., Department of Biomedical Engineering and Sciences, School of Mechanical and Manufacturing Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Gilani S.O., Department of Biomedical Engineering and Sciences, School of Mechanical and Manufacturing Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Waris A., Department of Biomedical Engineering and Sciences, School of Mechanical and Manufacturing Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Zafar K., Department of Biomedical Engineering and Sciences, School of Mechanical and Manufacturing Engineering, National University of Sciences and Technology, Islamabad, Pakistan; Jamil M., Department of Biomedical Engineering and Sciences, School of Mechanical and Manufacturing Engineering, National University of Sciences and Technology, Islamabad, Pakistan, Department of Electrical and Computer Engineering, Memorial University of Newfoundland, St. John's, NL A1B, Canada","Automated segmentation of brain tumour from multimodal MR images is pivotal for the analysis and monitoring of disease progression. As gliomas are malignant and heterogeneous, efficient and accurate segmentation techniques are used for the successful delineation of tumours into intra-tumoural classes. Deep learning algorithms outperform on tasks of semantic segmentation as opposed to the more conventional, context-based computer vision approaches. Extensively used for biomedical image segmentation, Convolutional Neural Networks have significantly improved the state-of-the-art accuracy on the task of brain tumour segmentation. In this paper, we propose an ensemble of two segmentation networks: a 3D CNN and a U-Net, in a significant yet straightforward combinative technique that results in better and accurate predictions. Both models were trained separately on the BraTS-19 challenge dataset and evaluated to yield segmentation maps which considerably differed from each other in terms of segmented tumour sub-regions and were ensembled variably to achieve the final prediction. The suggested ensemble achieved dice scores of 0.750, 0.906 and 0.846 for enhancing tumour, whole tumour, and tumour core, respectively, on the validation set, performing favourably in comparison to the state-of-the-art architectures currently available. © 2013 IEEE.","BraTS; CNN; Deep learning; ensembling; medical imaging; segmentation; U-Net","Brain; Convolutional neural networks; Deep learning; Image enhancement; Learning algorithms; Magnetic resonance imaging; Predictive analytics; Semantics; Tumors; Accurate prediction; Automated segmentation; Biomedical image segmentation; Disease progression; Segmentation map; Segmentation techniques; Semantic segmentation; State of the art; Image segmentation","","","","","","","Bauer S., Wiest R., Nolte L.P., Reyes M., A Survey of MRI-Based Medical Image Analysis for Brain Tumour Studies, (2013); Leece R., Xu J., Ostrom Q.T., Chen Y., Kruchko C., Barnholtz-Sloan J.S., Global incidence of malignant brain and other central nervous system tumors by histology, 2003-2007, Neuro-Oncology, 19, 11, pp. 1553-1564, (2017); Dolecek T.A., Propp J.M., Stroup N.E., Kruchko C., CBTRUS statistical report: Primary brain and central nervous system tumours diag-nosed in the United States in 2005-2009, Neuro. Oncol, 14, 5, pp. v1-v49, (2012); Louis D.N., Perry A., Reifenberger G., Von Deimling A., Figarella-Branger D., Cavenee W.K., Ohgaki H., Wiestler O.D., Kleihues P., Ellison D.W., The 2016 World Health Organization classification of tumours of the central nervous system: A summary, Acta Neuropathol, 131, 6, pp. 803-820, (2016); Stupp R., Et al., Radiotherapy plus concomitant and adjuvant temo-zolomide for glioblastoma, New England J. Med, 352, 10, pp. 987-996, (2005); Bakas S., Et al., Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge, (2018); Menze B.H., Van Leemput K., Lashkari D., Weber M.-A., Ayache N., Golland P., A generative model for brain tumor segmentation in multi-modal images, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 151-159, (2010); Bakas S., Akbari H., Sotiras A., Bilello M., Rozycki M., Kirby J.S., Freymann J.B., Farahani K., Davatzikos C., Advancing the cancer genome atlas glioma MRI collections with expert segmentation labels and radiomic features, Sci. Data, 4, 1, (2017); Bakas S., Et al., Segmentation labels and radiomic features for the pre-operative scans of the TCGA-LGG collection, Cancer Imag. Arch, 286, (2017); Bakas S., Akbari H., Sotiras A., Bilello M., Rozycki M., Kirby J., Freymann J., Farahani K., Davatzikos C., Segmentation labels and radiomic features for the pre-operative scans of the TCGA-GBM col-lection. The cancer imaging archive, Nat. Sci. Data, 4, (2017); Menze B.H., Et al., The multimodal brain tumor image segmenta-tion benchmark (BRATS), IEEE Trans. Med. Imag, 34, 10, pp. 1993-2024, (2015); Pereira S., Pinto A., Alves V., Silva C.A., Brain tumor segmentation using convolutional neural networks in MRI images, IEEE Trans. Med. Imag, 35, 5, pp. 1240-1251, (2016); Naceur M.B., Saouli R., Akil M., Kachouri R., Fully automatic brain tumor segmentation using end-to-end incremental deep neural net-works in MRI images, Comput. Methods Programs Biomed, 166, pp. 39-49, (2018); Goetz M., Weber C., Binczyk F., Polanska J., Tarnawski R., Bobek-Billewicz B., Koethe U., Kleesiek J., Stieltjes B., Maier-Hein K.H., DALSA: Domain adaptation for supervised learning from sparsely annotated MR images, IEEE Trans. Med. Imag, 35, 1, pp. 184-196, (2016); Farahani K., Menze B., Reyes M., Brats 2014 Challenge Manuscripts (2014), (2014); Bengio Y., Courville A., Vincent P., Representation learning: A review and new perspectives, IEEE Trans. Pattern Anal. Mach. Intell, 35, 8, pp. 1798-1828, (2013); Hinton G.E., Osindero S., Teh Y.-W., A fast learning algorithm for deep belief nets, Neural Comput, 18, 7, pp. 1527-1554, (2006); Bengio Y., Lamblin P., Popovici D., Larochelle H., Greedy layer-wise training of deep networks, Proc. Adv. Neural Inf. Process. Syst, pp. 153-160, (2007); Lee H., Ekanadham C., Ng A.Y., Sparse deep belief net model for visual area V2, Proc. Adv. Neural Inf. Process. Syst, pp. 873-880, (2008); Wang G., Li W., Ourselin S., Vercauteren T., Automatic brain tumor segmentation based on cascaded convolutional neural networks with uncer-tainty estimation, Frontiers Comput. Neurosci, 13, (2019); Mukherjee P., Mukherjee A., Advanced processing techniques and secure architecture for sensor networks in ubiquitous healthcare systems, Sensors for Health Monitoring. Amsterdam, the Netherlands: Elsevier, pp. 3-29, (2019); Chen W., Li Y., Li C., A visual detection method for foreign objects in power lines based on mask R-CNN, Int. J. Ambient Comput. Intell, 11, 1, pp. 34-47, (2020); Burger P.C., Heinz E.R., Shibata T., Kleihues P., Topographic anatomy and CT correlations in the untreated glioblastoma multiforme, J. Neurosurgery, 68, 5, pp. 698-704, (1988); Raschke F., Barrick T.R., Jones T.L., Yang G., Ye X., Howe F.A., Tissue-type mapping of gliomas, NeuroImage, Clin, 21, (2019); Soltaninejad M., Et al., Brain tumour grading in different MRI protocols using SVM on statistical features, Med. Image Understand. Anal, pp. 259-264, (2014); Soltaninejad M., Yang G., Lambrou T., Allinson N., Jones T.L., Barrick T.R., Howe F.A., Ye X., Automated brain tumour detec-tion and segmentation using superpixel-based extremely randomized trees in FLAIR MRI, Int. J. Comput. Assist. Radiol. Surg, 12, 2, pp. 183-203, (2017); Soltaninejad M., Yang G., Lambrou T., Allinson N., Jones T.L., Barrick T.R., Howe F.A., Ye X., Supervised learning based multimodal MRI brain tumour segmentation using texture features from supervoxels, Comput. Methods Programs Biomed, 157, pp. 69-84, (2018); Jones T.L., Byrnes T.J., Yang G., Howe F.A., Bell B.A., Barrick T.R., Brain tumor classification using the diffusion tensor image segmenta-tion (D-SEG) technique, Neuro-Oncology, 17, 3, pp. 466-476, (2014); Galleguillos C., Belongie S., Context based object categorization: A critical survey, Comput. Vis. Image Understand, 114, 6, pp. 712-722, (2010); Kamnitsas K., Ledig C., Newcombe V.F.J., Simpson J.P., Kane A.D., Menon D.K., Rueckert D., Glocker B., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation, Med. Image Anal, 36, pp. 61-78, (2017); Isensee F., Kickingereder P., Wick W., Bendszus M., Maier-Hein K.H., Brain tumor segmentation and radiomics survival prediction: Contribution to the brats 2017 challenge, Proc. Int. MICCAI Brainlesion Workshop, pp. 287-297, (2017); Li X., Chen H., Qi X., Dou Q., Fu C.-W., Heng P.-A., H-DenseUNet: Hybrid densely connected UNet for Liver and tumor segmentation from CT volumes, IEEE Trans. Med. Imag, 37, 12, pp. 2663-2674, (2018); Isensee F., Jaeger P.F., Full P.M., Wolf I., Engelhardt S., Maier-Hein K.H., Automatic cardiac disease assessment on cine-MRI via time-series segmentation and domain specific features, Proc. Int. Workshop Stat. Atlases Comput. Models Heart, pp. 120-129, (2017); Kamnitsas K., Bai W., Ferrante E., McDonagh S., Sinclair M., Pawlowski N., Rajchl M., Lee M., Kainz B., Rueckert D., Glocker B., Ensembles of multiple models and architectures for robust brain tumour segmentation, Proc. Int. MICCAI Brainlesion Workshop, pp. 450-462, (2017); Wang G., Li W., Ourselin S., Vercauteren T., Automatic brain tumor segmentation using cascaded anisotropic convolutional neural networks, Proc. Int. MICCAI Brainlesion Workshop, pp. 178-190, (2017); Dong H., Yang G., Liu F., Mo Y., Guo Y., Automatic brain tumor detection and segmentation using U-net based fully convolutional net-works, Proc. Annu. Conf. Med. Image Understand. Anal, pp. 506-517, (2017); Fidon L., Li W., Garcia-Peraza-Herrera L.C., Ekanayake J., Kitchen N., Ourselin S., Vercauteren T., Scalable multimodal convolutional net-works for brain tumour segmentation, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 285-293, (2017); Le T.H.N., Gummadi R., Savvides M., Deep recurrent level set for segmenting brain tumors, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 646-653, (2018); Qin Y., Kamnitsas K., Ancha S., Nanavati J., Cottrell G., Criminisi A., Nori A., Autofocus layer for semantic segmentation, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 603-611, (2018); Shen H., Wang R., Zhang J., McKenna S.J., Boundary-aware fully convolutional network for brain tumor segmentation, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 433-441, (2017); Pereira S., Alves V., Silva C.A., Adaptive feature recombination and recalibration for semantic segmentation: Application to brain tumor segmentation in MRI, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 706-714, (2018); Zhou C., Ding C., Lu Z., Wang X., Tao D., One-pass multi-task convolutional neural networks for efficient brain tumor segmentation, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 637-645, (2018); Ji Z., Shen Y., Ma C., Gao M., Scribble-based hierarchical weakly supervised learning for brain tumor segmentation, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 175-183, (2019); Xu H., Xie H., Liu Y., Cheng C., Niu C., Zhang Y., Deep cascaded attention network for multi-task brain tumor segmentation, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 420-428, (2019); Myronenko A., 3D MRI brain tumor segmentation using autoencoder regularization, Proc. Int. MICCAI Brainlesion Workshop, pp. 311-320, (2018); Isensee F., Kickingereder P., Wick W., Bendszus M., Maier-Hein K.H., No new-net, Proc. Int. MICCAI Brainlesion Workshop, pp. 234-244, (2018); McKinley R., Meier R., Wiest R., Ensembles of densely-connected CNNs with label-uncertainty for brain tumor segmentation, Proc. Int. MICCAI Brainlesion Workshop, pp. 456-465, (2018); Zhou C., Chen S., Ding C., Tao D., Learning contextual and attentive information for brain tumor segmentation, Proc. Int. MICCAI Brainle-sion Workshop, pp. 497-507, (2018); Murugesan G.K., Nalawade S., Ganesh C., Wagner B., Yu F.F., Fei B., Madhuranthakam A.J., Maldjian J.A., Multidimensional and mul-tiresolution ensemble networks for brain tumor segmentation, Proc. Int. MICCAI Brainlesion Workshop, pp. 148-157, (2019); Chen C., Liu X., Ding M., Zheng J., Li J., 3D dilated multi-ber network for real-time brain tumor segmentation in MRI, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent, pp. 184-192, (2019); Jiang Z., Ding C., Liu M., Tao D., Two-stage cascaded U-Net: 1st place solution to BraTS challenge 2019 segmentation task, Proc. Int. MICCAI Brainlesion Workshop, pp. 231-241, (2019); Zhao Y.-X., Zhang Y.-M., Liu C.-L., Bag of tricks for 3D MRI brain tumor segmentation, Proc. Int. MICCAI Brainlesion Workshop, pp. 210-220, (2019); McKinley R., Rebsamen M., Meier R., Wiest R., Triplanar ensemble of 3D-to-2D CNNs with label-uncertainty for brain tumor segmentation, Proc. Int. MICCAI Brainlesion Workshop, pp. 379-387, (2019); Hamghalam M., Lei B., Wang T., Brain tumor synthetic segmen-tation in 3D multimodal MRI scans, Proc. Int. MICCAI Brainlesion Workshop, pp. 153-162, (2019); Frey M., Nau M., Memory efficient brain tumor segmentation using an autoencoder-regularized U-net, Proc. Int. MICCAI Brainlesion Workshop, pp. 388-396, (2019); Xue Y., Xie M., Farhat F.G., Boukrina O., Barrett A.M., Binder J.R., Roshan U.W., Graves W.W., A multi-path decoder network for brain tumor segmentation, Proc. Int. MICCAI Brainlesion Workshop, pp. 255-265, (2019); Myronenko A., Hatamizadeh A., Robust semantic segmentation of brain tumor regions from 3D MRIs, Proc. Int. MICCAI Brainlesion Workshop, pp. 82-89, (2019); Goetz M., Weber C., Bloecher J., Stieltjes B., Meinzer H.-P., Maier-Hein K., Extremely randomised trees based brain tumour segmentation, Proc. BRATS Challenge-MICCAI, pp. 6-11, (2014); Zhao X., Wu Y., Song G., Li Z., Zhang Y., Fan Y., A deep learning model integrating FCNNs and CRFs for brain tumor segmentation, Med. Image Anal, 43, pp. 98-111, (2018); Tustison N.J., Avants B.B., Cook P.A., Zheng Y., Egan A., Yushkevich P.A., Gee J.C., N4ITK: Improved n3 bias correction, IEEE Trans. Med. Imag, 29, 6, pp. 1310-1320, (2010); Bauer S., Fejes T., Slotboom J., Wiest R., Nolte L.-P., Reyes M., Segmentation of brain tumor images based on integrated hierarchical classification and regularization, Proc. MICCAI BraTSWorkshop Nice, Miccai Soc, (2012)","S.O. Gilani; Department of Biomedical Engineering and Sciences, School of Mechanical and Manufacturing Engineering, National University of Sciences and Technology, Islamabad, Pakistan; email: omer@smme.nust.edu.pk","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85090585705"
"Isensee F.; Jaeger P.F.; Kohl S.A.A.; Petersen J.; Maier-Hein K.H.","Isensee, Fabian (57194378532); Jaeger, Paul F. (57201075948); Kohl, Simon A. A. (57204142298); Petersen, Jens (56343682900); Maier-Hein, Klaus H. (55647018100)","57194378532; 57201075948; 57204142298; 56343682900; 55647018100","nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation","2021","Nature Methods","18","2","","203","211","8","3049","10.1038/s41592-020-01008-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097254681&doi=10.1038%2fs41592-020-01008-z&partnerID=40&md5=ec84e152cb0adba256bd723c59b59329","Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Faculty of Biosciences, University of Heidelberg, Heidelberg, Germany; DeepMind, London, United Kingdom; Faculty of Physics & Astronomy, University of Heidelberg, Heidelberg, Germany; Pattern Analysis and Learning Group, Department of Radiation Oncology, Heidelberg University Hospital, Heidelberg, Germany","Isensee F., Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany, Faculty of Biosciences, University of Heidelberg, Heidelberg, Germany; Jaeger P.F., Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Kohl S.A.A., Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany, DeepMind, London, United Kingdom; Petersen J., Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany, Faculty of Physics & Astronomy, University of Heidelberg, Heidelberg, Germany; Maier-Hein K.H., Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany, Pattern Analysis and Learning Group, Department of Radiation Oncology, Heidelberg University Hospital, Heidelberg, Germany","Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training. © 2020, The Author(s), under exclusive licence to Springer Nature America, Inc.","","Algorithms; Deep Learning; Image Processing, Computer-Assisted; Neural Networks, Computer; article; competition; deep learning; image segmentation; algorithm; image processing; procedures","","","","","","","Falk T., Et al., U-net: deep learning for cell counting, detection, and morphometry, Nat. Methods, 16, pp. 67-70, (2019); Hollon T.C., Et al., Near real-time intraoperative brain tumor diagnosis using stimulated Raman histology and deep neural networks, Nat. Med., 26, pp. 52-58, (2020); Aerts H.J.W.L., Et al., Decoding tumour phenotype by noninvasive imaging using a quantitative radiomics approach, Nat. Commun., 5, (2014); Nestle U., Et al., Comparison of different methods for delineation of 18F-FDG PET-positive tissue for target volume definition in radiotherapy of patients with non-small cell lung cancer, J. Nucl. Med., 46, pp. 1342-1348, (2005); De Fauw J., Et al., Clinically applicable deep learning for diagnosis and referral in retinal disease, Nat. Med., 24, pp. 1342-1350, (2018); Bernard O., Et al., Deep learning techniques for automatic MRI cardiac multi-structures segmentation and diagnosis: is the problem solved?, IEEE Trans. Med. Imaging, 37, pp. 2514-2525, (2018); Nikolov S., Et al., Deep Learning to Achieve Clinically Applicable Segmentation of Head and Neck Anatomy for Radiotherapy, (2018); Kickingereder P., Et al., Automated quantitative tumour response assessment of MRI in neuro-oncology with artificial neural networks: a multicentre, retrospective study, Lancet Oncol., 20, pp. 728-740, (2019); Maier-Hein L., Et al., Why rankings of biomedical image analysis competitions should be interpreted with care, Nat. Commun., 9, (2018); Litjens G., Et al., A survey on deep learning in medical image analysis, Med. Image Anal., 42, pp. 60-88, (2017); Y. 1.1 deep learning hardware: Past, present, and future, 2019 IEEE International Solid-State Circuits Conference, pp. 12-19, (2019); Hutter F., Kotthoff L., Vanschoren J., Automated Machine Learning: Methods, (2019); Bergstra J., Bengio Y., Random search for hyper-parameter optimization, J. Mach. Learn. Res., 13, pp. 281-305, (2012); Simpson A.L., Et al., A Large Annotated Medical Image Dataset for the Development and Evaluation of Segmentation Algorithms, (2019); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, In MICCAI, pp. 234-241, (2015); Landman B., Et al., MICCAI Multi-Atlas Labeling beyond the Cranial vault—workshop and Challenge, (2015); Litjens G., Et al., Evaluation of prostate segmentation algorithms for MRI: the PROMISE12 challenge, Med. Image Anal., 18, pp. 359-373, (2014); Bilic P., Et al., The Liver Tumor Segmentation Benchmark (Lits), (2019); Carass A., Et al., Longitudinal multiple sclerosis lesion segmentation: resource and challenge, NeuroImage, 148, pp. 77-102, (2017); Kavur A.E., Et al., CHAOS challenge—combined (CT–MR) Healthy Abdominal Organ Segmentation, (2020); Heller N., Et al., The Kits19 Challenge Data: 300 Kidney Tumor Cases with Clinical Context, CT Semantic Segmentations, and Surgical Outcomes, (2019); Lambert Z., Petitjean C., Dubray B., Ruan S., Segthor: Segmentation of Thoracic Organs at Risk in CT Images, (2019); Maska M., Et al., A benchmark for comparison of cell tracking algorithms, Bioinformatics, 30, pp. 1609-1617, (2014); Ulman V., Et al., An objective comparison of cell-tracking algorithms, Nat. Methods, 14, pp. 1141-1152, (2017); Heller N., Et al., The state of the art in kidney and kidney tumor segmentation in contrast-enhanced CT imaging: Results of the KiTS19 challenge, Medical Image Analysis, 67, (2021); Cicek O., Abdulkadir A., Lienkamp S.S., Brox T., Ronneberger O., 3D U-net: Learning dense volumetric segmentation from sparse annotation, In International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 424-432, (2016); Milletari F., Navab N., Ahmadi S.-A., V-net: Fully convolutional neural networks for volumetric medical image segmentation, International Conference on 3D Vision (3DV), pp. 565-571, (2016); He K., Zhang Z., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Jegou S., Drozdzal M., Vazquez D., Romero A., Bengio Y., The one hundred layers tiramisu: Fully convolutional DenseNets for semantic segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops 11–19 (IEEE, (2017); Huang G., Liu Z., van Der Maaten L., Weinberger K.Q., Densely connected convolutional networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 4700–4708 (IEEE, (2017); Oktay O., Et al., Attention U-Net: Learning Where to Look for the Pancreas, (2018); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A., DeepLab: semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs, IEEE Trans. Pattern Anal. Mach. Intell., 40, pp. 834-848, (2017); McKinley R., Meier R., Wiest R., Ensembles of densely-connected CNNs with label-uncertainty for brain tumor segmentation, In International MICCAI Brain Lesion Workshop, pp. 456-465, (2018); Heinrich L., Funke J., Pape C., Nunez-Iglesias J., Saalfeld S., Synaptic cleft segmentation in non-isotropic volume electron microscopy of the complete Drosophila brain, In International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 317-325, (2018); Nolden M., Et al., The Medical Imaging Interaction Toolkit: challenges and advances, Int. J. Comput. Assist. Radiol. Surg., 8, pp. 607-620, (2013); Castilla C., Maska M., Sorokin D.V., Meijering E., Ortiz-de-Solorzano C., 3-D quantification of filopodia in motile cancer cells, IEEE Trans. Med. Imaging, 38, pp. 862-872, (2018); Sorokin D.V., Et al., FiloGen: a model-based generator of synthetic 3-D time-lapse sequences of single motile cells with growing and branching filopodia, IEEE Trans. Med. Imaging, 37, pp. 2630-2641, (2018); Menze B.H., Et al., The Multimodal Brain Tumor Image Segmentation benchmark (BRATS), IEEE Trans. Med. Imaging, 34, pp. 1993-2024, (2014); Svoboda D., Ulman V., MitoGen: a framework for generating 3D synthetic time-lapse sequences of cell populations in fluorescence microscopy, IEEE Trans. Med. Imaging, 36, pp. 310-321, (2016); Wu Z., Shen C., van Den Hengel A., Bridging Category-Level and Instance-Level Semantic Image Segmentation, (2016); He K., Zhang X., Ren S., Sun J., Identity mappings in deep residual networks, In European Conference on Computer Vision, pp. 630-645, (2016); Kingma D.P., Ba J., Adam: A method for stochastic optimization, 3Rd International Conference on Learning Representations; Ioffe S., Szegedy C., Batch normalization: Accelerating deep network training by reducing internal covariate shift, Proceedings of Machine Learning Research Vol. 37, pp. 448-456, (2015); Ulyanov D., Vedaldi A., Lempitsky V., Instance Normalization: The Missing Ingredient for Fast Stylization, (2016); Wiesenfarth M., Et al., Methods and Open-Source Toolkit for Analyzing and Visualizing Challenge Results, (2019); Hu J., Shen L., Sun G., Squeeze-and-excitation networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7132-7141, (2018); Wu Y., He K., Group normalization, Proceedings of the European Conference on Computer Vision (ECCV), pp. 3-19, (2018); Singh S., Krishnan S., Filter response normalization layer: Eliminating batch dependence in the training of deep neural networks, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 11237-11246, (2020); Maas A.L., Hannun A.Y., Ng A.Y., Rectifier nonlinearities improve neural network acoustic models, Proceedings of the International Conference on Machine Learning 3; Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., Rethinking the inception architecture for computer vision, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826, (2016); Drozdzal M., Vorontsov E., Chartrand G., Kadoury S., Pal C., The importance of skip connections in biomedical image segmentation, In Deep Learning and Data Labeling for Medical Applications, pp. 179-187, (2016); Paszke A., PyTorch: An imperative style, high-performance deep learning library, In Advances in Neural Information Processing Systems, pp. 8024-8035, (2019); Isensee F., Batchgenerators—a Python framework for data augmentation, Zenodo, (2020)","K.H. Maier-Hein; Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; email: k.maier-hein@dkfz.de","","Nature Research","","","","","","15487091","","","33288961","English","Nat. Methods","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85097254681"
"Wang Y.; He Z.; Xie P.; Yang C.; Zhang Y.; Li F.; Chen X.; Lu K.; Li T.; Zhou J.; Zuo K.","Wang, Yuan (57219774374); He, Zhiyou (57191858920); Xie, Peizhen (57218281149); Yang, Canqun (13408914200); Zhang, Yu (59072202600); Li, Fangfang (56039980600); Chen, Xiang (57212086254); Lu, Kai (8685091500); Li, Tao (56965840800); Zhou, Jiao (57218285366); Zuo, Ke (24588344100)","57219774374; 57191858920; 57218281149; 13408914200; 59072202600; 56039980600; 57212086254; 8685091500; 56965840800; 57218285366; 24588344100","Segment Medical Image Using U-Net Combining Recurrent Residuals and Attention","2020","Lecture Notes in Electrical Engineering","633 LNEE","","","77","86","9","5","10.1007/978-981-15-5199-4_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088573030&doi=10.1007%2f978-981-15-5199-4_8&partnerID=40&md5=1e6a6402f1c7e5647e76b659c5f9b5eb","National University of Defense Technology, Changsha, 410073, Hunan, China; The Department of Burns and Reconstructive Surgery, Xiangya Hospital, Central South University, Changsha, 410008, Hunan, China; The Department of Dermatology, Xiangya Hospital, Central Source University, Changsha, 410008, Hunan, China; Hunan Key Laboratory of Skin Cancer and Psoriasis, Changsha, Hunan, China; Hunan Engineering Research Center of Skin Health and Disease, Changsha, Hunan, China","Wang Y., National University of Defense Technology, Changsha, 410073, Hunan, China; He Z., The Department of Burns and Reconstructive Surgery, Xiangya Hospital, Central South University, Changsha, 410008, Hunan, China; Xie P., National University of Defense Technology, Changsha, 410073, Hunan, China; Yang C., National University of Defense Technology, Changsha, 410073, Hunan, China; Zhang Y., The Department of Dermatology, Xiangya Hospital, Central Source University, Changsha, 410008, Hunan, China, Hunan Key Laboratory of Skin Cancer and Psoriasis, Changsha, Hunan, China, Hunan Engineering Research Center of Skin Health and Disease, Changsha, Hunan, China; Li F., The Department of Dermatology, Xiangya Hospital, Central Source University, Changsha, 410008, Hunan, China, Hunan Key Laboratory of Skin Cancer and Psoriasis, Changsha, Hunan, China, Hunan Engineering Research Center of Skin Health and Disease, Changsha, Hunan, China; Chen X., The Department of Dermatology, Xiangya Hospital, Central Source University, Changsha, 410008, Hunan, China, Hunan Key Laboratory of Skin Cancer and Psoriasis, Changsha, Hunan, China, Hunan Engineering Research Center of Skin Health and Disease, Changsha, Hunan, China; Lu K., National University of Defense Technology, Changsha, 410073, Hunan, China; Li T., National University of Defense Technology, Changsha, 410073, Hunan, China; Zhou J., National University of Defense Technology, Changsha, 410073, Hunan, China; Zuo K., National University of Defense Technology, Changsha, 410073, Hunan, China","Medical image segmentation is the key to decide the issue of medical images in clinical practice that can provide a reliable basis. The development of medical image segmentation technology not only affects the development of other related technologies in medical image processing, such as visualization 3D reconstruction, but in the analysis of biomedical images also occupies an extremely important position. With the application of deep learning algorithms in medical image segmentation, medical image segmentation technology has made significant progress. In this paper, we discuss the segmentation method of 2D medical images about U-net variant network. Use the U-net combing recurrent residual model and attention model to segmented the image can get better result. © 2020, Springer Nature Singapore Pte Ltd.","Attention; Medical image; Residual; Segmentation; U-net","Computer aided diagnosis; Engineering education; Image segmentation; Learning algorithms; Recurrent neural networks; Three dimensional computer graphics; 3D reconstruction; Attention model; Biomedical images; Clinical practices; Residual model; Segmentation methods; Medical image processing","","","","","","","Haralick R.M., Shapiro L.G., Image segmentation techniques, Comput. Vis. Graph. Image Process, 29, 1, pp. 100-132, (1985); Sharma N., Aggarwal L.M., Automated medical image segmentation techniques, J. Med. Phys./Assoc. Med. Phys. India, 35, 1, (2010); Yushkevich P.A., Gao Y., Gerig G., ITK-SNAP: an interactive tool for semi-automatic segmentation of multi-modality biomedical images, 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 3342-3345, (2016); Stephen I., Perceptron-based learning algorithms, IEEE Trans. Neural Netw, 50, 2, (1990); Rumelhart D.E., Hinton G.E., Williams R.J., Learning representations by back-propagating errors, Nature, 323, 6088, pp. 533-536, (1986); Hinton G.E., Salakhutdinov R.R., Reducing the dimensionality of data with neural networks, Science, 313, 5786, pp. 504-507, (2006); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Hinton G., Deng L., Yu D., Et al., Deep neural networks for acoustic modeling in speech recognition, IEEE Signal Process. Mag, 29, pp. 82-97, (2012); Han K., Yu D., Tashev I., Speech emotion recognition using deep neural network and extreme learning machine, Fifteenth Annual Conference of the International Speech Communication Association, (2014); Lin K., Yang H.F., Hsiao J.H., Et al., Deep learning of binary hash codes for fast image retrieval, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 27-35, (2015); Gordo A., Almazan J., Revaud J., Et al., Deep image retrieval: learning global representations for image search, European Conference on Computer Vision, pp. 241-257, (2016); Liu H., Wang R., Shan S., Et al., Deep supervised hashing for fast image retrieval, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2064-2072, (2016); Sarikaya R., Hinton G.E., Deoras A., Application of deep belief networks for natural language understanding, IEEE/ACM Trans. Audio Speech Lang. Process. (TASLP), 22, 4, pp. 778-784, (2014); Young T., Hazarika D., Poria S., Et al., Recent trends in deep learning based natural language processing, IEEE Comput. Intell. Mag, 13, 3, pp. 55-75, (2018); Parkhi O.M., Vedaldi A., Zisserman A., Deep face recognition, BMVC, 1, 3, (2015); Wen Y., Zhang K., Li Z., Et al., A discriminative feature learning approach for deep face recognition, European Conference on Computer Vision, pp. 499-515, (2016); Liu W., Wen Y., Yu Z., Et al., SphereFace: deep hypersphere embedding for face recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 212-220, (2017); Kumar N., Verma R., Sharma S., Et al., A dataset and a technique for generalized nuclear segmentation for computational pathology, IEEE Trans. Med. Imaging, 36, 7, pp. 1550-1560, (2017); Kao P.Y., Ngo T., Zhang A., Et al., Brain tumor segmentation and tractographic feature extraction from structural MR images for overall survival prediction, International MICCAI Brainlesion Workshop, pp. 128-141, (2018); Qaiser T., Sirinukunwattana K., Nakane K., Et al., Persistent homology for fast tumor segmentation in whole slide histology images, Procedia Comput. Sci, 90, pp. 119-124, (2016); Yu L., Chen H., Dou Q., Et al., Automated melanoma recognition in dermoscopy images via very deep residual networks, IEEE Trans. Med. Imaging, 36, 4, pp. 994-1004, (2016); Ronneberger O., Fischer P., Brox T., U-Net: convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Cicek O., Abdulkadir A., Lienkamp S.S., Et al., 3D U-Net: learning dense volumetric segmentation from sparse annotation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 424-432, (2016); Milletari F., Navab N., Ahmadi S.A., V-Net: fully convolutional neural networks for volumetric medical image segmentation, 2016 Fourth International Conference on 3D Vision (3DV), pp. 565-571, (2016); Drozdzal M., Vorontsov E., Chartrand G., Et al., The importance of skip connections in biomedical image segmentation, Deep Learning and Data Labeling for Medical Applications, pp. 179-187, (2016); Kamnitsas K., Ledig C., Newcombe V.F.J., Et al., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation, Med. Image Anal, 36, pp. 61-78, (2016); Ghafoorian M., Karssemeijer N., Heskes T., Et al., Non-uniform patch sampling with deep convolutional neural networks for white matter hyperintensity segmentation, 2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI), pp. 1414-1417, (2016); Wang C., Yan X., Smith M., Et al., A unified framework for automatic wound segmentation and analysis with deep convolutional neural networks, 2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 2415-2418, (2015); Brosch T., Tang L.Y.W., Yoo Y., Et al., Deep 3D convolutional encoder networks with shortcuts for multiscale feature integration applied to multiple sclerosis lesion segmentation, IEEE Trans. Med. Imaging, 35, 5, pp. 1229-1239, (2016); Sutskever I., Vinyals O., Le Q.V., Sequence to sequence learning with neural networks, Advances in NIPS, (2014)","K. Zuo; National University of Defense Technology, Changsha, 410073, China; email: zuoke@nudt.edu.cn","Su R.; Liu H.","Springer","","International Conference on Medical Imaging and Computer-Aided Diagnosis, MICAD 2020","20 January 2020 through 21 January 2020","Oxford","241909","18761100","978-981155198-7","","","English","Lect. Notes Electr. Eng.","Conference paper","Final","","Scopus","2-s2.0-85088573030"
"Godec P.; Pančur M.; Ilenič N.; Čopar A.; Stražar M.; Erjavec A.; Pretnar A.; Demšar J.; Starič A.; Toplak M.; Žagar L.; Hartman J.; Wang H.; Bellazzi R.; Petrovič U.; Garagna S.; Zuccotti M.; Park D.; Shaulsky G.; Zupan B.","Godec, Primož (56377091000); Pančur, Matjaž (6505935502); Ilenič, Nejc (57211229867); Čopar, Andrej (56248208600); Stražar, Martin (55603807500); Erjavec, Aleš (26036093300); Pretnar, Ajda (57209645602); Demšar, Janez (55075851300); Starič, Anže (55884822000); Toplak, Marko (35118222500); Žagar, Lan (36100591700); Hartman, Jan (57211229987); Wang, Hamilton (57211227150); Bellazzi, Riccardo (58709404600); Petrovič, Uroš (55917218200); Garagna, Silvia (7004583165); Zuccotti, Maurizio (56256935600); Park, Dongsu (8437663600); Shaulsky, Gad (7003920656); Zupan, Blaž (7003934784)","56377091000; 6505935502; 57211229867; 56248208600; 55603807500; 26036093300; 57209645602; 55075851300; 55884822000; 35118222500; 36100591700; 57211229987; 57211227150; 58709404600; 55917218200; 7004583165; 56256935600; 8437663600; 7003920656; 7003934784","Democratized image analytics by visual programming through integration of deep models and small-scale machine learning","2019","Nature Communications","10","1","4551","","","","47","10.1038/s41467-019-12397-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073058466&doi=10.1038%2fs41467-019-12397-x&partnerID=40&md5=3a477570104ac85aa863c7641f976fe8","Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, 77030, TX, United States; Faculty of Engineering, University of Pavia, Pavia, 27100, Italy; Biotechnical Faculty, University of Ljubljana, Ljubljana, 1000, Slovenia; Department of Molecular and Biomedical Sciences, Jožef Stefan Institute, Ljubljana, 1000, Slovenia; Department of Biology and Biotechnology, University of Pavia, Pavia, 27100, Italy","Godec P., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Pančur M., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Ilenič N., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Čopar A., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Stražar M., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Erjavec A., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Pretnar A., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Demšar J., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Starič A., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Toplak M., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Žagar L., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Hartman J., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; Wang H., Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, 77030, TX, United States; Bellazzi R., Faculty of Engineering, University of Pavia, Pavia, 27100, Italy; Petrovič U., Biotechnical Faculty, University of Ljubljana, Ljubljana, 1000, Slovenia, Department of Molecular and Biomedical Sciences, Jožef Stefan Institute, Ljubljana, 1000, Slovenia; Garagna S., Department of Biology and Biotechnology, University of Pavia, Pavia, 27100, Italy; Zuccotti M., Department of Biology and Biotechnology, University of Pavia, Pavia, 27100, Italy; Park D., Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, 77030, TX, United States; Shaulsky G., Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, 77030, TX, United States; Zupan B., Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia, Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, 77030, TX, United States","Analysis of biomedical images requires computational expertize that are uncommon among biomedical scientists. Deep learning approaches for image analysis provide an opportunity to develop user-friendly tools for exploratory data analysis. Here, we use the visual programming toolbox Orange (http://orange.biolab.si) to simplify image analysis by integrating deep-learning embedding, machine learning procedures, and data visualization. Orange supports the construction of data analysis workflows by assembling components for data preprocessing, visualization, and modeling. We equipped Orange with components that use pre-trained deep convolutional networks to profile images with vectors of features. These vectors are used in image clustering and classification in a framework that enables mining of image sets for both novel and experienced users. We demonstrate the utility of the tool in image analysis of progenitor cells in mouse bone healing, identification of developmental competence in mouse oocytes, subcellular protein localization in yeast, and developmental morphology of social amoebae. © 2019, The Author(s).","","Animals; Computational Biology; Dictyostelium; Green Fluorescent Proteins; Image Processing, Computer-Assisted; Internet; Life Cycle Stages; Machine Learning; Mice, Transgenic; Neural Networks, Computer; Oocytes; Reproducibility of Results; Saccharomyces cerevisiae; Saccharomyces cerevisiae Proteins; green fluorescent protein; Saccharomyces cerevisiae protein; algorithm; biochemical composition; data assimilation; data mining; image analysis; machine learning; numerical model; protein; visualization; animal cell; animal experiment; animal model; Article; cellular distribution; convolutional neural network; data analysis; data classification; data clustering; data mining; data processing; data visualization; deep learning; Dictyostelium discoideum; embedding; female; fracture healing; image analysis; model; mouse; nonhuman; oocyte; protein localization; stem cell; workflow; yeast; animal; biology; cytology; Dictyostelium; genetics; growth, development and aging; image processing; Internet; life cycle stage; machine learning; metabolism; procedures; reproducibility; Saccharomyces cerevisiae; transgenic mouse","","Green Fluorescent Proteins, ; Saccharomyces cerevisiae Proteins, ","","","National Institute of General Medical Sciences, NIGMS, (R35GM118016)","","LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, pp. 436-444, (2015); Cruz-Roa A., Et al., Accurate and reproducible invasive breast cancer detection in whole-slide images: A Deep Learning approach for quantifying tumor extent, Sci. Rep., 7, (2017); Kraus O.Z., Et al., Automated analysis of high‐content microscopy data with deep learning, Mol. Syst. Biol., 13, (2017); Mohanty S.P., Hughes D.P., Salathe M., Using deep learning for image-based plant disease detection, Front. Plant Sci., 7, (2016); Pan S.J., Yang Q., A survey on transfer learning, IEEE Trans. Knowl. Data Eng., 22, pp. 1345-1359, (2010); Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., Rethinking the inception architecture for computer vision, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2818-2826, (2016); Webb S., Deep learning for biology, Nature, 554, pp. 555-557, (2018); Esteva A., Et al., Dermatologist-level classification of skin cancer with deep neural networks, Nature, 542, pp. 115-118, (2017); Zhang W., Et al., Deep model based transfer and multi-task learning for biological image analysis, Proc. of the 21Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1475-1484, (2015); Modarres M.H., Et al., Neural network for nanoscience scanning electron microscope image recognition, Sci. Rep., 7, (2017); Abidin A.Z., Et al., Deep transfer learning for characterizing chondrocyte patterns in phase contrast X-Ray computed tomography images of the human patellar cartilage, Comput. Biol. Med., 95, pp. 24-33, (2018); Khosravi P., Kazemi E., Imielinski M., Elemento O., Hajirasouliha I., Deep convolutional neural networks enable discrimination of heterogeneous digital pathology images, EBioMedicine, 27, pp. 317-328, (2018); Pratt L.Y., Discriminability-based transfer between neural networks, NIPS: Advances in Neural Information Processing Systems, 5, pp. 204-211, (1993); Thrun S., Pratt L.Y., Special Issue on Inductive Transfer. Mach. Learn, (1997); Angermueller C., Parnamaa T., Parts L., Stegle O., Deep learning for computational biology, Mol. Syst. Biol., 12, (2016); Curk T., Et al., Microarray data mining with visual programming, Bioinformatics, 21, pp. 396-398, (2005); Demsar J., Et al., Orange: data mining toolbox in python, J. Mach. Learn. Res., 14, pp. 2349-2353, (2013); Zuccotti M., Merico V., Cecconi S., Redi C.A., Garagna S., What does it take to make a developmentally competent mammalian egg?, Hum. Reprod. Update, 17, pp. 525-540, (2011); Bui T.T.H., Et al., Cytoplasmic movement profiles of mouse surrounding nucleolus and not-surrounding nucleolus antral oocytes during meiotic resumption, Mol. Reprod. Dev., 84, pp. 356-362, (2017); Carpenter A.E., Et al., CellProfiler: Image analysis software for identifying and quantifying cell phenotypes, Genome Biol., 7, (2006); Lowe D.G., Object recognition from local scale-invariant features, Proc. of the Seventh IEEE International Conference on Computer Vision, pp. 1150-1157, (1999); Iandola F.N., Et al., Squeezenet: Alexnet-Level Accuracy with 50X Fewer Parameters and <0.5MB Model Size, (2016); Ilenic N., Deep Models of Painting Authorship, (2017); Keim D.A., Mansmann F., Schneidewind J., Thomas J., Ziegler H., Lecture Notes in Computer Science, Visual Data Mining, 4404, (2008); Sacha D., Et al., What you see is what you can change: human-centered machine learning by interactive visualization, Neurocomputing, 268, pp. 164-175, (2017); Pedregosa F., Et al., Scikit-learn: machine learning in Python, J. Mach. Learn. Res., 12, pp. 2825-2830, (2011)","B. Zupan; Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, 1000, Slovenia; email: blaz.zupan@fri.uni-lj.si","","Nature Publishing Group","","","","","","20411723","","","31591416","English","Nat. Commun.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85073058466"
"Tang X.; Spaink H.A.J.; Wijk R.C.V.; Verbeek F.J.","Tang, Xiaoqin (58836185400); Spaink, Hermes A. J. (57761041300); Wijk, Rob C. Van (57194397640); Verbeek, Fons J. (6701677480)","58836185400; 57761041300; 57194397640; 6701677480","Segmentation-Driven Optimization for Iterative Reconstruction in Optical Projection Tomography: An Exploration","2020","IEEE Transactions on Computational Imaging","6","","9262061","1537","1547","10","1","10.1109/TCI.2020.3038489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097195004&doi=10.1109%2fTCI.2020.3038489&partnerID=40&md5=62b1094292dfb8fbb83d2e8175c03a5b","Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands; Department of Pharmaceutial Biosciences, Uppsala University, Uppsala, Sweden","Tang X., Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands; Spaink H.A.J., Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands; Wijk R.C.V., Department of Pharmaceutial Biosciences, Uppsala University, Uppsala, Sweden; Verbeek F.J., Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands","Three-dimensional reconstruction of tomograms from optical projection microscopy is confronted with several drawbacks. In this paper we employ iterative reconstruction algorithms to avoid streak artefacts in the reconstruction and explore possible ways to optimize two parameters of the algorithms, i.e., iteration number and initialization, in order to improve the reconstruction performance. As benchmarks for direct reconstruction evaluation in optical projection tomography are absent, we consider the assessment through the performance of the segmentation on the 3D reconstruction. In our explorative experiments we use the zebrafish model system which is a typical specimen for use in optical projection tomography system; and as such frequently used. In this manner data can be easily obtained from which a benchmark set can be built. For the segmentation approach we apply a two-dimensional U-net convolutional neural network because it is recognized to have a good performance in biomedical image segmentation. In order to prevent the training from getting stuck in local minima, a novel learning rate schema is proposed. This optimization achieves a lower training loss during the training process, as compared to an optimal constant learning rate. Our experiments demonstrate that the approach to the benchmarking of iterative reconstruction via results of segmentation is very useful. It contributes an important tool to the development of computational tools for optical projection tomography.  © 2015 IEEE.","Convolutional neural network; Deep learning; Image reconstruction; Image segmentation; OPT","Benchmarking; Computerized tomography; Convolutional neural networks; Image segmentation; Iterative methods; Optical projectors; Biomedical image segmentation; Computational tools; Iteration numbers; Iterative reconstruction; Iterative reconstruction algorithms; Optical projection tomography; Optical projections; Three-dimensional reconstruction; Image reconstruction","","","","","China Scholarship Council, CSC","Manuscript received March 20, 2020; revised July 10, 2020 and September 19, 2020; accepted October 29, 2020. Date of publication November 17, 2020; date of current version December 4, 2020. This work was supported by China Scholarship Council (CSC). The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Ilaria Catapano. (Corresponding author: Xiaoqin Tang.) Xiaoqin Tang, Hermes A. J. Spaink, and Fons J. Verbeek are with the Leiden Institute t of Advanced Computer Science, Leiden University, Leiden 2333, The Netherlands (e-mail: x.tang@liacs.leidenuniv.nl; f.j.verbeek@ liacs.leidenuniv.nl; hermes.spaink@gmail.com).","Van Wijk R.C., Krekels E.H.J., Hankemeier T., Spaink H.P., Van Der Graaf P.H., Systems pharmacology of hepatic metabolism in zebrafish larvae, Drug Discov. Today: Dis. Models, 22, pp. 27-34, (2016); Schulthess P., Wijk R.C.V., Krekels E.H.J., Yates J.W.T., Spaink H.P., Van Der Graaf P.H., Outside-in systems pharmacology combines innovative computational methods with high-throughput whole vertebrate studies, Cpt Pharmacometrics & Syst. Pharmacol, 7, 5, pp. 285-287, (2018); Walls J.R., Sled J.G., Sharpe J., Henkelman R.M., Correction of artefacts in optical projection tomography, Phys. Med. Biol, 50, 19, pp. 4645-4665, (2005); Dudgeon D.E., Mersereau R.M., Multidimensional digital signal processing, Ieee Commun. Mag, 78, 4, pp. 590-597, (1990); Pawley J.B., Handbook Biological Confocal Microscopy, Springer Science & Business Media, 236, (2006); Nwaneshiudu A., Kuschal C., Sakamoto F.H., Anderson R.R., Schwarzenberger K., Young R.C., Introduction to confocal microscopy, J. Invest. Dermatol, 132, 12, pp. 1-5, (2012); Tang X., Lamers G.E.M., Verbeek F.J., 3D image deblur using point spread function modelling for optical projection tomography, Proc. Bioimaging 2019-6th Int. Conf. Bioimaging, Proc.; Part 12th Int. Joint Conf. Biomed. Eng. Syst. Technol., Biostec, pp. 67-75, (2019); Geyer L.L., Et al., State of the art: Iterative CT reconstruction techniques, Radiology, 276, 2, pp. 339-357, (2015); Hahn D., Et al., Statistical iterative reconstruction algorithm for X-ray phase-contrast cT, Sci. Rep, 5, 1, pp. 1-8, (2015); Wang G., Snyder D.L., O'Sullivan J.A., Vannier M.W., Iterative deblurring for CT metal artifact reduction, Ieee Trans. Med. Imag, 15, 5, pp. 657-664, (1996); Beister M., Kolditz D., Kalender W.A., Iterative reconstruction methods in X-ray cT, Physica Medica, 28, 2, pp. 94-108, (2012); Gordon R., Bender R., Herman G.T., Algebraic reconstruction techniques (ART) for three-dimensional electron microscopy and X-ray photography, J. Theor. Biol, 29, 3, pp. 471-481, (1970); Abeida H., Zhang Q., Li J., Merabtine N., Iterative sparse asymptotic minimum variance based approaches for array processing, Ieee Trans. Signal Process, 61, 4, pp. 933-944, (2013); Fessler J.A., Penalized weighted least-squares image reconstruction for positron emission tomography, Ieee Trans. Med. Imag, 13, 2, pp. 290-300, (1994); Adler J., Oktem O., Learned primal-dual reconstruction, Ieee Trans. Med. Imag, 37, 6, pp. 1322-1332, (2018); Chen H., Et al., LEARN: Learned experts' assessment-based reconstruction network for sparse-data cT, Ieee Trans. Med. Imag, 37, 6, pp. 1333-1347, (2018); Correia T., Et al., Accelerated optical projection tomography applied to in vivo imaging of zebrafish, PLoS One, 10, 8, (2015); Hudson H.M., Larkin R.S., Ordered subsets of projection data, Ieee Trans. Med. Imag, 13, 4, pp. 601-609, (1994); Ghetti C., Ortenzia O., Serreli A., CT iterative reconstruction in image space: A phantom study, Phys.Medica, 28, 2, pp. 161-165, (2012); Hudson H.M., Larkin R.S., Accelerated image reconstruction using ordered subsets of projection data, Ieee Trans.Med. Imag, 13, 4, pp. 601-609, (1994); Shepp L.A., Vardi Y., Maximum likelihood reconstruction for emission tomography, Ieee Trans. Med. Imag, 1, 2, pp. 113-122, (1982); Ronneberger O., Fischer O.P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, Proc. Int. Conf. Medical Image Comput. Computer-Assisted Intervention, pp. 234-241, (2015); Guo Y., Xiong Z., Verbeek F.J., An efficient and robust hybrid method for segmentation of zebrafish objects from bright-field microscope images, Mach. Vis. Appl, 29, 8, pp. 1211-1225, (2018); Weisstein E.W., Sigmoid function, MathWorld-a Wolfram Web Resour, (2006); Cox D.R., The regression analysis of binary sequences, J. R. Statist. Soc. Ser. B, 20, 2, pp. 215-232, (1958); Kingma D.P., Ba J.L., Adam: A method for stochastic optimization, Proc. 3rd Int. Conf. Learn. Represent, (2015); Keras, (2017); Stalling D., Westerhoff M., Hege H.C., Amira: A highly interactive system for visual data analysis, The Visualization Handbook, 38, pp. 749-767, (2005); Matthews B.W., Comparison of the predicted and observed secondary structure of T4 phage lysozyme, Biochimica et Biophysica Acta (BBA)-Protein Structure, 405, 2, pp. 442-451, (1975); Becker K., Jahrling N., Saghafi S., Weiler R., Dodt H.U., Chemical clearing and dehydration of GFP expressing mouse brains, PLoS One, 7, 3, (2012); Kolesova H., Radochova B., Janacek J., Sedmera D., Comparison of different tissue clearingmethods and 3Dimaging techniques for visualization of GFP-expressing mouse embryos and embryonic hearts, Histochem. Cell Biol, 146, 2, pp. 141-152, (2016); Tang X., Lamers G.E.M., Verbeek F.J., 3D Image quality improvement for optical projection tomography via point spread function modelling, Proc. Imag. Appl. Opt. 2018 Osa Tech. Dig.; Opt. Soc. America, (2018); He S., Et al., Synergy between loss of NF1 and overexpression of MYCN in neuroblastoma is mediated by the GAP-related domain, Elife, 5, (2016); Kantae V., Et al., Pharmacokinetic modeling of paracetamol uptake and clearance in zebrafish larvae: Expanding the allometric scale in vertebrates with five orders ofmagnitude, Zebrafish, 13, 6, pp. 504-510, (2016); Van Wijk R.C., Et al., Impact of post-hatching maturation on the pharmacokinetics of paracetamol in zebrafish larvae, Sci. Rep, 9, 1, pp. 1-9, (2019); Wijk R.C.V., Krekels E.H.J., Kantae V., Ordas A., Der P.H.V., Graaf, Mechanistic and quantitative understanding of pharmacokinetics in zebrafish larvae through nanoscale blood sampling and metabolite modeling of paracetamol, J. Pharmacol. Exp. Ther, 372, 1, pp. 15-24, (2019); Council Directive 2010/63/EU Protection Animals Used for Sci. Purposes, (2010)","X. Tang; Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands; email: x.tang@liacs.leidenuniv.nl","","Institute of Electrical and Electronics Engineers Inc.","","","","","","25730436","","","","English","IEEE Trans. Comput. Imaging","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85097195004"
"Xiang S.; Liang Q.; Hu Y.; Tang P.; Coppola G.; Zhang D.; Sun W.","Xiang, Shao (57203872779); Liang, Qiaokang (35174463400); Hu, Yucheng (57205548591); Tang, Pen (57209741175); Coppola, Gianmarc (36134250400); Zhang, Dan (58846287300); Sun, Wei (57161531200)","57203872779; 35174463400; 57205548591; 57209741175; 36134250400; 58846287300; 57161531200","AMC-Net: Asymmetric and multi-scale convolutional neural network for multi-label HPA classification","2019","Computer Methods and Programs in Biomedicine","178","","","275","287","12","9","10.1016/j.cmpb.2019.07.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068552534&doi=10.1016%2fj.cmpb.2019.07.009&partnerID=40&md5=97a5af5007322b59ccd7e20ac6640481","College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China; Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, Hunan University, Changsha, 410082, China; National Engineering Laboratory for Robot Vision Perception and Control technologies, Hunan University, Changsha, 410082, China; Faculty of Engineering and Applied Science, University of Ontario Institute of Technology, Oshawa, L1H 7K4, Ontario, Canada; Department of Mechanical Engineering, York University, Toronto, M3J 1P3, ON, Canada","Xiang S., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, Hunan University, Changsha, 410082, China, National Engineering Laboratory for Robot Vision Perception and Control technologies, Hunan University, Changsha, 410082, China; Liang Q., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, Hunan University, Changsha, 410082, China, National Engineering Laboratory for Robot Vision Perception and Control technologies, Hunan University, Changsha, 410082, China; Hu Y., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, Hunan University, Changsha, 410082, China, National Engineering Laboratory for Robot Vision Perception and Control technologies, Hunan University, Changsha, 410082, China; Tang P., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, Hunan University, Changsha, 410082, China, National Engineering Laboratory for Robot Vision Perception and Control technologies, Hunan University, Changsha, 410082, China; Coppola G., Faculty of Engineering and Applied Science, University of Ontario Institute of Technology, Oshawa, L1H 7K4, Ontario, Canada; Zhang D., Department of Mechanical Engineering, York University, Toronto, M3J 1P3, ON, Canada; Sun W., College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, Hunan University, Changsha, 410082, China, National Engineering Laboratory for Robot Vision Perception and Control technologies, Hunan University, Changsha, 410082, China","Background and objectives: The multi-label Human Protein Atlas (HPA) classification can yield a better understanding of human diseases and help doctors to enhance the automatic analysis of biomedical images. The existing automatic protein recognition methods have been limited to single pattern. Therefore, an automatic multi-label human protein atlas recognition system with satisfactory performance should be conducted. This work aims to build an automatic recognition system for multi-label human protein atlas classification based on deep learning. Methods: In this work, an automatic feature extraction and multi-label classification framework is proposed. Specifically, an asymmetric and multi-scale convolutional neural network is designed for HPA classification. Furthermore, this work introduces a combined loss that consists of the binary cross-entropy and F1-score losses to improve identification performance. Results: Rigorous experiments are conducted to estimate the proposed system. In particular, unlike the current automatic identification systems, which focus on a limited number of patterns, the proposed method is capable of classifying mixed patterns of proteins in microscope images and can handle the subcellular multi-label protein classification task including 28 subcellular localization patterns. The proposed framework based on deep convolutional neural network outperformed the existing approaches with a F1-score of 0.823, which illustrates the robustness and effectiveness of the proposed system. Conclusion: This study proposed a high-performance recognition system for protein atlas classification based on deep learning, and it achieved an automatic multi-label human protein atlas identification framework with superior performance than previous studies. © 2019 Elsevier B.V.","Convolutional neural network; Deep learning; Human protein atlas; Multi-label classification","Algorithms; Cell Nucleus; Databases, Protein; False Positive Reactions; Humans; Image Processing, Computer-Assisted; Microscopy; Microscopy, Fluorescence; Microtubules; Neural Networks, Computer; Pattern Recognition, Automated; Phenotype; Probability; Proteins; Reproducibility of Results; Automation; Classification (of information); Convolution; Deep learning; Image enhancement; Neural networks; Proteins; protein; Automatic feature extraction; Automatic identification system; Automatic recognition system; Convolutional neural network; Human proteins; Multi label classification; Multi-label proteins; Subcellular localizations; Article; autoanalysis; cellular distribution; classification algorithm; data analysis; deep learning; feature extraction; human protein atlas; microscope image; protein analysis; qualitative analysis; receptive field; algorithm; automated pattern recognition; cell nucleus; chemistry; false positive result; fluorescence microscopy; human; image processing; metabolism; microscopy; microtubule; phenotype; physiology; probability; procedures; protein database; reproducibility; Deep neural networks","","protein, 67254-75-5; Proteins, ","","","Chang-Zhu-Tan National Indigenous Innovation Demonstration Zone Project, (2017XK2102); National Nature Science Foundation of China; National Natural Science Foundation of China, NSFC, (61673163); National Natural Science Foundation of China, NSFC; Changzhou Key Laboratory of Special Robot and Intelligent Technology, (IRT2018003); Changzhou Key Laboratory of Special Robot and Intelligent Technology","This work was supported in part by the National Nature Science Foundation of China ( NSFC 61673163 ), the Chang-Zhu-Tan National Indigenous Innovation Demonstration Zone Project ( 2017XK2102 ), and the Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing ( IRT2018003 ).  ","Swamidoss I.N., Karsnas A., Uhlmann V., Ponnusamy P., Kampf C., Simonsson M., Wahlby C., Strand R., Automated classification of immunostaining patterns in breast tissue from the human protein atlas, J. Pathol. Inform., 4, 2, (2013); Uhlen M., Oksvold P., Fagerberg L., Lundberg E., Jonasson K., Forsberg M., Et al., Towards a knowledge-based human protein atlas, Nat. Biotechnol., 28, pp. 1248-1250, (2010); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, NIPS, (2012); Silver D., Huang A., Maddison C.J., Guez A., Sifre L., Van Den Driessche G., Schrittwieser J., Antonoglou I., Panneershelvam V., Lanctot M., Mastering the game of go with deep neural networks and tree search, Nature, 529, 7587, pp. 484-489, (2016); Hinton G., Deng L., Yu D., Dahl G.E., Mohamed A.-R., Jaitly N., Senior A., Vanhoucke V., Nguyen P., Sainath T.N., Et al., Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups, IEEE Signal Process Mag., 29, pp. 82-97, (2012); Simonyan K., Zisserman A.; Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Et al., Going deeper with convolutions, Comput. Vis. Pattern Recognit., (2015); He K., Zhang K., Ren S., Sun J., Identity mappings in deep residual networks, European Conference on Computer Vision, pp. 630-645, (2016); Huang G., Liu Z., van der Maaten L., Weinberger K.Q., Densely connected convolutional networks, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269, (2017); Xie S., Girshick R., Dollar P., Tu Z., He K., Aggregated residual transformations for deep neural networks, Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pp. 5987-5995, (2017); Chollet F., Xception: deep learning with depthwise separable convolutions, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1251-1258, (2017); Howard A.G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., (2017); Sandler M., Howard A., Zhu M., Zhmoginov A., Chen L.C., (2018); Zhang X., Zhou X., Lin M., Sun J., (2017); Ma N., Zhang X., Zheng H.T., Sun J., (2018); Huang G., Liu S., van der Maaten L., Weinberger K.Q., (2017); Sullivan D.P., Winsnes C.F., Lovisa A., Martin H., Mikaela W., Rutger S., Deep learning is combined with massive-scale citizen science to improve large-scale image classification, Nat. Biotechnol., 36, pp. 820-828, (2018); Huang K., Murphy R.F., Boosting accuracy of automated classification of fluorescence microscope images for location proteomics, BMC Bioinformatics, 5, 1, (2004); Newberg J.Y., Li J., Rao A., Ponten F., Uhlen M., Lundberg E., Et al., Automated analysis of human protein atlas immunofluorescence Images[J], Proceedings, 5193229, (2009); Coelho L.P., Kangas J.D., Naik A.W., Osuna-Highley E., Glory-Afshar E., Fuhrman M., Et al., Determining the subcellular location of new proteins from microscope images using local features, Bioinformatics, 29, 18, pp. 2343-2349, (2013); Alex L., Oren Z.K., Sam C.; Liang G.B., Hong H.C., Xie W.F., Zheng L.X., Combining convolutional neural network with recursive neural network for blood cell image classification, IEEE Access, pp. 36188-36197, (2018); Gao Z., Wang L., Zhou L., Zhang J.J., HEp-2 cell image classification with deep convolutional neural networks, IEEE J. Biomed. Health Inform., 21, 2, pp. 416-428, (2015); Godinez W.J., Hossain I., Lazic S.E., Davies J.W., Zhang X., A multi-scale convolutional neural network for phenotyping high-content cellular images, Bioinformatics, 33, 13, pp. 2010-2019, (2017); Sergey I., Szegedy C., Batch normalization: accelerating deep network training by reducing internal covariate shift, International Conference on International Conference on Machine Learning, pp. 448-456, (2015); Nair V., Hinton G.E., Rectified linear units improve restricted boltzmann machines, International Conference on International Conference on Machine Learning, pp. 807-814, (2010); Lin T.Y., Goyal P., Girshick R., He K., Dolla P., Focal loss for dense object detection, IEEE Trans. Pattern Anal. Mach. Intell., 99, pp. 2999-3007, (2017); (2017); Kingma D.P., Ba J., (2015); Ashish S., Jain R., Scikit-learn: machine learning in python, J. Mach. Learn. Res., 12, 10, pp. 2825-2830, (2012)","Q. Liang; College of Electrical and Information Engineering, Hunan University, Changsha, 410082, China; email: qiaokang@hnu.edu.cn","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","31416555","English","Comput. Methods Programs Biomed.","Article","Final","","Scopus","2-s2.0-85068552534"
"Siregar O.R.; Sasongko P.S.; Endah S.N.","Siregar, Obed Reinhard (58062863800); Sasongko, Priyo Sidik (56027168300); Endah, Sukmawati Nur (35731392400)","58062863800; 56027168300; 35731392400","Optic Disc Segmentation on Eye Retinal Image with U-Net Convolutional Neural Network Architecture","2021","Proceedings - International Conference on Informatics and Computational Sciences","2021-November","","","69","74","5","3","10.1109/ICICoS53627.2021.9651795","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199704&doi=10.1109%2fICICoS53627.2021.9651795&partnerID=40&md5=2178038a33b09bf16207307879114e6f","Diponegoro University, Department of Computer Science/Informatics, Semarang, Indonesia","Siregar O.R., Diponegoro University, Department of Computer Science/Informatics, Semarang, Indonesia; Sasongko P.S., Diponegoro University, Department of Computer Science/Informatics, Semarang, Indonesia; Endah S.N., Diponegoro University, Department of Computer Science/Informatics, Semarang, Indonesia","Glaucoma is a disease that causes blindness of the eye. This blindness occurs due to failure of tissue embryogenesis in the eye drainage structure. There are various approaches to early detection of glaucoma. One of them is the optic disc and optic cup segmentation. However, the delineation of the boundaries of the optic disc and the optic cup by experts is highly subjective, time-consuming, and impractical. On the other hand, the automatic segmentation approach using computers is a more attractive method because it can be more objective and faster than human segmentation. Therefore, automatic segmentation using computers is the right solution. U-Net is one of the first convolutional networks designed specifically for biomedical image segmentation. This study only performs semantic optic disc segmentation on eye retinal images using U-Net architecture. This network optimization is done by looking for the parameters of the U-Net architecture which include image size, epoch value, learning rate value, and dropout value. The data used consisted of three public retinal eye image datasets, namely the DRIONS-DB, Drishti-GS, and RIM-ONE dataset. The total data distribution was 287 training data, 16 validation data, and 16 test data. The training and data testing process resulted in the highest Intersection over Union (IoU) score of 93.34% and the highest F1-Score of 96.56%. These results were obtained using epochs 100, learning rate 0.0001, dropout 0.3, and image size 256×256.  © 2021 IEEE.","deep learning; glaucoma; optic disc; semantic segmentation; u-net","Convolution; Convolutional neural networks; Deep learning; Eye protection; Learning algorithms; Network architecture; Ophthalmology; Semantics; Automatic segmentations; Deep learning; Glaucoma; Learning rates; NET architecture; Optic cups; Optic disks; Retinal image; Semantic segmentation; U-net; Semantic Segmentation","","","","","","","Quigley H., Broman A.T., The number of people with glaucoma worldwide in 2010 and 2020, Br. J. Ophthalmol., 90, 3, pp. 262-267, (2006); Quigley H.A., Glaucoma : What Every Patient Should Know. Part 1. What is Glaucoma and How Did You Get It ?, pp. 69-76, (2014); Sevastopolsky A., Optic disc and cup segmentation methods for glaucoma detection with modification of U-net convolutional neural network, Pattern Recognit. Image Anal., 27, 3, pp. 618-624, (2017); Jonas J.B., Bergua A., Schmitz-Valckenberg P., Papastathopoulos K.I., Budde W.M., Ranking of optic disc variables for detection of glaucomatous optic nerve damage, Investig. Ophthalmol. Vis. Sci., 41, 7, pp. 1764-1773, (2000); Abdullah M., Fraz M.M., Barman S.A., Localization and segmentation of optic disc in retinal images using circular hough transform and grow-cut algorithm, PeerJ, 2016, 5, pp. 1-22, (2016); Zilly J., Buhmann J.M., Mahapatra D., Glaucoma detection using entropy sampling and ensemble learning for automatic optic cup and disc segmentation, Comput. Med. Imaging Graph., 55, pp. 28-41, (2017); Zahoor M.N., Fraz M.M., Fast optic disc segmentation in retina using polar transform, IEEE Access, 5, 100, pp. 12293-12300, (2017); O'Mahony N., Et al., Deep learning vs. Traditional computer vision, Adv. Intell. Syst. Comput., 943, 105, pp. 128-144, (2020); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), 9351, pp. 234-241, (2015); Surikov I.Y., Nakhatovich M.A., Belyaev S.Y., Savchuk D.A., Floor plan recognition and vectorization using combination UNet, faster-RCNN, statistical component analysis and ramer-douglas-peucker, Comput. Sci. Commun. Secur., 1235, pp. 16-28, (2020); Zyuzin V., Et al., Identification of the left ventricle endocardial border on two-dimensional ultrasound images using the convolutional neural network unet, IEEE Trans. Inf. Technol. Biomed., (2018); Carmona E.J., Rincon M., Garcia-Feijoo J., Martinez-De-La-Casa J.M., Identification of the optic nerve head with genetic algorithms, Artif. Intell. Med., 43, 3, pp. 243-259, (2008); Sivaswamy J., Gopal S.R.K., Joshi D., Jain M., Syed U., Hospital A.E., DRISHTI-GS : Retinal Image Dataset for Optic Nerve Head ( ONH ) Segmentation IIIT, Hyderabad, India, pp. 53-56, (2014); Fumero F., Alayon S., Sanchez J.L., Sigut J., Gonzalez-Hernandez M., RIM-ONE: An open retinal image database for optic nerve evaluation, Proc. - IEEE Symp. Comput. Med. Syst., pp. 4-9, (2011); Bertels J., Et al., Optimizing the dice score and jaccard index for medical image segmentation: Theory & practice, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 92-100, (2019)","","","Institute of Electrical and Electronics Engineers Inc.","IEEE Indonesia Chapter; IEEE Systems, Man, and Cybernetics Society","5th International Conference on Informatics and Computational Sciences, ICICos 2021","24 November 2021 through 25 November 2021","Semarang","175965","27677087","978-166543807-0","","","English","Proc. Int. Conf. Informatics Comput. Sci.","Conference paper","Final","","Scopus","2-s2.0-85146199704"
"Shirazi A.Z.; Fornaciari E.; McDonnell M.D.; Yaghoobi M.; Cevallos Y.; Tello-Oquendo L.; Inca D.; Gomez G.A.","Shirazi, Amin Zadeh (55320828900); Fornaciari, Eric (57215673150); McDonnell, Mark D. (7102564709); Yaghoobi, Mahdi (56234245700); Cevallos, Yesenia (57209662798); Tello-Oquendo, Luis (56028218500); Inca, Deysi (57209652996); Gomez, Guillermo A. (7202293576)","55320828900; 57215673150; 7102564709; 56234245700; 57209662798; 56028218500; 57209652996; 7202293576","The application of deep convolutional neural networks to brain cancer images: A survey","2020","Journal of Personalized Medicine","10","4","224","1","27","26","38","10.3390/jpm10040224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096146619&doi=10.3390%2fjpm10040224&partnerID=40&md5=f5b07afb73940044dc85caaf111a4e0b","Centre for Cancer Biology, SA Pathology and the University of South of Australia, Adelaide, 5000, SA, Australia; Computational Learning Systems Laboratory, UniSA STEM, University of South Australia, Mawson Lakes, 5095, SA, Australia; Department of Mathematics of Computation, University of California, Los Angeles (UCLA), Los Angeles, 90095, CA, United States; Electrical and Computer Engineering Department, Islamic Azad University, Mashhad Branch, Mashad, 917794-8564, Iran; College of Engineering, Universidad Nacional de Chimborazo, Riobamba, 060150, Ecuador","Shirazi A.Z., Centre for Cancer Biology, SA Pathology and the University of South of Australia, Adelaide, 5000, SA, Australia, Computational Learning Systems Laboratory, UniSA STEM, University of South Australia, Mawson Lakes, 5095, SA, Australia; Fornaciari E., Department of Mathematics of Computation, University of California, Los Angeles (UCLA), Los Angeles, 90095, CA, United States; McDonnell M.D., Computational Learning Systems Laboratory, UniSA STEM, University of South Australia, Mawson Lakes, 5095, SA, Australia; Yaghoobi M., Electrical and Computer Engineering Department, Islamic Azad University, Mashhad Branch, Mashad, 917794-8564, Iran; Cevallos Y., College of Engineering, Universidad Nacional de Chimborazo, Riobamba, 060150, Ecuador; Tello-Oquendo L., College of Engineering, Universidad Nacional de Chimborazo, Riobamba, 060150, Ecuador; Inca D., College of Engineering, Universidad Nacional de Chimborazo, Riobamba, 060150, Ecuador; Gomez G.A., Centre for Cancer Biology, SA Pathology and the University of South of Australia, Adelaide, 5000, SA, Australia","In recent years, improved deep learning techniques have been applied to biomedical image processing for the classification and segmentation of different tumors based on magnetic resonance imaging (MRI) and histopathological imaging (H&E) clinical information. Deep Convolutional Neural Networks (DCNNs) architectures include tens to hundreds of processing layers that can extract multiple levels of features in image-based data, which would be otherwise very difficult and time-consuming to be recognized and extracted by experts for classification of tumors into different tumor types, as well as segmentation of tumor images. This article summarizes the latest studies of deep learning techniques applied to three different kinds of brain cancer medical images (histology, magnetic resonance, and computed tomography) and highlights current challenges in the field for the broader applicability of DCNN in personalized brain cancer care by focusing on two main applications of DCNNs: classification and segmentation of brain cancer tumors images. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Brain cancer; Classification; Convolutional neural networks; DCNN; Deep learning; Histology; MRI; Segmentation","accuracy; algorithm; artificial neural network; brain cancer; convolutional neural network; deep learning; diagnostic accuracy; histopathology; human; human tissue; image processing; image segmentation; learning algorithm; measurement accuracy; neuroimaging; nuclear magnetic resonance imaging; Review; sensitivity and specificity; support vector machine; total quality management; training; tumor microenvironment","","","","","Cancer Council; National Health and Medical Research Council of Australia, (1067405, 1123816); Australian Research Council, ARC, (FT160100366); Neurosurgical Research Foundation, NRF; University of South Australia, UniSA; Cure Brain Cancer Foundation, CBCF","Funding: This work was supported by grants from the National Health and Medical Research Council of Australia (1067405 and 1123816 to G.A.G.), the Cure Brain Cancer Foundation (to G.A.G.), the University of South Australia (to G.A.G. and A.Z.S.), the Neurosurgical Research Foundation (to G.A.G.) and the Cancer Council SA Beat Cancer Project Infrastructure (to G.A.G.). G.A.G. is also supported by an Australian Research Council Future Fellowship (FT160100366). A.Z.S. is supported by an Australian Government Research Training Program (RTP) Scholarship.","Shirazi A.Z., Mohammadi Z., A hybrid intelligent model combining ANN and imperialist competitive algorithm for prediction of corrosion rate in 3C steel under seawater environment, Neural Comput. Appl, 28, pp. 3455-3464, (2017); Shirazi A.Z., Hatami M., Yaghoobi M., Chabok S.J.S.M., An intelligent approach to predict vibration rate in a real gas turbine, Intell. Ind. Syst, 2, pp. 253-267, (2016); Shirazi A.Z., Tofighi M., Ganjefar S., Mahdavi S.J.S., An optimized adaptive-neuro fuzzy inference system (ANFIS) for reliable prediction of entrance length in pipes, Int. J. Enhanc. Res. Sci. Technol. Eng, 3, pp. 79-89, (2014); Yavuz E., Eyupoglu C., An effective approach for breast cancer diagnosis based on routine blood analysis features, Med. Biol. Eng. Comput, 58, pp. 1583-1601, (2020); Becker A., Artificial intelligence in medicine: What is it doing for us today?, Health Policy Technol, 8, pp. 198-205, (2019); Shirazi A.Z., Fornaciari E., Gomez G.A., Deep learning in precision medicine, Artificial Intelligence in Precision Health, pp. 61-90, (2020); Shirazi A.Z., Chabok S.J.S.M., Mohammadi Z., A novel and reliable computational intelligence system for breast cancer detection, Med. Biol. Eng. Comput, 56, pp. 721-732, (2018); Zhu W., Xie L., Han J., Guo X., The Application of Deep Learning in Cancer Prognosis Prediction, Cancers, 12, (2020); Coccia M., Deep learning technology for improving cancer care in society: New directions in cancer imaging driven by artificial intelligence, Technol. Soc, 60, (2020); Huang Z., Johnson T.S., Han Z., Helm B., Cao S., Zhang C., Salama P., Rizkalla M., Yu C.Y., Cheng J., Et al., Deep learning-based cancer survival prognosis from RNA-seq data: Approaches and evaluations, BMC Med. Genom, 13, pp. 1-12, (2020); Baptista D., Ferreira P.G., Rocha M., Deep learning for drug response prediction in cancer, Brief. Bioinform, (2020); Shao L., Shum H.P., Hospedales T., Special Issue on Machine Vision with Deep Learning, Int. J. Comput. Vis, 128, pp. 771-772, (2020); Gour M., Jain S., Kumar T.S., Residual learning based CNN for breast cancer histopathological image classification, Int. J. Imaging Syst. Technol, 30, pp. 621-635, (2020); Chen X., Men K., Chen B., Tang Y., Zhang T., Wang S., Li Y., Dai J., CNN-Based Quality Assurance for Automatic Segmentation of Breast Cancer in Radiotherapy, Front. Oncol, 10, (2020); Duran-Lopez L., Dominguez-Morales J.P., Conde-Martin A.F., Vicente-Diaz S., Linares-Barranco A., PROMETEO: A CNN-Based Computer-Aided Diagnosis System for WSI Prostate Cancer Detection, IEEE Access, 8, pp. 128613-128628, (2020); Liu Z., Yang C., Huang J., Liu S., Zhuo Y., Lu X., Deep learning framework based on integration of S-Mask R-CNN and Inception-v3 for ultrasound image-aided diagnosis of prostate cancer, Future Gener. Comput. Syst, 114, pp. 358-367, (2020); Meng J., Xue L., Chang Y., Zhang J., Chang S., Liu K., Liu S., Wang B., Yang K., Automatic detection and segmentation of adenomatous colorectal polyps during colonoscopy using Mask R-CNN, Open Life Sci, 15, pp. 588-596, (2020); Fonolla R., van der Zander Q.E., Schreuder R.M., Masclee A.A., Schoon E.J., van der Sommen F., A CNN CADx System for Multimodal Classification of Colorectal Polyps Combining WL, BLI, and LCI Modalities, Appl. Sci, 10, (2020); Takahashi M., Kameya Y., Yamada K., Hotta K., Takahashi T., Sassa N., Iwano S., Yamamoto T., An empirical study on the use of visual explanation in kidney cancer detection, Proceedings of the Twelfth International Conference on Digital Image Processing (ICDIP 2020); Vasanthselvakumar R., Balasubramanian M., Sathiya S., Automatic Detection and Classification of Chronic Kidney Diseases Using CNN Architecture, Data Engineering and Communication Technology, pp. 735-744, (2020); Hashemzehi R., Mahdavi S.J.S., Kheirabadi M., Kamel S.R., Detection of brain tumors from MRI images base on deep learning using hybrid model CNN and NADE, Biocybern. Biomed. Eng, 40, pp. 1225-1232, (2020); Mzoughi H., Njeh I., Wali A., Slima M.B., BenHamida A., Mhiri C., Mahfoudhe K.B., Deep Multi-Scale 3D Convolutional Neural Network (CNN) for MRI Gliomas Brain Tumor Classification, J. Digit. Imaging, 33, pp. 903-915, (2020); Siegel R.L., Miller K.D., Jemal A., Cancer statistics, 2020, CA Cancer J. Clin, 70, pp. 7-30, (2020); Amin Z.S., Fornaciari E., Ebert L.M., Koszyca B., Gomez G.A., DeepSurvNet: Deep survival convolutional network for brain cancer survival rate classification based on histopathological images, Med. Biol. Eng. Comput, 58, pp. 1031-1045, (2020); Perrin S.L., Samuel M.S., Koszyca B., Brown M.P., Ebert L.M., Oksdath M., Gomez G.A., Glioblastoma heterogeneity and the tumour microenvironment: Implications for preclinical research and development of new treatments, Biochem. Soc. Trans, 47, pp. 625-638, (2019); Muhammad K., Khan S., Ser J.D., de Albuquerque V.H.C., Deep learning for multigrade brain tumor classification in smart healthcare systems: A prospective survey, IEEE Trans. Neural Netw. Learn. Syst, (2020); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, (2015); Liu S., Shah Z., Sav A., Russo C., Berkovsky S., Qian Y., Coiera E., Di Ieva A., Isocitrate dehydrogenase (iDH) status prediction in histopathology images of gliomas using deep learning, Sci. Rep, 10, pp. 1-11, (2020); Sumi P.S., Delhibabu R., Glioblastoma Multiforme Classification On High Resolution Histology Image Using Deep Spatial Fusion Network, Proceedings of the CEUR Workshop, pp. 109-120; Yonekura A., Kawanaka H., Prasath V.S., Aronow B.J., Takase H., Automatic disease stage classification of glioblastoma multiforme histopathological images using deep convolutional neural network, Biomed. Eng. Lett, 8, pp. 321-327, (2018); LeCun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc. IEEE, 86, pp. 2278-2324, (1998); Zeiler M.D., Fergus R., Visualizing and understanding convolutional networks, European Conference on Computer Vision, (2014); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, (2014); Fukuma R., Yanagisawa T., Kinoshita M., Shinozaki T., Arita H., Kawaguchi A., Takahashi M., Narita Y., Terakawa Y., Tsuyuguchi N., Et al., Prediction of IDH and TERT promoter mutations in low-grade glioma from magnetic resonance images using a convolutional neural network, Sci. Rep, 9, pp. 1-8, (2019); Chang K., Bai H.X., Zhou H., Su C., Bi W.L., Agbodza E., Kavouridis V.K., Senders J.T., Boaro A., Beers A., Et al., Residual convolutional neural network for the determination of IDH status in low-and high-grade gliomas from MR imaging, Clin. Cancer Res, 24, pp. 1073-1081, (2018); Alqudah A.M., Alquraan H., Qasmieh I.A., Alqudah A., Al-Sharu W., Brain Tumor Classification Using Deep Learning Technique—A Comparison between Cropped, Uncropped, and Segmented Lesion Images with Different Sizes, (2020); Kalaiselvi T., Padmapriya T., Sriramakrishnan P., Priyadharshini V., Development of automatic glioma brain tumor detection system using deep convolutional neural networks, Int. J. Imaging Syst. Technol, 30, pp. 926-938, (2020); Badza M.M., Barjaktarovic M.C., Classification of Brain Tumors from MRI Images Using a Convolutional Neural Network, Appl. Sci, 10, (2020); Liu D., Liu Y., Dong L., G-ResNet: Improved ResNet for brain tumor classification, International Conference on Neural Information Processing, (2019); Hemanth D.J., Anitha J., Naaji A., Geman O., Popescu D.E., Son L.H., Hoang L., A modified deep convolutional neural network for abnormal brain image classification, IEEE Access, 7, pp. 4275-4283, (2018); Afshar P., Plataniotis K.N., Mohammadi A., Capsule networks for brain tumor classification based on MRI images and coarse tumor boundaries, ICASSP 2019—2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), (2019); Seetha J., Raja S.S., Brain tumor classification using convolutional neural networks, Biomed. Pharmacol. J, 11, (2018); Pashaei A., Sajedi H., Jazayeri N., Brain tumor classification via convolutional neural network and extreme learning machines, 2018 8th International Conference on Computer and Knowledge Engineering (ICCKE), (2018); Zhou Y., Li Z., Zhu H., Chen C., Gao M., Xu K., Xu J., Holistic brain tumor screening and classification based on densenet and recurrent neural network, International MICCAI Brainlesion Workshop, (2018); Mohsen H., El-Dahshan E.S.A., El-Horbaty E.S.M., Salem A.B.M., Classification using deep learning neural networks for brain tumors, Future Comput. Inform. J, 3, pp. 68-71, (2018); Ari A., Hanbay D., Deep learning based brain tumor classification and detection system, Turk. J. Electr. Eng. Comput. Sci, 26, pp. 2275-2286, (2018); Suter Y., Jungo A., Rebsamen M., Knecht U., Herrmann E., Wiest R., Reyes M., Deep learning versus classical regression for brain tumor patient survival prediction, International MICCAI Brainlesion Workshop, (2018); Banerjee S., Mitra S., Masulli F., Rovetta S., Brain tumor detection and classification from multi-sequence MRI: Study using convnets, International MICCAI Brainlesion Workshop, (2018); Afshar P., Mohammadi A., Plataniotis K.N., Brain tumor type classification via capsule networks, 2018 25th IEEE International Conference on Image Processing (ICIP), (2018); Bagari A., Kumar A., Kori A., Khened M., Krishnamurthi G., A combined Radio-Histological Approach for Classification of Low Grade Gliomas, International MICCAI Brainlesion Workshop, (2018); Sajjad M., Khan S., Muhammad K., Wu W., Ullah A., Baik S.W., Multi-grade brain tumor classification using deep CNN with extensive data augmentation, J. Comput. Sci, 30, pp. 174-182, (2019); Cheng J., Huang W., Cao S., Yang R., Yang W., Yun Z., Wang Z., Feng Q., Enhanced performance of brain tumor classification via tumor region augmentation and partition, PLoS ONE, 10, (2015); Clark K., Vendt B., Smith K., Freymann J., Kirby J., Koppel P., Moore S., Phillips S., Maffitt D., Pringle M., Et al., The Cancer Imaging Archive (TCIA): Maintaining and operating a public information repository, J. Digit. Imaging, 26, pp. 1045-1057, (2013); Menze B.H., Jakab A., Bauer S., Kalpathy-Cramer J., Farahani K., Kirby J., Burren Y., Porz N., Slotboom J., Wiest R., Et al., The multimodal brain tumor image segmentation benchmark (BRATS), IEEE Trans. Med. Imaging, 34, pp. 1993-2024, (2014); Vidoni E.D., The Whole Brain Atlas: Www. med. harvard. edu/aanlib, J. Neurol. Phys. Ther, 36, (2012); Caldairou B., Passat N., Habas P.A., Studholme C., Rousseau F., A non-local fuzzy segmentation method: Application to brain MRI, Pattern Recognit, 44, pp. 1916-1927, (2011); Weinstein J.N., Collisson E.A., Mills G.B., Shaw K.R., Ozenberger B.A., Ellrott K., Shmulevich I., Sander C., Stuart J.M., The cancer genome atlas pan-cancer analysis project, Nat. Genet, 45, (2013); Devaki Scans & Diagnostics; Suhag S., Saini L.M., Automatic brain tumor detection and classification using svm classifier, Proceedings of the ISER 2nd International Conference, (2015); Kwan R.-S., Evans A.C., Pike G.B., MRI simulation-based evaluation of image-processing and classification methods, IEEE Trans. Med. Imaging, 18, pp. 1085-1097, (1999); Scarpace L., Mikkelsen L., Cha T., Rao S., Tekchandani S., Gutman S., Pierce D., Radiology data from the cancer genome atlas glioblastoma multiforme [TCGA-GBM] collection, Cancer Imaging Arch, 11, (2016); Pedano N., Flanders A.E., Scarpace L., Mikkelsen T., Eschbacher J.M., Hermes B., Ostrom Q., Radiology data from the cancer genome atlas low grade glioma [TCGA-LGG] collection, Cancer Imaging Arch, (2016); Ismael S.A.A., Mohammed A., Hefny H., An enhanced deep learning approach for brain cancer MRI images classification using residual networks, Artif. Intell. Med, 102, (2020); Maharjan S., Alsadoon A., Prasad P.W.C., Al-Dalain T., Alsadoon O.H., A novel enhanced softmax loss function for brain tumour detection using deep learning, J. Neurosci. Methods, 330, (2020); Vijh S., Sharma S., Gaurav P., Brain Tumor Segmentation Using OTSU Embedded Adaptive Particle Swarm Optimization Method and Convolutional Neural Network, Data Visualization and Knowledge Engineering, pp. 171-194, (2020); Rani N.S., Karthik U., Ranjith S., Extraction of Gliomas from 3D MRI Images using Convolution Kernel Processing and Adaptive Thresholding, Procedia Comput. Sci, 167, pp. 273-284, (2020); Deng W., Shi Q., Wang M., Zheng B., Ning N., Deep Learning-Based HCNN and CRF-RRNN Model for Brain Tumor Segmentation, IEEE Access, 8, pp. 26665-26675, (2020); Deng W., Shi Q., Luo K., Yang Y., Ning N., Brain tumor segmentation based on improved convolutional neural network in combination with non-quantifiable local texture feature, J. Med. Syst, 43, (2019); Kumar G.A., Sridevi P., Intensity Inhomogeneity Correction for Magnetic Resonance Imaging of Automatic Brain Tumor Segmentation, Microelectronics, Electromagnetics and Telecommunications, pp. 703-711, (2019); Mittal M., Goyal L.M., Kaur S., Kaur I., Verma A., Jude Hemanth D., Hemanth Deep learning based enhanced tumor segmentation approach for MR brain images, Appl. Soft Comput, 78, pp. 346-354, (2019); Mittal A., Kumar D., AiCNNs (Artificially-integrated Convolutional Neural Networks) for Brain Tumor Prediction, Eai Endorsed Trans. Pervasive Health Technol, 5, pp. 346-354, (2019); Thillaikkarasi R., Saravanan S., An enhancement of deep learning algorithm for brain tumor segmentation using kernel based CNN with M-SVM, J. Med. Syst, 43, (2019); Sharma A., Kumar S., Singh S.N., Brain tumor segmentation using DE embedded OTSU method and neural network, Multidimens. Syst. Signal Process, 30, pp. 1263-1291, (2019); Kong X., Sun G., Wu Q., Liu J., Lin F., Hybrid pyramid u-net model for brain tumor segmentation, International Conference on Intelligent Information Processing, (2018); Benson E., Pound M.P., French A.P., Jackson A.S., Pridmore T.P., Deep hourglass for brain tumor segmentation, International MICCAI Brainlesion Workshop, (2018); Zhou C., Chen S., Ding C., Tao D., Learning contextual and attentive information for brain tumor segmentation, International MICCAI Brainlesion Workshop, (2018); Dai L., Li T., Shu H., Zhong L., Shen H., Zhu H., Automatic brain tumor segmentation with domain adaptation, International MICCAI Brainlesion Workshop, (2018); Kermi A., Mahmoudi I., Khadir M.T., Deep convolutional neural networks using U-Net for automatic brain tumor segmentation in multimodal MRI volumes, International MICCAI Brainlesion Workshop, (2018); Mlynarski P., Delingette H., Criminisi A., Ayache N., Deep learning with mixed supervision for brain tumor segmentation, J. Med. Imaging, 6, (2019); Wang G., Li W., Zuluaga M.A., Pratt R., Patel P.A., Aertsen M., Doel T., David A.L., Deprest J., Ourselin S., Et al., Interactive medical image segmentation using deep learning with image-specific fine tuning, IEEE Trans. Med. Imaging, 37, pp. 1562-1573, (2018); Monteiro M., Newcombe V.F., Mathieu F., Adatia K., Kamnitsas K., Ferrante E., Das T., Whitehouse D., Rueckert D., Menon D.K., Multiclass semantic segmentation and quantification of traumatic brain injury lesions on head CT using deep learning: An algorithm development and multicentre validation study, Lancet Digit. Health, 2, pp. 314-322, (2020); Xu Y., Jia Z., Ai Y., Zhang F., Lai M., Eric I., Chang C., Deep convolutional activation features for large scale brain tumor histopathology image classification and segmentation, 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), (2015); DICOM Image Sample Sets; (2014); Wang Q., Hu B., Hu X., Kim H., Squatrito M., Scarpace L., Decarvalho A.C., Lyu S., Li P., Li Y., Et al., Tumor evolution of glioma-intrinsic gene expression subtypes associates with immunological changes in the microenvironment, Cancer Cell, 32, pp. 42-56, (2017)","G.A. Gomez; Centre for Cancer Biology, SA Pathology and the University of South of Australia, Adelaide, 5000, Australia; email: guillermo.gomez@unisa.edu.au","","MDPI AG","","","","","","20754426","","","","English","J. Pers. Med.","Review","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85096146619"
"de Pinho Pinheiro C.A.; Nedjah N.; de Macedo Mourelle L.","de Pinho Pinheiro, Cesar Affonso (57207830460); Nedjah, Nadia (6701673657); de Macedo Mourelle, Luiza (6602182066)","57207830460; 6701673657; 6602182066","Detection and classification of pulmonary nodules using deep learning and swarm intelligence","2020","Multimedia Tools and Applications","79","21-22","","15437","15465","28","32","10.1007/s11042-019-7473-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062995200&doi=10.1007%2fs11042-019-7473-z&partnerID=40&md5=dc2efe422c1efa76ab5db998fd632447","Department of Electronics Engineering and Telecommunications, Faculty of Engineering, State University of Rio de Janeiro, Rio de Janeiro, Brazil; Department of Systems Engineering and Computation, Faculty of Engineering, State University of Rio de Janeiro, Rio de Janeiro, Brazil","de Pinho Pinheiro C.A., Department of Electronics Engineering and Telecommunications, Faculty of Engineering, State University of Rio de Janeiro, Rio de Janeiro, Brazil; Nedjah N., Department of Electronics Engineering and Telecommunications, Faculty of Engineering, State University of Rio de Janeiro, Rio de Janeiro, Brazil; de Macedo Mourelle L., Department of Systems Engineering and Computation, Faculty of Engineering, State University of Rio de Janeiro, Rio de Janeiro, Brazil","Cancer diagnosis is usually an arduous task in medicine, especially when it comes to pulmonary cancer, which is one of the most deadly and hard to treat types of that disease. Early detecting pulmonary cancerous nodules drastically increases surviving chances but also makes it an even harder problem to solve, as it mostly depends on a visual inspection of tomography scans. In order to help improving cancer detection and surviving rates, engineers and scientists have been developing computer-aided diagnosis systems, similar to the one presented in this paper. These systems are used as second opinions, to help health professionals during the diagnosis of numerous diseases. This work uses computational intelligence techniques to propose a new approach towards solving the problem of detecting pulmonary carcinogenic nodules in computed tomography scans. The applied technology consists of using Deep Learning and Swarm Intelligence to develop different nodule detection and classification models. We exploit seven different swarm intelligence algorithms and convolutional neural networks, prepared for biomedical image segmentation, to find and classify cancerous pulmonary nodules in the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) databases. The aim of this work is to use swarm intelligence to train convolutional neural networks and verify whether this approach brings more efficiency than the classic training algorithms, such as back-propagation and gradient descent methods. As main contribution, this work confirms the superiority of swarm-trained models over the back-propagation-based model for this application, as three out of the seven algorithms are proved to be superior regarding all four performance metrics, which are accuracy, precision, sensitivity, and specificity, as well as training time, where the best swarm-trained model operates 25% faster than the back-propagation model. The performed experiments show that the developed models can achieve up to 93.71% accuracy, 93.53% precision, 92.96% sensitivity, and 98.52% specificity. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Convolutional neural networks; Deep learning; Nodule detection; Swarm intelligence","Backpropagation algorithms; Bioinformatics; Classification (of information); Computer aided diagnosis; Computerized tomography; Convolution; Database systems; Deep learning; Deep neural networks; Diseases; Gradient methods; Image segmentation; Neural networks; Biomedical image segmentation; Computational intelligence techniques; Computed tomography scan; Computer aided diagnosis systems; Convolutional neural network; Gradient Descent method; Nodule detection; Swarm intelligence algorithms; Swarm intelligence","","","","","","","Biopsy, (2018); Armato S.G.I.I.I., McLennan G., Bidaut L., McNitt-Gray M.F., Meyer C.R., Reeves A.P., Zhao B., Aberle D.R., Henschke C.I., Hoffman E.A., Et al., The lung image database consortium (lidc) and image database resource initiative (idri): a completed reference database of lung nodules on ct scans, Med Phys, 38, 2, pp. 915-931, (2011); Chon A., Balachandra N., Lu P., Deep Convolutional Neural Networks for Lung Cancer Detection, (2017); U-Net, (2018); Geem Z.W., Kim J.H., Loganathan G.V., A new heuristic optimization algorithm: harmony search, Simulation, 76, 2, pp. 60-68, (2001); Ritchie H., Roser M., Causes of Death, (2019); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Jayanthi S.K., Preetha K., Breast cancer detection and classification using artificial neural network with particle swarm optimization, Int J Adv Res Basic Eng Sci Technol, 2, (2016); Karaboga D., Basturk B., A powerful and efficient algorithm for numerical function optimization: artificial bee colony (abc) algorithm, J Global Optim, 39, 3, pp. 459-471, (2007); Kennedy J., Eberhart R., Particle swarm optimization, (1995); Khajehzadeh M., Eslami M., Gravitational search algorithm for optimization of retaining structures, Indian J Sci Technol, 5, 1, (2012); Kuan K., Ravaut M., Manek G., Chen H., Lin J., Nazir B., Chen C., Howe T.C., Zeng Z., Chandrasekhar V., Deep Learning for Lung Cancer Detection: Tackling the Kaggle Data Science Bowl 2017 Challenge, (2017); Lee M.C., Boroczky L., Sungur-Stasik K., Cann A.D., Borczuk A.C., Kawut S.M., Powell C.A., Computer-aided diagnosis of pulmonary nodules using a two-step approach for feature selection and classifier ensemble construction, Artif Intell Med, 50, 1, pp. 43-53, (2010); Mazurowski M.A., Habas P.A., Zurada J.M., Lo J.Y., Baker J.A., Tourassi G.D., Training neural network classifiers for medical decision making: the effects of imbalanced datasets on classification performance, Neur Netw, 21, 2-3, pp. 427-436, (2008); Mhetre M.R.R., Sache MRG Detection of Lung Cancer Nodule on Ct Scan Images by Using Region Growing Method; Miah M.B.A., Yousuf M.A., Detection of lung cancer from ct image using image processing and neural network, 2015 International Conference on Electrical Engineering and Information Communication Technology (ICEEICT), pp. 1-6, (2015); Morais R., Mourelle L.M., Nedjah N., Hitchcock birds inspired algorithm: 10th international conference, 1, pp. 169-180, (2018); Cancer costs projected to reach at least 158 billion in 2020, (2011); Passino K.M., Bacterial foraging optimization, Int J Swarm Intell Res, 1, 1, pp. 1-16, (2010); Ritthipakdee T., Premasathian J., Firefly Mating Algorithm for Continuous Optimization Problems, (2017); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241, (2015); Sivakumar S., Chandrasekar C., Lung nodule detection using fuzzy clustering and support vector machines, Int J Eng Technol, 5, 1, pp. 179-185, (2013); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); Tan Y., Zhu Y., Fireworks algorithm for optimization, Proceedings of the First International Conference on Advances in Swarm Intelligence - Volume Part I, ICSI’10, pp. 355-364, (2010); Wang S., Zhang Y., Dong Z., Du S., Ji G., Yan J., Yang J., Wang Q., Feng C., Phillips P., Feed-forward neural network optimized by hybridization of pso and abc for abnormal brain detection, Int J Imaging Syst Technol, 25, 2, pp. 153-164, (2015); Zhang Y., Wang S., Wu L., A novel method for magnetic resonance brain image classification based on adaptive chaotic pso, Prog Electromagn Res, 109, pp. 325-343, (2010); Zhang Y., Wang S., Phillips P., Dong Z., Ji G., Yang J., Detection of alzheimer’s disease and mild cognitive impairment based on structural volumetric mr images using 3d-dwt and wta-ksvm trained by psotvac, Biomed Signal Process Control, 21, pp. 58-73, (2015); Zhou Z.-H., Jiang Y., Yang Y.-B., Chen S.-F., Lung cancer cell identification based on artificial neural network ensembles, Artif Intell Med, 24, 1, pp. 25-36, (2002)","N. Nedjah; Department of Electronics Engineering and Telecommunications, Faculty of Engineering, State University of Rio de Janeiro, Rio de Janeiro, Brazil; email: nadia@eng.uerj.br","","Springer","","","","","","13807501","","MTAPF","","English","Multimedia Tools Appl","Article","Final","","Scopus","2-s2.0-85062995200"
"Mahanty M.; Bhattacharyya D.; Midhunchakkaravarthy D.","Mahanty, Mohan (57220483702); Bhattacharyya, Debnath (57216142572); Midhunchakkaravarthy, Divya (56380232700)","57220483702; 57216142572; 56380232700","Su-net based colorectal polyp segmentation from colon cancer morphology images","2021","Natural Volatiles and Essential Oils","8","4","","649","659","10","2","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119325222&partnerID=40&md5=43e1216cf0665997590d3c2ab0adec9b","Department of Computer Science and Multimedia, Lincoln University College, Malaysia; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Green Field, Guntur 522502, Vaddeswaram, India","Mahanty M., Department of Computer Science and Multimedia, Lincoln University College, Malaysia; Bhattacharyya D., Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Green Field, Guntur 522502, Vaddeswaram, India; Midhunchakkaravarthy D., Department of Computer Science and Multimedia, Lincoln University College, Malaysia","Precise demarcation of glands from clinical histology images are pre-requirement for accurate medical diagnosis. Colorectal polyps that originate and expandsover the rectum or colon membrane are the decisive reason for colorectal Cancer(CRC). The early-stage recognition and of polyps and treatment can decrease the mortality rate. To lower the polyp miss-rate in colonoscopy, a Computer-Aided Medical Diagnosing(CAD) system with high accuracy is needed. In recent times, researchers develop deep learning models for accurate polyp detection from histomorphology images, but accuracy is still the most requisite factor for reliable results. In this paper, we propose to develop and test a Convolutional Neural Network(CNN) based U-shape network (SU-NET) model for semantic segmentation of colorectal polyps from colonoscopy images.SU-NET is an Encoder-Decoder-based architecture, inspired by the popular segmentation architectures SegNet and U-Net for improved colon polyp segmentation. In the proposed model the top most layers transfer the Pooling indices whereas the lower-level layers transfer the feature-maps to incorporate fine multiscale information for better colon polyp contour identification.We evaluated the proposed algorithm in contrast with various prominentdeep learning architectures across multi-modal biomedical image segmentation tasks to segment polyps from the colonoscopy and histopathology images.For evaluating the proposed model, an accredited and publicly available colonoscopy image dataset CVC-ColonDB is employed. The model achieves a recall of 91.3%, F1-Score of 90.81%, F2-Score of 86.39%, Precision of 89.21%, and the Dice similarity coefficient of 0.895 outshines the existing advanced deep learning CNN models. © 2021, Badebio Biotechnololgy Ltd. All rights reserved.","Colonoscopy; Colorectal cancer; Deep convolutional neural network; Medical image analysis; Polyp semantic segmentation; SU-NET","","","","","","","","Siegel R. L., Et al., Colorectal cancer statistics, 2017, CA. Cancer J. Clin, 67, 3, pp. 177-193, (2017); Colon cancer: Symptoms, treatment, and causes; Rathore S., Hussain M., Ali A., Khan A., A recent survey on colon cancer detection techniques, IEEE/ACM Transactions on Computational Biology and Bioinformatics, 10, 3, pp. 545-563, (2013); Deeba F., Bui F. M., Wahid K. A., Computer-aided polyp detection based on image enhancement and saliency-based selection, Biomed. Signal Process. Control, 55, (2020); Bernal J., Sanchez J., Vilarino F., Towards automatic polyp detection with a polyp appearance model, Pattern Recognition, 45, 9, pp. 3166-3182, (2012); Sornapudi S., Meng F., Yi S., Region-based automated localization of colonoscopy and wireless capsule endoscopy polyps, Appl. Sci, 9, 12, (2019); Tashk A., Herp J., Nadimi E., Muller M.-K., Automatic Segmentation of Colorectal Polyps based on a Novel and Innovative Convolutional Neural Network Approach; Kang J., Gwak J., Ensemble of Instance Segmentation Models for Polyp Segmentation in Colonoscopy Images, IEEE Access, 7, pp. 26440-26447, (2019); Nguyen N. Q., Lee S. W., Robust Boundary Segmentation in Medical Images Using a Consecutive Deep Encoder-Decoder Network, IEEE Access, 7, pp. 33795-33808, (2019); IEEE Xplore Full-Text PDF; Thu Hong L. T., Chi Thanh N., Long T. Q., Polyp Segmentation in Colonoscopy Images Using Ensembles of U-Nets with EfficientNet and Asymmetric Similarity Loss Function, Proceedings-2020 RIVF International Conference on Computing and Communication Technologies, RIVF 2020, pp. 1-6, (2020); Qadir H. A., Shin Y., Solhusvik J., Bergsland J., Aabakken L., Balasingham I., Toward real-time polyp detection using fully CNNs for 2D Gaussian shapes prediction, Med. Image Anal, 68, (2021); Simonyan K., Zisserman A., VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION, (2015); Wu Y., He K., Group Normalization, Int. J. Comput. Vis, 128, 3, pp. 742-755, (2020); Bjorck J., Gomes C., Selman B., Weinberger K. Q., Understanding Batch Normalization; Maas A. L., Hannun A. Y., Ng A. Y., Rectifier Nonlinearities Improve Neural Network Acoustic Models, (2013); Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 9351, pp. 234-241, (2015); Badrinarayanan V., Kendall A., Cipolla R., SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation, IEEE Trans. Pattern Anal. Mach. Intell, 39, 12, pp. 2481-2495, (2017); Abadi M., Et al., TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems","D. Bhattacharyya; Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation, Vaddeswaram, Green Field, Guntur 522502, India; email: debnathb@kluniversity.in","","Badebio Biotechnololgy Ltd","","","","","","21489637","","","","English","Nat. Vol. Essent. Oil","Article","Final","","Scopus","2-s2.0-85119325222"
"Hoar D.; Lee P.Q.; Guida A.; Patterson S.; Bowen C.V.; Merrimen J.; Wang C.; Rendon R.; Beyea S.D.; Clarke S.E.","Hoar, David (57247745000); Lee, Peter Q. (57208753589); Guida, Alessandro (57201347780); Patterson, Steven (57543543500); Bowen, Chris V. (7103158567); Merrimen, Jennifer (13610935600); Wang, Cheng (57208751752); Rendon, Ricardo (6602247041); Beyea, Steven D. (7005347832); Clarke, Sharon E. (7402969177)","57247745000; 57208753589; 57201347780; 57543543500; 7103158567; 13610935600; 57208751752; 6602247041; 7005347832; 7402969177","Combined Transfer Learning and Test-Time Augmentation Improves Convolutional Neural Network-Based Semantic Segmentation of Prostate Cancer from Multi-Parametric MR Images","2021","Computer Methods and Programs in Biomedicine","210","","106375","","","","24","10.1016/j.cmpb.2021.106375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114302101&doi=10.1016%2fj.cmpb.2021.106375&partnerID=40&md5=0181490d89442e17b0ad0bd9e1eddfa8","Department of Electrical and Computer Engineering, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Biomedical Translational Imaging Centre, Nova Scotia Health Authority and IWK Health Centre, Halifax, NS, Canada; Department of Diagnostic Radiology, Dalhousie University, Halifax, NS, Canada; Department of Pathology, Dalhousie University, Halifax, NS, Canada; Department of Urology, Dalhousie University, Halifax, NS, Canada","Hoar D., Department of Electrical and Computer Engineering, Dalhousie University, Halifax, NS, Canada; Lee P.Q., Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Guida A., Biomedical Translational Imaging Centre, Nova Scotia Health Authority and IWK Health Centre, Halifax, NS, Canada; Patterson S., Biomedical Translational Imaging Centre, Nova Scotia Health Authority and IWK Health Centre, Halifax, NS, Canada; Bowen C.V., Biomedical Translational Imaging Centre, Nova Scotia Health Authority and IWK Health Centre, Halifax, NS, Canada, Department of Diagnostic Radiology, Dalhousie University, Halifax, NS, Canada; Merrimen J., Department of Pathology, Dalhousie University, Halifax, NS, Canada; Wang C., Department of Pathology, Dalhousie University, Halifax, NS, Canada; Rendon R., Department of Urology, Dalhousie University, Halifax, NS, Canada; Beyea S.D., Biomedical Translational Imaging Centre, Nova Scotia Health Authority and IWK Health Centre, Halifax, NS, Canada, Department of Diagnostic Radiology, Dalhousie University, Halifax, NS, Canada; Clarke S.E., Biomedical Translational Imaging Centre, Nova Scotia Health Authority and IWK Health Centre, Halifax, NS, Canada, Department of Diagnostic Radiology, Dalhousie University, Halifax, NS, Canada","Purpose: Multiparametric MRI (mp-MRI) is a widely used tool for diagnosing and staging prostate cancer. The purpose of this study was to evaluate whether transfer learning, unsupervised pre-training and test-time augmentation significantly improved the performance of a convolutional neural network (CNN) for pixel-by-pixel prediction of cancer vs. non-cancer using mp-MRI datasets. Methods: 154 subjects undergoing mp-MRI were prospectively recruited, 16 of whom subsequently underwent radical prostatectomy. Logistic regression, random forest and CNN models were trained on mp-MRI data using histopathology as the gold standard. Transfer learning, unsupervised pre-training and test-time augmentation were used to boost CNN performance. Models were evaluated using Dice score and area under the receiver operating curve (AUROC) with leave-one-subject-out cross validation. Permutation feature importance testing was performed to evaluate the relative value of each MR contrast to CNN model performance. Statistical significance (p<0.05) was determined using the paired Wilcoxon signed rank test with Benjamini-Hochberg correction for multiple comparisons. Results: Baseline CNN outperformed logistic regression and random forest models. Transfer learning and unsupervised pre-training did not significantly improve CNN performance over baseline; however, test-time augmentation resulted in significantly higher Dice scores over both baseline CNN and CNN plus either of transfer learning or unsupervised pre-training. The best performing model was CNN with transfer learning and test-time augmentation (Dice score of 0.59 and AUROC of 0.93). The most important contrast was apparent diffusion coefficient (ADC), followed by Ktrans and T2, although each contributed significantly to classifier performance. Conclusions: The addition of transfer learning and test-time augmentation resulted in significant improvement in CNN segmentation performance in a small set of prostate cancer mp-MRI data. Results suggest that these techniques may be more broadly useful for the optimization of deep learning algorithms applied to the problem of semantic segmentation in biomedical image datasets. However, further work is needed to improve the generalizability of the specific model presented herein. © 2021 Elsevier B.V.","Computer aided diagnosis; Convolutional neural network; Machine learning; MRI; Prostate cancer; Segmentation","Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Prostatic Neoplasms; Semantics; Calcium compounds; Computer aided diagnosis; Computer aided instruction; Convolution; Convolutional neural networks; Decision trees; Deep learning; Diseases; Image enhancement; Image segmentation; Learning algorithms; Medical imaging; Pixels; Regression analysis; Semantics; Surface diffusion; Urology; fleet enema; gadobenate dimeglumine; Computer-aided; Convolutional neural network; Learning time; Machine-learning; Performance; Pre-training; Prostate cancers; Segmentation; Test time; Transfer learning; adult; aged; apparent diffusion coefficient; Article; cancer diagnosis; cancer patient; cancer surgery; classifier; comparative study; computer assisted diagnosis; controlled study; convolutional neural network; data analysis software; diagnostic accuracy; diagnostic test accuracy study; diffusion weighted imaging; dynamic contrast-enhanced magnetic resonance imaging; false positive result; gold standard; histopathology; human; human tissue; image segmentation; leave one out cross validation; logistic regression analysis; machine learning; major clinical study; male; multiparametric magnetic resonance imaging; prospective study; prostate cancer; prostatectomy; random forest; receiver operating characteristic; test time augmentation; transfer of learning; unsupervised machine learning; diagnostic imaging; image processing; machine learning; nuclear magnetic resonance imaging; prostate tumor; semantics; Magnetic resonance imaging","","gadobenate dimeglumine, 127000-20-8","GenIQ, GE Healthcare; MATLAB, Mathworks, United States; MR750, GE Healthcare, United States; Python; multihance, Bracco","Bracco; GE Healthcare; GE Healthcare, United States; Mathworks, United States","Atlantic Innovation Fund; Google Cloud; Radiology Research Foundation; GE Healthcare","Funding text 1: Drs. Guida, Bowen, Beyea and Clarke acknowledge research funding and support from GE Healthcare. ; Funding text 2: This work is supported by the Atlantic Innovation Fund, an Investigator Sponsored Research Agreement with GE Healthcare, Brain Canada, the Radiology Research Foundation, Canada Summer Jobs Program and Nova Scotia Cooperative Education Incentive grant. This material is based upon work supported by Google Cloud. The authors would like to acknowledge Liette Connor for recruiting subjects, Manjari Murthy, Jessica Leudi, Nathan Murtha and Allister Mason for consenting participants and David McAllindon for creating the pseudo-wholemount histopathology sections.","Torre L.A., Bray F., Siegel R.L., Ferlay J., Lortet-Tieulent J., Jemal A., Global cancer statistics, 2012, CA: a cancer journal for clinicians, 65, 2, pp. 87-108, (2015); Stokes M.E., Ishak J., Proskorovsky I., Black L.K., Huang Y., Lifetime economic burden of prostate cancer, BMC health services research, 11, 1, (2011); Roehrborn C.G., Black L.K., The economic burden of prostate cancer, BJU international, 108, 6, pp. 806-813, (2011); Molinier L., Castelli C., Bauvin E., Et al., Cost study of the clinical management of prostate cancer in France: results on the basis of population-based data, The European Journal of Health Economics, 12, pp. 363-371, (2010); Freedland S.J., Kane C.J., Amling C.L., Aronson W.J., Terris M.K., Presti J.C., Upgrading and downgrading of prostate needle biopsy specimens: risk factors and clinical implications, Urology, 69 3, pp. 495-499, (2006); Siddiqui M.M., Rais-Bahrami S., Turkbey B., Et al., Comparison of MR/ultrasound fusion-guided biopsy with ultrasound-guided biopsy for the diagnosis of prostate cancer, JAMA, 313, 4, pp. 390-397, (2015); Weinreb J.C., Barentsz J.O., Choyke P.L., Et al., PI-RADS Prostate Imaging - Reporting and Data System: 2015, Version 2, European urology, 69, 1, pp. 16-40, (2016); Rosenkrantz A.B., Ginocchio L.A., Cornfeld D., Et al., Interobserver Reproducibility of the PI-RADS Version 2 Lexicon: A Multicenter Study of Six Experienced Prostate Radiologists, Radiology, 280, 3, pp. 793-804, (2016); Muller B.G., Shih J.H., Sankineni S., Et al., Prostate Cancer: Interobserver Agreement and Accuracy with the Revised Prostate Imaging Reporting and Data System at Multiparametric MR Imaging, Radiology, 277, 3, pp. 741-750, (2015); Hambrock T., Vos P.C., Kaa C.-V.D., Barentsz J.O., Huisman H.J., Prostate cancer: computer-aided diagnosis with multiparametric 3-T MR imaging–effect on observer performance, Radiology, 266, 2, pp. 521-530, (2013); Giannini V., Mazzetti S., Armando E., Et al., Multiparametric magnetic resonance imaging of the prostate with computer-aided detection: experienced observer performance study, European Radiology, 27, pp. 4200-4208, (2017); Iyama Y., Nakaura T., Katahira K., Et al., Development and validation of a logistic regression model to distinguish transition zone cancers from benign prostatic hyperplasia on multi-parametric prostate MRI, European Radiology, 27, pp. 3600-3608, (2017); Peng Y., Jiang Y., Yang C., Et al., Quantitative analysis of multiparametric prostate MR images: differentiation between prostate cancer and normal tissue and correlation with Gleason score–a computer-aided diagnosis development study, Radiology, 267, 3, pp. 787-796, (2013); Litjens G.J.S., Debats O., Barentsz J.O., Karssemeijer N., Huisman H.J., Computer-Aided Detection of Prostate Cancer in MRI, IEEE Transactions on Medical Imaging, 33, pp. 1083-1092, (2014); Sun Y., Reynolds H.M., Wraith D., Et al., Predicting prostate tumour location from multiparametric MRI using Gaussian kernel support vector machines: a preliminary study, Australasian Physical & Engineering Sciences in Medicine, 40, pp. 39-49, (2016); Hua K.-L., Hsu C.-H., Hidayati S.C., Cheng W.-H., Chen Y.-J., Computer-aided classification of lung nodules on computed tomography images via deep learning technique, OncoTargets and therapy, 8, pp. 2015-2022, (2015); Pereira S., Pinto A., Alves V., Silva C.A., Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images, IEEE transactions on medical imaging, 35, 5, pp. 1240-1251, (2016); Lakhani P., Sundaram B., Deep Learning at Chest Radiography: Automated Classification of Pulmonary Tuberculosis by Using Convolutional Neural Networks, Radiology, 284, 2, pp. 574-582, (2017); Yang X., Liu C., Wang Z., Et al., Co-trained convolutional neural networks for automated detection of prostate cancer in multi-parametric MRI, Medical image analysis, 42, pp. 212-227, (2017); Le M.H., Chen J., Wang L., Et al., Automated diagnosis of prostate cancer in multi-parametric MRI based on multimodal convolutional neural networks, Physics in medicine and biology, 62, 16, pp. 6497-6514, (2017); Schelb P., Kohl S., Radtke J.P., Et al., Classification of Cancer at Prostate MRI: Deep Learning versus Clinical PI-RADS Assessment, Radiology, 293, 3, pp. 607-617, (2019); Erickson B.J., Korfiatis P., Akkus Z., Kline T.L., Machine Learning for Medical Imaging, Radiographics, 37, 2, pp. 505-515, (2017); Chen Y., Xing L., Yu L., Bagshaw H.P., Buyyounouski M.K., Han B., Automatic intraprostatic lesion segmentation in multiparametric magnetic resonance images with proposed multiple branch UNet, Medical Physics, 47, pp. 6421-6429, (2020); Arif M., Schoots I.G., Tovar J.C., Et al., Clinically significant prostate cancer detection and segmentation in low-risk patients using a convolutional neural network on multi-parametric MRI, European Radiology, 30, pp. 6582-6592, (2020); Cao R., Bajgiran A.M., Mirak S.A., Et al., Joint Prostate Cancer Detection and Gleason Score Prediction in mp-MRI via FocalNet, IEEE Transactions on Medical Imaging, 38, pp. 2496-2506, (2019); Cao R., Zhong X., Shakeri S., Et al., Prostate Cancer Detection and Segmentation in Multi-parametric MRI via CNN and Conditional Random Field, 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), (2019); Aldoj N., Lukas S., Dewey M., Penzkofer T., Semi-automatic classification of prostate cancer on multi-parametric MR imaging using a multi-channel 3D convolutional neural network, European Radiology, 30, pp. 1243-1253, (2019); Chen Q., Hu S., Long P., Lu F., Shi Y., Li Y., A Transfer Learning Approach for Malignant Prostate Lesion Detection on Multiparametric MRI, Technology in Cancer Research & Treatment, 18, pp. 1-9, (2019); Yuan Y., Qin W., Buyyounouski M., Et al., Prostate cancer classification with multiparametric MRI transfer learning model, Medical Physics, 46, pp. 756-765, (2019); Song Y., Zhang Y.-D., Yan X., Et al., Computer-aided diagnosis of prostate cancer using a deep convolutional neural network from multiparametric MRI, Journal of Magnetic Resonance Imaging, 48, pp. 1570-1577, (2018); Alkadi R., Taher F., El-baz A., Werghi N., A Deep Learning-Based Approach for the Detection and Localization of Prostate Cancer in T2 Magnetic Resonance Images, Journal of Digital Imaging, 32, pp. 793-807, (2018); Sanford T., Harmon S.A., Turkbey E.B., Et al.; Yang X., Liu C., Wang Z., Et al., Co-trained convolutional neural networks for automated detection of prostate cancer in multi-parametric MRI, Medical Image Analysis, 42, pp. 212-227, (2017); Dai Z., Carver E., Liu C., Et al., Segmentation of the Prostatic Gland and the Intraprostatic Lesions on Multiparametic Magnetic Resonance Imaging Using Mask Region-Based Convolutional Neural Networks, Advances in Radiation Oncology, 5, pp. 473-481, (2020); Schelb P., Kohl S., Radtke J.P., Et al., Classification of Cancer at Prostate MRI: Deep Learning versus Clinical PI-RADS Assessment, Radiology, 293, pp. 607-617, (2019); Lee P.Q., Guida A., Patterson S., Et al., Model-free prostate cancer segmentation from dynamic contrast-enhanced MRI with recurrent convolutional networks: A feasibility study, Computerized Medical Imaging and Graphics, 75, pp. 14-23, (2019); Saritas E.U., Cunningham C.W., Lee J.H., Han E.T., Nishimura D.G., DWI of the spinal cord with reduced FOV single-shot EPI, Magnetic resonance in medicine, 60, 2, pp. 468-473, (2008); Fritz-Hansen T., Rostrup E., Larsson H.B., Sondergaard L., Ring P., Henriksen O., Measurement of the arterial concentration of Gd-DTPA using MRI: a step toward quantitative perfusion imaging, Magn Reson Med, 36, pp. 225-231, (1996); Matoso A., Epstein J.I., Defining clinically significant prostate cancer on the basis of pathological findings, Histopathology, 74, 1, pp. 135-145, (2019); Taha A.A., Hanbury A., Metrics for evaluating 3D medical image segmentation: analysis, selection, and tool, BMC Medical Imaging, 15, (2015); Pedregosa F., Varoquaux G., Gramfort A., Et al., Scikit-learn: Machine Learning in Python, Journal of Machine Learning Research, 12, pp. 2825-2830, (2011); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, CoRR, (2014); Russakovsky O., Deng J., Su H., Et al., ImageNet Large Scale Visual Recognition Challenge, International Journal of Computer Vision, 115, pp. 211-252, (2015); Deng J., Dong W., Socher R., Li L.-J., Li K., ImageNet F.-F.L., A Large-Scale Hierarchical Image Database, 2009 IEEE Conference on Computer Vision and Pattern Recognition, pp. 248-255, (2009); Shi W., Caballero J., Theis L., Et al., Is the deconvolution layer the same as a convolutional layer?, CoRR, (2016); Shelhamer E., Long J., Darrell T., Fully Convolutional Networks for Semantic Segmentation, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3431-3440, (2015); Ronneberger O., Fischer P., U-Net B.T., Convolutional Networks for Biomedical Image Segmentation, MICCAI, (2015); He K., Zhang X., Ren S., Sun J., Deep Residual Learning for Image Recognition, 2016 IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Milletari F., Navab N., Ahmadi S.-A., V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation, 2016 Fourth International Conference on 3D Vision (3DV), pp. 565-571, (2016); Kingma D.P., Adam B.J., A Method for Stochastic Optimization, CoRR, (2014); Yosinski J., Clune J., Bengio Y., Lipson H., How transferable are features in deep neural networks?, NIPS, (2014); Erhan D., Bengio Y., Courville A.C., Manzagol P.-A., Vincent P., Bengio S., Why Does Unsupervised Pre-training Help Deep Learning?, Journal of Machine Learning Research, 11, pp. 625-660, (2010); Dieleman S., Fauw J.D., Kavukcuoglu K., Exploiting Cyclic Symmetry in Convolutional Neural Networks, ICML, (2016); Armato S.G., Huisman H., Drukker K., Et al., PROSTATEx Challenges for computerized classification of prostate lesions from multiparametric magnetic resonance images, Journal of Medical Imaging, 5, (2018); Westphalen A.C., McCulloch C.E., Anaokar J.M., Et al., Variability of the Positive Predictive Value of PI-RADS for Prostate MRI across 26 Centers: Experience of the Society of Abdominal Radiology Prostate Cancer Disease-focused Panel, Radiology, 296, pp. 76-84, (2020); Turkbey B., Rosenkrantz A.B., Haider M.A., Et al., Prostate Imaging Reporting and Data System Version 2.1: 2019 Update of Prostate Imaging Reporting and Data System Version 2, European Urology, 76, pp. 340-351, (2019); Barth B.K., De Visschere P.J.L., Cornelius A., Nicolau C., Vargas H.A., Eberli D., Donati O.F., Detection of Clinically Significant Prostate Cancer: Short Dual–Pulse Sequence versus Standard Multiparametric MR Imaging—A Multireader Study, Radiology, (2016); Greer M.D., Shih J.H., Lay N., Et al., Validation of the Dominant Sequence Paradigm and Role of Dynamic Contrast-enhanced Imaging in PI-RADS Version 2, Radiology, 285, pp. 859-869, (2017)","S.E. Clarke; Department of Diagnostic Radiology, Dalhousie University, Halifax, Halifax Infirmary site, Suite 3900, 1796 Summer St, Canada; email: sharon.clarke@dal.ca","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","34500139","English","Comput. Methods Programs Biomed.","Article","Final","","Scopus","2-s2.0-85114302101"
"Shahraki F.F.; Saadatifard L.; Berisha S.; Lotfollahi M.; Mayerich D.; Prasad S.","Shahraki, Farideh Foroozandeh (57033991400); Saadatifard, Leila (57202704612); Berisha, Sebastian (56642641000); Lotfollahi, Mahsa (57195399716); Mayerich, David (7801383946); Prasad, Saurabh (14018500100)","57033991400; 57202704612; 56642641000; 57195399716; 7801383946; 14018500100","Deep learning for hyperspectral image analysis, part II: Applications to remote sensing and biomedicine","2020","Advances in Computer Vision and Pattern Recognition","","","","69","115","46","1","10.1007/978-3-030-38617-7_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085170932&doi=10.1007%2f978-3-030-38617-7_4&partnerID=40&md5=aa38ad3027ef17466d28e97cfee68daf","University of Houston, Houston, TX, United States","Shahraki F.F., University of Houston, Houston, TX, United States; Saadatifard L., University of Houston, Houston, TX, United States; Berisha S., University of Houston, Houston, TX, United States; Lotfollahi M., University of Houston, Houston, TX, United States; Mayerich D., University of Houston, Houston, TX, United States; Prasad S., University of Houston, Houston, TX, United States","Deep neural networks are emerging as a popular choice for hyperspectral image analysis—compared with other machine learning approaches, they are more effective for a variety of applications in hyperspectral imaging. Part I (Chap. 3) introduces the fundamentals of deep learning algorithms and techniques deployed with hyperspectral images. In this chapter (Part II), we focus on application-specific nuances and design choices with respect to deploying such networks for robust analysis of hyperspectral images. We provide quantitative and qualitative results with a variety of deep learning architectures, and compare their performance to baseline state-of-the-art methods for both remote sensing and biomedical image analysis tasks. In addition to surveying recent developments in these areas, our goal in these two chapters is to provide guidance on how to utilize such algorithms for multichannel optical imagery. With that goal, we also provide code and example datasets used in this chapter. © 2020, Springer Nature Switzerland AG.","","","","","","","","","Gowen A., O'Donnell C., Cullen P., Downey G., Frias J., Hyperspectral imaging an emerging process analytical tool for food quality and safety control, Trends Food Sci Technol, 18, 12, pp. 590-598, (2007); Schuler R.L., Kish P.E., Plese C.A., Preliminary observations on the ability of hyperspectral imaging to provide detection and visualization of bloodstain patterns on black fabrics, J Forensic Sci, 57, 6, pp. 1562-1569, (2012); Fischer C., Kakoulli I., Multispectral and hyperspectral imaging technologies in conservation: Current research and potential applications, Stud Conserv, 51, pp. 3-16, (2006); Zhang Y., Chen Y., Yu Y., Xue X., Tuchin V.V., Zhu D., Visible and near-infrared spectroscopy for distinguishing malignant tumor tissue from benign tumor and normal breast tissues in vitro, J Biomed Opt, 18, 7, (2013); Salzer R., Steiner G., Mantsch H., Mansfield J., Lewis E., Infrared and raman imaging of biological and biomimetic samples, Fresenius’ J Anal Chem, 366, 6-7, pp. 712-726, (2000); Liu K., Li X., Shi X., Wang S., Monitoring mangrove forest changes using remote sensing and gis data with decision-tree learning, Wetlands, 28, 2, (2008); Everitt J., Yang C., Sriharan S., Judd F., Using high resolution satellite imagery to map black mangrove on the texas gulf coast, J Coast Res, pp. 1582-1586, (2008); Yuen P.W., Richardson M., An introduction to hyperspectral imaging and its application for security, surveillance and target acquisition, Imaging Sci J, 58, 5, pp. 241-253, (2010); Shahraki F.F., Prasad S., Graph convolutional neural networks for hyperspectral data classification, 2018 IEEE Global Conference on Signal and Information Processing, pp. 968-972, (2018); Melgani F., Bruzzone L., Classification of hyperspectral remote sensing images with support vector machines, IEEE Trans Geosci Remote Sens, 42, 8, pp. 1778-1790, (2004); Wu H., Prasad S., Dirichlet process based active learning and discovery of unknown classes for hyperspectral image classification, IEEE Trans Geosci Remote Sens, 54, 8, pp. 4882-4895, (2016); Dong Y., Du B., Zhang L., Target Detection Based on Random Forest Metric Learning. IEEE J Sel Top Appl Earth Obs Remote Sens 8:1830–1838 April, (2015); Zhang L., Zhang L., Tao D., Huang X., Du B., Hyperspectral remote sensing image subpixel target detection based on supervised metric learning, IEEE Trans Geosci Remote Sens, 52, pp. 4955-4965, (2014); Zhou X., Armitage A.R., Prasad S., Mapping mangrove communities in coastal wetlands using airborne hyperspectral data. In: 2016 8th workshop on hyperspectral image and signal processing: Evolution in remote sensing (WHISPERS), IEEE, pp. 1-5, (2016); Cui M., Prasad S., Spectral-angle-based discriminant analysis of hyperspectral data for robustness to varying illumination, IEEE J Sel Top Appl Earth Obs Remote Sens, 9, 9, pp. 4203-4214, (2016); Xia J., Bombrun L., Berthoumieu Y., Germain C., Du P., Spectral-spatial rotation forest for hyperspectral image classification, IEEE J Sel Top Appl Earth Obs Remote Sens, 10, 10, pp. 4605-4613, (2017); Tarabalka Y., Fauvel M., Chanussot J., Benediktsson J.A., Svm-and mrf-based method for accurate classification of hyperspectral images, IEEE Geosci Remote Sens Lett, 7, pp. 736-740, (2010); Fauvel M., Benediktsson J.A., Chanussot J., Sveinsson J.R., Spectral and spatial classification of hyperspectral data using svms and morphological profiles, IEEE Trans Geosci Remote Sens, 46, pp. 3804-3814, (2008); Joelsson S.R., Benediktsson J.A., Sveinsson J.R., Random forest classifiers for hyperspectral data, Proceedings, 2005 IEEE International Geoscience and Remote Sensing Symposium 2005, IGARSS ’05, 1, (2005); Zhang Y., Cao G., Li X., Wang B., Cascaded Random Forest for Hyperspectral Image Classification. IEEE J Sel Top Appl Earth Obs Remote Sens 11:1082–1094 April, (2018); Samaniego L., Bardossy A., Schulz K., Supervised classification of remotely sensed imagery using a modified k-nn technique, IEEE Trans Geosci Remote Sens, 46, 7, pp. 2112-2125, (2008); Chan J.-W., Paelinckx D., Evaluation of random forest and adaboost tree-based ensemble classification and spectral band selection for ecotope mapping using airborne hyperspectral imagery, Remote Sens Environ, 112, 6, pp. 2999-3011, (2008); Li J., Bioucas-Dias J.M., Plaza A., Semisupervised hyperspectral image segmentation using multinomial logistic regression with active learning, IEEE Trans Geosci Remote Sens, 48, 11, pp. 4085-4098, (2010); Chen Y., Lin Z., Zhao X., Wang G., Gu Y., Deep learning-based classification of hyperspectral data, IEEE J Sel Top Appl Earth Obs Remote Sens, 7, 6, pp. 2094-2107, (2014); Hu W., Huang Y., Wei L., Zhang F., Li H., Deep convolutional neural networks for hyperspectral image classification, J Sens, 2015, (2015); Makantasis K., Karantzalos K., Doulamis A., Doulamis N., Deep supervised learning for hyperspectral data classification through convolutional neural networks, Geoscience and Remote Sensing Symposium (IGARSS), 2015 IEEE International. IEEE, pp. 4959-4962, (2015); Fang B., Li Y., Zhang H., Chan J.-W., Hyperspectral images classification based on dense convolutional networks with spectral-wise attention mechanism, Remote Sens, 11, 2, (2019); Yu F., Koltun V., Multi-Scale Context Aggregation by Dilated Convolutions. Arxiv:1511.07122, (2015); Mou L., Ghamisi P., Zhu X.X., Deep recurrent neural networks for hyperspectral image classification, IEEE Trans Geosci Remote Sens, 55, 7, pp. 3639-3655, (2017); Hang R., Liu Q., Hong D., Ghamisi P., Cascaded recurrent neural networks for hyperspectral image classification, IEEE Trans Geosci Remote Sens, (2019); Wu H., Prasad S., Convolutional recurrent neural networks forhyperspectral data classification, Remote Sens, 9, 3, (2017); Marini F., Bucci R., Magri A., Magri A., Artificial neural networks in chemometrics: History, examples and perspectives, Microchem J, 88, 2, pp. 178-185, (2008); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Sermanet P., Chintala S., Lecun Y., Convolutional neural networks applied to house numbers digit classification, 2012 21St International Conference on Pattern Recognition (ICPR). IEEE, pp. 3288-3291, (2012); Lecun Y., Bengio Y., Et al., Convolutional networks for images, speech, and time series, Handb Brain Theory Neural Netw, 3361, 10, (1995); Lecun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proc IEEE, 86, 11, pp. 2278-2324, (1998); Chen Y., Jiang H., Li C., Jia X., Ghamisi P., Deep feature extraction and classification of hyperspectral images based on convolutional neural networks, IEEE Trans Geosci Remote Sens, 54, 10, pp. 6232-6251, (2016); Li Y., Zhang H., Shen Q., Spectral-spatial classification of hyperspectral imagery with 3D convolutional neural network, Remote Sens, 9, 1, (2017); 2013 Ieee Grss Data Fusion Contest-Fusion of Hyperspectral and Lidar Data, (2013); 2018 Ieee Grss Data Fusion Challenge-Fusion of Multispectral Lidar and Hyperspectral Data, (2018); Mittal S., Yeh K., Leslie L.S., Kenkel S., Kajdacsy-Balla A., Bhargava R., Simultaneous cancer and tumor microenvironment subtyping using confocal infrared microscopy for all-digital molecular histopathology, Proc Natl Acad Sci, 115, 25, pp. E5651-E5660, (2018); Beck A.H., Sangoi A.R., Leung S., Marinelli R.J., Nielsen T.O., van De Vijver M.J., West R.B., van De Rijn M., Koller D., Systematic analysis of breast cancer morphology uncovers stromal features associated with survival, Sci Transl Med 3(108):108ra113–108ra113, (2011); Ciresan D.C., Giusti A., Gambardella L.M., Schmidhuber J., Mitosis detection in breast cancer histology images with deep neural networks, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Berlin, pp. 411-418, (2013); Araujo T., Aresta G., Castro E., Rouco J., Aguiar P., Eloy C., Polonia A., Campilho A., Classification of breast cancer histology images using convolutional neural networks, Plos One, 12, 6, (2017); Pahlow S., Weber K., Popp J., Bayden R.W., Kochan K., Ruther A., Perez-Guaita D., Heraud P., Stone N., Dudgeon A., Et al., Application of vibrational spectroscopy and imaging to point-of-care medicine: A review, Appl Spectrosc, 72, 101, pp. 52-84, (2018); Gazi E., Dwyer J., Gardner P., Ghanbari-Siahkali A., Wade A., Miyan J., Lockyer N.P., Vick-Erman J.C., Clarke N.W., Shanks J.H., Et al., Applications of fourier transform infrared microspectroscopy in studies of benign prostate and prostate cancer. A pilot study, J Pathol, 201, 1, pp. 99-108, (2003); Fernandez D.C., Bhargava R., Hewitt S.M., Levin I.W., Infrared spectroscopic imaging for histopathologic recognition, Nat Biotechnol, 23, 4, pp. 469-474, (2005); Gazi E., Baker M., Dwyer J., Lockyer N.P., Gardner P., Shanks J.H., Reeve R.S., Hart C.A., Clarke N.W., Brown M.D., A correlation of ftir spectra derived from prostate cancer biopsies with gleason grade and tumour stage, Eur Urol, 50, 4, pp. 750-761, (2006); Bhargava R., Fernandez D.C., Hewitt S.M., Levin I.W., High throughput assessment of cells and tissues: Bayesian classification of spectral metrics from infrared vibrational spectroscopic imaging data, Biochimica Et Biophysica Acta (Bba)-Biomembranes, 1758, 7, pp. 830-845, (2006); Srinivasan G., Bhargava R., Fourier transform-infrared spectroscopic imaging: The emerging evolution from a microscopy tool to a cancer imaging modality, Spectroscopy (Santa Monica), 22, 7, pp. 30-43, (2007); Bird B., Bedrossian K., Laver N., Miljkovic M., Romeo M.J., Diem M., Detection of breast micro-metastases in axillary lymph nodes by infrared micro-spectral imaging, Analyst, 134, 6, pp. 1067-1076, (2009); Baker M.J., Gazi E., Brown M.D., Shanks J.H., Clarke N.W., Gardner P., (2009); Sablinskas V., Urboniene V., Ceponkus J., Laurinavicius A., Dasevicius D., Jankevicius F., Hen-Drixson V., Koch E., Steiner G., Infrared spectroscopic imaging of renal tumor tissue, J Biomed Opt, 16, 9, (2011); Walsh M.J., Holton S.E., Kajdacsy-Balla A., Bhargava R., Attenuated total reflectance fourier-transform infrared spectroscopic imaging for breast histopathology, Vib Spectrosc, 60, pp. 23-28, (2012); Bergner N., Romeike B.F., Reichart R., Kalff R., Krafft C., Popp J., Tumor margin identification and prediction of the primary tumor from brain metastases using ftir imaging and support vector machines, Analyst, 138, 14, pp. 3983-3990, (2013); Kallenbach-Thieltges A., Grosseruschkamp F., Mosig A., Diem M., Tannapfel A., Gerwert K., Immunohistochemistry, histopathology and infrared spectral histopathology of colon cancer tissue sections, J Biophotonics, 6, 1, pp. 88-100, (2013); Mayerich D.M., Walsh M., Kadjacsy-Balla A., Mittal S., Bhargava R., Breast histopathology using random decision forests-based classification of infrared spectroscopic imaging data, Proceedings of Spie-The International Society for Optical Engineering, 9041, (2014); Nallala J., Diebold M.-D., Gobinet C., Bouche O., Sockalingum G.D., Piot O., Manfait M., Infrared spectral histopathology for cancer diagnosis: A novel approach for automated pattern recognition of colon adenocarcinoma, Analyst, 139, 16, pp. 4005-4015, (2014); Ahmadzai A.A., Patel I.I., Veronesi G., Martin-Hirsch P.L., Llabjani V., Cotte M., Stringfellow H.F., Martin F.L., Determination using synchrotron radiation-based fourier transform infrared microspectroscopy of putative stem cells in human adenocarcinoma of the intestine: Corresponding benign tissue as a template, Appl Spectrosc, 68, 8, pp. 812-822, (2014); Mu X., Kon M., Ergin A., Remiszewski S., Akalin A., Thompson C.M., Diem M., Statistical analysis of a lung cancer spectral histopathology (SHP) data set, Analyst, 140, 7, pp. 2449-2464, (2015); Grosserueschkamp F., Kallenbach-Thieltges A., Behrens T., Bruning T., Altmayer M., Stamatis G., Theegarten D., Gerwert K., Marker-free automated histopathological annotation of lung tumour subtypes by FTIR imaging, Analyst, 140, 7, pp. 2114-2120, (2015); Kuepper C., Grosserueschkamp F., Kallenbach-Thieltges A., Mosig A., Tannapfel A., Gerwert K., Label-free classification of colon cancer grading using infrared spectral histopathology, Faraday Discuss, 187, pp. 105-118, (2016); Berisha S., Lotfollahi M., Jahanipour J., Gurcan I., Walsh M., Bhargava R., van Nguyen H., Mayerich D., Deep learning for FTIR histology: Leveraging spatial and spectral features with convolutional neural networks, Analyst, 144, 5, pp. 1642-1653, (2019); Mayerich D., Walsh M.J., Kadjacsy-Balla A., Ray P.S., Hewitt S.M., Bhargava R., Stain-less staining for computed histopathology, Technology, 3, 1, pp. 27-31, (2015); Lotfollahi M., Berisha S., Daeinejad D., Mayerich D., Digital staining of high-definition fourier transform infrared (FT-IR) images using deep learning, Appl Spectrosc, (2019); Scalable Tissue Imaging and Modeling Laboratory; Baker M.J., Trevisan J., Bassan P., Bhargava R., Butler H.J., Dorling K.M., Fielden P.R., Fogarty S.W., Fullwood N.J., Heys K.A., Et al., Using fourier transform IR spectroscopy to analyze biological materials, Nat Protoc, 9, 8, pp. 1771-1791, (2014); Berisha S., Chang S., Saki S., Daeinejad D., He Z., Mankar R., Mayerich D., Siproc: An open-source biomedical data processing platform for large hyperspectral images, Analyst, 142, 8, pp. 1350-1357, (2017); Bassan P., Sachdeva A., Kohler A., Hughes C., Henderson A., Boyle J., Shanks J.H., Brown M., Clarke N.W., Gardner P., FTIR microscopy of biological cells and tissue: Data analysis using resonant Mie scattering (RMieS) EMSC algorithm, Analyst, 137, 6, pp. 1370-1377, (2012); Derrick M.R., Stulik D., Landry J.M., Infrared Spectroscopy in Conservation Science, (2000); Trevisan J., Angelov P.P., Carmichael P.L., Scott A.D., Martin F.L., Extracting biological information with computational analysis of fourier-transform infrared (FTIR) biospectroscopy datasets: Current practices to future perspectives, Analyst, 137, 14, pp. 3202-3215, (2012); Lunga D., Prasad S., Crawford M.M., Ersoy O., Manifold-learning-based feature extraction for classification of hyperspectral data: A review of advances in manifold learning, IEEE Signal Process Mag, 31, 1, pp. 55-66, (2013); Yu X., Wu X., Luo C., Ren P., Deep learning in remote sensing scene classification: A data augmentation enhanced convolutional neural network framework, Giscience Remote Sens, 54, 5, pp. 741-758, (2017); Wu H., Prasad S., Semi-Supervised Deep Learning Using Pseudo Labels for Hyperspectral Image Classification, (2018); Zhou X., Prasad S., Domain adaptation for robust classification of disparate hyperspectral images, IEEE Trans Comput Imaging, 3, pp. 822-836, (2017); Acquarelli J., van Laarhoven T., Gerretzen J., Tran T.N., Buydens L.M., Marchiori E., Convolutional neural networks for vibrational spectroscopic data analysis, Anal Chim Acta, 954, pp. 22-31, (2017); Morchhale S., Pauca V.P., Plemmons R.J., Torgersen T.C., Classification of pixel-level fused hyperspectral and lidar data using deep convolutional neural networks, 2016 8Th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS), pp. 1-5, (2016); Li H., Ghamisi P., Soergel U., Zhu X., Hyperspectral and lidar fusion using deep three-stream convolutional neural networks, Remote Sens, 10, 10, (2018); Pohl C., van Genderen J.L., Review article multisensor image fusion in remote sensing: Concepts, methods and applications, Int J Remote Sens, 19, 5, pp. 823-854, (1998); Wan Z., Yang R., You Y., Cao Z., Fang X., Scene classification of multisource remote sensing data with two-stream densely connected convolutional neural network. In: Image and signal processing for remote sensing XXIV, International Society for Optics and Photonics, 10789, (2018); Xu X., Li W., Ran Q., Du Q., Gao L., Zhang B., Multisource remote sensing data classification based on convolutional neural network, IEEE Trans Geosci Remote Sens, 56, 2, pp. 937-949, (2018); Huang G., Liu Z., van Der Maaten L., Weinberger K.Q., Densely connected convolutional networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4700-4708, (2017); Zhu J., Fang L., Ghamisi P., Deformable convolutional neural networks for hyperspectral image classification, IEEE Geosci Remote Sens Lett, 15, 8, pp. 1254-1258, (2018); Dai J., Qi H., Xiong Y., Li Y., Zhang G., Hu H., Wei Y., Deformable convolutional networks, Proceedings of the IEEE International Conference on Computer Vision, pp. 764-773, (2014); Labate D., Safari K., Karantzas N., Prasad S., Foroozandeh Shahraki F., Structured Receptive Field Networks and Applications to Hyperspectral Image Classification, (2019); Labate D., Lim W.Q., Kutyniok G., Weiss G., Sparse multidimensional representation using shearlets. In: Wavelets XI, vol 5914. International Society for Optics and Photonics, P 59140U, (2005); Cho K., van Merrienboer B., Gulcehre C., Bahdanau D., Bougares F., Schwenk H., Bengio Y., Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation. Arxiv, 1406, (2014); Chollet F., Et al., Keras, (2015); Glorot X., Bengio Y., Understanding the difficulty of training deep feedforward neural networks, Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pp. 249-256, (2010); Chung J., Gulcehre C., Cho K., Bengio Y., Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. Arxiv:1412.3555, (2014); Ly E., Piot O., Wolthuis R., Durlach A., Bernard P., Manfait M., Combination of FTIR spectral imaging and chemometrics for tumour detection from paraffin-embedded biopsies, Analyst, 133, 2, pp. 197-205, (2008); Yu P., Applications of hierarchical cluster analysis (CLA) and principal component analysis (PCA) in feed structure and feed molecular chemistry research, using synchrotron-based fourier transform infrared (ftir) microspectroscopy, J Agric Food Chem, 53, 18, pp. 7115-7127, (2005); Tiwari S., Bhargava R., Extracting knowledge from chemical imaging data using computational algorithms for digital cancer diagnosis, Yale J Biol Med, 88, 2, pp. 131-143, (2015); Yang H., Irudayaraj J., Paradkar M.M., Discriminant analysis of edible oils and fats by FTIR, FT-NIR and FT-raman spectroscopy, Food Chem, 93, 1, pp. 25-32, (2005); Fabian H., Thi N.A.N., Eiden M., Lasch P., Schmitt J., Naumann D., Diagnosing benign and malignant lesions in breast tissue sections by using IR-microspectroscopy, Biochimica Et Biophysica Acta (Bba)-Biomembranes, 1758, 7, pp. 874-882, (2006); Solomon R.W., Free and open source software for the manipulation of digital images, Am J Roentgenol, 192, 6, pp. W330-W334, (2009); Wang Z., Bovik A.C., Sheikh H.R., Simoncelli E.P., Image quality assessment: From error visibility to structural similarity, IEEE Trans Image Process, 13, 4, pp. 600-612, (2004); Bhargava R., Towards a practical Fourier transform infrared chemical imaging protocol for cancer histopathology, Anal Bioanal Chem, 389, pp. 1155-1169, (2007); Github Link of the Book Chapter; Dong C., Loy C.C., He K., Tang X., Image super-resolution using deep convolutional networks, IEEE Trans Pattern Anal Mach Intell, 38, 2, pp. 295-307, (2016); Mobiny A., Moulik S., Nguyen H., Lung Cancer Screening Using Adaptive Memory-Augmented Recurrent Networks. Arxiv:1710.05719, (2017); Mobiny A., Lu H., Nguyen H.V., Roysam B., Varadarajan N., Automated classification of apoptosis in phase contrast microscopy using capsule network, IEEE Trans Med Imaging, (2019); Berisha S., Nagy J.G., Iterative methods for image restoration. In: Academic press library in signal processing, vol 4. Elsevier, Pp 193–247, (2014); Mobiny A., van Nguyen H., Fast capsnet for lung cancer screening, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Berlin, pp. 741-749, (2018); Hinton G.E., Srivastava N., Krizhevsky A., Sutskever I., Salakhutdinov R.R., Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors. Arxiv:1207.0580, (2012); Lecun Y., Bengio Y., Hinton G., Deep learning, Nature 521:436–444 May, (2015); Scherer D., Muller A., Behnke S., Evaluation of pooling operations in convolutional architectures for object recognition, International Conference on Artificial Neural Networks. Springer, Berlin, pp. 92-101, (2010); Goodfellow I., Bengio Y., Courville A., Deep Learning, (2016); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization. Arxiv, 1412, (2014); Duchi J., Hazan E., Singer Y., Adaptive subgradient methods for online learning and stochastic optimization, J Mach Learn Res, 12, pp. 2121-2159, (2011); Zeiler M.D., Adadelta: An Adaptive Learning Rate Method. Arxiv:1212.5701, (2012); Lipton Z.C., Berkowitz J., Elkan C., A Critical Review of Recurrent Neural Networks for Sequence Learning. Arxiv:1506.00019, (2015); Jin X., Xu C., Feng J., Wei Y., Xiong J., Yan S., Deep learning with s-shaped rectified linear activation units, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Zheng H., Yang Z., Liu W., Liang J., Li Y., Improving deep neural networks using softplus units, 2015 International Joint Conference on Neural Networks (IJCNN). IEEE, pp. 1-4, (2015); Ioffe S., Szegedy C., Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, (2015); Liu J., Ye J., Efficient L1/Lq Norm Regularization. Arxiv, 1009, (2010); Xu Z., Zhang H., Wang Y., Chang X., Liang Y., L 1/2 regularization, Sci China Inf Sci, 53, 6, pp. 1159-1169, (2010)","S. Prasad; University of Houston, Houston, United States; email: saurabh.prasad@ieee.org","","Springer","","","","","","21916586","","","","English","Adv. Comput. Vis. Pattern Recognit.","Book chapter","Final","","Scopus","2-s2.0-85085170932"
"Liang Q.; Nan Y.; Coppola G.; Zou K.; Sun W.; Zhang D.; Wang Y.; Yu G.","Liang, Qiaokang (35174463400); Nan, Yang (57217028826); Coppola, Gianmarc (36134250400); Zou, Kunglin (58447764100); Sun, Wei (57161531200); Zhang, Dan (58846287300); Wang, Yaonan (55998880600); Yu, Guanzhen (7403528362)","35174463400; 57217028826; 36134250400; 58447764100; 57161531200; 58846287300; 55998880600; 7403528362","Weakly supervised biomedical image segmentation by reiterative learning","2019","IEEE Journal of Biomedical and Health Informatics","23","3","8394987","1205","1214","9","37","10.1109/JBHI.2018.2850040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049063548&doi=10.1109%2fJBHI.2018.2850040&partnerID=40&md5=5cbed3aeee7beb49a64dd13b416c09bd","College of Electrical and Information Engineering, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, National Engineering Laboratory for Robot Vision Perception and Control, Hunan University, Changsha, 410082, China; Faculty of Engineering and Applied Science, University of Ontario Institute of Technology, Oshawa, L1H7K4, ON, Canada; Department of Mechanical Engineering, York University, Toronto, M3J1P3, ON, Canada; Department of Oncology, Longhua Hospital Affiliated, Shanghai University of Traditional Chinese Medicine, Shanghai, 201203, China","Liang Q., College of Electrical and Information Engineering, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, National Engineering Laboratory for Robot Vision Perception and Control, Hunan University, Changsha, 410082, China; Nan Y., College of Electrical and Information Engineering, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, National Engineering Laboratory for Robot Vision Perception and Control, Hunan University, Changsha, 410082, China; Coppola G., Faculty of Engineering and Applied Science, University of Ontario Institute of Technology, Oshawa, L1H7K4, ON, Canada; Zou K., College of Electrical and Information Engineering, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, National Engineering Laboratory for Robot Vision Perception and Control, Hunan University, Changsha, 410082, China; Sun W., College of Electrical and Information Engineering, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, National Engineering Laboratory for Robot Vision Perception and Control, Hunan University, Changsha, 410082, China; Zhang D., Department of Mechanical Engineering, York University, Toronto, M3J1P3, ON, Canada; Wang Y., College of Electrical and Information Engineering, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, National Engineering Laboratory for Robot Vision Perception and Control, Hunan University, Changsha, 410082, China; Yu G., Department of Oncology, Longhua Hospital Affiliated, Shanghai University of Traditional Chinese Medicine, Shanghai, 201203, China","Recent advances in deep learning have produced encouraging results for biomedical image segmentation; however, outcomes rely heavily on comprehensive annotation. In this paper, we propose a neural network architecture and a new algorithm, known as overlapped region forecast, for the automatic segmentation of gastric cancer images. To the best of our knowledge, this report for the first time describes that deep learning has been applied to the segmentation of gastric cancer images. Moreover, a reiterative learning framework that achieves superior performance without pretraining or further manual annotation is presented to train a simple network on weakly annotated biomedical images. We customize the loss function to make the model converge faster while avoiding becoming trapped in local minima. Patch boundary errors were eliminated by our overlapped region forecast algorithm. By studying the characteristics of the model trained using two different patch extraction methods, we train iteratively and integrate predictions and weak annotations to improve the quality of the training data. Using these methods, a mean Intersection over Union coefficient of 0.883 and a mean accuracy of 91.09% were achieved on the partially labeled dataset, thereby securing a win in the 2017 China Big Data and Artificial Intelligence Innovation and Entrepreneurship Competition. © 2018 IEEE.","biomedical image segmentation; deep neural networks; gastric histopathology; Reiterative learning","Algorithms; Histological Techniques; Humans; Image Interpretation, Computer-Assisted; Neural Networks, Computer; Stomach Neoplasms; Supervised Machine Learning; Deep learning; Deep neural networks; Diseases; Forecasting; Iterative methods; Large dataset; Network architecture; Neural networks; Automatic segmentations; Biomedical image segmentation; Biomedical images; Forecast algorithm; gastric histopathology; Learning frameworks; Manual annotation; Reiterative learning; accuracy; Article; histopathology; image preprocessing; image processing; image quality; image segmentation; imaging; inflammation; learning; machine learning; mathematical parameters; necrosis; nerve cell network; recall; reiterative learning; stomach cancer; stomach tumor; training; tumor growth; algorithm; computer assisted diagnosis; diagnostic imaging; histology; human; procedures; supervised machine learning; Image segmentation","","","","","Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing; National Natural Science Foundation of China, NSFC, (61673163); National Natural Science Foundation of China, NSFC; Hunan Provincial Science and Technology Department, HSTD, (2016JJ3045); Hunan Provincial Science and Technology Department, HSTD; Natural Science Foundation of Hunan Province; Changzhou Key Laboratory of Special Robot and Intelligent Technology, (IRT2018003); Changzhou Key Laboratory of Special Robot and Intelligent Technology","Funding text 1: This work was supported in part by the National Natural Science Foundation of China under Grant 61673163, in part by the Hunan Provincial Natural Science Foundation of China under Grant 2016JJ3045, and in part by the Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing (IRT2018003).; Funding text 2: Manuscript received January 16, 2018; revised May 2, 2018; accepted June 19, 2018. Date of publication June 25, 2018; date of current version May 6, 2019. This work was supported in part by the National Natural Science Foundation of China under Grant 61673163, in part by the Hunan Provincial Natural Science Foundation of China under Grant 2016JJ3045, and in part by the Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing (IRT2018003). (Corresponding authors: Qiaokang Liang; Yang Nan; Guanzhen Yu.) Q. Liang, Y. Nan, K. Zou, W. Sun, and Y. Wang are with the College of Electrical and Information Engineering, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, and the National Engineering Laboratory for Robot Vision Perception and Control, Hunan University, Changsha 410082, China (e-mail:, qiaokang@hnu.edu.cn; nanyang@hnu.edu.cn; kunlin@hnu.edu.cn; wei_sun@hnu.edu.cn; yaonan@hnu.edu.cn).","Ronneberger O., Fischer P., Brox T., U-net: Convolutional networks for biomedical image segmentation, Proc. Int. Conf. Med. Image Comput. Comput.-Assisted Intervention, pp. 234-241, (2015); Chen H., Qi X., Yu L., Heng P.-A., Dcan: Deep contour-aware networks for accurate gland segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 2487-2496, (2016); Chen H., Qi X., Cheng J.-Z., Heng P.-A., Deep contextual networks for neuronal structure segmentation, Proc. 13th AAAI Conf. Artif. Intell., pp. 1167-1173, (2016); Esteva A., Et al., Dermatologist-level classification of skin cancer with deep neural networks, Nature, 542, pp. 115-118, (2017); Papandreou G., Chen L.-C., Murphy K.P., Yuille A.L., Weakly-and semi-supervised learning of a deep convolutional network for semantic image segmentation, Proc. IEEE Int. Conf. Comput. Vis., pp. 1742-1750, (2015); Hong S., Noh H., Han B., Decoupled deep neural network for semisupervised semantic segmentation, Proc. 28th Int. Conf. Neural Inf. Process. Syst., pp. 1495-1503, (2015); Li Z., Tang J., Weakly supervised deep matrix factorization for social image understanding, IEEE Trans. Image Process., 26, 1, pp. 276-288, (2017); Li Z., Tang J., Weakly supervised deep metric learning for community-contributed image retrieval, IEEE Trans. Multimedia, 17, 11, pp. 1989-1999, (2015); Dutt Jain S., Grauman K., Active image segmentation propagation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 2864-2873, (2016); Yang L., Zhang Y., Chen J., Zhang S., Chen D.Z., Suggestive annotation: A deep active learning framework for biomedical image segmentation, Proc. Int. Conf. Med. Image Comput. Comput. Assist. Intervention, pp. 399-407, (2017); Drozdzal M., Vorontsov E., Chartrand G., Kadoury S., Pal C., The importance of skip connections in biomedical image segmentation, Proc. 2nd Workshop Deep Learn. Med. Image Anal., pp. 179-187, (2016); Wang G., Li W., Ourselin S., Vercauteren T., Automatic brain tumor segmentation using cascaded anisotropic convolutional neural networks, Proc. Int. MICCAI Brainlesion Workshops, pp. 178-190, (2017); Yan Z., Zhang H., Jia Y., Breuel T., Yu Y., Combining the Best of Convolutional Layers and Recurrent Layers: A Hybrid Network for Semantic Segmentation, (2016); Visin F., Et al., Reseg: A recurrent neural network-based model for semantic segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops, pp. 41-48, (2016); Badrinarayanan V., Kendall A., Cipolla R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation, IEEE Trans. Pattern Anal. Mach. Intell., 39, 12, pp. 2481-2495, (2017); 3D U-Net: Learning dense volumetric segmentation from sparse annotation, Proc. Int. Conf. Med. Image Comput. Comput. Assist. Intervention, pp. 424-432, (2016); Abdulnabi A.H., Winkler S., Wang G., Beyond Forward Shortcuts: Fully Convolutional Master-slave Networks (Msnets) with Backward Skip Connections for Semantic Segmentation, (2017); Drozdzal S.J.M., Vazquez D., Bengio A.R.Y., The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops, pp. 1175-1183, (2017); Huang G., Liu Z., Weinberger K.Q., Maaten Der L.Van, Densely connected convolutional networks, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 2261-2269, (2017); Chen L.C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs, (2015); Chen L.-C., Papandreou G., Kokkinos I., Murphy K., Yuille A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs, IEEE Trans. Pattern Anal. Mach. Intell., 40, 4, pp. 834-848, (2018); Chen L.-C., Papandreou G., Schroff F., Adam H., Rethinking Atrous Convolution for Semantic Image Segmentation, (2017); Lin T.-Y., Et al., Microsoft coco: Common objects in context, Proc. Eur. Conf. Comput. Vis., pp. 740-755, (2014); Everingham M., Van Gool L., Williams C.K., Winn J., Zisserman A., The pascal visual object classes (voc) challenge, Int. J. Comput. Vis., 88, pp. 303-338, (2010); Paeng K., Hwang S., Park S., Kim M., A unified framework for tumor proliferation score prediction in breast histopathology, Proc. 3rd Workshop Deep Learn. Med. Image Anal., pp. 231-239, (2017); Havaei M., Et al., Brain tumor segmentation with deep neural networks, Med. Image Anal., 35, pp. 18-31, (2017); Han J., Quan R., Zhang D., Nie F., Robust object co-segmentation using background prior, IEEE Trans. Image Process., 27, 4, pp. 1639-1651, (2018); Quellec G., Laniard M., Cazuguel G., Abramoff M.D., Cochener B., Roux C., Weakly supervised classification of medical images, Proc 9th IEEE Int. Symp.. Biomed. Imag., pp. 110-113, (2012); Zhang D., Meng D., Han J., Co-saliency detection via a self-paced multiple-instance learning framework, IEEE Trans. Pattern Anal. Mach. Intell., 39, 5, pp. 865-878, (2017); Zhang D., Yang L., Meng D., Xu D., Han J., Spftn: A selfpaced fine-tuning network for segmenting objects in weakly labelled videos, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 4429-4437, (2017); Han J., Zhang D., Cheng G., Liu N., Xu D., Advanced deeplearning techniques for salient and category-specific object detection: A survey, IEEE Signal Process. Mag., 35, 1, pp. 84-100, (2018); Papandreou G., Chen L.-C., Murphy K., Yuille A.L., Weakly-and Semi-supervised Learning of a DCNN for Semantic Image Segmentation, (2015); Rajan S., Ghosh J., Crawford M.M., An active learning approach to hyperspectral data classification, IEEE Trans. Geosci. Remote Sens., 46, 4, pp. 1231-1242, (2008); Zhou Z., Shin J., Zhang L., Gurudu S., Gotway M., Liang J., Finetuning convolutional neural networks for biomedical image analysis: Actively and incrementally, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 7340-7349, (2017); Wang D., Shang Y., A new active labeling method for deep learning, Proc. Int. Joint Conf. Neural Netw., pp. 112-119, (2014); Xu Y., Zhu J.-Y., Eric I., Chang C., Lai M., Tu Z., Weakly supervised histopathology cancer image segmentation and classification, Med. Image Anal., 18, pp. 591-604, (2014); Coupe P., Manjon J.V., Fonov V., Pruessner J., Robles M., Collins D.L., Patch-based segmentation using expert priors: Application to hippocampus and ventricle segmentation, NeuroImage, 54, pp. 940-954, (2011); Wang D., Khosla A., Gargeya R., Irshad H., Beck A.H., Deep Learning for Identifying Metastatic Breast Cancer, (2016); He K., Zhang X., Ren S., Sun J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification, Proc. IEEE Int. Conf. Comput. Vis., pp. 1026-1034, (2015); Glorot X., Bengio Y., Understanding the difficulty of training deep feedforward neural networks, Proc. 13th Int. Conf. Artif. Intell. Statist., pp. 249-256, (2010); Kingma D.P., Ba J., Adam: A Method for Stochastic Optimization, (2014); Abadi M., Et al., TensorFlow: A system for large-scale machine learning, Proc. 12th USENIX Conf. Oper. Syst. Des. Implementation, pp. 265-283, (2016); Chollet F., Keras, (2015)","Q. Liang; College of Electrical and Information Engineering, Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, National Engineering Laboratory for Robot Vision Perception and Control, Hunan University, Changsha, 410082, China; email: qiaokang@hnu.edu.cn","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21682194","","ITIBF","29994489","English","IEEE J. Biomedical Health Informat.","Article","Final","","Scopus","2-s2.0-85049063548"
"Dawson M.; Zisserman A.; Nellåker C.","Dawson, Mitchell (57196047258); Zisserman, Andrew (7006619672); Nellåker, Christoffer (57209053608)","57196047258; 7006619672; 57209053608","Mining faces from biomedical literature using deep learning","2017","ACM-BCB 2017 - Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics","","","","562","567","5","1","10.1145/3107411.3107476","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031329267&doi=10.1145%2f3107411.3107476&partnerID=40&md5=edb1812a35b91b0d72dc4654076c7c20","Visual Geometry Group, Dept. of Engineering Science, University of Oxford, United Kingdom; Nuffield Dept. of Obstetrics and Gynaecology, University of Oxford, United Kingdom","Dawson M., Visual Geometry Group, Dept. of Engineering Science, University of Oxford, United Kingdom; Zisserman A., Visual Geometry Group, Dept. of Engineering Science, University of Oxford, United Kingdom; Nellåker C., Nuffield Dept. of Obstetrics and Gynaecology, University of Oxford, United Kingdom","Gaining access to large, labelled sets of relevant images is crucial for the development and testing of biomedical imaging algorithms. Using images found in biomedical research articles would contribute some way towards a solution to this problem. However, this approach critically depends on being able to identify the most relevant images from very large sets of potentially useful figures. In this paper a deep convolutional neural network (CNN) classifier is trained using only synthetic data, to rapidly and accurately label raw images taken from biomedical articles. We apply this method in the context of detecting faces in biomedical images; and show that the classifier is able to retrieve figures containing faces with an average precision of 94.8%, from a dataset of over 31,000 images taken from articles held in the PubMed database. The utility of the classifier is then demonstrated through a case study, by aiding the mining of photographs of patients with rare genetic disorders from targeted articles. This approach is readily adaptable to facilitate the retrieval of other categories of biomedical images.","Biomedical data mining; Computer vision; Convolutional neural network; Deep learning; Image classification; Machine learning","Classification (of information); Computer vision; Convolution; Data mining; Deep learning; Deep neural networks; Image classification; Learning systems; Medical imaging; Neural networks; Biomedical data; Biomedical images; Biomedical imaging; Biomedical literature; Biomedical research; Convolutional neural network; Development and testing; Genetic disorders; Bioinformatics","","","","","EPSRC Systems Biology DTC, (EP/G03706X/1); Medical Research Council, MRC, (MR/M014568/1); Engineering and Physical Sciences Research Council, EPSRC, (EP/M013774/1)","This research was financially supported by the EPSRC programme grant Seebibyte EP/M013774/1, the EPSRC Systems Biology DTC EP/G03706X/1, and the MRC Grant MR/M014568/1.","Chatfield K., Simonyan K., Vedaldi A., Zisserman A., Return of the devil in the details: Delving deep into convolutional nets, Proc. BMVC., (2014); Clark C., Divvala S., PDFFigures 2.0: Mining figures from research papers, JCDL, pp. 143-152, (2016); Demner-Fushman D., Antani S., Simpson M., Thoma G., Design and development of a multimodal biomedical information retrieval system, JCSE, 6, 2, pp. 168-177, (2012); Ferry Q., Steinberg J., Webber C., FitzPatrick D.R., Ponting C.P., Zisserman A., Nellaker C., Diagnostically relevant facial gestalt information from ordinary photos, ELIFE, (2014); Fleuren W., Alkema W., Application of text mining in the biomedical domain, Methods, 74, pp. 97-106, (2015); Gonzalez G., Tahsin T., Goodale B., Greene A., Greene C., Recent advances and emerging applications in text and data mining for biomedical discovery, Brief. Bioinform., 17, 1, pp. 33-42, (2016); Gupta A., Vedaldi A., Zisserman A., Synthetic data for text localisation in natural images, Proc. CVPR., (2016); Jaderberg M., Simonyan K., Vedaldi A., Zisserman A., Synthetic data and artificial neural networks for natural scene text recognition, Workshop on Deep Learning, NIPS, (2014); Koike A., Takagi T., Classifying biomedical figures using combination of bag of keypoints and bag of words, CISIS, pp. 848-853, (2009); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, NIPS, pp. 1106-1114, (2012); LeCun Y., Boser B., Denker J.S., Henderson D., Howard R.E., Hubbard W., Jackel L.D., Backpropagation applied to handwritten zip code recognition, Neural Computation, 1, 4, pp. 541-551, (1989); Lehmann T., Guld M., Deselaers T., Keysers D., Schubert H., Spitzer K., Ney H., Wein B., Automatic categorization of medical images for content-based retrieval and data mining, Comput Med Imaging Graph, 29, 2, pp. 143-155, (2005); Rozantsev A., Lepetit V., Fua P., On rendering synthetic images for training an object detector, Comput Vis Image und, 137, pp. 24-37, (2015); Russakovsky O., Deng J., Su H., Krause J., Satheesh S., Ma S., Huang S., Karpathy A., Khosla A., Bernstein M., Berg A.C., Li F.F., ImageNet large scale visual recognition challenge, IJCV, (2015); Sharif Razavian A., Azizpour H., Sullivan J., Carlsson S., CNN features off-the-shelf: An astounding baseline for recognition, CVPRW, pp. 806-813, (2014); Vedaldi A., Lenc K., MatConvNet: Convolutional neural networks for MAT-LAB, Proc. ACMM., (2015); Xu S., McCusker J., Krauthammer M., Yale Image Finder (YIF): A new search engine for retrieving biomedical images, Bioinformatics, 24, 17, pp. 1968-1970, (2008)","","","Association for Computing Machinery, Inc","ACM Special Interest Group in Bioinformatics, Computational Biology, and Biomedical Informatics (SIGBIO)","8th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics, ACM-BCB 2017","20 August 2017 through 23 August 2017","Boston","130145","","978-145034722-8","","","English","ACM-BCB - Proc. ACM Int. Conf. Bioinform., Comput. Biol., Health Informatics","Conference paper","Final","","Scopus","2-s2.0-85031329267"
"Du J.; Fang M.; Yu Y.; Lu G.","Du, Jiao (55416429400); Fang, Meie (56266034300); Yu, Yufeng (57192163579); Lu, Gang (57709221200)","55416429400; 56266034300; 57192163579; 57709221200","An adaptive two-scale biomedical image fusion method with statistical comparisons","2020","Computer Methods and Programs in Biomedicine","196","","105603","","","","19","10.1016/j.cmpb.2020.105603","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086575506&doi=10.1016%2fj.cmpb.2020.105603&partnerID=40&md5=a989b2bcfe7fb7f9f06f6b3d4dee296d","School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, 510006, China; Department of Statistics, Guangzhou University, Guangzhou, 510006, China; Laboratory of Image Science and Technology, Key Laboratory of Computer Network and Information Integration, Southeast University, Ministry of Education, Nanjing, 210096, China","Du J., School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, 510006, China; Fang M., School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, 510006, China; Yu Y., Department of Statistics, Guangzhou University, Guangzhou, 510006, China; Lu G., Laboratory of Image Science and Technology, Key Laboratory of Computer Network and Information Integration, Southeast University, Ministry of Education, Nanjing, 210096, China","Two-scale image representation of base and detail in the spatial-domain is a well-known decomposition scheme for its lower computational complexity than that performed in the transform-domain in the field of image fusion. Unfortunately, for a pseudo-colour input image, the base and detail images in the spatial-domain obtained via image decomposition scheme always display in greyscale. In this paper, a two-scale image fusion method with adaptive threshold obtained by Otsu's method is proposed for pseudo-colour image in the colour space domain. For greyscale image, detail and base image are obtained using structural information extracted from the difference image between a global and a local patch size. Consequently, local edge-preserving filter for preserving luminance information and local energy with the discussed window size are adopted to combine base and detail image. Experimental results show that structural and luminance information has been better preserved in terms of subjective and objective evaluations for medical image and protein image fusion. Specially, a two-step non-parametric statistical test (Friedman test and Nemenyi post-hoc test) with p-values is adopted to analysis the statistical significant of the relative difference between the proposed and compared methods in terms of values of objective metrics including 30 co-registered pairs of imaging data. © 2020","Adaptive two-scale representation; Base and detail; Friedman test; Otsu's method; Statistical significant analysis","Algorithms; Color; Luminance; Medical imaging; Decomposition scheme; Edge-preserving filter; Image fusion methods; Image representations; Non-parametric statistical tests; Statistical comparisons; Structural information; Subjective and objective evaluations; Article; blood flow; comparative study; controlled study; convolutional neural network; decomposition; deep learning; Friedman test; human; image analysis; image processing; image quality; luminance; neuroimaging; nuclear magnetic resonance imaging; positron emission tomography; pulse coupled neural network; signal noise ratio; single photon emission computed tomography; statistical analysis; wavelet transform; algorithm; Image fusion","","","","","National Natural Science Foundation of China, NSFC, (61772164, 61802148); Natural Science Foundation of Guangdong Province, (2019A1515011266)","The authors would like to thank the Editor and anonymous reviewers for their comments and suggestions. This work was supported in part by National Natural Science Foundation of China (No. 61802148 , No. 61772164 ), Natural Science Foundation of Guangdong Province under Grant (No. 2019A1515011266 ).","Goyal A., Arya M.K., Agrawal R., Agrawal D., Hossain G., Challoo R., Automated segmentation of gray and white matter regions in brain MRI images for computer aided diagnosis of neurodegenerative diseases, Proceedings of the International Conference on Multimedia, Signal Processing and Communication Technologies (IMPACT), Aligarh, pp. 204-208, (2017); Verclytte S., Lopes R., Lenfant P., Rollin A., Semah F., Leclerc X., Pasquier F., Delmaire C., Cerebral hypoperfusion and hypometabolism detected by arterial spin labeling mri and FDG-PET in early-onset Alzheimer's disease, J. Neuroimaging, 26, pp. 207-212, (2015); Nguyen M.P., Kim H., Chun S.Y., Fessler J.A., Dewaraja Y.K., Joint spectral image reconstruction for Y-90 SPECT with multi-window acquisition, Proceedings of the IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), San Diego, CA, pp. 1-4, (2015); Xue-Yuan L., Wei-Wei M., Hua Z., Et al., Age- and Brain Region-Specific Changes of Glucose Metabolic Disorder, Learning, and Memory Dysfunction in Early Alzheimer's Disease Assessed in APP/PS1 Transgenic Mice Using 18F-FDG-PET, Int. J. Mol. Sci., 17, 10, (2016); Liu Z., Song Y., Sheng V S., Et al., MRI and PET image fusion using the nonparametric density model and the theory of variable-weight, Comput. Methods Progr. Biomed., 175, pp. 73-82, (2019); Liu Z., Blasch E., Xue Z., Et al., Objective assessment of multiresolution image fusion algorithms for context enhancement in night vision: a comparative study, IEEE Trans. Pattern Anal. Mach. Intell., 34, 1, pp. 94-109, (2012); Daniel E., Anitha J., Gnanaraj J., Optimum laplacian wavelet mask based medical image using hybrid cuckoo search – grey wolf optimization algorithm, Knowl Based Syst, (2017); Xu X., Wang Y., Chen S., Medical image fusion using discrete fractional wavelet transform, Biomed. Signal Process. Control, 27, pp. 103-111, (2016); Celik T., Tjahjadi T., Image resolution enhancement using dual-tree complex wavelet transform, IEEE Geosci Remote Sens. Lett., pp. 1-6, (2010); Bhatnagar G., Wu Q.M.J., Liu Z., Directive Contrast Based Multimodal Medical Image Fusion in NSCT Domain, IEEE Trans. Multimed., 15, pp. 1014-1024, (2013); Singh S., Anand R.S., Ripplet domain fusion approach for CT and MR medical image information, Biomed. Signal Process. Control, 46, pp. 281-292, (2018); Yin M., Liu X.N., Liu Y., Medical image fusion with parameter-adaptive pulse coupled neural network in nonsubsampled shearlet transform Domain, IEEE Trans. Instrum. Meas., 68, pp. 49-64, (2019); Vishwakarma A., K.Bhuyan M., Iwahori Y., An optimized non-subsampled shearlet transform-based image fusion using Hessian features and unsharp masking, J. Vis. Commun. Image Represent, 57, pp. 48-60, (2018); Zhu Y.X., Varshney P.K., Chen H., ICA-based fusion for colour display of hyperspectral images, Int. J. Remote Sens., 32, 9, pp. 2427-2450, (2011); Li S.T., Yin H.T., Fang L.Y., Group-sparse representation with dictionary learning for medical image denoising and fusion, IEEE Trans. Biomed. Eng., 59, pp. 3450-3459, (2012); Dian R.W., Li S.T., Fang L.Y., Hyperspectral and Multispectral Image Fusion Based on a Sparse Representation, Inf. Fusion, 49, pp. 262-270, (2019); Wang Q.Z., Li S., Qin H., Robust Multi-modal Medical Image Fusion via Anisotropic Heat Diffusion guided Low-rank Structural Analysis, Inf. Fusion, 26, pp. 103-121, (2015); Li H., Wu X.J., (2018); Li S., Kang X., Hu J., Image fusion with guided filtering, IEEE Trans. Image Process., 22, pp. 2864-2875, (2013); Gan W., Wu X.H., Wu W., Infrared and visible image fusion with the use of multi-scale edge-preserving decomposition and guided image filter, Infrared Phys. Technol., 72, pp. 37-51, (2015); Liu Y., Chen X., Wang Z., Et al., Deep learning for pixel-level image fusion: recent advances and future prospects, Inf. Fusion, 42, pp. 158-173, (2018); Liu Y., Chen X., Cheng J., Et al., A medical image fusion method based on convolutional neural networks//, Proceedings of the 20th International Conference on Information Fusion (Fusion), (2017); Jiayi M., Wei Y., Pengwei L., Et al., FusionGAN: a generative adversarial network for infrared and visible image fusion, Inf. Fusion, (2018); Yang Y., Que Y., Huang S.Y., Multimodal sensor medical image fusion based on type-2 fuzzy logic in NSCT domain, IEEE Sens. J., 16, pp. 3735-3745, (2016); Yin S.F., Cao L.C., Ling Y.S., One color contrast enhanced infrared and visible image fusion method, Infrared Phys. Technol., 53, pp. 146-150, (2010); Jin X., Zhou D.M., Yao S.W., Remote sensing image fusion method in CIELab color space using nonsubsampled shearlet transform and pulse coupled neural networks, J. Appl. Remote Sens., (2016); Li T.J., Wang Y.Y., Chang C., Color-appearance-model based fusion of gray and pseudo-color images for medical applications, Inf. Fusion, 19, pp. 103-114, (2014); Li T.J., Wang Y.Y., Biological image fusion using a NSCT based variable-weight method, Inf. Fusion, 12, pp. 85-92, (2011); Haddadpour M., Daneshavar S., Seyedarabi H., PET and MRI image fusion based on combination of 2-D Hilbert transform and IHS method, Biomed. J., 40, pp. 219-225, (2017); Sabalan D., Hassan G., MRI and PET image fusion by combining IHS and retina-inspired models, Inf. Fusion, 11, pp. 114-123, (2010); Huang D.Y., Wang C.H., Optimal multi-level thresholding using a two-stage Otsu optimization approach, Pattern Recognit. Lett., 30, pp. 275-284, (2009); Bhandari A.K., Kumar A., Singh G.K., Modified artificial bee colony based computationally efficient multilevel thresholding for satellite image segmentation using Kapur's, Otsu and Tsallis functions, Expert Syst. Appl., 42, pp. 1573-1601, (2015); Gu B., Li W., Zhu M., Et al., Local edge-preserving multiscale decomposition for high dynamic range image tone mapping, IEEE Trans. Image Process., 22, 1, pp. 70-79, (2013); Li S., Kang X., Hu J., Image fusion with guided filtering, IEEE Trans. Image Process., 22, 7, pp. 2864-2875, (2013); Bavirisetti D.P., Dhuli R., Two-scale image fusion of visible and infrared images using saliency detection, Infrared Phys. Technol., 76, pp. 52-64, (2016); Han X., Lv T., Song X., Nie T., Liang H., He B., Kuijper A., An adaptive two-scale image fusion of visible and infrared images, IEEE Access., (2019); Meng L., Guo X., Li H., MRI/CT fusion based on latent low rank representation and gradient transfer, Biomed. Process. Control, 53, (2019); Jiang Y., Wang M., Image fusion with morphological component analysis, Inf. Fusion, 18, pp. 107-118, (2014); Padma K., Asha C.S., Maya K., Et al., A novel medical image fusion by combining TV-L1 decomposed textures based on adaptive weighting scheme, Eng. Sci. Technol. Int. J., (2019); Zhu Z., Yin H., Chai Y., Et al., A novel multi-modality image fusion method based on image decomposition and sparse representation, Inf. Sci. (Ny), (2018); Hu J., Li S., The multiscale directional bilateral filter and its application to multisensor image fusion, Inf. Fusion, 13, 3, pp. 196-206, (2012); Xu Z., Medical image fusion using multi-level local extrema, Inf. Fusion, 19, pp. 38-48, (2014); Jiang Y., Wang M., Image fusion using multiscale edge-preserving decomposition based on weighted least squares filter, IET Image Process., 8, 3, pp. 183-190, (2014); Du J., Li W., Xiao B., Anatomical-functional image fusion by information of interest in local Laplacian filtering domain, IEEE Trans. Image Process., 26, 17, pp. 5855-5866, (2017); Ma W.Y., Morel J.M., Osher S., An L1-based variational model for Retinex theory and its application to medical images, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Colorado Springs, CO, 20-25, pp. 153-160, (2011); Li S., Kang X., Fang L., Et al., Pixel-level image fusion: a survey of the state of the art, Inf. Fusion, (2016); Song Q., Wang Y., Bai K., High dynamic range infrared images detail enhancement based on local edge preserving filter, Infrared Phys. Technol., 77, pp. 464-473, (2016); Farbman Z., Fattal R., Lischinski D., Et al., Edge-preserving decompositions for multi-scale tone and detail manipulation, ACM Trans. Graph, 27, 3, (2008); Cheng J., Li Z., Gu Z., Et al., Structure-preserving guided retinal image filtering and its application for optic disc analysis, IEEE Trans. Med. Imaging, (2018); Liu L., Liu B., Huang H., Et al., No-reference image quality assessment based on spatial and spectral entropies, Signal Process.: Image Commun., 29, 8, pp. 856-863, (2014); Li H., Yu Z., Mao C., Fractional differential and variational method for image fusion and super-resolution, Neurocomputing, (2015); Zhang L., Zhang L., Mou X.Q., FSIM: a Feature Similarity Index for Image Quality Assessment, IEEE Trans. Image Process., 20, pp. 2378-2386, (2011); Mittal A., Fellow I.E.E.E., Et al., Making a 'Completely Blind' Image Quality Analyzer, IEEE Signal Process. Lett., 20, 3, pp. 209-212, (2013); Yeganeh H., Zhou W., Objective quality assessment of tone-mapped images, IEEE Trans. Image Process., 22, 2, (2012); Hossny M., Nahavandi S., Creighton D., Comments on 'Information measure for performance of image fusion, Electron. Lett., 44, 18, pp. 1066-1067, (2008); Chandler D.M., Hemami S.S., VSNR: a wavelet-based Visual Signal-to-Noise Ratio for natural images, IEEE Trans. Image Process., 16, 9, pp. 2284-2298, (2007); Wang L., Li B., Tian L.F., EGGDD: an explicit dependency model for multi-modal medical image fusion in shift-invariant shearlet transform domain, Inf. Fusion, 19, pp. 29-37, (2014); Ma K.D., Zeng K., Wang Z., Perceptual quality assessment for multi-exposure image fusion, IEEE Trans. Image Process., 24, 11, pp. 3345-3356, (2015); Du J., Li W., Xiao B., Et al., Medical image fusion by combining parallel features on multi-scale local extrema scheme, Knowl. Based Syst., (2016); Liu Z., Blasch E., John V., Statistical comparison of image fusion algorithms: recommendations, Information Fusion, 36, pp. 251-260, (2017); Ali M.Z., Awad N.H., Suganthan P.N., Et al., A novel hybrid cultural algorithms framework with trajectory-based search for global numerical optimization, Inf. Sci. (Ny), 334, 100, pp. 219-249, (2015); Janez D., Statistical comparisons of classifiers over multiple data sets, J. Mach. Learn. Res., 7, pp. 1-30, (2006); Sun M.T., Cheng J.L., Zhang Y., Application of DWIBS in malignant lymphoma: correlation between ADC values and Ki-67 index, Eur. Radiol., 28, 4, pp. 1701-1708, (2018); Faust O., Hagiwara Y., Hong T.J., Et al., Deep learning for healthcare applications based on physiological signals: a review, Comput. Methods Progr. Biomed., (2018); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, Proceedings of the ICRL, (2015)","J. Du; School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, 510006, China; email: dujiao19880429@126.com","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","32570007","English","Comput. Methods Programs Biomed.","Article","Final","","Scopus","2-s2.0-85086575506"
"Hammam A.A.; Elmousalami H.H.; Hassanien A.E.","Hammam, Ahmed A. (57212442079); Elmousalami, Haytham H. (57196150503); Hassanien, Aboul Ella (57192178208)","57212442079; 57196150503; 57192178208","Stacking Deep Learning for Early COVID-19 Vision Diagnosis","2020","Studies in Big Data","78","","","297","307","10","10","10.1007/978-3-030-55258-9_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105991222&doi=10.1007%2f978-3-030-55258-9_18&partnerID=40&md5=ffadd5964b78e7837d9856add11198a1","Faculty of Computers and Artificial Intelligence, Cairo University, Cairo, Egypt; Scientific Research Group, Cairo, Egypt","Hammam A.A., Faculty of Computers and Artificial Intelligence, Cairo University, Cairo, Egypt, Scientific Research Group, Cairo, Egypt; Elmousalami H.H., Faculty of Computers and Artificial Intelligence, Cairo University, Cairo, Egypt, Scientific Research Group, Cairo, Egypt; Hassanien A.E., Faculty of Computers and Artificial Intelligence, Cairo University, Cairo, Egypt, Scientific Research Group, Cairo, Egypt","early and accurate COVID-19 diagnosis prediction plays a crucial role for helping radiologists and health care workers to take reliable corrective actions for classify patients and detecting the COVID 19 confirmed cases. Prediction and classification accuracy are critical for COVID-19 diagnosis application. Current practices for COVID-19 images classification are mostly built upon convolutional neural network (CNNs) where CNN is a single algorithm. On the other hand, ensemble machine learning models produce higher accuracy than a single machine leaning. Therefore, this study conducts stacking deep learning methodology to produce the highest results of COVID-19 classification. The stacked ensemble deep learning model accuracy has produced 98.6% test accuracy. Accordingly, the stacked ensemble deep learning model produced superior performance than any single model. Accordingly, ensemble machine learning evolves as a future trend due to its high scalability, stability, and prediction accuracy. © 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.","Biomedical image processing; Classification; COVID-19; Deep learning; Ensemble learning; Stacking","Computer aided diagnosis; Convolutional neural networks; Deep learning; Forecasting; Image classification; Learning systems; Classification accuracy; Convolutional neural network; Corrective actions; Current practices; Deep learning; Ensemble learning; Health care workers; Learning models; Prediction accuracy; Stackings; COVID-19","","","","","","","Elmousalami H.H., Hassanien A.E., Day Level Forecasting for Coronavirus Disease (COVID-19) Spread: Analysis, Modeling and Recommendations, Arxiv Preprint Arxiv, 2003, (2020); Elmousalami H.H., Comparison of artificial intelligence techniques for project conceptual cost prediction: A case study and comparative analysis, IEEE Trans. Eng. Manage., pp. 1-14, (2020); Hassanien A.E., Mahdy L.N., Ezzat K.A., Elmousalami H.H., Ella H.A., Automatic X-Ray COVID-19 Lung Image Classification Model Based on Multi-Level Thresholding and Support Vector Machine, (2020); Xu X., Jiang X., Ma C., Du P., Li X., Lv S., Yu L., Chen Y., Su J., Lang G., Et al., Deep Learning Model to Screen Coronavirus Disease 2019 Pneumonia. Arxiv Preprint Arxiv, 2002, (2020); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Models, pp. 1097-1105, (2012); Howard A.G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications. Arxiv Preprint Arxiv, 1704, (2017); Li Y., Huang H., Xie Q., Yao L., Chen Q., Research on a surface defect detection algorithm based on MobileNet-SSD, Appl. Sci., 8, 9, (2018); Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Rabinovich A., Going deeper with convolutions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9, (2015); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Dietterich T.G., Ensemble methods in machine learning, International Workshop on Multiple Classifier Models, pp. 1-15, (2000); Goyal A., Sardana N., Empirical analysis of ensemble machine learning techniques for bug Triaging, 2019 Twelfth International Conference on Contemporary Computing (IC3), pp. 1-6, (2019); Deng L., Yu D., Platt J., Scalable stacking and learning for building deep architectures, 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Pp. 2133–2136. IEEE, (2012); Tharwat A., Classification assessment methods, Appl. Comput. Inf., (2018)","A.A. Hammam; Faculty of Computers and Artificial Intelligence, Cairo University, Cairo, Egypt; email: ahmed.a.hammam@grad.fci-cu.edu.eg","","Springer Science and Business Media Deutschland GmbH","","","","","","21976503","","","","English","Stud. Big. Data.","Book chapter","Final","","Scopus","2-s2.0-85105991222"
"Shen Y.; Ji Z.; Gao M.","Shen, Yan (57204107888); Ji, Zhanghexuan (57212001918); Gao, Mingchen (55424598500)","57204107888; 57212001918; 55424598500","An End-to-End Learnable Flow Regularized Model for Brain Tumor Segmentation","2020","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","12436 LNCS","","","532","541","9","0","10.1007/978-3-030-59861-7_54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092733086&doi=10.1007%2f978-3-030-59861-7_54&partnerID=40&md5=1fd84a4d1a8470ff684418218d80cfa8","Department of Computer Science and Engineering, University at Buffalo, The State University of New York, Buffalo, United States","Shen Y., Department of Computer Science and Engineering, University at Buffalo, The State University of New York, Buffalo, United States; Ji Z., Department of Computer Science and Engineering, University at Buffalo, The State University of New York, Buffalo, United States; Gao M., Department of Computer Science and Engineering, University at Buffalo, The State University of New York, Buffalo, United States","Many segmentation tasks for biomedical images can be modeled as the minimization of an energy function and solved by a class of max-flow and min-cut optimization algorithms. However, the segmentation accuracy is sensitive to the contrasting of semantic features of different segmenting objects, as the traditional energy function usually uses hand-crafted features in their energy functions. To address these limitations, we propose to incorporate end-to-end trainable neural network features into the energy functions. Our deep neural network features are extracted from the down-sampling and up-sampling layers with skip-connections of a U-net. In the inference stage, the learned features are fed into the energy functions. And the segmentations are solved in a primal-dual form by ADMM solvers. In the training stage, we train our neural networks by optimizing the energy function in the primal form with regularizations on the min-cut and flow-conservation functions, which are derived from the optimal conditions in the dual form. We evaluate our methods, both qualitatively and quantitatively, in a brain tumor segmentation task. As the energy minimization model achieves a balance on sensitivity and smooth boundaries, we would show how our segmentation contours evolve actively through iterations as ensemble references for doctor diagnosis. © 2020, Springer Nature Switzerland AG.","","Bioinformatics; Brain; Computer aided instruction; Deep learning; Deep neural networks; Diagnosis; Image segmentation; Medical imaging; Multilayer neural networks; Semantics; Signal sampling; Tumors; Brain tumor segmentation; Down sampling and up samplings; Energy minimization; Neural network features; Optimal conditions; Optimization algorithms; Segmentation accuracy; Semantic features; Learning systems","","","","","National Science Foundation, NSF, (1910492)","","Chan T.F., Esedoglu S., Nikolova M., Algorithms for finding global minimizers of image segmentation and denoising models, SIAM J. Appl. Math., 66, 5, pp. 1632-1648, (2006); Chan T.F., Vese L.A., Active contours without edges, IEEE Trans. Image Process., 10, 2, pp. 266-277, (2001); Chen L., Wu Y., Dsouza A.M., Abidin A.Z., Wismuller A., Xu C., MRI tumor segmentation with densely connected 3D CNN, International Society for Optics and Photonics, 10574, (2018); Cohen L.D., On active contour models and balloons, CVGIP Image Underst, 53, 2, pp. 211-218, (1991); Dey R., Hong Y., CompNet: Complementary segmentation network for brain MRI extraction, MICCAI 2018. LNCS, 11072, pp. 628-636, (2018); Ganaye P.-A., Sdika M., Benoit-Cattin H., Semi-supervised learning for segmentation under semantic constraint, MICCAI 2018. LNCS, 11072, pp. 595-602, (2018); Greig D.M., Porteous B.T., Seheult A.H., Exact maximum a posteriori estimation for binary images, J. Roy. Stat. Soc.: Ser. B (Methodol.), 51, 2, pp. 271-279, (1989); Kamnitsas K., Chen L., Ledig C., Rueckert D., Glocker B., Multi-scale 3D CNNs for segmentation of brain lesions in multi-modal MRI, Proceeding of Isles Challenge, (2015); Kamnitsas K., Et al., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation, Med. Image Anal., 36, pp. 61-78, (2017); Karimaghaloo Z., Arnold D.L., Arbel T., Adaptive multi-level conditional random fields for detection and segmentation of small enhanced pathology in medical images, Med. Image Anal., 27, pp. 17-30, (2016); Kass M., Witkin A., Terzopoulos D., Snakes: Active contour models, Int. J. Comput. Vis., 1, 4, pp. 321-331, (1988); Le T.H.N., Gummadi R., Savvides M., Deep recurrent level set for segmenting brain tumors, MICCAI 2018. LNCS, 11072, pp. 646-653, (2018); Mangasarian O.L., Nonlinear Programming, (1994); Menze B.H., Et al., The multimodal brain tumor image segmentation benchmark (BRATS), IEEE Trans. Med. Imaging, 34, 10, pp. 1993-2024, (2014); Qin Y., Et al., Autofocus layer for semantic segmentation, MICCAI 2018. LNCS, 11072, pp. 603-611, (2018); Spitzer H., Kiwitz K., Amunts K., Harmeling S., Dickscheid T., Improving cytoarchitectonic segmentation of human brain areas with self-supervised Siamese networks, MICCAI 2018. LNCS, 11072, pp. 663-671, (2018); Yuan J., Bae E., Tai X.-C., A study on continuous max-flow and min-cut approaches, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 2217-2224, (2010); Zhou C., Ding C., Lu Z., Wang X., Tao D., One-pass multi-task convolutional neural networks for efficient brain tumor segmentation, MICCAI 2018. LNCS, 11072, pp. 637-645, (2018)","M. Gao; Department of Computer Science and Engineering, University at Buffalo, The State University of New York, Buffalo, United States; email: mgao8@buffalo.edu","Liu M.; Lian C.; Yan P.; Cao X.","Springer Science and Business Media Deutschland GmbH","","11th International Workshop on Machine Learning in Medical Imaging, MLMI 2020, held in conjunction with the 23rd International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2020","4 October 2020 through 4 October 2020","Lima","249769","03029743","978-303059860-0","","","English","Lect. Notes Comput. Sci.","Conference paper","Final","","Scopus","2-s2.0-85092733086"
"","","","International Conference on Computers and Information Processing Technologies, ICCIPT 2014","2014","Applied Mechanics and Materials","571-572","","","","","","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903445629&partnerID=40&md5=4d99cfb04c5d3dd6e4e752446f64f5d7","","","The proceedings contain 223 papers. The special focus in this conference is on Computers and Information Processing Technologies. The topics include: A large-scale and flexible BMS design; research on map reduce task dynamic balancing strategy based on file label; researches on data privacy in cloud computing based on game theory; the MPI and OpenMP implementation of parallel algorithm for generating Mandelbrot set; adaptive congestion control via dynamic output feedback; an advanced ECC dynamic password-based remote authentication scheme for cloud computing; an audio hiding algorithm based on spline interpolation and wavelet transform; evaluation method for anti-interference performance of measuring based on entropy loss; RE-based weighted distributed equipment layout; algorithms of mining maximum frequent itemsets based on compression matrix; a secret sharing scheme on access structure; a tag-based signature scheme with shorter signature length; an identity-based conditional proxy re-encryption in cloud computing environments; fine-grained access control with efficient revocation in cloud storage; integrity and fidelity evaluation of digital evidence in live forensics; MANET-based stable clustering algorithm and its performance analysis;; reinforcement learning for cloud computing digital library; research on design and construction method of bent functions; a novelty model for reliability assessment of complex system; a multi-attribute decision-making method based on SPAOWA operator; the forecasting research of Beijing tourism demand based on the BP neural network; setting of academic warning based on multivariate copula functions; the application of iteration learning control in silkworm incubation chamber system; fault diagnoses using inverse fuzzy model; a community detection method based on multi-objective optimization method; a high precision indoor positioning system based on VLC and smart handheld; a hybrid IGA-SA algorithm for optimization problems in fault diagnosis; efficient particle swarm optimization algorithm based on affinity propagation; fault diagnosis of transformer based on RBF neural network; features extraction for Lhasa Tibetan speech recognition; FECG extraction algorithm based on BSS using temporal structure and DWT; fuzzy clustering segmentation algorithm research for biomedical image based on artificial life; hourly solar radiation forecast based on k-NN nonparametric regression model; multi-thread memory particle swarm optimization for dynamic optimization problems; recognizing event in short text based on decision tree; reliability analysis based on Markov process for repairable systems; short-term prediction of ship motion based on EMD-SVM; design of a two-wheel self-balanced vehicle system; moving target detection and tracking control simulation platform; new research for traffic state identification; large naval ship evaluation method attended by multiple experts; fuzzy comprehensive evaluation method of experimental teaching quality based on AHP; the planning system based on the postponement manufacturing theory; Tibetan-Chinese named entity extraction based on comparable corpus; the research on the development of smart library; an Iot-based remote health monitoring and management system; analysis of user influence using user behavior and random walk; tax revenue loss under electronic commerce in China; tax administration problem in the e-business environment; research on the elements of e-government performance evaluation; application of information technology in the county government; a study on simulative system of mobile payment; casting process solutions optimization of LFC forklift box; FEM analysis of sheet incremental forming process; application research of PBL method in PLC control technology; a phase anti-ambiguity method for USBL system; smart community security system based on sensor web; research on static game theory based secure routing algorithm in WSN; human activity recognition using smart-phone sensors; design of circuit for alcohol measurements using three-electrode biosensor; study on passivity-based control of TNPC PV grid-connected inverter; theoretical studies of novel high power millimeter generator based on vacuum electron devices; the study on intelligent insecticidal lamp with LED; the intelligent desk lamp designed for special populations; the design of freeform surface Fresnel lens used for LED uniform illumination; stabilization of a class of chaotic systems via single-state adaptive feedback controller; research on 5V internal power supply circuit of switching power supply; optimization design of photovoltaic system MPPT controller; modeling hydraulic power system with surge tank; dispersion curves and fields for a chiral negative refraction parallel-plate waveguide under PMC boundary; a novel dead-time control method for double end converter; a low standby power consumption control circuit for switching power supply; a flyback 25W switching power supply for electric vehicle; a distributed DC power devise based on DSP; a 3 GHz semi-digital delay locked loop with high resolution; a dual-DSP sonobuoy signal processing system; transmission of image information in the network multimedia teaching; context-assisted fast face detection; the EMD analysis AE signals of rock failure under uniaxial compression; simulation of dynamic light scattering signal based on AR Model; disparity estimation of 3-D mesh for stereo video coding; taxi bidirectional search system based on smart phone; dynamic biomedical image segmentation based on wavelet transform; research on issues of across border area in network games; an RFID-assisted digital souvenir generation system; rock image pore identification based on fuzzy C-means clustering and neural networks; a video characteristics watermarking algorithm based on bees evolutional computation; study of slice cell counting system; upper-body pose recognition using cylinder pattern model; tomato disease image retrieval based on composite features the research of ortho-rectification to QuickBird image with more mountains based on ERDAS10.0; pedestrian detection optimization algorithm based on low-altitude UAV; improved face recognition using 2D-LDA with weighted covariance scatter; challenging the recognition of facial expression via deep learning and applied study of size measurement based on image.","","","","","","","","","","","","Trans Tech Publications Ltd","","","","","","16609336","978-303835139-9","","","English","Appl. Mech. Mater.","Conference review","Final","","Scopus","2-s2.0-84903445629"
"Ding J.; Li X.; Gudivada V.N.","Ding, Junhua (7402608357); Li, Xinchuan (36194758400); Gudivada, Venkat N. (6602858683)","7402608357; 36194758400; 6602858683","Augmentation and evaluation of training data for deep learning","2017","Proceedings - 2017 IEEE International Conference on Big Data, Big Data 2017","2018-January","","","2603","2611","8","31","10.1109/BigData.2017.8258220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047761559&doi=10.1109%2fBigData.2017.8258220&partnerID=40&md5=a55fd08262459b1a6b2d24cc9bc3a6c2","Department of Computer Science, East Carolina University, Greenville, NC, United States; School of Computer Science, China University of Geosciences, Wuhan, China","Ding J., Department of Computer Science, East Carolina University, Greenville, NC, United States; Li X., School of Computer Science, China University of Geosciences, Wuhan, China; Gudivada V.N., Department of Computer Science, East Carolina University, Greenville, NC, United States","Deep learning is an important technique for extracting value from big data. However, the effectiveness of deep learning requires large volumes of high quality training data. In many cases, the size of training data is not large enough for effectively training a deep learning classifier. Data augmentation is a widely adopted approach for increasing the amount of training data. But the quality of the augmented data may be questionable. Therefore, a systematic evaluation of training data is critical. Furthermore, if the training data is noisy, it is necessary to separate out the noise data automatically. In this paper, we propose a deep learning classifier for automatically separating good training data from noisy data. To effectively train the deep learning classifier, the original training data need to be transformed to suit the input format of the classifier. Moreover, we investigate different data augmentation approaches to generate sufficient volume of training data from limited size original training data. We evaluated the quality of the training data through cross validation of the classification accuracy with different classification algorithms. We also check the pattern of each data item and compare the distributions of datasets. We demonstrate the effectiveness of the proposed approach through an experimental investigation of automated classification of massive biomedical images. Our approach is generic and is easily adaptable to other big data domains. © 2017 IEEE.","big data; convolutional neural network; deep learning; diffraction image; machine learning; neural network; support vector machine","Big data; Clustering algorithms; Deep learning; Deep neural networks; Learning systems; Neural networks; Quality control; Support vector machines; Automated classification; Classification accuracy; Classification algorithm; Convolutional neural network; Diffraction images; Experimental investigations; Learning classifiers; Systematic evaluation; Classification (of information)","","","","","National Science Foundation, NSF, (1730568); East Carolina University, ECU","The authors would like to thank Dr. Xin-Hua Hu and Pruthvish Patel at East Carolina University for assistance with the experiments. This research is supported in part by grants #1560037 and #1730568 from the National Science Foundation. We gratefully acknowledge NVIDIA Corporation for Tesla K40 GPU gift, which is used for conducting this research.","Bengio Y., Learning deep architectures for ai, Foundations and Trends in Machine Learning, 2, 1, pp. 1-127, (2009); Giannoulatou E., Park S.-H., Humphreys D., Ho J., Verification and validation of bioinformatics software without a gold standard: A case study of bwa and bowtie, BMC Bioinformatics, 15, (2014); Zhang J., Feng Y., Moran M.S., Lu J., Yang L., Et al., Analysis of cellular objects through diffraction images acquired by flow cytometry, Opt. Express, 21, 21, pp. 24819-24828, (2013); Saez J.A., Krawczyk B., Wozniak M., On the influence of class noise in medical data classification: Treatment using noise filtering methods, Applied Artificial Intelligence, 30, 6, pp. 590-609, (2016); Gao J., Xie C., Tao C., Big data validation and quality assurance-issuses, challenges, and needs, 2016 IEEE Symposium on Service-Oriented System Engineering (SOSE), pp. 433-441, (2016); Wu C.H., Song Y., Robust and distributed web-scale near-dup document conflation in microsoft academic service, 2015 IEEE International Conference on Big Data (Big Data), pp. 2606-2611, (2015); Gudivada V., Raeza-Yates R., Raghavan V., Big data: Promises and problems, IEEE Computer, 48, 3, pp. 20-23, (2015); Jacobs K., Lu J., Hu X., Development of a diffraction imaging flow cytometer, Opt. Lett., 34, 19, (2009); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Burges C.J., A tutorial on support vector machines for pattern recognition, Data Mining and Knowledge Discovery, 2, pp. 121-167, (1998); Ding J., Zhang D., Hu X., An application of metamorphic testing for testing scientific software, 1st Intl. Workshop on Metamorphic Testing with ICSE, (2016); Dong K., Feng Y., Jacobs K., Lu J., Brock R., Et al., Label-free classification of cultured cells through diffraction imaging, Biomed. Opt. Express, 2, 6, (2011); Chang C.-C., Lin C.-J., LIBSVM: A library for support vector machines, ACM Transactions on Intelligent Systems and Technology, 2, pp. 271-2727, (2011); Haralick R., On a texture-context feature extraction algorithm for remotely sensed imagery, Proceedings of the IEEE Computer Society Conference on Decision and Control, pp. 650-657, (1971); Thati S.K., Ding J., Zhang D., Hu X., Feature selection and analysis of diffraction images, 4th IEEE Intl. Workshop on Information Assurance, (2015); Ding J., Wang J., Kang X., Hu X., Building an SVM classifier for automated selection of big data, 2017 IEEE International Congress on Big Data, (2017); Vilkomir S., Wang J., Thai N.L., Ding J., Combinatorial methods of feature selection for cell image classification, 2017 IEEE Intl. Workshop. on Combinatorial Testing and Applications, (2017); Ding J., Kang X., Hu X.H., Gudivada V., Building a deep learning classifier for enhancing a biomedical big data service, 2017 IEEE Intl. Conf. on Services Computing, (2017); Adda Project, (2016); Deep Learning Tutorial, (2017); Shin H.-C., Roth H.R., Gao M., Lu L., Xu Z., Nogues I., Yao J., Mollura D., Summers R.M., Deep convolutional neural networks for computer-aided detection: Cnn architectures, dataset characteristics and transfer learning, IEEE Transactions on Medical Imaging, 35, 5, pp. 1285-1298, (2016); Hariharan B., Girshick R.B., Low-shot Visual Object Recognition, (2016); Ciresan D., Giusti A., Gambardella L.M., Schmidhuber J., Mitosis detection in breast cancer histology images with deep neural networks, Intl. Conf. on Medical Image Computing and Computer-assisted Intervention, pp. 411-418, (2013); Dong B., Shao L., Costa M.D., Bandmann O., Frangi A.F., Deep learning for automatic cell detection in wide-field microscopy zebrafish images, 2015 IEEE 12th Intl. Symposium on Biomedical Imaging (ISBI), pp. 772-776, (2015); Open Ai: Generative Models, (2017); Cai L., Zhu Y., The challenges of data quality and data quality assessment in the big data era, Data Science Journal, 14, 2, pp. 1-10, (2015); Ekambaram R., Goldgof D., Hall L., Finding label noise examples in large scale datasets, 2017 IEEE Intl. Conf. on Systems, Man, and Cybernetics (SMC), (2017)","","Nie J.-Y.; Obradovic Z.; Suzumura T.; Ghosh R.; Nambiar R.; Wang C.; Zang H.; Baeza-Yates R.; Baeza-Yates R.; Hu X.; Kepner J.; Cuzzocrea A.; Tang J.; Toyoda M.","Institute of Electrical and Electronics Engineers Inc.","Cisco; Elsevier; IEEE; IEEE Computer Society; The Mit Press","5th IEEE International Conference on Big Data, Big Data 2017","11 December 2017 through 14 December 2017","Boston","134260","","978-153862714-3","","","English","Proc. - IEEE Int. Conf. Big Data, Big Data","Conference paper","Final","","Scopus","2-s2.0-85047761559"
"Kandaswamy C.; Silva L.M.; Alexandre L.A.; Santos J.M.","Kandaswamy, Chetak (56038853000); Silva, Luís M (57210568776); Alexandre, Luís A (8847713100); Santos, Jorge M (7402389359)","56038853000; 57210568776; 8847713100; 7402389359","Deep transfer learning ensemble for classification","2015","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","9094","","","335","348","13","15","10.1007/978-3-319-19258-1_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937439174&doi=10.1007%2f978-3-319-19258-1_29&partnerID=40&md5=3d3beada33ef02236f0429504be93c4f","Instituto de Investiga, cão e Inova¸cão em Saúde, Universidade do Porto, Porto, Portugal; INEB - Instituto de Engenharia Biomédica, Porto, Portugal; Department of Electrical and Computer Engineering, University of Porto, Porto, Portugal; Departamento de MatemÁtica, Universidade de Aveiro, Aveiro, Portugal; Universidade da Beira Interior and Instituto de Telecomunicacoes, Covilhã, Portugal; Instituto Superior de Engenharia, Politécnico do Porto, Porto, Portugal","Kandaswamy C., Instituto de Investiga, cão e Inova¸cão em Saúde, Universidade do Porto, Porto, Portugal, INEB - Instituto de Engenharia Biomédica, Porto, Portugal, Department of Electrical and Computer Engineering, University of Porto, Porto, Portugal; Silva L.M., INEB - Instituto de Engenharia Biomédica, Porto, Portugal, Departamento de MatemÁtica, Universidade de Aveiro, Aveiro, Portugal; Alexandre L.A., Universidade da Beira Interior and Instituto de Telecomunicacoes, Covilhã, Portugal; Santos J.M., INEB - Instituto de Engenharia Biomédica, Porto, Portugal, Instituto Superior de Engenharia, Politécnico do Porto, Porto, Portugal","Transfer learning algorithms typically assume that the training data and the test data come from different distribution. It is better at adapting to learn new tasks and concepts more quickly and accurately by exploiting previously gained knowledge. Deep Transfer Learning (DTL) emerged as a new paradigm in transfer learning in which a deep model offer greater flexibility in extracting high-level features. DTL offers selective layer based transference, and it is problem specific. In this paper, we propose the Ensemble of Deep Transfer Learning (EDTL) methodology to reduce the impact of selective layer based transference and provide optimized framework to work for three major transfer learning cases. Empirical results on character, object and biomedical image recognition tasks achieves that the proposed method indicate statistically significant classification accuracy over the other established transfer learning method. © Springer International Publishing Switzerland 2015.","Deep learning; Ensemble; Transfer learning","Algorithms; Artificial intelligence; Image recognition; Neural networks; Classification accuracy; Deep learning; Different distributions; Ensemble; High-level features; Selective layers; Transfer learning; Transfer learning methods; Learning algorithms","","","","","","","Thrun S., Learning to learn: Introduction, Learning to Learn, (1996); Caruana R., Multitask learning, Machine Learning, 28, 1, pp. 41-75, (1997); Daume H., Marcu D., Domain Adaptation for Statistical Classifiers, J. Artif. Intell. Res. (JAIR), 26, pp. 101-126, (2006); Raina R., Battle A., Lee H., Packer B., Ng A.Y., Self-taught learning: Transfer learning from unlabeled data, Proc of the ACM Conference on (ICML), pp. 759-766, (2007); Lecun Y., Bottou L., Bengio Y., Haffner P., Gradient-based learning applied to document recognition, Proceedings of the IEEE, 86, 11, pp. 2278-2324, (1998); Hinton G.E., Osindero S., Teh Y., A fast learning algorithm for deep belief nets, The Journal of Neural Computation, 7, pp. 1527-1554, (2006); Vincent P., Larochelle H., Lajoie I., Bengio Y., Manzagol P.-A., Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion, J. Mach. Learn. Res, 11, pp. 3371-3408, (2010); Bengio Y., Et al., Towards Biologically Plausible Deep Learning. Arxiv Preprint Arxiv, 1502, (2015); Kandaswamy C., Silva L., Alexandre L., Sousa R., Santos J.M., Marques De S., Improving transfer learning accuracy by reusing Stacked Denoising Autoencoders, IEEE Conference on Systems Man and Cybernetics, (2014); Kandaswamy C., Silva L.M., Alexandre L.A., Santos J.M., De S., J.M.: Improving deep neural network performance by reusing features trained with transductive transference, ICANN 2014, 8681, pp. 265-272, (2014); Yosinski J., Clune J., Bengio Y., Lipson H., How transferable are features in deep neural networks?, Advances in Neural Information Processing Systems, pp. 3320-3328, (2014); Kandaswamy C., Silva L., Cardoso J.S., Source-target-source classification using Stacked Denoising Autoencoders, Proc of the 7Th Iberian Conference on Pattern Recognition and Image Analysis, Santiago De Compostela, (2015); Razavian A.S., Azizpour H., Sullivan J., Carlsson S., CNN features off-the-shelf: An astounding baseline for recognition, 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 512-519, (2014); Deng L., Platt J.C., Ensemble deep learning for speech recognition, Proceedings of the Annual Conference of International Speech Communication Association (INTERSPEECH), (2014); Abdullah A., Veltkamp R.C., Wiering M.A., An ensemble of deep support vector machines for image categorization, International Conference of Soft Computing and Pattern Recognition, SOCPAR 2009, pp. 301-306, (2009); Ciresan D., Meier U., Schmidhuber J., Multi-column deep neural networks for image classification, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (2012); Lin J., Divergence measures based on the Shannon entropy, IEEE Transactions on Information Theory, 37, pp. 145-151, (1991); Ljosa V., Katherine L., Sokolnicki, And Anne E., Annotated highthroughput microscopy image sets for validation, Nat Methods, 9, 7, (2012); Ljosa V., Et al., Comparison of methods for image-based profiling of cellular morphological responses to small-molecule treatment, Journal of Biomolecular Screening, (2013); Kuncheva L.I., Combining Pattern Classifiers: Methods and Algorithms, (2004)","","Rojas I.; Joya G.; Catala A.","Springer Verlag","IEEE Computational Intelligence Society; Universidad de Granada; UNIVERSIDAD DE MALAGA; Universitat de les llles Balears; UNIVERSITAT POLITECNICA DE CATALUNYA BARCELONATECH","13th International Work-Conference on Artificial Neural Networks, IWANN 2015","10 June 2015 through 12 June 2015","Palma de Mallorca","119599","03029743","978-331919257-4","","","English","Lect. Notes Comput. Sci.","Conference paper","Final","","Scopus","2-s2.0-84937439174"
"Pang S.; Orgun M.A.; Du A.; Yu Z.","Pang, Shuchao (55639762100); Orgun, Mehmet A. (6603681610); Du, Anan (56167972000); Yu, Zhezhou (8938987700)","55639762100; 6603681610; 56167972000; 8938987700","Leveraging deep preference learning for indexing and retrieval of biomedical images","2017","International IEEE/EMBS Conference on Neural Engineering, NER","","","8008308","126","129","3","2","10.1109/NER.2017.8008308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028599309&doi=10.1109%2fNER.2017.8008308&partnerID=40&md5=e6b7c31eed1e4172f3af6ab7a0d4ea44","College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China; Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; China Mobile (HangZhou) Information Technology Co., Ltd., China","Pang S., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China, Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Orgun M.A., Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Du A., China Mobile (HangZhou) Information Technology Co., Ltd., China; Yu Z., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China","This paper presents an original framework based on deep learning and preference learning to retrieve and characterize biomedical images for assisting physicians in diagnosing complex diseases with potentially only small differences between them. In particular, we use deep learning to extract the high-level and compact features for biomedical images. In contrast to the traditional biomedical algorithms or general image retrieval systems that only consider the use of pixel and/or hand-crafted features to represent images, we utilize deep neural networks for feature discovery of biomedical images. Moreover, in order to be able to index the similarly referenced images, we introduce preference learning in a novel way to learn what kinds of images we need so that we can obtain the similarity ranking list of biomedical images. We evaluate the performance of our system in detailed experiments over the well-known available OASIS-MRI database for whole brain neuroimaging as a benchmark and compare it with those of the traditional biomedical and general image retrieval approaches. Our proposed system exhibits an outstanding retrieval ability and efficiency for biomedical image applications. © 2017 IEEE.","","Benchmarking; Bioinformatics; Deep learning; Deep neural networks; Diagnosis; Image retrieval; Magnetic resonance imaging; Neuroimaging; Bio-medical algorithms; Biomedical images; Compact Features; Feature discovery; Image retrieval systems; Indexing and retrieval; Preference learning; Similarity rankings; Search engines","","","","","Science and Technology Development Plan of Jilin Province, (20150204007GX); Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP, (20120061110045)","Resrach supported by the project of Science and Technology Development Plan of Jilin Province, China (Grant 20150204007GX) and Specialized Research Fund for the Doctoral Program of Higher Education of China (Grant 20120061110045).","Smith B., Arabandi S., Brochhausen M., Calhoun M., Ciccarese P., Doyle S., Gibaud B., Goldberg I., Kahn Jr.C.E., Overton J., Tomaszewski J., Biomedical imaging ontologies: A survey and proposal for future work, J. Pathol. Inf, 6, (2015); Quellec G., Lamard M., Cazuguel G., Cochener B., Roux C., Wavelet optimization for content-based image retrieval in medical databases, Medical Image Analysis, 14, 2, pp. 227-241, (2010); Quddus A., Basir O., Semantic image retrieval in magnetic resonance brain volumes, IEEE Trans. Inf. Tech. Biomed, 16, 3, pp. 348-355, (2012); Ojala T., Pietikainen M., Maenpaa T., Multiresolution gray-scale and rotation invariant texture classification with local binary patterns, IEEE Trans. PAMI, 24, 7, pp. 971-987, (2002); Murala S., Wu Q.J., Local mesh patterns versus local binary patterns: Biomedical image indexing and retrieval, IEEE JBHI, 18, 3, pp. 929-938, (2014); Dubey S.R., Singh S., Singh R., Local bit-plane decoded pattern: A novel feature descriptor for biomedical image retrieval, IEEE JBHI, (2015); Pei X., Emphysema classification using convolutional neural networks, Springer International Publishing: In International Conf. on Intelligent Robotics and Appli, pp. 455-461, (2015); Su H., Xing F., Kong X., Xie Y., Zhang S., Yang L., Robust cell detection and segmentation in histopathological images using sparse reconstruction and stacked denoising autoencoders, International Conf. on Med. Image Computing and Computer-Assisted Intervention, pp. 383-390, (2015); Marcus D.S., Wang T.H., Parker J., Csernansky J.G., Morris J.C., Buckner R.L., Open access series of imaging studies (oasis): Crosssectional mri data in young, middle aged, nondemented, and demented older adults, Journal of Cognitive Neuroscience, 19, 9, pp. 1498-1507, (2007); Noor A.M., Holmberg L., Gillett C., Grigoriadis A., Big Data: The challenge for small research groups in the era of cancer genomics, British Journal of Cancer, (2015); Andreu-Perez J., Poon C.C., Merrifield R.D., Wong S.T., Yang G.Z., Big data for health, IEEE JBHI, 19, 4, pp. 1193-1208, (2015); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Beli J., Halje P., Richter U., Petersson P., Kotaleski J.H., Behavior discrimination using a discrete wavelet based approach for feature extraction on local field potentials in the cortex and striatum, 7th International IEEE/EMBS Conf. on NER, pp. 964-967, (2015); Masood A., Al-Jumaily A., Anam K., Self-supervised learning model for skin cancer diagnosis, 7th International IEEE/EMBS Conf. on NER, pp. 1012-1015, (2015); Rahman M., Bhattacharya P., Multimodal Biomedical Image Classification and Retrieval with Multi Response Linear Regression (MLR)-Based Meta Learning, (2016)","Z. Yu; College of Computer Science and Technology, Jilin University, Jilin Province, Qianjin Street: 2699, China; email: yuzz@jlu.edu.cn","","IEEE Computer Society","EMB; IEEE","8th International IEEE EMBS Conference on Neural Engineering, NER 2017","25 May 2017 through 28 May 2017","Shanghai","129986","19483546","978-153861916-2","","","English","Int. IEEE/EMBS Conf. Neural Eng., NER","Conference paper","Final","","Scopus","2-s2.0-85028599309"
"Albarqouni S.; Baur C.; Achilles F.; Belagiannis V.; Demirci S.; Navab N.","Albarqouni, Shadi (55129204800); Baur, Christoph (56982679100); Achilles, Felix (57118240900); Belagiannis, Vasileios (35483155200); Demirci, Stefanie (57213376774); Navab, Nassir (7003458998)","55129204800; 56982679100; 57118240900; 35483155200; 57213376774; 7003458998","AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images","2016","IEEE Transactions on Medical Imaging","35","5","7405343","1313","1321","8","480","10.1109/TMI.2016.2528120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969939903&doi=10.1109%2fTMI.2016.2528120&partnerID=40&md5=ff385d9219cfc107aeb2fa15261a230e","Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany; Deutsches Zentrum für Neurodegenerative Erkrankungen, Bonn, 53175, Germany; Visual Geometry Group, University of Oxford, Oxford, United Kingdom; Whiting School of Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States","Albarqouni S., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany, Deutsches Zentrum für Neurodegenerative Erkrankungen, Bonn, 53175, Germany; Baur C., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany; Achilles F., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany; Belagiannis V., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany, Visual Geometry Group, University of Oxford, Oxford, United Kingdom; Demirci S., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany; Navab N., Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany, Whiting School of Engineering, Johns Hopkins University, Baltimore, 21218, MD, United States","The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration. © 2016 IEEE.","Aggregation; crowdsourcing; deep learning; gamification; online learning","Breast Neoplasms; Crowdsourcing; Female; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Internet; Machine Learning; Mitosis; Neural Networks (Computer); Video Games; Agglomeration; Artificial intelligence; Crowdsourcing; Image retrieval; Learning systems; Neural networks; Biomedical image database; Conventional machines; Convolutional neural network; Deep learning; Gamification; Large-scale database; Online learning; Precise definition; algorithm; Article; breast biopsy; breast cancer; cancer diagnosis; clinical article; convolutional neural network; crowdsourcing; data base; experimental study; histopathology; human; human tissue; machine learning; mitosis; artificial neural network; breast tumor; computer assisted diagnosis; crowdsourcing; cytochemistry; diagnostic imaging; female; Internet; machine learning; physiology; procedures; video game; Medical imaging","","","","","","","Estelles-Arolas E., Gonzalez-Ladron-De-Guevara F., Towards an integrated crowdsourcing definition, J. Inf. Sci., 38, 2, pp. 189-200, (2012); Howe J., The rise of crowdsourcing, Wired Mag., 14, 6, pp. 1-4, (2006); Kleemann F., Voss G., Rieder K., Un(der)paid innovators: The commercial utilization of consumer work through crowdsourcing, STI Studies, 4, 1, (2008); Von Ahn L., Maurer B., McMillen C., Abraham D., Blum M., Recaptcha: Human-based character recognition via web security measures, Science, 321, 5895, pp. 1465-1468, (2008); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Adv. Neural Inf. Proc. Sys., pp. 1097-1105, (2012); Inel O., Et al., Crowdtruth: Machine-human computation framework for harnessing disagreement in gathering annotated data, Proc. Int. Semantic Web Conf., Part II, pp. 486-504, (2014); Von Ahn L., Games with a purpose, Comput., 39, 6, pp. 92-94, (2006); Yu B., Willis M., Sun P., Wang J., Crowdsourcing participatory evaluation of medical pictograms using amazon mechanical turk, J. Med. Internet Res., 15, 6, (2013); Maier-Hein L., Et al., Crowdsourcing for reference correspondence generation in endoscopic images, Medical Image Computing and Comput.-Assisted Intervention-MICCAI 2014, pp. 349-356, (2014); Volpi D., Et al., Online tracking of interventional devices for endovascular aortic repair, Int. J. Comp. Assist. Radiol. Surg., 10, 6, pp. 773-781, (2015); Mavandadi S., Et al., Biogames: A platform for crowd-sourced biomedical image analysis and telediagnosis, Games Health J., 1, 5, pp. 373-376, (2012); Gurari D., Et al., How to collect segmentations for biomedical images? A benchmark evaluating the performance of experts, crowdsourced non-experts, and algorithms, Proc. IEEE Winter Conf. Appl. Comput. Vis., pp. 1169-1176, (2015); Foncubierta Rodriguez A., Muller H., Ground truth generation in medical imaging: A crowdsourcing-based iterative approach, Proc. ACM Multim. Work. Crowdsourcing Multimedia, pp. 9-14, (2012); Celi L.A., Ippolito A., Montgomery R.A., Moses C., Stone D.J., Crowdsourcing knowledge discovery and innovations in medicine, J. Med. Internet Res., 16, 9, (2014); Aroyo L., Welty C., Truth is a lie: Crowd truth and the seven myths of human annotation, AI Mag., 36, 1, (2015); Sheng V.S., Provost F., Ipeirotis P.G., Get another label? Improving data quality and data mining using multiple, noisy labelers, Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 614-622, (2008); Hung N.Q.V., Tam N., Tran L., Aberer K., An evaluation of aggregation techniques in crowdsourcing, Web Inf. Syst. Eng., pp. 1-15, (2013); Raykar V.C., Et al., Learning from crowds, J. Mach. Learn. Res., 11, pp. 1297-1322, (2010); Schmidhuber J., Deep learning in neural networks: An overview, Neural Netw., 61, pp. 85-117, (2015); Girshick R., Donahue J., Darrell T., Malik J., Rich feature hierarchies for accurate object detection and semantic segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 580-587, (2014); Long J., Shelhamer E., Darrell T., Fully convolutional networks for semantic segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3431-3440, (2015); Belagiannis V., Rupprecht C., Carneiro G., Navab N., Robust optimization for deep regression, Proc. IEEE Int. Conf. Comput. Vis., pp. 2830-2838, (2015); Eigen D., Puhrsch C., Fergus R., Depth map prediction from a single image using a multi-scale deep network, Adv. Neural Inf. Proc. Syst., (2014); Xie Y., Xing F., Kong X., Su H., Yang L., Beyond classification: Structured regression for robust cell detection using convolutional neural network, Medical Image Computing and Comput.-Assisted Intervention-MICCAI 2015, pp. 358-365, (2015); Liu F., Yang L., A novel cell detection method using deep convolutional neural network and maximum-weight independent set, Medical Image Computing and Comput.-Assisted Intervention-MICCAI 2015, pp. 349-357, (2015); Ciresan D.C., Giusti A., Gambardella L.M., Schmidhuber J., Mitosis detection in breast cancer histology images with deep neural networks, Medical Image Computing and Comput.-Assisted Intervention-MICCAI 2013, pp. 411-418, (2013); Carneiro G., Nascimento J.C., Freitas A., The segmentation of the left ventricle of the heart from ultrasound data using deep learning architectures and derivative-based search methods, IEEE Trans. Image Process, 21, 3, pp. 968-982, (2012); Nair V., Hinton G.E., Rectified linear units improve restricted boltzmann machines, Proc. Int. Conf. Mach. Learn., pp. 807-814, (2010); Kuncheva L.I., Whitaker C.J., Shipp C.A., Duin R.P., Limits on the majority vote accuracy in classifier fusion, Pattern Anal. Appl., 6, 1, pp. 22-31, (2003); LeCun Y.A., Bottou L., Orr G.B., Muller K.-R., Efficient backprop, Neural Netw., Tricks of the Trade, pp. 9-48, (2012); Bottou L., Large-scale machine learning with stochastic gradient descent, Proc. Computational Statist., pp. 177-186, (2010); Veta M., Et al., Assessment of algorithms for mitosis detection in breast cancer histopathology images, Med. Image Anal., 20, 1, pp. 237-248, (2015); Macenko M., Et al., A method for normalizing histology slides for quantitative analysis, Proc. ISBI, 9, pp. 1107-1110, (2009); Vedaldi A., Lenc K., Matconvnet-convolutional neural networks for MATLAB, Proc. ACM Int. Conf. Multimedia, (2015); Whitehill J., Wu T.-F., Bergsma J., Movellan J.R., Ruvolo P.L., Whose vote should count more: Optimal integration of labels from labelers of unknown expertise, Adv. Neural Inf. Process. Syst., pp. 2035-2043, (2009); Lee K., Caverlee J., Webb S., The social honeypot project: Protecting online communities from spammers, Proc. Int. Conf. World Wide Web, pp. 1139-1140, (2010); Venanzi M., Guiver J., Kazai G., Kohli P., Shokouhi M., Community-based Bayesian aggregation models for crowdsourcing, Proc. Int. Conf. World Wide Web., pp. 155-164, (2014); Raykar V.C., Yu S., Ranking annotators for crowdsourced labeling tasks, Adv. Neural Inf. Proc. Sys., pp. 1809-1817, (2011)","S. Albarqouni; Department for Computer Aided Medical Procedure, Technische Universitat München, Munich, 85748, Germany; email: shadi.albarqouni@tum.de","","Institute of Electrical and Electronics Engineers Inc.","","","","","","02780062","","ITMID","26891484","English","IEEE Trans. Med. Imaging","Article","Final","","Scopus","2-s2.0-84969939903"
"Lee C.S.; Tyring A.J.; Deruyter N.P.; Wu Y.; Rokem A.; Lee A.Y.","Lee, Cecilia S. (56472056400); Tyring, Ariel J. (56221971100); Deruyter, Nicolaas P. (57193351908); Wu, Yue (57194851622); Rokem, Ariel (6507945628); Lee, Aaron Y. (26635526200)","56472056400; 56221971100; 57193351908; 57194851622; 6507945628; 26635526200","Deep-learning based, automated segmentation of macular edema in optical coherence tomography","2017","Biomedical Optics Express","8","7","295030","3440","3448","8","271","10.1364/BOE.8.003440","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023600747&doi=10.1364%2fBOE.8.003440&partnerID=40&md5=23e1aa7909ff747ee8d7b8a90f60665b","Department of Ophthalmology, University of Washington, Seattle, WA, United States; Department of Ophthalmology, Puget Sound Veteran Affairs, Seattle, WA, United States; University of Washington School of Medicine, Seattle, WA, United States; eScience Institute, University of Washington, Seattle, WA, United States","Lee C.S., Department of Ophthalmology, University of Washington, Seattle, WA, United States; Tyring A.J., Department of Ophthalmology, University of Washington, Seattle, WA, United States; Deruyter N.P., University of Washington School of Medicine, Seattle, WA, United States; Wu Y., Department of Ophthalmology, University of Washington, Seattle, WA, United States; Rokem A., eScience Institute, University of Washington, Seattle, WA, United States; Lee A.Y., Department of Ophthalmology, University of Washington, Seattle, WA, United States, Department of Ophthalmology, Puget Sound Veteran Affairs, Seattle, WA, United States, eScience Institute, University of Washington, Seattle, WA, United States","Evaluation of clinical images is essential for diagnosis in many specialties. Therefore the development of computer vision algorithms to help analyze biomedical images will be important. In ophthalmology, optical coherence tomography (OCT) is critical for managing retinal conditions. We developed a convolutional neural network (CNN) that detects intraretinal fluid (IRF) on OCT in a manner indistinguishable from clinicians. Using 1,289 OCT images, the CNN segmented images with a 0.911 cross-validated Dice coefficient, compared with segmentations by experts. Additionally, the agreement between experts and between experts and CNN were similar. Our results reveal that CNN can be trained to perform automated segmentations of clinically relevant image features. © 2017 Optical Society of America.","","Bioinformatics; Deep learning; Image segmentation; Neural networks; Ophthalmology; Tomography; Automated segmentation; Biomedical images; Clinical images; Computer vision algorithms; Convolutional neural network; Dice coefficient; Intra-retinal fluids; Segmented images; Article; artificial neural network; correlation coefficient; human; image analysis; image segmentation; learning algorithm; macular edema; optical coherence tomography; retina detachment; training; validation process; Optical tomography","","","","","National Eye Institute, NEI, (K23EY02492); Alfred P. Sloan Foundation; Gordon and Betty Moore Foundation, GBMF; Research to Prevent Blindness, RPB; Nvidia","National Eye Institute (NEI) (K23EY02492); Latham Vision Science Innovation Grant; Research to Prevent Blindness; The Gordon & Betty Moore Foundation; Alfred P. Sloan Foundation. This work was supported by Research to Prevent Blindness. The hardware used in the completion of this project was donated by NVIDIA.","Mitchell J.B., Machine learning methods in chemoinformatics, Wiley Interdiscip. Rev. Comput. Mol. Sci., 4, 5, pp. 468-481, (2014); Lecun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Kendall A., Badrinarayanan V., Cipolla R., Bayesian Segnet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding, (2015); Korfiatis P., Kline T.L., Erickson B.J., Automated segmentation of hyperintense regions in FLAIR MRI using deep learning, Tomography, 2, 4, pp. 334-340, (2016); Hatipoglu N., Bilgin G., Cell segmentation in histopathological images with deep learning algorithms by utilizing spatial relationships, Med. Biol. Eng. Comput., (2017); Abramoff M.D., Lou Y., Erginay A., Clarida W., Amelon R., Folk J.C., Niemeijer M., Improved automated detection of diabetic retinopathy on a publicly available data set through integration of deep learning, Invest. Ophthalmol. Vis. Sci, 57, 13, pp. 5200-5206, (2016); Burlina P., Pacheco K.D., Joshi N., Freund D.E., Bressler N.M., Comparing humans and deep learning performance for grading AMD: A study in using universal deep features and transfer learning for automated AMD analysis, Comput. Biol. Med., 82, pp. 80-86, (2017); Asaoka R., Murata H., Iwase A., Araie M., Detecting preperimetric glaucoma with standard automated perimetry using a deep learning classifier, Ophthalmology, 123, 9, pp. 1974-1980, (2016); Prentasic P., Heisler M., Mammo Z., Lee S., Merkur A., Navajas E., Beg M.F., Sarunic M., Loncaric S., Segmentation of the foveal microvasculature using deep learning networks, J. Biomed. Opt., 21, 7, (2016); Gao X., Lin S., Wong T.Y., Automatic feature learning to grade nuclear cataracts based on deep learning, IEEE Trans. Biomed. Eng, 62, 11, pp. 2693-2701, (2015); Coscas G., Cunha-Vaz J., Soubrane G., Macular edema: Definition and basic concepts, Dev. Ophthalmol., 47, pp. 1-9, (2010); Keane P.A., Sadda S.R., Predicting visual outcomes for macular disease using optical coherence tomography, Saudi J. Ophthalmol., 25, 2, pp. 145-158, (2011); Kumar A., Sahni J.N., Stangos A.N., Campa C., Harding S.P., Effectiveness of ranibizumab for neovascular age-related macular degeneration using clinician-determined retreatment strategy, Br. J. Ophthalmol., 95, 4, pp. 530-533, (2011); Browning D.J., Glassman A.R., Aiello L.P., Beck R.W., Brown D.M., Fong D.S., Bressler N.M., Danis R.P., Kinyoun J.L., Nguyen Q.D., Bhavsar A.R., Gottlieb J., Pieramici D.J., Rauser M.E., Apte R.S., Lim J.I., Miskala P.H., Diabetic Retinopathy Clinical Research Network, “Relationship between optical coherence tomography-measured central retinal thickness and visual acuity in diabetic macular edema, Ophthalmology, 114, 3, pp. 525-536, (2007); Srinivas S., Nittala M.G., Hariri A., Pfau M., Gasperini J., Ip M., Sadda S.R., Quantification of intraretinal hard exudates in eyes with diabetic retinopathy by optical coherence tomography, Retina, (2017); Golbaz I., Ahlers C., Stock G., Schutze C., Schriefl S., Schlanitz F., Simader C., Prunte C., Schmidt-Erfurth U.M., Quantification of the therapeutic response of intraretinal, subretinal, and subpigment epithelial compartments in exudative AMD during anti-VEGF therapy, Invest. Ophthalmol. Vis. Sci., 52, 3, pp. 1599-1605, (2011); Zheng Y., Sahni J., Campa C., Stangos A.N., Raj A., Harding S.P., Computerized assessment of intraretinal and subretinal fluid regions in spectral-domain optical coherence tomography images of the retina, Am. J. Ophthalmol., 155, 2, pp. 277-286, (2013); Lang A., Carass A., Swingle E.K., Al-Louzi O., Bhargava P., Saidha S., Ying H.S., Calabresi P.A., Prince J.L., Automatic segmentation of microcystic macular edema in OCT, Biomed. Opt. Express, 6, 1, pp. 155-169, (2015); Hu Z., Medioni G.G., Hernandez M., Hariri A., Wu X., Sadda S.R., Segmentation of the geographic atrophy in spectral-domain optical coherence tomography and fundus autofluorescence images, Invest. Ophthalmol. Vis. Sci, 54, 13, pp. 8375-8383, (2013); Swingle E.K., Lang A., Carass A., Al-Louzi O., Saidha S., Prince J.L., Segmentation of microcystic macular edema in Cirrus OCT scans with an exploratory longitudinal study, Proc SPIE Int Soc Opt Eng, 9417, (2015); Chiu S.J., Allingham M.J., Mettu P.S., Cousins S.W., Izatt J.A., Farsiu S., Kernel regression based segmentation of optical coherence tomography images with diabetic macular edema, Biomed. Opt. Express, 6, 4, pp. 1172-1194, (2015); Fang L., Cunefare D., Wang C., Guymer R.H., Li S., Farsiu S., Automatic segmentation of nine retinal layer boundaries in OCT images of non-exudative AMD patients using deep learning and graph search, Biomed. Opt. Express, 8, 5, pp. 2732-2744, (2017); Lee C.S., Baughman D.M., Lee A.Y., Deep Learning is Effective for Classifying Normal versus Age-Related Macular Degeneration Optical Coherence Tomography Images; Sahni J., Stanga P., Wong D., Harding S., Optical coherence tomography in photodynamic therapy for subfoveal choroidal neovascularisation secondary to age related macular degeneration: A cross sectional study, Br. J. Ophthalmol., 89, 3, pp. 316-320, (2005); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional Networks for Biomedical Image Segmentation, pp. 234-241, (2015); Esmaeili M., Dehnavi A.M., Rabbani H., Hajizadeh F., Three-dimensional segmentation of retinal cysts from spectral-domain optical coherence tomography images by the use of three-dimensional curvelet based K-SVD, J. Med. Signals Sens., 6, 3, pp. 166-171, (2016); Zijdenbos A.P., Dawant B.M., Margolin R.A., Palmer A.C., Morphometric analysis of white matter lesions in MR images: Method and validation, IEEE Trans. Med. Imaging, 13, 4, pp. 716-724, (1994); Wang J., Zhang M., Pechauer A.D., Liu L., Hwang T.S., Wilson D.J., Li D., Jia Y., Automated volumetric segmentation of retinal fluid on optical coherence tomography, Biomed. Opt. Express, 7, 4, (2016)","","","OSA - The Optical Society","","","","","","21567085","","","","English","Biomed. Opt. Express","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85023600747"
"Pang S.; Yu Z.; Orgun M.A.","Pang, Shuchao (55639762100); Yu, Zhezhou (8938987700); Orgun, Mehmet A. (6603681610)","55639762100; 8938987700; 6603681610","A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images","2017","Computer Methods and Programs in Biomedicine","140","","","283","293","10","69","10.1016/j.cmpb.2016.12.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011883667&doi=10.1016%2fj.cmpb.2016.12.019&partnerID=40&md5=3461c46640f53b42561a301ee3e549bd","College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China; Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Faculty of Information Technology, Macau University of Science and Technology, Taipa, Macao","Pang S., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China, Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia; Yu Z., College of Computer Science and Technology, Jilin University, Qianjin Street: 2699, Jilin Province, China; Orgun M.A., Department of Computing, Macquarie University, Sydney, 2109, NSW, Australia, Faculty of Information Technology, Macau University of Science and Technology, Taipa, Macao","Background and objectives Highly accurate classification of biomedical images is an essential task in the clinical diagnosis of numerous medical diseases identified from those images. Traditional image classification methods combined with hand-crafted image feature descriptors and various classifiers are not able to effectively improve the accuracy rate and meet the high requirements of classification of biomedical images. The same also holds true for artificial neural network models directly trained with limited biomedical images used as training data or directly used as a black box to extract the deep features based on another distant dataset. In this study, we propose a highly reliable and accurate end-to-end classifier for all kinds of biomedical images via deep learning and transfer learning. Methods We first apply domain transferred deep convolutional neural network for building a deep model; and then develop an overall deep learning architecture based on the raw pixels of original biomedical images using supervised training. In our model, we do not need the manual design of the feature space, seek an effective feature vector classifier or segment specific detection object and image patches, which are the main technological difficulties in the adoption of traditional image classification methods. Moreover, we do not need to be concerned with whether there are large training sets of annotated biomedical images, affordable parallel computing resources featuring GPUs or long times to wait for training a perfect deep model, which are the main problems to train deep neural networks for biomedical image classification as observed in recent works. Results With the utilization of a simple data augmentation method and fast convergence speed, our algorithm can achieve the best accuracy rate and outstanding classification ability for biomedical images. We have evaluated our classifier on several well-known public biomedical datasets and compared it with several state-of-the-art approaches. Conclusions We propose a robust automated end-to-end classifier for biomedical images based on a domain transferred deep convolutional neural network model that shows a highly reliable and accurate performance which has been confirmed on several public biomedical image datasets. © 2017 Elsevier Ireland Ltd","Biomedical image classification; Convolutional neural network; Data augmentation; Deep learning; Transfer learning","Diagnostic Imaging; Machine Learning; Models, Theoretical; Neural Networks (Computer); Bioinformatics; Computer aided diagnosis; Convolution; Data mining; Deep learning; Deep neural networks; Diagnosis; Image classification; Image segmentation; Medical imaging; Neural networks; Program processors; Vector spaces; Artificial neural network models; Classification ability; Classification methods; Convolutional neural network; Data augmentation; Fast convergence speed; State-of-the-art approach; Transfer learning; Article; artificial neural network; automation; back propagation; biomedicine; classification algorithm; classifier; controlled study; convolutional neural network; deep learning; diagnostic imaging; high resolution computer tomography; histogram; human; image analysis; image processing; machine learning; medical technology; support vector machine; training; transfer learning; velocity; machine learning; theoretical model; Classification (of information)","","","","","","","Andreu-Perez J., Poon C.C., Merrifield R.D., Wong S.T., Yang G.Z., Big data for health, IEEE J. Biomed. Health Inform., 19, 4, pp. 1193-1208, (2015); Depeursinge A., Vargas A., Platon A., Geissbuhler A., Poletti P.A., Muller H., Building a reference multimedia database for interstitial lung diseases, Comput. Med. Imaging Graph., 36, 3, pp. 227-238, (2012); NEMA–CT image database, (2012); Marcus D.S., Wang T.H., Parker J., Csernansky J.G., Morris J.C., Buckner R.L., Open access series of imaging studies (OASIS): cross-sectional MRI data in young, middle aged, nondemented, and demented older adults, J. Cogn. Neurosci., 19, 9, pp. 1498-1507, (2007); Clark K., Vendt B., Smith K., Freymann J., Kirby J., Koppel P., Moore S., Phillips S., Maffitt D., Pringle M., Tarbox L., The cancer imaging archive (TCIA): maintaining and operating a public information repository, J. Digit. Imaging, 26, 6, pp. 1045-1057, (2013); Depeursinge A., Van de Ville D., Platon A., Geissbuhler A., Poletti P.A., Muller H., Near-affine-invariant texture learning for lung tissue analysis using isotropic wavelet frames, IEEE Trans. Inf. Technol. Biomed., 16, 4, pp. 665-675, (2012); Song Y., Cai W., Zhou Y., Feng D.D., Feature-based image patch approximation for lung tissue classification, IEEE Trans. Med. Imaging, 32, 4, pp. 797-808, (2013); Song Y., Cai W., Huang H., Zhou Y., Feng D.D., Wang Y., Fulham M.J., Chen M., Large margin local estimate with applications to medical image classification, IEEE Trans. Med. Imaging, 34, 6, pp. 1362-1377, (2015); Coppini G., Diciotti S., Falchini M., Villari N., Valli G., Neural networks for computer-aided diagnosis: detection of lung nodules in chest radiograms, IEEE Trans. Inf. Technol. Biomed., 7, 4, pp. 344-357, (2003); Abdullah A.A., Shaharum S.M., Lung cancer cell classification method using artificial neural network, Inf. Eng. Lett., 2, 1, (2012); Kuruvilla J., Gunavathi K., Lung cancer classification using neural networks for CT images, Comput. Methods. Programs. Biomed., 113, 1, pp. 202-209, (2014); Li Q., Cai W., Wang X., Zhou Y., Feng D.D., Chen M., Medical image classification with convolutional neural network, Proceedings of the 13th IEEE International Conference on Control Automation Robotics & Vision (ICARCV), pp. 844-848, (2014); Gao Z., Zhang J., Zhou L., Wang L., HEp-2 cell image classification with convolutional neural networks, Proceedings of 2014 1st IEEE Workshop on Pattern Recognition Techniques for Indirect Immunofluorescence Images (I3A), pp. 24-28, (2014); Roth H.R., Lee C.T., Shin H.C., Seff A., Kim L., Yao J., Lu L., Summers R.M., Anatomy-specific classification of medical images using deep convolutional nets, Proceedings of IEEE 12th International Symposium on Biomedical Imaging (ISBI), pp. 101-104, (2015); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Ahn E., Kumar A., Kim J., Li C., Feng D., Fulham M., X-ray image classification using domain transferred convolutional neural networks and local sparse spatial pyramid, Proceedings of IEEE 13th International Symposium on Biomedical Imaging (ISBI), pp. 855-858, (2016); Phan H.T.H., Kumar A., Kim J., Feng D., Transfer learning of a convolutional neural network for HEp-2 cell image classification, Proceedings of IEEE 13th International Symposium on Biomedical Imaging (ISBI), pp. 1208-1211, (2016); Lumini A., Nanni L., Brahnam S., Multilayer descriptors for medical image classification, Comput. Biol. Med., 72, pp. 239-247, (2016); Khachane M.Y., Ramteke R.J., Modality based medical image classification, Emerging Research in Computing, Information, Communication and Applications, pp. 597-606, (2016); Gao X.W., Hui R., Tian Z., Classification of CT brain images based on deep learning networks, Comput. Methods. Programs Biomed., 138, pp. 49-56, (2017); Arevalo J., Gonzalez F.A., Ramos-Pollan R., Oliveira J.L., Lopez M.A., Representation learning for mammography mass lesion classification with convolutional neural networks, Comput. Methods. Programs Biomed., 127, pp. 248-257, (2016); Long M., Wang J., Jordan M.I., Deep Transfer Learning with Joint Adaptation Networks, (2016); Deng J., Dong W., Socher R., Li L.J., Li K., Fei-Fei L., Imagenet: A large-scale hierarchical image database, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, CVPR, pp. 248-255, (2009); Jia Y., Shelhamer E., Donahue J., Karayev S., Long J., Girshick R., Guadarrama S., Darrell T., Caffe: convolutional architecture for fast feature embedding, Proceedings of the 22nd ACM International Conference on Multimedia, pp. 675-678, (2014); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, pp. 1097-1105, (2012); Goodfellow I.J., Warde-Farley D., Mirza M., Courville A.C., Bengio Y., Maxout networks, Proceedings of International Conference on Machine Learning, ICML, 28, pp. 1319-1327, (2013); Murala S., Wu Q.J., Local mesh patterns versus local binary patterns: biomedical image indexing and retrieval, IEEE J. Biomed. Health Inform., 18, 3, pp. 929-938, (2014); Dubey S.R., Singh S.K., Singh R.K., Local wavelet pattern: a new feature descriptor for image retrieval in medical CT databases, IEEE Trans. Image Proc., 24, 12, pp. 5892-5903, (2015); Odeh S.M., Baareh A.K., A comparison of classification methods as diagnostic system: a case study on skin lesions, Comput. Methods. Programs. Biomed., 137, pp. 311-319, (2016); Dubey S.R., Singh S., Singh R., Local bit-plane decoded pattern: a novel feature descriptor for biomedical image retrieval, IEEE J. Biomed. Health Inform., 20, 4, pp. 1139-1147, (2016)","M.A. Orgun; Department of Computing, Macquarie University, Sydney, 2109, Australia; email: mehmet.orgun@mq.edu.au","","Elsevier Ireland Ltd","","","","","","01692607","","CMPBE","28254085","English","Comput. Methods Programs Biomed.","Article","Final","","Scopus","2-s2.0-85011883667"
