"Authors","Author full names","Author(s) ID","Title","Volume","Issue","Art. No.","Page start","Page end","Page count","DOI","Link","Abstract","Author Keywords","Index Keywords","Funding Details","Publisher","PubMed ID","EID"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","14449 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177829395&partnerID=40&md5=2c68efa2f1a85a474ed80ce2170e721e","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85177829395"
"Apostolopoulos I.D.; Papathanasiou N.D.; Papandrianos N.I.; Papageorgiou E.I.; Panayiotakis G.S.","Apostolopoulos, Ioannis D. (57195641603); Papathanasiou, Nikolaos D. (23995562200); Papandrianos, Nikolaos I. (24779749100); Papageorgiou, Elpiniki I. (56429800100); Panayiotakis, George S. (7006755481)","57195641603; 23995562200; 24779749100; 56429800100; 7006755481","Deep Learning Assessment for Mining Important Medical Image Features of Various Modalities","12","10","2333","","","","10.3390/diagnostics12102333","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140777302&doi=10.3390%2fdiagnostics12102333&partnerID=40&md5=a89512a0ce1f2fb4400dbafd50a79d7c","Deep learning (DL) is a well-established pipeline for feature extraction in medical and nonmedical imaging tasks, such as object detection, segmentation, and classification. However, DL faces the issue of explainability, which prohibits reliable utilisation in everyday clinical practice. This study evaluates DL methods for their efficiency in revealing and suggesting potential image biomarkers. Eleven biomedical image datasets of various modalities are utilised, including SPECT, CT, photographs, microscopy, and X-ray. Seven state-of-the-art CNNs are employed and tuned to perform image classification in tasks. The main conclusion of the research is that DL reveals potential biomarkers in several cases, especially when the models are trained from scratch in domains where low-level features such as shapes and edges are not enough to make decisions. Furthermore, in some cases, device acquisition variations slightly affect the performance of DL models. © 2022 by the authors.","biomarkers; deep learning; feature extraction; medical imaging","area under the curve; Article; classification algorithm; clinical article; computer assisted tomography; congenital skin disease; convolutional neural network; coronary artery disease; coronavirus disease 2019; data mining; deep learning; diagnostic accuracy; diagnostic imaging; diagnostic value; disease marker; feature extraction; gradient weighted class activation mapping; human; image processing; lung nodule; myocardial perfusion imaging; photography; positron emission tomography-computed tomography; prostate cancer; radiography; residual neural network; sensitivity and specificity; single photon emission computed tomography; skin cancer","Second Call for H.F.R.I., (3656); Hellenic Foundation for Research and Innovation, ΕΛ.ΙΔ.Ε.Κ","Multidisciplinary Digital Publishing Institute (MDPI)","","2-s2.0-85140777302"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","1965 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178596621&partnerID=40&md5=19f437f49d9e65ba67b8d9c5dfb5867d","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178596621"
"Zidane M.; Makky A.; Bruhns M.; Rochwarger A.; Babaei S.; Claassen M.; Schürch C.M.","Zidane, Mohammed (58251599200); Makky, Ahmad (58076474600); Bruhns, Matthias (58534904300); Rochwarger, Alexander (58096322800); Babaei, Sepideh (57221709578); Claassen, Manfred (26640261400); Schürch, Christian M. (26642210200)","58251599200; 58076474600; 58534904300; 58096322800; 57221709578; 26640261400; 26642210200","Corrigendum: A review on deep learning applications in highly multiplexed tissue imaging data analysis (Front. Bioinform., (2023), 3, 1159381, 10.3389/fbinf.2023.1159381)","3","","1287407","","","","10.3389/fbinf.2023.1287407","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174854913&doi=10.3389%2ffbinf.2023.1287407&partnerID=40&md5=0fd80dad07ad512a9fc94f4ad14f9ff2","In the published article, there was an error. “The abstract is duplicated.” A correction has been made to Abstract. This sentence previously stated: “Since its introduction into the field of oncology, deep learning (DL) has impacted clinical discoveries and biomarker predictions. DL-driven discoveries and predictions in oncology are based on a variety of biological data such as genomics, proteomics, and imaging data. DL-based computational frameworks can predict genetic variant effects on gene expression, as well as protein structures based on amino acid sequences. Furthermore, DL algorithms can capture valuable mechanistic biological information from several spatial “omics” technologies, such as spatial transcriptomics and spatial proteomics. Here, we review the impact that the combination of artificial intelligence (AI) with spatial omics technologies has had on oncology, focusing on DL and its applications in biomedical image analysis, encompassing cell segmentation, cell phenotype identification, cancer prognostication, and therapy prediction. We highlight the advantages of using highly multiplexed images (spatial proteomics data) compared to single-stained, conventional histopathological (“simple”) images, as the former can provide deep mechanistic insights that cannot be obtained by the latter, even with the aid of explainable AI. Furthermore, we provide the reader with the advantages/disadvantages of DL-based pipelines used in preprocessing highly multiplexed images (cell segmentation, cell type annotation). Therefore, this review also guides the reader to choose the DLbased pipeline that best fits their data. In conclusion, DL continues to be established as an essential tool in discovering novel biological mechanisms when combined with technologies such as highly multiplexed tissue imaging data. In balance with conventional medical data, its role in clinical routine will become more important, supporting diagnosis and prognosis in oncology, enhancing clinical decision-making, and improving the quality of care for patients. Since its introduction into the field of oncology, deep learning (DL) has impacted clinical discoveries and biomarker predictions. DL-driven discoveries and predictions in oncology are based on a variety of biological data such as genomics, proteomics, and imaging data. DL-based computational frameworks can predict genetic variant effects on gene expression, as well as protein structures based on amino acid sequences. Furthermore, DL algorithms can capture valuable mechanistic biological information from several spatial “omics” technologies, such as spatial transcriptomics and spatial proteomics. Here, we review the impact that the combination of artificial intelligence (AI) with spatial omics technologies has had on oncology, focusing on DL and its applications in biomedical image analysis, encompassing cell segmentation, cell phenotype identification, cancer prognostication, and therapy prediction. We highlight the advantages of using highly multiplexed images (spatial proteomics data) compared to single-stained, conventional histopathological (“simple”) images, as the former can provide deep mechanistic insights that cannot be obtained by the latter, even with the aid of explainable AI. Furthermore, we provide the reader with the advantages/ disadvantages of the DL-based pipelines used in preprocessing the highly multiplexed images (cell segmentation, cell type annotation). Therefore, this review also guides the reader to choose the DL-based pipeline that best fits their data. In conclusion, DL continues to be established as an essential tool in discovering novel biological mechanisms when combined with technologies such as highly multiplexed tissue imaging data. In balance with conventional medical data, its role in clinical routine will become more important, supporting diagnosis and prognosis in oncology, enhancing clinical decision-making, and improving the quality of care for patients.” The corrected sentence appears below: “Since its introduction into the field of oncology, deep learning (DL) has impacted clinical discoveries and biomarker predictions. DL-driven discoveries and predictions in oncology are based on a variety of biological data such as genomics, proteomics, and imaging data. DL-based computational frameworks can predict genetic variant effects on gene expression, as well as protein structures based on amino acid sequences. Furthermore, DL algorithms can capture valuable mechanistic biological information from several spatial “omics” technologies, such as spatial transcriptomics and spatial proteomics. Here, we review the impact that the combination of artificial intelligence (AI) with spatial omics technologies has had on oncology, focusing on DL and its applications in biomedical image analysis, encompassing cell segmentation, cell phenotype identification, cancer prognostication, and therapy prediction. We highlight the advantages of using highly multiplexed images (spatial proteomics data) compared to single-stained, conventional histopathological (“simple”) images, as the former can provide deep mechanistic insights that cannot be obtained by the latter, even with the aid of explainable AI. Furthermore, we provide the reader with the advantages/disadvantages of DL-based pipelines used in preprocessing highly multiplexed images (cell segmentation, cell type annotation). Therefore, this review also guides the reader to choose the DL-based pipeline that best fits their data. In conclusion, DL continues to be established as an essential tool in discovering novel biological mechanisms when combined with technologies such as highly multiplexed tissue imaging data. In balance with conventional medical data, its role in clinical routine will become more important, supporting diagnosis and prognosis in oncology, enhancing clinical decision-making, and improving the quality of care for patients.” In the published article, there was an error. “the word ‘recently’ is repeated.” A correction has been made to Applications in highly multiplexed images, [paragraph 3]. This sentence previously stated: “Recently, Graph Neural Networks (GNNs) (Scarselli et al., 2009) were recently used to model the TME.” The corrected sentence appears below: “Recently, Graph Neural Networks (GNNs) (Scarselli et al., 2009) were used to model the TME.” In the published article, there was an error. “the term ‘convolutional neural network’ is repeated”. A correction has been made to Applications in conventional medical (“simple”) images, [paragraph 5]. This sentence previously stated: “The DL-based framework consists of two neural networks: a convolutional neural network: a convolutional neural network CNN (pre-trained GoogleNet on ImageNet), which was trained on the CT scans to extract the important features from lesions of different organs, and a recurrent neural network RNN which learned the changes happening in these lesions across multiple time points.” The corrected sentence appears below: “The DL-based framework consists of two neural networks: a convolutional neural network CNN (pre-trained GoogleNet on ImageNet), which was trained on the CT scans to extract the important features from lesions of different organs, and a recurrent neural network RNN which learned the changes happening in these lesions across multiple time points.” In the published article, there was an error. “two references are not written as a hyperlink; it is just a number that you cannot click on”. A correction has been made to reference (148) in Table 1 is not a hyperlink and reference (171) in Table 3. Both references are written as numbers not as hyperlinks. This sentence previously stated: “Could be combined with TrackMate (148) for cell tracking in Table 1.” “Map snRNA-seq data to spatial data of different resolutions, ISH associated with histological and anatomical coordinates, midresolution Spatial Transcriptomics, and high-resolution STARmap (171) and MERFISH in Table 3.” The corrected sentence appears below: “They should be hyperlinks.” The authors apologize for these errors and state that this does not change the scientific conclusions of the article in any way. The original article has been updated. Copyright © 2023 Zidane, Makky, Bruhns, Rochwarger, Babaei, Claassen and Schürch.","artificial intelligence; biomarker; cancer; deep learning; highly multiplexed tissue imaging; prediction; review; spatial transcriptomics","","","Frontiers Media SA","","2-s2.0-85174854913"
"Woessner A.E.; Anjum U.; Salman H.; Lear J.; Turner J.T.; Campbell R.; Beaudry L.; Zhan J.; Cornett L.E.; Gauch S.; Quinn K.P.","Woessner, Alan E. (57202230415); Anjum, Usman (57367380200); Salman, Hadi (57526140800); Lear, Jacob (58848242400); Turner, Jeffrey T. (59233896100); Campbell, Ross (57204853222); Beaudry, Laura (59231463000); Zhan, Justin (59233555300); Cornett, Lawrence E. (7004305090); Gauch, Susan (6602196195); Quinn, Kyle P. (16647213500)","57202230415; 57367380200; 57526140800; 58848242400; 59233896100; 57204853222; 59231463000; 59233555300; 7004305090; 6602196195; 16647213500","Identifying and training deep learning neural networks on biomedical-related datasets","25","","bbae232","","","","10.1093/bib/bbae232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199492909&doi=10.1093%2fbib%2fbbae232&partnerID=40&md5=aaa77e45465e75e2c5cea912d90afc82","This manuscript describes the development of a resources module that is part of a learning platform named ‘NIGMS Sandbox for Cloud-based Learning’ https://github.com/NIGMS/NIGMS-Sandbox. The overall genesis of the Sandbox is described in the editorial NIGMS Sandbox at the beginning of this Supplement. This module delivers learning materials on implementing deep learning algorithms for biomedical image data in an interactive format that uses appropriate cloud resources for data access and analyses. Biomedical-related datasets are widely used in both research and clinical settings, but the ability for professionally trained clinicians and researchers to interpret datasets becomes difficult as the size and breadth of these datasets increases. Artificial intelligence, and specifically deep learning neural networks, have recently become an important tool in novel biomedical research. However, use is limited due to their computational requirements and confusion regarding different neural network architectures. The goal of this learning module is to introduce types of deep learning neural networks and cover practices that are commonly used in biomedical research. This module is subdivided into four submodules that cover classification, augmentation, segmentation and regression. Each complementary submodule was written on the Google Cloud Platform and contains detailed code and explanations, as well as quizzes and challenges to facilitate user training. Overall, the goal of this learning module is to enable users to identify and integrate the correct type of neural network with their data while highlighting the ease-of-use of cloud computing for implementing neural networks. This manuscript describes the development of a resource module that is part of a learning platform named “NIGMS Sandbox for Cloud-based Learning” https://github.com/NIGMS/NIGMS-Sandbox. The overall genesis of the Sandbox is described in the editorial NIGMS Sandbox [1] at the beginning of this Supplement. This module delivers learning materials on the analysis of bulk and single-cell ATACseq data in an interactive format that uses appropriate cloud resources for data access and analyses. © The Author(s) 2024. Published by Oxford University Press.","artificial intelligence; biomedical research; cloud-based computing; deep learning; engineering education","Algorithms; Biomedical Research; Cloud Computing; Deep Learning; Humans; Neural Networks, Computer; algorithm; artificial neural network; cloud computing; deep learning; human; medical research","National Institute of General Medical Sciences, NIGMS, (3P20GM103429-21S2); National Institute of General Medical Sciences, NIGMS; Arkansas Integrative Metabolic Research Center, (P20GM139768); National Institutes of Health, NIH, (R01AG056560, R01EB031032); National Institutes of Health, NIH","Oxford University Press","39041915","2-s2.0-85199492909"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","1967 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180334873&partnerID=40&md5=16d85a38e9dcfbace5d1b62acb39bd6e","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85180334873"
"Valanarasu J.M.J.; Sindagi V.A.; Hacihaliloglu I.; Patel V.M.","Valanarasu, Jeya Maria Jose (57219450328); Sindagi, Vishwanath A. (56829595000); Hacihaliloglu, Ilker (24467768400); Patel, Vishal M. (56660008900)","57219450328; 56829595000; 24467768400; 56660008900","KiU-Net: Overcomplete Convolutional Architectures for Biomedical Image and Volumetric Segmentation","41","4","","965","976","11","10.1109/TMI.2021.3130469","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120042907&doi=10.1109%2fTMI.2021.3130469&partnerID=40&md5=eefa38c45acc8d157806cf40dddf3b17","Most methods for medical image segmentation use U-Net or its variants as they have been successful in most of the applications. After a detailed analysis of these 'traditional' encoder-decoder based approaches, we observed that they perform poorly in detecting smaller structures and are unable to segment boundary regions precisely. This issue can be attributed to the increase in receptive field size as we go deeper into the encoder. The extra focus on learning high level features causes U-Net based approaches to learn less information about low-level features which are crucial for detecting small structures. To overcome this issue, we propose using an overcomplete convolutional architecture where we project the input image into a higher dimension such that we constrain the receptive field from increasing in the deep layers of the network. We design a new architecture for im- age segmentation- KiU-Net which has two branches: (1) an overcomplete convolutional network Kite-Net which learns to capture fine details and accurate edges of the input, and (2) U-Net which learns high level features. Furthermore, we also propose KiU-Net 3D which is a 3D convolutional architecture for volumetric segmentation. We perform a detailed study of KiU-Net by performing experiments on five different datasets covering various image modalities. We achieve a good performance with an additional benefit of fewer parameters and faster convergence. We also demonstrate that the extensions of KiU-Net based on residual blocks and dense blocks result in further performance improvements. Code: https://github.com/jeya-maria-jose/KiU-Net-pytorch © 1982-2012 IEEE.","deep learning; Medical image segmentation; overcomplete representations","Image Processing, Computer-Assisted; Neural Networks, Computer; Computer architecture; Convolution; Deep learning; Diagnosis; Image segmentation; Medical imaging; Network architecture; Network layers; Signal encoding; Three dimensional displays; Deep learning; Features extraction; Images segmentations; Learn+; Medical diagnostic imaging; Medical image segmentation; Over-complete; Over-complete representations; Three-dimensional display; Volumetric segmentations; Article; clinical article; convolutional neural network; deep learning; echoencephalography; feature extraction; glioblastoma; glioma; human; image processing; image segmentation; liver tumor; neuroanatomy; newborn; nuclear magnetic resonance imaging; qualitative analysis; quantitative analysis; receptive field; segmentation algorithm; image processing; procedures; Feature extraction","","Institute of Electrical and Electronics Engineers Inc.","34813472","2-s2.0-85120042907"
"Khan R.U.; Almakdi S.; Alshehri M.; Haq A.U.; Ullah A.; Kumar R.","Khan, Riaz Ullah (57202445169); Almakdi, Sultan (57211498975); Alshehri, Mohammed (57210193521); Haq, Amin Ul (59157731200); Ullah, Aman (57208471108); Kumar, Rajesh (58488212700)","57202445169; 57211498975; 57210193521; 59157731200; 57208471108; 58488212700","An intelligent neural network model to detect red blood cells for various blood structure classification in microscopic medical images","10","4","e26149","","","","10.1016/j.heliyon.2024.e26149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187303011&doi=10.1016%2fj.heliyon.2024.e26149&partnerID=40&md5=adad2207a4666da4c8a5340283f9cd09","Biomedical image analysis plays a crucial role in enabling high-performing imaging and various clinical applications. For the proper diagnosis of blood diseases related to red blood cells, red blood cells must be accurately identified and categorized. Manual analysis is time-consuming and prone to mistakes. Analyzing multi-label samples, which contain clusters of cells, is challenging due to difficulties in separating individual cells, such as touching or overlapping cells. High-performance biomedical imaging and several medical applications are made possible by advanced biosensors. We develop an intelligent neural network model that can automatically identify and categorize red blood cells from microscopic medical images using region-based convolutional neural networks (RCNN) and cutting-edge biosensors. Our model successfully navigates obstacles like touching or overlapping cells and accurately recognizes various blood structures. Additionally, we utilized data augmentation as a pre-processing method on microscopic images to enhance the model's computational efficiency and expand the sample size. To refine the data and eliminate noise from the dataset, we utilized the Radial Gradient Index filtering algorithm for imaging data equalization. We exhibit improved detection accuracy and a reduced model loss rate when using medical imagery datasets to apply our proposed model in comparison to existing ResNet and GoogleNet models. Our model precisely detected red blood cells in a collection of medical images with 99% training accuracy and 91.21% testing accuracy. Our proposed model outperformed earlier models like ResNet-50 and GoogleNet by 10-15%. Our results demonstrated that Artificial intelligence (AI)-assisted automated red blood cell detection has the potential to revolutionize and speed up blood cell analysis, minimizing human error and enabling early illness diagnosis. © 2024 The Author(s)","Deep learning; Image processing; Object detection; RBC detection","","University of Electronic Science and Technology of China, UESTC, (U03210068); University of Electronic Science and Technology of China, UESTC; Deanship of Scientific Research, University of Jordan, DSR, (NU/RG/SERC/12/3); Deanship of Scientific Research, University of Jordan, DSR","Elsevier Ltd","","2-s2.0-85187303011"
"Shchetinin E.Y.; Glushkova A.G.; Blinkov Y.A.","Shchetinin, Eugene Yu. (16408533100); Glushkova, Anastasia G. (57485591900); Blinkov, Yury A. (6701893186)","16408533100; 57485591900; 6701893186","On Effectiveness of the Adversarial Attacks on the Computer Systems of Biomedical Images Classification","1748 CCIS","","","91","103","12","10.1007/978-3-031-30648-8_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161391475&doi=10.1007%2f978-3-031-30648-8_8&partnerID=40&md5=1be7cdf52aeacb41c838831351b7b3da","The problems of vulnerability of the computer systems of biomedical images classification to adversarial attacks on are investigated. The aim of the work is to study the effectiveness of the impact of various models of adversarial attacks on biomedical images and the values of control parameters of algorithms for generating their attacking versions. The effectiveness of attacks prepared using the projected gradient descent algorithm (PGD), Deep Fool (DF) algorithm and Carlini-Wagner algorithm (CW) is investigated. Experimental studies were carried out on the example of solving typical problems of medical images classification using deep neural networks VGG16, EfficientNetB2, DenseNet121, Xception, ResNet50 as well as data containing chest X-rays images and brain MRI-scan images. Our findings in this work are as follows. Deep models were very susceptible to adversarial attacks, which led to decrease of the accuracy classification of the models for all datasets. Prior to the use of adversarial methods, we achieved a classification accuracy of 93.6% for brain MRI and 99.1% for chest X-rays. During the DF attack the accuracy of the VGG16 model showed a maximum absolute decrease of 49.8% for MRI-scans, and 57.3% for chest X-rays images. The gradient descent (PGD) algorithm with the same values of malicious image disturbances is less effective than the DF and the CW adversarial attacks. VGG16 deep model is more effective in accuracy classification on considered datasets and most vulnerable to adversarial attacks among other deep models. We hope that these results would be useful to design more robust and secure medical deep learning systems. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","adversarial attacks; black-box attack; brain tumor MRI-scans; chest X-ray images; deep learning; white-box attacks","Bioinformatics; Deep neural networks; Gradient methods; Image classification; Learning systems; Magnetic resonance imaging; Medical imaging; Medical problems; Adversarial attack; Black boxes; Black-box attack; Brain tumor MRI-scan; Brain tumors; Chest X-ray image; Deep learning; MRI scan; White box; White-box attack; Classification (of information)","RUDN University","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85161391475"
"Mishra A.K.; Gupta I.K.; Diwan T.D.; Srivastava S.","Mishra, Awanish Kumar (57222248739); Gupta, Indresh Kumar (57188752252); Diwan, Tarun Dhar (57195319554); Srivastava, Swati (57198632001)","57222248739; 57188752252; 57195319554; 57198632001","Cervical precancerous lesion classification using quantum invasive weed optimization with deep learning on biomedical pap smear images","41","7","e13308","","","","10.1111/exsy.13308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158055678&doi=10.1111%2fexsy.13308&partnerID=40&md5=07f0811a97227eda45c6eebe7a88a959","Biomedical imaging devices, in general, have been made and used a lot lately to examine the insides of the body during diagnostic and analytic procedures. Biomedical imaging gives accurate information about metabolites, which can be used to find and classify diseases because it is not invasive. For the study of cervical cancer (CC), the pap smear is a crucial type of biological imaging. CC is a crucial reason to enhance the rate of women's mortalities. Proper screening of pap smear images is critical for assisting in the early detection and analysis of CC. Computer-aided systems for cancerous cell recognition need well established artificial intelligence (AI) methods. In this study, we introduce an automated Cervical Precancerous Lesion Classification using Quantum Invasive Weed Optimization with Deep Learning (CPLC-QIWODL) on biomedical pap smear images. The presented CPLC-QIWODL technique examines the pap smear images for cervical cancer classification. To do so, the presented CPLC-QIWODL technique pre-processes the biomedical images using a Gabor filtering (GF) approach. Moreover, the CPLC-QIWODL technique uses a deep convolutional neural network-based SqueezeNet system for feature extraction. Furthermore, the hyperparameter tuning of the SqueezeNet methodology takes place using the QIWO technique, showing the novelty of the work. Finally, to classify CC, the deep variational autoencoder (DVAE) model is applied. The experimental result analysis of the CPLC-QIWODL technique is tested using a benchmark medical image database. Extensive comparative results demonstrated the enhanced outcomes of the CPLC-QIWODL technique over other existing algorithms, with a maximum accuracy of 99.07%. © 2023 John Wiley & Sons Ltd.","artificial intelligence; biomedical imaging; cervical cancer; metaheuristics; pap smear images","Classification (of information); Computer aided analysis; Computer aided diagnosis; Deep neural networks; Diseases; Image analysis; Image classification; Learning systems; Medical imaging; Metabolites; Biological imaging; Biomedical imaging; Cervical cancers; Imaging device; Invasive weed optimization; Learning techniques; Lesion classification; Metaheuristic; Pap smear; Pap smear images; Invasive weed optimization","","John Wiley and Sons Inc","","2-s2.0-85158055678"
"Naeem A.; Anees T.; Fiza M.; Naqvi R.A.; Lee S.-W.","Naeem, Ahmad (57215772535); Anees, Tayyaba (50461069100); Fiza, Makhmoor (57853673900); Naqvi, Rizwan Ali (55975847900); Lee, Seung-Won (57223118056)","57215772535; 50461069100; 57853673900; 55975847900; 57223118056","SCDNet: A Deep Learning-Based Framework for the Multiclassification of Skin Cancer Using Dermoscopy Images","22","15","5652","","","","10.3390/s22155652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136341545&doi=10.3390%2fs22155652&partnerID=40&md5=e88839a56ed44629475b2fc55ce2fb19","Skin cancer is a deadly disease, and its early diagnosis enhances the chances of survival. Deep learning algorithms for skin cancer detection have become popular in recent years. A novel framework based on deep learning is proposed in this study for the multiclassification of skin cancer types such as Melanoma, Melanocytic Nevi, Basal Cell Carcinoma and Benign Keratosis. The proposed model is named as SCDNet which combines Vgg16 with convolutional neural networks (CNN) for the classification of different types of skin cancer. Moreover, the accuracy of the proposed method is also compared with the four state-of-the-art pre-trained classifiers in the medical domain named Resnet 50, Inception v3, AlexNet and Vgg19. The performance of the proposed SCDNet classifier, as well as the four state-of-the-art classifiers, is evaluated using the ISIC 2019 dataset. The accuracy rate of the proposed SDCNet is 96.91% for the multiclassification of skin cancer whereas, the accuracy rates for Resnet 50, Alexnet, Vgg19 and Inception-v3 are 95.21%, 93.14%, 94.25% and 92.54%, respectively. The results showed that the proposed SCDNet performed better than the competing classifiers. © 2022 by the authors.","automated/computer aided diagnosis; biomedical image; melanoma; skin cancer; transfer learning","Deep Learning; Dermoscopy; Humans; Melanoma; Neural Networks, Computer; Skin Neoplasms; Classification (of information); Convolutional neural networks; Deep learning; Dermatology; Diseases; Learning algorithms; Oncology; Transfer learning; Accuracy rate; Automated/computer aided diagnose; Biomedical images; Dermoscopy images; Early diagnosis; Melanoma; Multi-classification; Skin cancers; State of the art; Transfer learning; diagnostic imaging; epiluminescence microscopy; human; melanoma; pathology; procedures; skin tumor; Computer aided diagnosis","Ministry of Science, ICT and Future Planning, MSIP, (NRF2021R1I1A2059735, NRF2022R1G1A101022611); National Research Foundation of Korea, NRF","MDPI","35957209","2-s2.0-85136341545"
"de Freitas Barbosa V.A.; Félix da Silva A.; de Santana M.A.; Rabelo de Azevedo R.; Fernandes de Lima R.D.C.; dos Santos W.P.","de Freitas Barbosa, Valter Augusto (57201760368); Félix da Silva, Anderson (57894860500); de Santana, Maíra Araújo (57211919598); Rabelo de Azevedo, Rian (57894860600); Fernandes de Lima, Rita de Cássia (8986453100); dos Santos, Wellington Pinheiro (57193746428)","57201760368; 57894860500; 57211919598; 57894860600; 8986453100; 57193746428","Deep-Wavelets and convolutional neural networks to support breast cancer diagnosis on thermography images","11","3","","895","913","18","10.1080/21681163.2022.2118174","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138268240&doi=10.1080%2f21681163.2022.2118174&partnerID=40&md5=84c3cf6717c0528b6b0a3920a75acd50","Breast cancer is the most dangerous type of cancer and one of the most lethal for women, both in underdeveloped and central countries. Breast thermography is an emerging imaging technique that can be applied as a complementary procedure for screening breast lesions. However, the low knowledge about the interpretation of these images by mastologists makes it difficult to adopt them in clinical practice. Computer-aided detection (CAD) systems can assist medical professionals in this task. Deep learning techniques have contributed to obtaining good results in the classification of biomedical images in general. In this work, we propose Deep-Wavelet Neural Networks (DWNN), convolutional architectures based on the general theory of Wavelets to extract features from images. For classification of thermographic images, we propose hybrid architectures based on deep network for feature extraction, Random Forests for selection of the most statistically relevant features and linear kernel support vector machines for final layer classification. We compare DWNN with next-gen deep networks. Our dataset consists of 336 thermographic images, classified into healthy (no lesion), cyst, benign lesion and malignant lesion. Experimental results show that the 6-layer DWNN achieved accuracy, sensitivity, specificity, kappa and precision above 98%. These results show that DWNN are competitive deep architectures that can be used to optimise thermographic image analysis and clinical adoption. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","breast cancer diagnosis; convolutional neural networks; Deep-Wavelet Neural Networks; Hybrid deep architectures; image diagnosis","Computer aided diagnosis; Computer aided instruction; Convolution; Decision trees; Deep neural networks; Diseases; Feature extraction; Image classification; Learning systems; Medical imaging; Network architecture; Support vector machines; Thermography (imaging); Architecture-based; Breast Cancer; Breast cancer diagnosis; Breast lesion; Convolutional neural network; Deep architectures; Deep-wavelet neural network; Hybrid deep architecture; Image diagnosis; Neural-networks; Article; breast cancer; cancer diagnosis; classifier; clinical decision making; clinical practice; computer assisted tomography; controlled study; convolutional neural network; cross validation; deep learning; deep neural network; diagnostic test accuracy study; feature extraction; female; high throughput sequencing; human; image segmentation; inception v3; learning algorithm; machine learning; mathematical analysis; measurement accuracy; mobilenet neural network; neighborhood; random forest; residual neural network; sensitivity and specificity; support vector machine; thermography; very deep convolutional network; wavelet analysis; xception nerual network; Convolutional neural networks","CAPES-PPGEC-UPE-2020; CNPq-DT2-2021; Ci?ncia e Tecnologia do Estado de Pernambuco, (IBPG-PPGEC-UPE-2020); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior, CAPES; Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq; Fundação de Amparo à Ciência e Tecnologia do Estado de Pernambuco, FACEPE; Universidade de Pernambuco, UPE, (PPGEC-UPE-2020); Universidade de Pernambuco, UPE","Taylor and Francis Ltd.","","2-s2.0-85138268240"
"Pradhan A.K.; Das K.; Mishra D.; Chithaluru P.","Pradhan, Ashwini Kumar (57223054673); Das, Kaberi (57210528390); Mishra, Debahuti (35070028500); Chithaluru, Premkumar (57201708482)","57223054673; 57210528390; 35070028500; 57201708482","Optimizing CNN-LSTM hybrid classifier using HCA for biomedical image classification","40","5","e13235","","","","10.1111/exsy.13235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147220372&doi=10.1111%2fexsy.13235&partnerID=40&md5=1adc130c8bfea14dd807c881a0b1023a","In medical science, imaging is the most effective diagnostic and therapeutic tool. Almost all modalities have transitioned to direct digital capture devices, which have emerged as a major future healthcare option. Three diseases such as Alzheimer's (AD), Haemorrhage (HD), and COVID-19 have been used in this manuscript for binary classification purposes. Three datasets (AD, HD, and COVID-19) were used in this research out of which the first two, that is, AD and HD belong to brain Magnetic Resonance Imaging (MRI) and the last one, that is, COVID-19 belongs to Chest X-Ray (CXR) All of the diseases listed above cannot be eliminated, but they can be slowed down with early detection and effective medical treatment. This paper proposes an intelligent method for classifying brain (MRI) and CXR images into normal and abnormal classes for the early detection of AD, HD, and COVID-19 based on an ensemble deep neural network (DNN). In the proposed method, the convolutional neural network (CNN) is used for automatic feature extraction from images and long-short term memory (LSTM) is used for final classification. Moreover, the Hill-Climbing Algorithm (HCA) is implemented for finding the best possible value for hyper parameters of CNN and LSTM, such as the filter size of CNN and the number of units of LSTM while fixing the other parameters. The data-set is pre-processed (resized, cropped, and noise removed) before feeding the train images to the proposed models for accurate and fast learning. Forty-five MR images of AD, Sixty MR images of HD, and 600 CXR images of COVID-19 were used for testing the proposed model ‘CNN-LSTM-HCA’. The performance of the proposed model is evaluated using six types of statistical assessment metrics such as; Accuracy, Sensitivity, Specificity, F-measure, ROC, and AUC. The proposed model compared with the other three types of hybrid models such as CNN-LSTM-PSO, CNN-LSTM-Jaya, and CNN-LSTM-GWO and also with state-of-art techniques. The overall accuracy of the proposed model received was 98.87%, 85.75%, and 99.1% for COVID-19, Haemorrhage, and Alzheimer's data sets, respectively. © 2023 John Wiley & Sons Ltd.","Alzheimer disease; CNN; COVID-19; CXR; deep learning; Haemorrhage disease; LSTM","Biomedical signal processing; Convolutional neural networks; Deep neural networks; Diagnosis; Digital devices; Image classification; Long short-term memory; Magnetic resonance imaging; Medical imaging; Neurodegenerative diseases; Optimization; Alzheimer; Alzheimers disease; Chest X-ray; Chest X-ray image; Convolutional neural network; Data set; Deep learning; Haemorrage; Hemorrhage disease; Hill-Climbing algorithm; COVID-19","","John Wiley and Sons Inc","","2-s2.0-85147220372"
"Obayya M.; Haj Hassine S.B.; Alazwari S.; K. Nour M.; Mohamed A.; Motwakel A.; Yaseen I.; Sarwar Zamani A.; Abdelmageed A.A.; Mohammed G.P.","Obayya, Marwa (6505869929); Haj Hassine, Siwar Ben (57556207300); Alazwari, Sana (57867288800); K. Nour, Mohamed (57885708800); Mohamed, Abdullah (57213606201); Motwakel, Abdelwahed (57103616300); Yaseen, Ishfaq (57410292800); Sarwar Zamani, Abu (57295189700); Abdelmageed, Amgad Atta (57876641300); Mohammed, Gouse Pasha (57886165200)","6505869929; 57556207300; 57867288800; 57885708800; 57213606201; 57103616300; 57410292800; 57295189700; 57876641300; 57886165200","Aquila Optimizer with Bayesian Neural Network for Breast Cancer Detection on Ultrasound Images","12","17","8679","","","","10.3390/app12178679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137843061&doi=10.3390%2fapp12178679&partnerID=40&md5=b463627ced7ee2bfa675a2a3c4b892a5","Breast cancer is the second most dominant kind of cancer among women. Breast Ultrasound images (BUI) are commonly employed for the detection and classification of abnormalities that exist in the breast. The ultrasound images are necessary to develop artificial intelligence (AI) enabled diagnostic support technologies. For improving the detection performance, Computer Aided Diagnosis (CAD) models are useful for breast cancer detection and classification. The current advancement of the deep learning (DL) model enables the detection and classification of breast cancer with the use of biomedical images. With this motivation, this article presents an Aquila Optimizer with Bayesian Neural Network for Breast Cancer Detection (AOBNN-BDNN) model on BUI. The presented AOBNN-BDNN model follows a series of processes to detect and classify breast cancer on BUI. To accomplish this, the AOBNN-BDNN model initially employs Wiener filtering (WF) related noise removal and U-Net segmentation as a pre-processing step. Besides, the SqueezeNet model derives a collection of feature vectors from the pre-processed image. Next, the BNN algorithm will be utilized to allocate appropriate class labels to the input images. Finally, the AO technique was exploited to fine-tune the parameters related to the BNN method so that the classification performance is improved. To validate the enhanced performance of the AOBNN-BDNN method, a wide experimental study is executed on benchmark datasets. A wide-ranging experimental analysis specified the enhancements of the AOBNN-BDNN method in recent techniques. © 2022 by the authors.","Aquila Optimizer; Bayesian Neural Network; breast cancer; medical images; ultrasound images","","Abdulrahman University, (PNURSP2022R203); Deanship of Scientific Research at Umm Al-Qura University, (22UQU4310373DSR31); Princess Nourah Bint Abdulrahman University, PNU; Deanship of Scientific Research, King Faisal University, DSR, KFU, (25/43)","MDPI","","2-s2.0-85137843061"
"Bose S.; Sur Chowdhury R.; Das R.; Maulik U.","Bose, Shirsha (57639719800); Sur Chowdhury, Ritesh (57230114200); Das, Rangan (57215627205); Maulik, Ujjwal (6603607810)","57639719800; 57230114200; 57215627205; 6603607810","Dense Dilated Deep Multiscale Supervised U-Network for biomedical image segmentation","143","","105274","","","","10.1016/j.compbiomed.2022.105274","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123837775&doi=10.1016%2fj.compbiomed.2022.105274&partnerID=40&md5=3b7826f5186811ab8949e135692c0509","Biomedical image segmentation is essential for computerized medical image analysis. Deep learning algorithms allow us to design state-of-the-art models for solving segmentation problems. The U-Net and its variants have provided positive results across various datasets. However, the existing networks have the same receptive field at each level and the models are supervised only at the shallow level. Considering these two ideas, we have proposed the D3MSU-Net where the field of view in each level is varied depending upon the depth of the resolution layer and the model is supervised at each resolution level. We have evaluated our network in eight benchmark datasets such as Electron Microscopy, Lung segmentation, Montgomery Chest X-ray, Covid-Radiopaedia, Wound, Medetec, Brain MRI, and Covid-19 lung CT dataset. Additionally, we have provided the performance for various ablations. The experimental results show the superiority of the proposed network. The proposed D3MSU-Net and ablation models are available at www.github.com/shirshabose/D3MSUNET. © 2022 Elsevier Ltd","Biomedical image segmentation; Deep learning; Deep multiscale supervision; Dense dilated convolution","Biological organs; Computerized tomography; Deep learning; Image segmentation; Learning algorithms; Magnetic resonance imaging; Medical imaging; ART model; Biomedical image segmentation; Deep learning; Deep multiscale supervision; Dense dilated convolution; Design state; Medical image analysis; Receptive fields; Shallow levels; State of the art; Article; brain; computer assisted tomography; controlled study; convolutional neural network; coronavirus disease 2019; deep learning; diagnostic imaging; electron microscopy; human; image segmentation; intermethod comparison; medical photography; nuclear magnetic resonance imaging; supervised machine learning; thorax radiography; three-dimensional imaging; Ablation","","Elsevier Ltd","35123135","2-s2.0-85123837775"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","1964 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178598232&partnerID=40&md5=efc2e5f9beece0459200cd1145901a6d","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178598232"
"Asif S.; Qurrat-ul-Ain; Awais M.; Khan S.U.R.","Asif, Sohaib (57221248320); Qurrat-ul-Ain (58179973500); Awais, Muhammad (59276254700); Khan, Saif Ur Rehman (58836834300)","57221248320; 58179973500; 59276254700; 58836834300","IR-CNN: Inception residual network for detecting kidney abnormalities from CT images","12","1","35","","","","10.1007/s13721-023-00431-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171877377&doi=10.1007%2fs13721-023-00431-4&partnerID=40&md5=e700067af39abaad0cb7f9c0215ae2a6","Kidney abnormalities are a public health problem and a common disease with adverse effects such as kidney damage. Due to the shortage of nephrologists worldwide, detecting these abnormalities are expensive and time consuming. Thus, deep learning (DL) techniques can help clinicians to automate the diagnosis of kidney diseases. However, achieving better performance is still a challenge in kidney disease detection. In this study, we propose an efficient architecture “IR-CNN” based on the Inception residual network for the detection of three major kidney diseases, tumor, kidney stone and cyst, using CT images. We customized the top layer of InceptionResNetV2 and further added global average pooling (GAP), batch normalization (BN), dropout and dense layers with swish activation functions to extract robust features, avoid vanishing gradient problems and achieve better accuracy in detecting kidney disease. The proposed IR-CNN model was trained and tested on a publicly available kidney CT dataset with 4000 images using different optimizers (Adam, SGD, and RMSprop). Experimental results show that IR-CNN achieves 99.38%, 94.63%, 97.38% using Adam, SGD and RMSprop optimizers, respectively. In addition, IR-CNN with Adam optimizer achieved better performance with only 5 misclassifications out of 800 test images and performed better than existing methods in diagnosing kidney disease. The superior results of our IR-CNN architecture can help urologists diagnose kidney disease, thereby reducing human error. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature.","Biomedical image analysis; Deep learning; Inception residual network; Kidney abnormalities; Kidney disease detection","Computerized tomography; Deep learning; Network architecture; Biomedical image analysis; CT Image; Deep learning; Disease detection; Inception residual network; Kidney abnormality; Kidney disease; Kidney disease detection; Optimizers; Performance; accuracy; Article; augmentation index; classification algorithm; computer assisted tomography; convolutional neural network; cyst; deep learning; feature extraction; global average pooling; human; image analysis; image segmentation; kidney disease; kidney injury; kidney malformation; learning; learning algorithm; machine learning; medical research; nephrolithiasis; network analysis; patient dropout; receiver operating characteristic; residual network; sensitivity and specificity; spatial discrimination; training; validation process; Diagnosis","","Springer","","2-s2.0-85171877377"
"Agarwal R.; Sarma P.; Dev N.; Mazumder P.P.","Agarwal, Rashi (59031244600); Sarma, Parismita (57195313986); Dev, Nabamita (58852199200); Mazumder, Partha Pratim (57405259600)","59031244600; 57195313986; 58852199200; 57405259600","Detection of Brain Tumor from MRI Samples Using Deep Learning Algorithms","","","","","","","10.1109/ICAEECI58247.2023.10370777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183550578&doi=10.1109%2fICAEECI58247.2023.10370777&partnerID=40&md5=f8a40d1c63e296105317ac6f6a7b69f1","Biomedical image processing is a rapidly expanding and challenging discipline. Brain tumor segmentation technique is critical in the detection and treatment of MRI brain cancers. It aids clinicians in the detection and measurement of cancers, as well as the development of treatment and rehabilitation methods. MRI brain tumor segmentation approaches based on U-Net architecture have gained popularity because they significantly enhance segmentation accuracy by combining high-level and low-level feature information using skip connections. This project, shows comparison of the performance of deep learning models such as ResNet50, VGG16 (via transfer learning), and CNN models in detecting brain tumor, demonstrating that ResNet50 outperforms VGG16 and CNN models by achieving the highest classification accuracy of 98 percent. © 2023 IEEE.","Brain tumor; CNN; MRI scan; ResNet-50; VGG-16","Brain; Convolutional neural networks; Deep learning; Diseases; Learning algorithms; Learning systems; Medical imaging; Tumors; Brain cancer; Brain tumor segmentation; Brain tumors; CNN models; Learning models; Measurements of; MRI scan; Resnet-50; Segmentation techniques; VGG-16; Magnetic resonance imaging","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85183550578"
"Smolders A.; Lomax A.; Weber D.C.; Albertini F.","Smolders, A. (57212110146); Lomax, A. (35596133400); Weber, D.C. (7402029492); Albertini, F. (36008103200)","57212110146; 35596133400; 7402029492; 36008103200","Patient-specific neural networks for contour propagation in online adaptive radiotherapy","68","9","095010","","","","10.1088/1361-6560/accaca","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153803344&doi=10.1088%2f1361-6560%2faccaca&partnerID=40&md5=6649d44df63088c0c377db717aa2ea4a","Objective. fast and accurate contouring of daily 3D images is a prerequisite for online adaptive radiotherapy. Current automatic techniques rely either on contour propagation with registration or deep learning (DL) based segmentation with convolutional neural networks (CNNs). Registration lacks general knowledge about the appearance of organs and traditional methods are slow. CNNs lack patient-specific details and do not leverage the known contours on the planning computed tomography (CT). This works aims to incorporate patient-specific information into CNNs to improve their segmentation accuracy. Approach. patient-specific information is incorporated into CNNs by retraining them solely on the planning CT. The resulting patient-specific CNNs are compared to general CNNs and rigid and deformable registration for contouring of organs-at-risk and target volumes in the thorax and head-and-neck regions. Results. patient-specific fine-tuning of CNNs significantly improves contour accuracy compared to standard CNNs. The method further outperforms rigid registration and a commercial DL segmentation software and yields similar contour quality as deformable registration (DIR). It is additionally 7-10 times faster than DIR. Significance. patient-specific CNNs are a fast and accurate contouring technique, enhancing the benefits of adaptive radiotherapy. © 2023 The Author(s). Published on behalf of Institute of Physics and Engineering in Medicine by IOP Publishing Ltd.","adaptive radiotherapy; biomedical image segmentation; contour propagation; deep learning","Algorithms; Cone-Beam Computed Tomography; Head and Neck Neoplasms; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Radiotherapy Planning, Computer-Assisted; Backpropagation; Convolutional neural networks; Deep learning; E-learning; Image segmentation; Radiotherapy; Adaptive radiotherapy; Biomedical image segmentation; Contour propagation; Contouring; Convolutional neural network; Deep learning; Online adaptive radiotherapies; Patient specific; Rigid registration; Specific information; algorithm; artificial neural network; cone beam computed tomography; head and neck tumor; human; image processing; procedures; Computerized tomography","Barbara Bachtiary; European Union’s Horizon 2020 Marie Skłodowska-Curie Actions, (955956); Reinhardt Krcek","Institute of Physics","37019120","2-s2.0-85153803344"
"Pattichis M.S.; Acton S.T.; Pattichis C.S.; Panayides A.S.","Pattichis, Marios S. (7004755649); Acton, Scott T. (7006577888); Pattichis, Constantinos S. (35495139000); Panayides, Andreas S. (16646871500)","7004755649; 7006577888; 35495139000; 16646871500","Guest Editorial Large-Scale Medical Image and Video Analytics for Clinical Decision Support","27","1","","4","6","2","10.1109/JBHI.2022.3227126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147148092&doi=10.1109%2fJBHI.2022.3227126&partnerID=40&md5=f37653dd0c112f20cea70bc2f5f37358","[No abstract available]","","accuracy; adenocarcinoma; artificial intelligence; artificial neural network; biomedical image classification method; brain tissue segmentation; Bruch membrane; conceptual framework; data base; decision support system; deep learning; degenerative disease; dual attention deep manifold harmonic discrimination; Editorial; endobronchial ultrasonography; endoscopy; ensemble learning; gastritis atrophy; geometry; glioma; human; image classification; intestinal metaplasia; large scale production; learning algorithm; light imaging; meta learning; microscopy; multiinstance learning; multilabel classification; nerve cell network; neurilemoma; optical coherence tomography; partial image phase correlation; performance; personalized medicine; polyculture; radiography; radiologist; rheumatoid arthritis; small cell carcinoma; squamous cell carcinoma; training; ultrasound; validation study; video analytics; videorecording; visual feature","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85147148092"
"Keshta I.; Deshpande P.S.; Shabaz M.; Soni M.; Bhadla M.; Muhammed Y.","Keshta, Ismail (56444410400); Deshpande, Pallavi Sagar (56591984200); Shabaz, Mohammad (57202955007); Soni, Mukesh (57202986134); Bhadla, Mohit kumar (57666121300); Muhammed, Yasser (57705952100)","56444410400; 56591984200; 57202955007; 57202986134; 57666121300; 57705952100","Multi-stage biomedical feature selection extraction algorithm for cancer detection","5","5","131","","","","10.1007/s42452-023-05339-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152771079&doi=10.1007%2fs42452-023-05339-2&partnerID=40&md5=87f215eb76631e8895e4ba4ef5c6135d","Cancer is a significant cause of death worldwide. Early cancer detection is greatly aided by machine learning and artificial intelligence (AI) to gene microarray data sets (microarray data). Despite this, there is a significant discrepancy between the number of gene features in the microarray data set and the number of samples. Because of this, it is crucial to identify markers for gene array data. Existing feature selection algorithms, however, generally use long-standing, are limited to single-condition feature selection and rarely take feature extraction into account. This work proposes a Multi-stage algorithm for Biomedical Deep Feature Selection (MBDFS) to address this issue. In the first, three feature selection techniques are combined for thorough feature selection, and feature subsets are obtained; in the second, an unsupervised neural network is used to create the best representation of the feature subset to enhance final classification accuracy. Using a variety of metrics, including a comparison of classification results before and after feature selection and the performance of alternative feature selection methods, we evaluate MBDFS's efficacy. The experiments demonstrate that although MBDFS uses fewer features, classification accuracy is either unchanged or enhanced. © 2023, The Author(s).","Artificial intelligence; Artificial Intelligence; Biomedical Image; Cancer Detection; Deep Feature Selection; Feature Selection; Machine Learning","Bioinformatics; Classification (of information); Deep learning; Diseases; Extraction; Genes; Learning systems; Biomedical images; Cancer detection; Deep feature selection; Feature subset; Features selection; Machine-learning; Microarray dataset; Multi-stages; STAGE algorithm; Feature Selection","","Springer Nature","","2-s2.0-85152771079"
"Altun S.; Alkan A.; Altun I.","Altun, Sinan (57482139300); Alkan, Ahmet (56261391700); Altun, İdiris (55975679200)","57482139300; 56261391700; 55975679200","LSS-VGG16: Diagnosis of Lumbar Spinal Stenosis with Deep Learning","36","5","","E180","E190","10","10.1097/BSD.0000000000001418","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160969409&doi=10.1097%2fBSD.0000000000001418&partnerID=40&md5=ad05ba3d2030aa119b22766cd58a0911","Study Design: This was a retrospective study. Objection: Lumbar Spinal Stenosis (LSS) is a disease that causes chronic low back pain and can often be confused with herniated disk. In this study, a deep learning-based classification model is proposed to make LSS diagnosis quickly and automatically with an objective tool. Summary of Background Data: LSS is a disease that causes negative consequences such as low back pain, foot numbness, and pain. Diagnosis of this disease is difficult because it is confused with herniated disk and requires serious expertise. The shape and amount of this stenosis are very important in deciding the surgery and the surgical technique to be applied in these patients. When the spinal canal narrows, as a result of compression on these nerves and/or pressure on the vessels feeding the nerves, poor nutrition of the nerves causes loss of function and structure. Image processing techniques are applied in biomedical images such as MR and CT and high classification success is achieved. In this way, computer-aided diagnosis systems can be realized to help the specialist in the diagnosis of different diseases. Methods: To demonstrate the success of the proposed model, different deep learning methods and traditional machine learning techniques have been studied. Results: The highest classification success was obtained in the VGG16 method, with 87.70%. Conclusions: The proposed LSS-VGG16 model reveals that a computer-aided diagnosis system can be created for the diagnosis of spinal canal stenosis. In addition, it was observed that higher classification success was achieved compared with similar studies in the literature. This shows that the proposed LSS-VGG16 model will be an important resource for scientists who will work in this field. © 2023 Lippincott Williams and Wilkins. All rights reserved.","deep learning; image processing; lumbar spinal stenosis; VGG16","Constriction, Pathologic; Deep Learning; Humans; Intervertebral Disc Displacement; Low Back Pain; Lumbar Vertebrae; Retrospective Studies; Spinal Stenosis; accuracy; adult; aged; algorithm; area under the curve; Article; artificial intelligence; artificial neural network; backache; cerebrospinal fluid; cervical spine; classification algorithm; compression; controlled study; decision tree; decompression surgery; deep learning; diagnostic test accuracy study; feeding; female; histogram; human; image processing; image quality; image reconstruction; intervertebral disk degeneration; intervertebral disk hernia; knee; learning algorithm; loss of function mutation; low back pain; lumbar spinal stenosis; machine learning; major clinical study; male; natural language processing; nerve; nuclear magnetic resonance imaging; operation duration; random forest; receiver operating characteristic; retrospective study; sensitivity and specificity; spine surgery; structure activity relation; support vector machine; surgical technique; three-dimensional imaging; vertebral canal; VGG16; complication; diagnostic imaging; intervertebral disk hernia; low back pain; lumbar vertebra; stenosis, occlusion and obstruction; surgery; vertebral canal stenosis","Türkiye Bilimsel ve Teknolojik Araştırma Kurumu, TÜBİTAK, (122E042)","Lippincott Williams and Wilkins","36727890","2-s2.0-85160969409"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","1968 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178625415&partnerID=40&md5=bb0a33ddf85aef908ebced83f2ea0b55","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178625415"
"Chen R.; Wang Q.; Huang X.","Chen, Rongcan (58508148800); Wang, Qinglian (57212104509); Huang, Xiaoyuan (58543221500)","58508148800; 57212104509; 58543221500","Intelligent deep learning supports biomedical image detection and classification of oral cancer","32","","","S465","S475","10","10.3233/THC-248041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195530501&doi=10.3233%2fTHC-248041&partnerID=40&md5=7a182e955099d55de2fab4ff1623b77f","BACKGROUND: Oral cancer is a malignant tumor that usually occurs within the tissues of the mouth. This type of cancer mainly includes tumors in the lining of the mouth, tongue, lips, buccal mucosa and gums. Oral cancer is on the rise globally, especially in some specific risk groups. The early stage of oral cancer is usually asymptomatic, while the late stage may present with ulcers, lumps, bleeding, etc. OBJECTIVE: The objective of this paper is to propose an effective and accurate method for the identification and classification of oral cancer. METHODS: We applied two deep learning methods, CNN and Transformers. First, we propose a new CANet classification model for oral cancer, which uses attention mechanisms combined with neglected location information to explore the complex combination of attention mechanisms and deep networks, and fully tap the potential of attention mechanisms. Secondly, we design a classification model based on Swim transform. The image is segmented into a series of two-dimensional image blocks, which are then processed by multiple layers of conversion blocks. RESULTS: The proposed classification model was trained and predicted on Kaggle Oral Cancer Images Dataset, and satisfactory results were obtained. The average accuracy, sensitivity, specificity and F1-Socre of Swin transformer architecture are 94.95%, 95.37%, 95.52% and 94.66%, respectively. The average accuracy, sensitivity, specificity and F1-Score of CANet model were 97.00%, 97.82%, 97.82% and 96.61%, respectively. CONCLUSIONS: We studied different deep learning algorithms for oral cancer classification, including convolutional neural networks, converters, etc. Our Attention module in CANet leverages the benefits of channel attention to model the relationships between channels while encoding precise location information that captures the long-term dependencies of the network. The model achieves a high classification effect with an accuracy of 97.00%, which can be used in the automatic recognition and classification of oral cancer.  © 2024 - The authors. Published by IOS Press.","attention mechanism; Oral cancer classification; transformer","Deep Learning; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Mouth Neoplasms; Neural Networks, Computer; Sensitivity and Specificity; Article; cancer classification; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; human; image analysis; image segmentation; learning algorithm; major clinical study; mouth cancer; sensitivity and specificity; artificial neural network; classification; computer assisted diagnosis; diagnosis; diagnostic imaging; image processing; mouth tumor; pathology; procedures","National Natural Science Foundation of China, NSFC, (62002304); National Natural Science Foundation of China, NSFC; Fundamental Research Funds for the Central Universities, (20720210053); Fundamental Research Funds for the Central Universities","IOS Press BV","38759069","2-s2.0-85195530501"
"Fu W.; Xue B.; Zhang M.; Schindler J.","Fu, Wenlong (36801652400); Xue, Bing (55329093700); Zhang, Mengjie (8729040400); Schindler, Jan (57219929281)","36801652400; 55329093700; 8729040400; 57219929281","Evolving U-Nets Using Genetic Programming for Tree Crown Segmentation","13836 LNCS","","","188","201","13","10.1007/978-3-031-25825-1_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147987723&doi=10.1007%2f978-3-031-25825-1_14&partnerID=40&md5=221f096403c5b621c4c069c1e08632d0","The U-Net deep learning algorithm and its variants have been developed for biomedical image segmentation, and due to their success gained popularity in other science domains including remote sensing. So far no U-Net structure has been specifically designed to segment complex tree canopies from aerial imagery. In this paper, a handcrafted convolutional block is introduced to replace the raw convolutional block used in the standard U-Net structure. Furthermore, we proposed a Genetic Programming (GP) approach to evolving convolutional blocks used in the U-Net structure. The experimental results on a tree crown dataset show that both the handcrafted block and the GP evolved blocks have better segmentation results than the standard U-Net. Additionally, the U-Net using the proposed handcrafted blocks has fewer numbers of the learning parameters than the standard U-Net. Also, the proposed GP approach can evolve convolutional blocks used in U-Nets that perform better than the handcrafted U-Net and the standard U-Net, and can also achieve automation. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Convolutional neural network; Genetic programming; Image segmentation; U-Net","Aerial photography; Antennas; Bioinformatics; Convolution; Deep learning; Genetic algorithms; Genetic programming; Learning algorithms; Remote sensing; Aerial imagery; Biomedical image segmentation; Convolutional neural network; Images segmentations; Net structures; Remote-sensing; Segmentation results; Tree canopy; Tree crowns; U-net; Image segmentation","Ministry of Business, Innovation and Employment, MBIE, (C09X1923); Ministry of Business, Innovation and Employment, MBIE","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85147987723"
"Elmoufidi A.; Ammoun H.","Elmoufidi, Abdelali (56252362600); Ammoun, Hind (57226315963)","56252362600; 57226315963","Diabetic Retinopathy Prevention Using EfficientNetB3 Architecture and Fundus Photography","4","1","78","","","","10.1007/s42979-022-01482-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143389752&doi=10.1007%2fs42979-022-01482-6&partnerID=40&md5=dbb921421744e589793bc923c4c9aeb5","Classification of stages of diabetic retinopathy (DR) is considered a key step in the assessment and management of diabetic retinopathy. Due to damage caused by high blood sugar in the retinal blood vessels, different microscopic structures can be occupied in the retinal area, such as micro-aneurysms, hard exudate, and neovascularization. The convolutional neural network (CNN) based on deep learning has become a promising method for the analysis of biomedical images. In this work, representative images of diabetic retinopathy (DR) are divided into five categories according to the professional knowledge of ophthalmologists. This article focuses on the use of convolutional neural networks to classify background images of DR according to disease severity and on the application of pooling, Softmax activation to achieve greater accuracy. The aptos2019-blindness-detection database makes it possible to verify the performance of the proposed algorithm. © 2022, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.","Convolutional neural networks; Deep learning; Diabetic retinopathy; EfficientNet; Fundus photography","","","Springer","","2-s2.0-85143389752"
"Rasal T.; Veerakumar T.; Subudhi B.N.; Esakkirajan S.","Rasal, Tushar (57223182545); Veerakumar, T. (24172086600); Subudhi, Badri Narayan (26423349500); Esakkirajan, S. (16051889700)","57223182545; 24172086600; 26423349500; 16051889700","Segmentation and counting of multiple myeloma cells using IEMD based deep neural network","122","","106950","","","","10.1016/j.leukres.2022.106950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138503251&doi=10.1016%2fj.leukres.2022.106950&partnerID=40&md5=6f178b05928840036344b9bd2bff01ef","In biomedical image analysis, segmentation of cell nuclei from microscopic images is a highly challenging research problem. In the computer-assisted health care system, the segmented microscopic cells have been used by many biological researchers for the early prediction of various diseases. Multiple myeloma is one type of disease which is also term as a plasma cell cancer. The segmentation of the nucleus and cell is a very critical step for multiple myeloma detection. Here, In this work, we have designed two modules. One is for recognizing the nucleus of myeloma cells with a deep IEMD neural network, and the other is for differentiating the cell i.e cytoplasm. The different IMFs provides detailed frequency component of an image which are used for feature extraction. This will significantly improves the performance. We proposed a new counting algorithm for counting the myeloma-affected plasma cells in this paper. An algorithm for counting overgrowth plasma cells within the myeloid tissue has been developed using the Python TensorFlow framework. Experimental outcomes on SegPC datasets substantiate that, the proposed deep learning approach outperforms other competitive methods in myeloma recognition and detection. The result of this research indicates that, the proposed image segmentation mechanism can recognize multiple myeloma with superiority. Early detection of multiple myeloma at the initial stage increases the chances to cure patients. © 2022 Elsevier Ltd","Deep learning; Fluorescence microscopy; Image segmentation; Multiple myeloma","Algorithms; Cell Nucleus; Humans; Image Processing, Computer-Assisted; Multiple Myeloma; Neural Networks, Computer; accuracy; algorithm; Article; cell membrane; cell nucleus; controlled study; convolutional neural network; cytoplasm; deep learning; deep neural network; Fourier analysis; health care system; human; human cell; image analysis; image processing; image quality; image segmentation; learning algorithm; leukocyte; mathematical model; mathematical phenomena; multiple myeloma; myeloma cell; prediction; recall; scoring system; training; validation process; vision; diagnostic imaging; procedures","","Elsevier Ltd","36152502","2-s2.0-85138503251"
"Yuan S.; Chen Y.; Ye C.; Bhatt M.W.; Saradeshmukh M.; Hossain M.S.","Yuan, Shuping (57224940153); Chen, Yang (57846517500); Ye, Chengqiong (57223099696); Bhatt, Mohammed Wasim (57222961220); Saradeshmukh, Mhalasakant (55898294500); Hossain, Md Shamim (57210989648)","57224940153; 57846517500; 57223099696; 57222961220; 55898294500; 57210989648","Cross-modal multi-label image classification modeling and recognition based on nonlinear","12","1","20220194","","","","10.1515/nleng-2022-0194","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146732047&doi=10.1515%2fnleng-2022-0194&partnerID=40&md5=c7a5b25aa71d42f0773d681a8b420685","Recently, it has become a popular strategy in multi-label image recognition to predict those labels that co-occur in a picture. Previous work has concentrated on capturing label correlation but has neglected to correctly fuse picture features and label embeddings, which has a substantial influence on the model's convergence efficiency and restricts future multi-label image recognition accuracy improvement. In order to better classify labeled training samples of corresponding categories in the field of image classification, a cross-modal multi-label image classification modeling and recognition method based on nonlinear is proposed. Multi-label classification models based on deep convolutional neural networks are constructed respectively. The visual classification model uses natural images and simple biomedical images with single labels to achieve heterogeneous transfer learning and homogeneous transfer learning, capturing the general features of the general field and the proprietary features of the biomedical field, while the text classification model uses the description text of simple biomedical images to achieve homogeneous transfer learning. The experimental results show that the multi-label classification model combining the two modes can obtain a hamming loss similar to the best performance of the evaluation task, and the macro average F1 value increases from 0.20 to 0.488, which is about 52.5% higher. The cross-modal multi-label image classification algorithm can better alleviate the problem of overfitting in most classes and has better cross-modal retrieval performance. In addition, the effectiveness and rationality of the two cross-modal mapping techniques are verified.  © 2023 the author(s), published by De Gruyter.","cross-mode retrieval; deep learning; multiple label points","Classification (of information); Convolutional neural networks; Deep neural networks; Image enhancement; Image recognition; Text processing; Transfer learning; Classification models; Cross-modal; Cross-mode retrieval; Deep learning; Images classification; Label images; Label points; Multi-labels; Multiple label point; Multiple labels; Image classification","","De Gruyter Open Ltd","","2-s2.0-85146732047"
"Jose A.; Roy R.; Stegmaier J.","Jose, Abin (57221473187); Roy, Rĳo (58080719100); Stegmaier, Johannes (55584699900)","57221473187; 58080719100; 55584699900","Weakly-supervised Temporal Segmentation of Cell-cycle Stages with Center-cell Focus using Recurrent Neural Networks","","","","212","219","7","10.1007/978-3-658-41657-7_47","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164964949&doi=10.1007%2f978-3-658-41657-7_47&partnerID=40&md5=9f3ab6bb9ca126f7607ba63067803d77","Training deep-learning models for biomedical images has always been a problem due to the lack of annotated data. Here we propose using a model and a training approach for the weakly-supervised temporal classification of cell-cycle stages during mitosis. Instead of using annotated data, by using an ordered set of classes called transcript, our proposed approach classifies the cell-cycle stages of cell video sequences. The network design helps to propagate information in time using Recurrent Neural Network and helps to focus the features on the center-cell. The algorithm is evaluated on four datasets from Moreno-Andrés et al. [1] and has a performance close to the supervised approaches, which is impressive, considering that annotated data is not used in training. © 2023 Der/die Autor(en), exklusiv lizenziert an Springer Fachmedien Wiesbaden GmbH, ein Teil von Springer Nature.","","Cells; Cytology; Biomedical images; Cell cycle; Learning models; Network design; Ordered set; Performance; Temporal classification; Temporal segmentations; Video sequences; Recurrent neural networks","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85164964949"
"Asif S.; Zheng X.; Zhu Y.","Asif, Sohaib (57221248320); Zheng, Xiaolong (57957660700); Zhu, Yusen (56172378600)","57221248320; 57957660700; 56172378600","An optimized fusion of deep learning models for kidney stone detection from CT images","36","7","102130","","","","10.1016/j.jksuci.2024.102130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198985257&doi=10.1016%2fj.jksuci.2024.102130&partnerID=40&md5=1f81bfe7987e3d620998e6bff837a323","Accurate diagnosis of kidney disease is crucial, as it is a significant health concern that demands precise identification for effective and appropriate treatment. Deep learning methods are increasingly recognized as valuable tools for disease diagnosis in the biomedical field. However, current models utilizing deep networks often encounter challenges of overfitting and low accuracy, necessitating further refinement for optimal performance. To overcome these challenges, this paper proposes the introduction of two ensemble models designed for kidney stone detection in CT images. The first model, called StackedEnsembleNet, is a two-level deep stack ensemble model that effectively integrates the predictions from four base models: InceptionV3, InceptionResNetV2, MobileNet, and Xception. By leveraging the collective knowledge of these models, StackedEnsembleNet improves the accuracy and reliability of kidney stone detection. The second model PSOWeightedAvgNet, leverages the Particle Swarm Optimization (PSO) algorithm to determine the optimal weights for the weighted average ensemble. Through PSO, this ensemble approach assigns optimized weights to each model during the ensembling process, effectively enhancing the performance by optimizing the combination of their predictions. Experimental results conducted on a large dataset of 1799 CT images demonstrate that both StackedEnsembleNet and PSOWeightedAvgNet outperform the individual base models, achieving high accuracy rates in kidney stone detection. Furthermore, additional experiments on an unseen dataset validate the models’ ability to generalize. The comparison with previous methods confirms the superior performance of the proposed ensemble models. The paper also presents Grad-CAM visualizations and error case analysis to provide insights into the decision-making processes of the models. By overcoming the limitations of existing deep learning models, StackedEnsembleNet and PSOWeightedAvgNet offer a promising approach for accurate kidney stone detection, contributing to improved diagnosis and treatment outcomes in the field of nephrology. © 2024 The Author(s)","Biomedical image classification; Deep neural networks; Kidney stone detection; Particle swarm optimization; Stack ensemble","","","King Saud bin Abdulaziz University","","2-s2.0-85198985257"
"Contino S.; Cruciata L.; Gambino O.; Pirrone R.","Contino, Salvatore (57211202805); Cruciata, Luca (58752332700); Gambino, Orazio (14015507500); Pirrone, Roberto (6603614874)","57211202805; 58752332700; 14015507500; 6603614874","IODeep: An IOD for the introduction of deep learning in the DICOM standard","248","","108113","","","","10.1016/j.cmpb.2024.108113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187197133&doi=10.1016%2fj.cmpb.2024.108113&partnerID=40&md5=a3495bbfa202199428925edb28fe80a8","Background and objective: In recent years, Artificial Intelligence (AI) and in particular Deep Neural Networks (DNN) became a relevant research topic in biomedical image segmentation due to the availability of more and more data sets along with the establishment of well known competitions. Despite the popularity of DNN based segmentation on the research side, these techniques are almost unused in the daily clinical practice even if they could support effectively the physician during the diagnostic process. Apart from the issues related to the explainability of the predictions of a neural model, such systems are not integrated in the diagnostic workflow, and a standardization of their use is needed to achieve this goal. Methods: This paper presents IODeep a new DICOM Information Object Definition (IOD) aimed at storing both the weights and the architecture of a DNN already trained on a particular image dataset that is labeled as regards the acquisition modality, the anatomical region, and the disease under investigation. Results: The IOD architecture is presented along with a DNN selection algorithm from the PACS server based on the labels outlined above, and a simple PACS viewer purposely designed for demonstrating the effectiveness of the DICOM integration, while no modifications are required on the PACS server side. Also a service based architecture in support of the entire workflow has been implemented. Conclusion: IODeep ensures full integration of a trained AI model in a DICOM infrastructure, and it is also enables a scenario where a trained model can be either fine-tuned with hospital data or trained in a federated learning scheme shared by different hospitals. In this way AI models can be tailored to the real data produced by a Radiology ward thus improving the physician decision making process. Source code is freely available at https://github.com/CHILab1/IODeep.git. © 2024 The Author(s)","Artificial Intelligence; Decision making in medical diagnosis; Deep Neural Networks; DICOM; Information Object Definition; Medical image segmentation","Artificial Intelligence; Computers; Deep Learning; Radiology Information Systems; Software; Clinical research; Computer aided diagnosis; Deep neural networks; Hospitals; Image segmentation; Learning systems; Medical imaging; Network architecture; Biomedical image segmentation; Decision making in medical diagnose; Decisions makings; DICOM; Information object; Information object definition; Intelligence models; Medical image segmentation; Research topics; Work-flows; algorithm; article; artificial intelligence; clinical practice; decision making; deep learning; deep neural network; diagnosis; digital imaging and communications in medicine; human; image segmentation; infrastructure; learning; physician; prediction; standardization; ward; workflow; artificial intelligence; software; Decision making","Sicilian MicronanoTech Research And Innovation Center, (B73C22000810001, DM 1061/2021, ECS_00000022)","Elsevier Ireland Ltd","38479148","2-s2.0-85187197133"
"Myriam H.; Abdelhamid A.A.; El-Kenawy E.-S.M.; Ibrahim A.; Eid M.M.; Jamjoom M.M.; Khafaga D.S.","Myriam, Hadjouni (23396729500); Abdelhamid, Abdelaziz A. (55328560100); El-Kenawy, El-Sayed M. (57191347112); Ibrahim, Abdelhameed (34876676400); Eid, Marwa Metwally (35795379100); Jamjoom, Mona M. (57142648900); Khafaga, Doaa Sami (58088844800)","23396729500; 55328560100; 57191347112; 34876676400; 35795379100; 57142648900; 58088844800","Advanced Meta-Heuristic Algorithm Based on Particle Swarm and Al-Biruni Earth Radius Optimization Methods for Oral Cancer Detection","11","","","23681","23700","19","10.1109/ACCESS.2023.3253430","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149834542&doi=10.1109%2fACCESS.2023.3253430&partnerID=40&md5=4ff93881a313e0eba3ffe3a4d5ca444c","Oral cancer is a deadly form of cancerous tumor that is widely spread in low and middle-income countries. An early and affordable oral cancer diagnosis might be achieved by automating the detection of precancerous and malignant lesions in the mouth. There are many research attempts to develop a robust machine-learning model that can detect oral cancer from images. However, these are still lacking high precision in oral cancer detection. Therefore, this work aims to propose a new approach capable of detecting oral cancer in medical images with higher accuracy. In this work, a novel and robust oral cancer detection based on a convolutional neural network (CNN) and optimized deep belief network (DBN). The design parameters of CNN and DBN are optimized using a new optimization algorithm, which is developed as a hybrid of Particle Swarm Optimization (PSO) and Al-Biruni Earth Radius (BER) Optimization algorithms and is denoted by (PSOBER). Using a standard biomedical images dataset available on the Kaggle repository, the proposed approach shows promising results outperforming various competing approaches with an accuracy of 97.35%. In addition, a set of statistical tests, such as One-way analysis-of-variance (ANOVA) and Wilcoxon signed-rank tests, are conducted to prove the significance and stability of the proposed approach. The proposed methodology is solid and efficient, and specialists can adopt it. However, additional research on a larger scale dataset is required to confirm the findings and highlight other oral features that can be utilized for cancer detection.  © 2013 IEEE.","Al-Biruni earth radius algorithm; convolutional neural network; deep belief network; metaheuristic optimization; Oral cancer; particle swarm optimization","Analysis of variance (ANOVA); Convolution; Deep neural networks; Diagnosis; Diseases; Heuristic algorithms; Heuristic methods; Medical imaging; Particle swarm optimization (PSO); Al-biruni earth radius algorithm; Cancer; Cancer detection; Convolutional neural network; Deep belief networks; Deep learning; Earth radii; Features extraction; Lesion; Metaheuristic; Metaheuristic optimization; Oral cancer; Particle swarm; Particle swarm optimization; Swarm optimization; Feature extraction","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85149834542"
"Sonneck J.; Zhou Y.; Chen J.","Sonneck, Justin (57892839100); Zhou, Yu (58488105700); Chen, Jianxu (56352708300)","57892839100; 58488105700; 56352708300","MMV_Im2Im: an open-source microscopy machine vision toolbox for image-to-image transformation","13","","giad120","","","","10.1093/gigascience/giad120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183847155&doi=10.1093%2fgigascience%2fgiad120&partnerID=40&md5=436270eaa2e3acee493454ee3e8306a9","Over the past decade, deep learning (DL) research in computer vision has been growing rapidly, with many advances in DL-based image analysis methods for biomedical problems. In this work, we introduce MMV_Im2Im, a new open-source Python package for image-to-image transformation in bioimaging applications. MMV_Im2Im is designed with a generic image-to-image transformation framework that can be used for a wide range of tasks, including semantic segmentation, instance segmentation, image restoration, image generation, and so on. Our implementation takes advantage of state-of-the-art machine learning engineering techniques, allowing researchers to focus on their research without worrying about engineering details. We demonstrate the effectiveness of MMV_Im2Im on more than 10 different biomedical problems, showcasing its general potentials and applicabilities. For computational biomedical researchers, MMV_Im2Im provides a starting point for developing new biomedical image analysis or machine learning algorithms, where they can either reuse the code in this package or fork and extend this package to facilitate the development of new methods. Experimental biomedical researchers can benefit from this work by gaining a comprehensive view of the image-to-image transformation concept through diversified examples and use cases. We hope this work can give the community inspirations on how DL-based image-to-image transformation can be integrated into the assay development process, enabling new biomedical studies that cannot be done only with traditional experimental assays. To help researchers get started, we have provided source code, documentation, and tutorials for MMV_Im2Im at [https://github.com/MMV-Lab/mmv_im2im] under MIT license. © The Author(s) 2024.","deep learning; microscopy image analysis; open-source","Algorithms; Image Processing, Computer-Assisted; Machine Learning; Microscopy; Software; Article; artificial intelligence; cell structure; cellular neural network; computer simulation; computer vision; confocal microscopy; deep learning; fluorescence microscopy; image analysis; image reconstruction; image segmentation; immunofluorescence; immunohistochemistry; learning algorithm; machine learning; microscopy; prediction; stimulated emission depletion microscopy; article; controlled study; human; vision","Ministry of Culture and Science of the State of North Rhine-Westphalia; Bundesministerium für Bildung und Forschung, BMBF, (161L0272); Bundesministerium für Bildung und Forschung, BMBF; Ministerium für Kultur und Wissenschaft des Landes Nordrhein-Westfalen, MKW NRW","Oxford University Press","38280188","2-s2.0-85183847155"
"Schilling M.P.; Ahuja N.; Rettenberger L.; Scherr T.; Reischl M.","Schilling, Marcel P. (57221699120); Ahuja, Niket (57888644700); Rettenberger, Luca (57361094700); Scherr, Tim (57211299072); Reischl, Markus (6602490688)","57221699120; 57888644700; 57361094700; 57211299072; 6602490688","Impact of Annotation Noise on Histopathology Nucleus Segmentation","8","2","","197","200","3","10.1515/cdbme-2022-1051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137934248&doi=10.1515%2fcdbme-2022-1051&partnerID=40&md5=576fc3b0dc2fcb6783a408e023f4a48d","Deep learning is often used for automated diagnosis support in biomedical image processing scenarios. Annotated datasets are essential for the supervised training of deep neural networks. The problem of consistent and noise-free annotation remains for experts such as pathologists. The variability within an annotator (intra) and the variability between annotators (inter) are current challenges. In clinical practice or biology, instance segmentation is a common task, but a comprehensive and quantitative study regarding the impact of noisy annotations lacks. In this paper, we present a concept to categorize and simulate various types of annotation noise as well as an evaluation of the impact on deep learning pipelines. Thereby, we use the multi-organ histology image dataset MoNuSeg to discuss the influence of annotator variability. We provide annotation recommendations for clinicians to achieve high-quality automated diagnostic algorithms. © 2022 The Author(s), published by De Gruyter.","Annotator Variability; Deep Learning; Image Processing; Instance Segmentation","Image annotation; Image segmentation; 'current; Annotated datasets; Annotator variability; Automated diagnosis; Deep learning; Diagnosis support; Images processing; Instance segmentation; Nucleus segmentation; Supervised trainings; Deep neural networks","","Walter de Gruyter GmbH","","2-s2.0-85137934248"
"Maiello L.; Ball L.; Micali M.; Iannuzzi F.; Scherf N.; Hoffmann R.-T.; Gama de Abreu M.; Pelosi P.; Huhle R.","Maiello, Lorenzo (57222163638); Ball, Lorenzo (55667696400); Micali, Marco (57215719490); Iannuzzi, Francesca (8672810400); Scherf, Nico (22935625000); Hoffmann, Ralf-Thorsten (55263364700); Gama de Abreu, Marcelo (57205413819); Pelosi, Paolo (7006547963); Huhle, Robert (55192776400)","57222163638; 55667696400; 57215719490; 8672810400; 22935625000; 55263364700; 57205413819; 7006547963; 55192776400","Automatic Lung Segmentation and Quantification of Aeration in Computed Tomography of the Chest Using 3D Transfer Learning","12","","725865","","","","10.3389/fphys.2021.725865","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124901369&doi=10.3389%2ffphys.2021.725865&partnerID=40&md5=278d2df56926a150cd69fa0770170ab3","Background: Identification of lung parenchyma on computer tomographic (CT) scans in the research setting is done semi-automatically and requires cumbersome manual correction. This is especially true in pathological conditions, hindering the clinical application of aeration compartment (AC) analysis. Deep learning based algorithms have lately been shown to be reliable and time-efficient in segmenting pathologic lungs. In this contribution, we thus propose a novel 3D transfer learning based approach to quantify lung volumes, aeration compartments and lung recruitability. Methods: Two convolutional neural networks developed for biomedical image segmentation (uNet), with different resolutions and fields of view, were implemented using Matlab. Training and evaluation was done on 180 scans of 18 pigs in experimental ARDS (u2NetPig) and on a clinical data set of 150 scans from 58 ICU patients with lung conditions varying from healthy, to COPD, to ARDS and COVID-19 (u2NetHuman). One manual segmentations (MS) was available for each scan, being a consensus by two experts. Transfer learning was then applied to train u2NetPig on the clinical data set generating u2NetTransfer. General segmentation quality was quantified using the Jaccard index (JI) and the Boundary Function score (BF). The slope between JI or BF and relative volume of non-aerated compartment (SJI and SBF, respectively) was calculated over data sets to assess robustness toward non-aerated lung regions. Additionally, the relative volume of ACs and lung volumes (LV) were compared between automatic and MS. Results: On the experimental data set, u2NetPig resulted in JI = 0.892 [0.88 : 091] (median [inter-quartile range]), BF = 0.995 [0.98 : 1.0] and slopes SJI = −0.2 {95% conf. int. −0.23 : −0.16} and SBF = −0.1 {−0.5 : −0.06}. u2NetHuman showed similar performance compared to u2NetPig in JI, BF but with reduced robustness SJI = −0.29 {−0.36 : −0.22} and SBF = −0.43 {−0.54 : −0.31}. Transfer learning improved overall JI = 0.92 [0.88 : 0.94], P < 0.001, but reduced robustness SJI = −0.46 {−0.52 : −0.40}, and affected neither BF = 0.96 [0.91 : 0.98] nor SBF = −0.48 {−0.59 : −0.36}. u2NetTransfer improved JI compared to u2NetHuman in segmenting healthy (P = 0.008), ARDS (P < 0.001) and COPD (P = 0.004) patients but not in COVID-19 patients (P = 0.298). ACs and LV determined using u2NetTransfer segmentations exhibited < 5% volume difference compared to MS. Conclusion: Compared to manual segmentations, automatic uNet based 3D lung segmentation provides acceptable quality for both clinical and scientific purposes in the quantification of lung volumes, aeration compartments, and recruitability. Copyright © 2022 Maiello, Ball, Micali, Iannuzzi, Scherf, Hoffmann, Gama de Abreu, Pelosi and Huhle.","ARDS; COVID-19; deep learning; Jaccard index; lung recruitment; lung segmentation; transfer learning; uNet","adult respiratory distress syndrome; Article; automation; chronic obstructive lung disease; clinical evaluation; cohort analysis; comparative study; computer assisted tomography; consensus; controlled study; convolutional neural network; coronavirus disease 2019; data analysis software; human; image quality; image segmentation; intensive care unit; lung volume; major clinical study; mathematical computing; mathematical model; quantitative analysis; thorax radiography; three-dimensional imaging; transfer of learning","Centre for Information Services; Deutsche Forschungsgemeinschaft, DFG, (GA 1256/8-1)","Frontiers Media S.A.","","2-s2.0-85124901369"
"Sharma S.; Gupta S.; Gupta D.; Rashid J.; Juneja S.; Kim J.; Elarabawy M.M.","Sharma, Sandhya (57226023345); Gupta, Sheifali (57072019200); Gupta, Deepali (57208714508); Rashid, Junaid (57203222981); Juneja, Sapna (57210408722); Kim, Jungeun (56600264800); Elarabawy, Mahmoud M. (56294009900)","57226023345; 57072019200; 57208714508; 57203222981; 57210408722; 56600264800; 56294009900","Performance Evaluation of the Deep Learning Based Convolutional Neural Network Approach for the Recognition of Chest X-Ray Images","12","","932496","","","","10.3389/fonc.2022.932496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134156021&doi=10.3389%2ffonc.2022.932496&partnerID=40&md5=f02ddfb99735a5764fe4d3a3d30ca686","Recent advancement in the field of deep learning has provided promising performance for the analysis of medical images. Every year, pneumonia is the leading cause for death of various children under the age of 5 years. Chest X-rays are the first technique that is used for the detection of pneumonia. Various deep learning and computer vision techniques can be used to determine the virus which causes pneumonia using Chest X-ray images. These days, it is possible to use Convolutional Neural Networks (CNN) for the classification and analysis of images due to the availability of a large number of datasets. In this work, a CNN model is implemented for the recognition of Chest X-ray images for the detection of Pneumonia. The model is trained on a publicly available Chest X-ray images dataset having two classes: Normal chest X-ray images and Pneumonic Chest X-ray images, where each class has 5000 Samples. 80% of the collected data is used for the purpose to train the model, and the rest for testing the model. The model is trained and validated using two optimizers: Adam and RMSprop. The maximum recognition accuracy of 98% is obtained on the validation dataset. The obtained results are further compared with the results obtained by other researchers for the recognition of biomedical images. Copyright © 2022 Sharma, Gupta, Gupta, Rashid, Juneja, Kim and Elarabawy.","biomedical images; chest X-rays; convolutional neural network; deep learning; optimizers","ADAM protein; accuracy; area under the curve; Article; biomedical image; computer model; computer vision; convolutional neural network; deep learning; human; image analysis; image segmentation; learning algorithm; lung infection; machine learning; pneumonia; radiodiagnosis; support vector machine; thorax radiography; training; validation process","Ministry of Science, ICT and Future Planning, MSIP, (2021R1A4A1031509); National Research Foundation of Korea, NRF; Ministry of SMEs and Startups, MSS, (S3033853)","Frontiers Media S.A.","","2-s2.0-85134156021"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","14450 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178556551&partnerID=40&md5=b0b91f9a575c994470ccc3db9fb3ab6e","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178556551"
"Rachmadi M.F.; Byra M.; Skibbe H.","Rachmadi, Muhammad Febrian (54974181500); Byra, Michal (56414988400); Skibbe, Henrik (14021955900)","54974181500; 56414988400; 14021955900","A new family of instance-level loss functions for improving instance-level segmentation and detection of white matter hyperintensities in routine clinical brain MRI","174","","108414","","","","10.1016/j.compbiomed.2024.108414","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189928902&doi=10.1016%2fj.compbiomed.2024.108414&partnerID=40&md5=201cdad67fee8975ed00ebd4596a05d6","In this study, we introduce “instance loss functions”, a new family of loss functions designed to enhance the training of neural networks in the instance-level segmentation and detection of objects in biomedical image data, particularly those of varied numbers and sizes. Intended to be utilized conjointly with traditional loss functions, these proposed functions, prioritize object instances over pixel-by-pixel comparisons. The specific functions, the instance segmentation loss (Linstance), the instance center loss (Lcenter), the false instance rate loss (Lfalse), and the instance proximity loss (Lproximity), serve distinct purposes. Specifically, Linstance improves instance-wise segmentation quality, Lcenter enhances segmentation quality of small instances, Lfalse minimizes the rate of false and missed detections across varied instance sizes, and Lproximity improves detection quality by pulling predicted instances towards the ground truth instances. Through the task of segmenting white matter hyperintensities (WMH) in brain MRI, we benchmarked our proposed instance loss functions, both individually and in combination via an ensemble inference models approach, against traditional pixel-level loss functions. Data were sourced from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and the WMH Segmentation Challenge datasets, which exhibit significant variation in WMH instance sizes. Empirical evaluations demonstrate that combining two instance-level loss functions through ensemble inference models outperforms models using other loss function on both the ADNI and WMH Segmentation Challenge datasets for the segmentation and detection of WMH instances. Further, applying these functions to the segmentation of nuclei in histopathology images demonstrated their effectiveness and generalizability beyond WMH, improving performance even in contexts with less severe instance imbalance. © 2024 The Author(s)","Brain lesions; Ensemble inference; Instance-level detection loss; Instance-level segmentation loss; White matter hyperintensities","Algorithms; Alzheimer Disease; Brain; Humans; Image Interpretation, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; White Matter; Image enhancement; Image segmentation; Magnetic resonance imaging; Neurodegenerative diseases; Neuroimaging; Object detection; Brain lesions; Brain MRI; Detection loss; Ensemble inference; Instance-level detection loss; Instance-level segmentation loss; Level detections; Loss functions; Segmentation quality; White matter hyperintensities; Alzheimer disease; Article; artificial neural network; brain; comparative study; deep learning; fluid-attenuated inversion recovery imaging; human; image segmentation; instance loss function; major clinical study; neuroimaging; nuclear magnetic resonance imaging; qualitative analysis; quantitative analysis; size; T2 weighted imaging; white matter; algorithm; computer assisted diagnosis; diagnostic imaging; procedures; Pixels","RIKEN; Fakultas Ilmu Komputer, Universitas Indonesia, CS UI; Japan Agency for Medical Research and Development, AMED, (JP15dm0207001); Japan Agency for Medical Research and Development, AMED","Elsevier Ltd","38599072","2-s2.0-85189928902"
"Ghosh A.; Jana N.D.; Mallik S.; Zhao Z.","Ghosh, Arjun (57219433879); Jana, Nanda Dulal (54795488300); Mallik, Saurav (56213777000); Zhao, Zhongming (57755838500)","57219433879; 54795488300; 56213777000; 57755838500","Designing optimal convolutional neural network architecture using differential evolution algorithm","","","100567","","","","10.1016/j.patter.2022.100567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141740726&doi=10.1016%2fj.patter.2022.100567&partnerID=40&md5=e3c68f927cd38442a20565a288744ac9","Convolutional neural networks (CNNs) are deep learning models used widely for solving various tasks like computer vision and speech recognition. CNNs are developed manually based on problem-specific domain knowledge and tricky settings, which are laborious, time consuming, and challenging. To solve these, our study develops an improved differential evolution of convolutional neural network (IDECNN) algorithm to design CNN layer architectures for image classification. Variable-length encoding is utilized to represent the flexible layer architecture of a CNN model in IDECNN. An efficient heuristic mechanism is proposed in IDECNN to evolve CNN architecture through mutation and crossover to prevent premature convergence during the evolutionary process. Eight well-known imaging datasets were utilized. The results showed that IDECNN could design suitable architecture compared with 20 existing CNN models. Finally, CNN architectures are applied to pneumonia and coronavirus disease 2019 (COVID-19) X-ray biomedical image data. The results demonstrated the usefulness of the proposed approach to generate a suitable CNN model. © 2022 The Author(s)","CNN; convolutional neural network; DE; differential evolution; DSML3: Development/pre-production: data science output has been rolled out/validated across multiple domains/problems; image classification; NAS; neural architecture search; neuroevolution; optimal neural architecture","Convolution; Convolutional neural networks; Deep learning; Domain Knowledge; Evolutionary algorithms; Image enhancement; Multilayer neural networks; Network architecture; Optimization; Speech recognition; Convolutional neural network; DE; Differential Evolution; Domain problems; DSML3: development/pre-production: data science output have been rolled out/validated across multiple domain/problem; Images classification; Multiple domains; NAS; Neural architecture search; Neural architectures; Neuro evolutions; Optimal neural architecture; Pre-production; Production data; Image classification","Cancer Prevention and Research Institute of Texas, CPRIT, (180734); Cancer Prevention and Research Institute of Texas, CPRIT","Cell Press","","2-s2.0-85141740726"
"Wu H.; Lu H.; Ping M.; Zhu W.; Li Z.","Wu, Hongli (57796712300); Lu, Huijuan (55729819200); Ping, Mingzhu (57796619100); Zhu, Wenjie (57217050076); Li, Zhao (57191700056)","57796712300; 55729819200; 57796619100; 57217050076; 57191700056","A Deep Learning Method for Pneumonia Detection Based on Fuzzy Non-Maximum Suppression","21","4","","902","911","9","10.1109/TCBB.2023.3247483","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149418789&doi=10.1109%2fTCBB.2023.3247483&partnerID=40&md5=ac5ea2f2a002e4d56b6955c7593bde58","Pneumonia is one of the largest causes of death in the world. Deep learning techniques can assist doctors to detect the areas of pneumonia in the chest X-rays images. However, existing methods lack sufficient consideration for the large variation scale and the blurred boundary of the pneumonia area. Here, we present a deep learning method based on Retinanet for pneumonia detection. First, we introduce Res2Net into Retinanet to get the multi-scale feature of pneumonia. Then, we proposed a novel predicted boxes fusion algorithm, named Fuzzy Non-Maximum Suppression (FNMS), which gets a more robust predicted box by fusing the overlapping detection boxes. Finally, we get the performance outperforms than existing methods by integrating two models with different backbones. We report the experimental result in the single model case and the model ensemble case. In the single model case, RetinaNet with FNMS algorithm and Res2Net backbone is better than RetinaNet and other models. In the model ensemble case, the final score of predicted boxes that fused by the FNMS algorithm is better than NMS, Soft-NMS, and weighted boxes fusion. Experimental results on the pneumonia detection dataset verify the superiority of the FNMS algorithm and the proposed method in the pneumonia detection task.  © 2004-2012 IEEE.","Biomedical image; deep learning; model ensemble; pneumonia detection","Algorithms; Deep Learning; Fuzzy Logic; Humans; Pneumonia; Radiographic Image Interpretation, Computer-Assisted; Radiography, Thoracic; Bioinformatics; Deep neural networks; Job analysis; Biomedical images; Convolutional neural network; Deep learning; Features extraction; Model ensembles; Pneumonia detection; Prediction algorithms; Predictive models; Task analysis; algorithm; computer assisted diagnosis; deep learning; diagnosis; diagnostic imaging; fuzzy logic; human; pneumonia; procedures; thorax radiography; Feature extraction","","Institute of Electrical and Electronics Engineers Inc.","37027655","2-s2.0-85149418789"
"Wang K.; Zhang X.; Lu Y.; Zhang X.; Zhang W.","Wang, Kun (57213024990); Zhang, Xiaohong (55276997400); Lu, Yuting (57221641587); Zhang, Xiangbo (57219114472); Zhang, Wei (57225164170)","57213024990; 55276997400; 57221641587; 57219114472; 57225164170","CGRNet: Contour-guided graph reasoning network for ambiguous biomedical image segmentation","75","","103621","","","","10.1016/j.bspc.2022.103621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125710797&doi=10.1016%2fj.bspc.2022.103621&partnerID=40&md5=885d0cb7f8b7928b8336770d11e69113","In this work, we propose to address the existing problem of biomedical image segmentation that often produces results, which fail to capture the exact contours of the target and suffer from ambiguity. Most previous techniques are suboptimal because they often simply concatenate contour information to alleviate this problem, while ignoring the correlation between regions and contours. As a matter of fact, the relationship between cross-domain features is an important clue for ambiguous pixel segmentation in biomedical images. To this end, we contribute a simple yet effective framework called Contour-Guided Graph Reasoning Network (CGRNet) for more accurate segmentation against ambiguity, which is capable of capturing the semantic relations between object regions and contours through graph reasoning. Specifically, we first perform a global graph representation of the low-level and high-level features extracted by the feature extractor, where clusters of pixels with similar features are mapped to each vertex. Further, we explicitly combine contour information as the geometric prior, which can aggregate features of contour pixels to graph vertices and focus on features along the boundaries. Then, the cross-domain features propagate information through the vertices on the graph to efficiently learn and reason about the semantic relations. Finally, the learned refinement graph features are projected back to the original pixel coordinate space for the final pixel-wise segmentation task. Extensive experiments on the three publicly available Kvasir, CVC-612, and COVID19-100 datasets show the effectiveness of our CGRNet with superior performance to existing state-of-the-art methods. Our code is publicly available at: https://github.com/DLWK/CGRNet. © 2022 Elsevier Ltd","Biomedical image segmentation; Computer-aided diagnosis (CAD); Contour-guided; Deep learning; Graph convolution network","Computer aided instruction; Deep learning; Graph theory; Medical imaging; Pixels; Semantic Segmentation; Semantics; Biomedical image segmentation; Computer-aided diagnose; Contour information; Contour-guided; Cross-domain; Deep learning; Domain feature; Existing problems; Graph convolution network; Semantic relations; Article; colonoscopy; computer assisted tomography; computer model; conceptual framework; contour guided graph reasoning network; controlled study; convolution algorithm; convolutional neural network; coronavirus disease 2019; data accuracy; data aggregation; feature extraction; image analysis; image segmentation; interferometry; measurement precision; reasoning; semantic web; sensitivity and specificity; Computer aided diagnosis","Chongqing Major Theme Projects, (cstc2018jszx-cyzt-zxX0017); Special key project of Chongqing technology innovation and application development, (cstc2019jscx-mbdxX0064); National Key Research and Development Program of China, NKRDPC, (2018YFB2101200); Fundamental Research Funds for the Central Universities, (2019CDYGYB014)","Elsevier Ltd","","2-s2.0-85125710797"
"Gupta K.; Bajaj V.; Jain D.K.; Hussain A.","Gupta, Kapil (57198261212); Bajaj, Varun (57209289122); Jain, Deepak Kumar (56206778300); Hussain, Amir (19734290900)","57198261212; 57209289122; 56206778300; 19734290900","Multi-model deep learning system for screening human monkeypox using skin images","","","","","","","10.1111/exsy.13651","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195513858&doi=10.1111%2fexsy.13651&partnerID=40&md5=2acc0808aed8db5dfb2a71d421dcb4e9","Purpose: Human monkeypox (MPX) is a viral infection that transmits between individuals via direct contact with animals, bodily fluids, respiratory droplets, and contaminated objects like bedding. Traditional manual screening for the MPX infection is a time-consuming process prone to human error. Therefore, a computer-aided MPX screening approach utilizing skin lesion images to enhance clinical performance and alleviate the workload of healthcare providers is needed. The primary objective of this work is to devise an expert system that accurately classifies MPX images for the automatic detection of MPX subjects. Methods: This work presents a multi-modal deep learning system through the fusion of convolutional neural network (CNN) and machine learning algorithms, which effectively and autonomously detect MPX-infected subjects using skin lesion images. The proposed framework, termed MPXCN-Net is developed by fusing deep features of three pre-trained CNNs: MobileNetV2, DarkNet19, and ResNet18. Three classifiers—K-nearest neighbour, support vector machine (SVM), and ensemble classifier—with various kernel functions, are used to identify infected patients. To validate the efficacy of our proposed system, we employ a publicly accessible MPX skin lesion dataset. Results: By amalgamating features extracted from all three CNNs and utilizing the medium Gaussian kernel of the SVM classifier, our proposed system achieves an outstanding average classification accuracy of 90.4%. Conclusions: Developed MPXCN-Net is suitable for testing with a large diversified dataset before being used in clinical settings. © 2024 John Wiley & Sons Ltd.","biomedical image classification; convolutional neural network; machine learning algorithm; monkeypox infection","Bioinformatics; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Expert systems; Image classification; Image enhancement; Large datasets; Learning algorithms; Nearest neighbor search; Statistical tests; Support vector machines; Biomedical image classification; Biomedical images; Convolutional neural network; Images classification; Machine learning algorithms; Monkeypox infection; Multi-modelling; Skin images; Skin lesion images; Support vector machine classifiers; Learning systems","Engineering and Physical Sciences Research Council, EPSRC, (EP/T021063/1, EP/T024917/1)","John Wiley and Sons Inc","","2-s2.0-85195513858"
"Thamilselvan R.; Kalpana T.; Natesan P.; Sheik Alaudeen Y.; Surendiran S.; Showket S.","Thamilselvan, R. (56683185600); Kalpana, T. (57921074200); Natesan, P. (56829436200); Sheik Alaudeen, Y. (59155407600); Surendiran, S. (59155307400); Showket, Sayeem (59155407700)","56683185600; 57921074200; 56829436200; 59155407600; 59155307400; 59155407700","Autism Spectrum Disorder Diagnosis using Deep Learning Techniques","","","","402","407","5","10.1109/ICC-ROBINS60238.2024.10533978","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195123955&doi=10.1109%2fICC-ROBINS60238.2024.10533978&partnerID=40&md5=bef1a0ea8d420436151b6d91d7c4f7eb","Autism spectrum disorder (ASD) represents a neurological condition rather than a mental illness, characterized by atypical brain development that can subsequently manifest in distinct facial features. Children with ASD often exhibit unique facial landmarks that differentiate them from Typically Developed individuals. This pioneering research introduces a novel approach, focusing on the detection of ASD through the analysis of both social media data and biomedical images, specifically by harnessing the power of face recognition technology and Convolutional Neural Networks (CNN). Deep learning techniques are precise identification of these facial features. The research aims to benefit both communities and mental health professionals by providing an accessible web application based on a CNN with transfer learning and Flask integration. In this refined approach, two robust models are exclusively retained, DenseNet121 with an accuracy of 54% and EfficientNetB0 with an impressive 90% accuracy rate. These models are intended for improving the accuracy and convenience for determining ASD using face traits, which will simplify the process of early diagnosis and intervention for those who need it. The dataset contains 2,940 images of faces that were retrieved from the Kaggle platform. Standard evaluation metrics are used to evaluate the effectiveness of the two CNN models, including sensitivity, specificity and accuracy. This research hopes to help people with ASD by finding a way to identify it early. Early help is very important for making things better for people with autism. So, the study aims to create a useful tool that can tell if someone might have ASD when the patients are very young.  © 2024 IEEE.","accuracy; Autism; DenseNet121; EfficientNetB0; Facial expression","Convolutional neural networks; Deep learning; Diseases; Face recognition; Learning algorithms; Learning systems; Neural network models; Transfer learning; Accuracy; Autism; Autism spectrum disorders; Condition; Convolutional neural network; Densenet121; Efficientnetb0; Facial Expressions; Facial feature; Learning techniques; Diagnosis","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85195123955"
"Al-Shahari E.A.; Obayya M.; Alotaibi F.A.; Alsafari S.; Salama A.S.; Assiri M.","Al-Shahari, Eman A. (57218120186); Obayya, Marwa (6505869929); Alotaibi, Faiz Abdullah (57217736578); Alsafari, Safa (57218956797); Salama, Ahmed S. (56480035100); Assiri, Mohammed (57219344932)","57218120186; 6505869929; 57217736578; 57218956797; 56480035100; 57219344932","Accelerating biomedical image segmentation using equilibrium optimization with a deep learning approach","9","3","","5905","5924","19","10.3934/math.2024288","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183902386&doi=10.3934%2fmath.2024288&partnerID=40&md5=5e3b7178cfd3a22e5cb4a4ddde2303ce","Biomedical image segmentation is a vital task in the analysis of medical imaging, including the detection and delineation of pathological regions or anatomical structures within medical images. It has played a pivotal role in a variety of medical applications, involving diagnoses, monitoring of diseases, and treatment planning. Conventionally, clinicians or expert radiologists have manually conducted biomedical image segmentation, which is prone to human error, subjective, and time-consuming. With the advancement in computer vision and deep learning (DL) algorithms, automated and semi-automated segmentation techniques have attracted much research interest. DL approaches, particularly convolutional neural networks (CNN), have revolutionized biomedical image segmentation. With this motivation, we developed a novel equilibrium optimization algorithm with a deep learning-based biomedical image segmentation (EOADL-BIS) technique. The purpose of the EOADL-BIS technique is to integrate EOA with the Faster RCNN model for an accurate and efficient biomedical image segmentation process. To accomplish this, the EOADL-BIS technique involves Faster R-CNN architecture with ResNeXt as a backbone network for image segmentation. The region proposal network (RPN) proficiently creates a collection of a set of region proposals, which are then fed into the ResNeXt for classification and precise localization. During the training process of the Faster RCNN algorithm, the EOA was utilized to optimize the hyperparameter of the ResNeXt model which increased the segmentation results and reduced the loss function. The experimental outcome of the EOADL-BIS algorithm was tested on distinct benchmark medical image databases. The experimental results stated the greater efficiency of the EOADL-BIS algorithm compared to other DL-based segmentation approaches. © 2024 the Author(s).","biomedical image segmentation; computer vision; deep learning; equilibrium optimizer; image processing","","Abdulrahman University, (PNURSP2023R203); Prince Sattam bin Abdulaziz University, PSAU, (PSAU/2023/R/1444); King Saud University, KSU; Princess Nourah Bint Abdulrahman University, PNU, (RSPD2024R838); Deanship of Scientific Research, King Khalid University, (RGP2/ 242 /44); Future University in Egypt, FUE","American Institute of Mathematical Sciences","","2-s2.0-85183902386"
"Morís D.I.; Hervella Á.S.; Rouco J.; Novo J.; Ortega M.","Morís, Daniel I. (57226478610); Hervella, Álvaro S. (57204014400); Rouco, José (23475243900); Novo, Jorge (57695901400); Ortega, Marcos (24475406900)","57226478610; 57204014400; 23475243900; 57695901400; 24475406900","Context encoder transfer learning approaches for retinal image analysis","152","","106451","","","","10.1016/j.compbiomed.2022.106451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144614337&doi=10.1016%2fj.compbiomed.2022.106451&partnerID=40&md5=89d0cd40210315db135ec150a75daaa7","During the last years, deep learning techniques have emerged as powerful alternatives to solve biomedical image analysis problems. However, the training of deep neural networks usually needs great amounts of labeled data to be done effectively. This is even more critical in the case of biomedical imaging due to the added difficulty of obtaining data labeled by experienced clinicians. To mitigate the impact of data scarcity, one of the most commonly used strategies is transfer learning. Nevertheless, the success of this approach depends on the effectiveness of the available pre-training techniques for learning from little or no labeled data. In this work, we explore the application of the Context Encoder paradigm for transfer learning in the domain of retinal image analysis. To this aim, we propose several approaches that allow to work with full resolution images and improve the recognition of the retinal structures. In order to validate the proposals, the Context Encoder pre-trained models are fine-tuned to perform two relevant tasks in the domain: vessels segmentation and fovea localization. The experiments performed on different public datasets demonstrate that the proposed Context Encoder approaches allow mitigating the impact of data scarcity, being superior to previous alternatives in this domain. © 2022 The Author(s)","Biomedical imaging; Context Encoder; Deep learning; Eye fundus; Self-supervised learning; Transfer learning","Diagnostic Imaging; Image Processing, Computer-Assisted; Machine Learning; Neural Networks, Computer; Retina; Deep neural networks; Image analysis; Learning algorithms; Learning systems; Medical imaging; Ophthalmology; Signal encoding; Biomedical imaging; Context encoder; Data scarcity; Deep learning; Eye fundus; Labeled data; Learning approach; Retinal image analysis; Self-supervised learning; Transfer learning; article; deep learning; eye fundus; human; image analysis; learning; retina fovea; retina image; transfer of learning; diagnostic imaging; image processing; machine learning; procedures; retina; Image enhancement","CITIC; Centro de Investigación de Galicia, (ED431G 2019/01); Consellería de Educación, Universidade e Formación Profesional; Ministerio de Ciencia e Innovación y Universidades, Government of Spain, (RTI2018-095894-B-I00); Secretaría Xeral de Universidades; Instituto de Salud Carlos III, ISCIII, (DTS18/00136); Instituto de Salud Carlos III, ISCIII; Ministerio de Ciencia e Innovación, MICINN, (PID2019-108435RB-I00); Ministerio de Ciencia e Innovación, MICINN; Consellería de Cultura, Educación e Ordenación Universitaria, Xunta de Galicia, (ED431C 2020/24, ED481A 2021/196, ED481B-2022-025); Consellería de Cultura, Educación e Ordenación Universitaria, Xunta de Galicia; European Regional Development Fund, ERDF; Axencia Galega de Innovación, GAIN; Xunta de Galicia, (IN845D 2020/38); Xunta de Galicia; Universidade da Coruña","Elsevier Ltd","36571941","2-s2.0-85144614337"
"Güler M.; Namlı E.","Güler, Mustafa (58984022900); Namlı, Ersin (55499104800)","58984022900; 55499104800","Skin Cancer Detection with Deep Learning Methods Using Medical Image; [Medikal Görüntüler Kullanılarak Derin Öğrenme Yöntemleriyle Cilt Kanseri Tespiti]","2","2","","1","10","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200895608&partnerID=40&md5=0222909f46514a14afa0dbdd2033f009","With the development of machine learning and deep learning models, very successful results have been obtained in recent years, especially in the field of biomedical image processing. Medical imaging techniques such as computed tomography (CT), magnetic resonance imaging (MR), mammography, X-ray, and ultrasound serve as a preliminary reference for specialists for the diagnosis and treatment of diseases. However, in recent years, deep learning techniques have been used in the field of health in order to diagnose diseases earlier and to reduce the density of specialists, as well as to minimize the mistakes that can be made in diagnosis and diagnosis. With the increasing amount of data and the development of mathematical models, deep learning techniques have started to be preferred a lot. In this study, the application of deep learning methods in the field of medical image processing is examined. The skin cancer dataset, which is considered as a dataset, classification and disease diagnosis, image creation, improvement and transformation processes are examined, and the classification results obtained with four different pre-trained Convolutional neural network architectures (CNN) are examined. The results obtained are also classified by classical machine learning techniques. As a result, an accuracy rate of 87% was obtained in the classification made with ResNet, one of the CNN algorithms, and the Support vector machines (SVM) algorithm, which had the highest rate in the classification made with machine learning techniques, achieved success with an accuracy rate of 0.848%. © 2022, Ebru Bagci. All rights reserved.","Classification; Convolutional Neural Network; Deep Learning; Image Processing","","","Ebru Bagci","","2-s2.0-85200895608"
"Rajput G.; Agrawal S.; Biyani K.; Vishvakarma S.K.","Rajput, Gunjan (57212573692); Agrawal, Shashank (57224899713); Biyani, Kunika (57415320400); Vishvakarma, Santosh Kumar (6506346978)","57212573692; 57224899713; 57415320400; 6506346978","Early breast cancer diagnosis using cogent activation function-based deep learning implementation on screened mammograms","32","4","","1101","1118","17","10.1002/ima.22701","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122957265&doi=10.1002%2fima.22701&partnerID=40&md5=f3ea1d48334fcd75f2a4551f353d08ae","Breast cancer is detected in one out of eight females worldwide. Principally biomedical image processing techniques work with images captured by a microscope and then analyzed with the help of different algorithms and methods. Instead of microscopic image diagnosis, machine learning algorithms are now incorporated to detect and diagnose therapeutic imagery. Computer-aided mechanisms are used for better efficiency and reliability compared with manual pathological detection systems. Machine learning algorithms detect tumors by extracting features through a convolutional neural network (CNN) and then classifying them using a fully connected network. As Machine learning does not require prior expertise, it is profoundly used in biomedical imaging. This article has customized a convolutional neural network by mathematical modeling of a proposed activation function. We have obtained an appreciable prediction accuracy of up to 99%, along with a precision of 0.97. © 2022 Wiley Periodicals LLC.","breast cancer classification; convolutional neural network; deep learning; detection; Mias dataset","Bioinformatics; Chemical activation; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Functions; Learning algorithms; Medical imaging; Activation functions; Breast Cancer; Breast cancer diagnosis; Computer-aided; Convolutional neural network; Early breast cancer; Image diagnosis; Image processing technique; Machine learning algorithms; Microscopic image; Convolution","Council of Scientific and Industrial Research, India, CSIR, (09/1022(0026)/2016‐EMR‐I)","John Wiley and Sons Inc","","2-s2.0-85122957265"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","1966 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178645226&partnerID=40&md5=cb77862583ffbc833416c3a13f9affec","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178645226"
"Pei R.; Yao K.; Xu X.; Zhang X.; Yang X.; Fu W.; Zhang Y.","Pei, Ronghao (57202691051); Yao, Kang (57211110694); Xu, Xiaobin (56427119400); Zhang, Xin (36622009600); Yang, Xiaodong (55265540400); Fu, Weiwei (57199403057); Zhang, Yang (57840371300)","57202691051; 57211110694; 56427119400; 36622009600; 55265540400; 57199403057; 57840371300","TransFusion-net for multifocus microscopic biomedical image fusion","240","","107688","","","","10.1016/j.cmpb.2023.107688","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165534150&doi=10.1016%2fj.cmpb.2023.107688&partnerID=40&md5=2ee972e7e1f7de02660f164337ba8a87","Background and objective: Due to the depth of focus (DOF) limitations of the optical systems of microscopes, it is often difficult to achieve full clarity from microscopic biomedical images under high-magnification microscopy. Multifocus microscopic biomedical image fusion (MFBIF) can effectively solve this problem. Considering both information richness and visual authenticity, this paper proposes a transformer network for MFBIF called TransFusion-Net. Methods: TransFusion-Net consists of two modules. One module is an interlayer cross-attention module, which is used to obtain feature mappings under the long-range dependencies observed among multiple nonfocus source images. The other module is a spatial attention upsampling network (SAU-Net) module, which is used to obtain global semantic information after further spatial attention is applied. Thus, TransFusion-Net can simultaneously receive multiple input images from a nonfull-focus microscope and make full use of the strong correlations between the source images to output accurate fusion results in an end-to-end manner. Results: The fusion results were quantitatively and qualitatively compared with those of eight state-of-the-art algorithms. In the quantitative experiments, five evaluation metrics, QAB/F, QMI, QAVG, QCB, and PSNR, were used to evaluate the performance of each method, and the proposed method achieved values of 0.6574, 8.4572, 5.6305, 0.7341, and 89.5685, respectively, which are higher than those of the current state-of-the-art algorithms. In the qualitative experiments, a differential image was used for further validation, and the near-zero residuals visually verified the adequacy of the proposed method for fusion. Furthermore, we showed some fusion results of multifocused biomedical microscopy images to verify the reliability of the proposed method, which shows high-quality fusion results. Conclusion: Multifocus biomedical microscopic image fusion can be accurately and effectively achieved by devising a deep convolutional neural network with joint cross-attention and spatial attention mechanisms. © 2023","Deep learning; End-to-end transformer network; Hybrid attention mechanism; Microscopic image fusion","Algorithms; Benchmarking; Electric Power Supplies; Image Processing, Computer-Assisted; Microscopy; Reproducibility of Results; Convolutional neural networks; Deep neural networks; Semantics; Attention mechanisms; Biomedical images; Deep learning; End to end; End-to-end transformer network; Hybrid attention mechanism; Microscopic image; Microscopic image fusion; Multi-focus; Spatial attention; Article; controlled study; convolutional neural network; deep learning; depth of focus; discrete wavelet transform; dual tree complex wavelet transform; genetic algorithm; human; imaging algorithm; intestine cancer; invasive ductal breast carcinoma; lung cancer; microscopy; multifocus microscopic biomedical image fusion; qualitative analysis; quantitative analysis; spatial analysis; stomach adenocarcinoma; transfusion; wavelet analysis; algorithm; benchmarking; image processing; microscopy; power supply; reproducibility; Image fusion","Natural Science Foundation of Shandong Province, (ZR2021QE205); Natural Science Foundation of Shandong Province","Elsevier Ireland Ltd","37487310","2-s2.0-85165534150"
"Alzakari S.A.; Maashi M.; Alahmari S.; Arasi M.A.; Alharbi A.A.K.; Sayed A.","Alzakari, Sarah A. (57220890847); Maashi, Mashael (57216199758); Alahmari, Saad (57924413000); Arasi, Munya A. (57200158993); Alharbi, Abeer A. K. (59076056000); Sayed, Ahmed (58872962100)","57220890847; 57216199758; 57924413000; 57200158993; 59076056000; 58872962100","Towards laryngeal cancer diagnosis using Dandelion Optimizer Algorithm with ensemble learning on biomedical throat region images","14","1","19713","","","","10.1038/s41598-024-70525-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201977162&doi=10.1038%2fs41598-024-70525-0&partnerID=40&md5=1c1904975c5ce2060b207f25be6ab435","Laryngeal cancer exhibits a notable global health burden, with later-stage detection contributing to a low mortality rate. Laryngeal cancer diagnosis on throat region images is a pivotal application of computer vision (CV) and medical image diagnoses in the medical sector. It includes detecting and analysing abnormal or cancerous tissue from the larynx, an integral part of the vocal and respiratory systems. The computer-aided system makes use of artificial intelligence (AI) through deep learning (DL) and machine learning (ML) models, including convolution neural networks (CNN), for automated disease diagnoses and detection. Various DL and ML approaches are executed to categorize the extraction feature as healthy and cancerous tissues. This article introduces an automated Laryngeal Cancer Diagnosis using the Dandelion Optimizer Algorithm with Ensemble Learning (LCD-DOAEL) method on Biomedical Throat Region Image. The LCD-DOAEL method aims to investigate the images of the throat region for the presence of laryngeal cancer. In the LCD-DOAEL method, the Gaussian filtering (GF) approach is applied to eliminate the noise in the biomedical images. Besides, the complex and intrinsic feature patterns can be extracted by the MobileNetv2 model. Meanwhile, the DOA model carries out the hyperparameter selection of MobileNetV2 architecture. Finally, the ensemble of three classifiers such as bidirectional long short-term memory (BiLSTM), regularized extreme learning machine (ELM), and backpropagation neural network (BPNN) models, are utilized for the classification process. A comprehensive set of simulations is conducted on the biomedical image dataset to highlight the efficient performance of the LCD-DOAEL technique. The comparison analysis of the LCD-DOAEL method exhibited a superior accuracy outcome of 97.54% over other existing techniques. © The Author(s) 2024.","Biomedical image; Dandelion Optimizer Algorithm; Ensemble learning; Laryngeal cancer; Narrow-band imaging","Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Humans; Image Processing, Computer-Assisted; Laryngeal Neoplasms; Machine Learning; Neural Networks, Computer; Pharynx; algorithm; artificial neural network; computer assisted diagnosis; deep learning; diagnosis; diagnostic imaging; human; image processing; larynx tumor; machine learning; pharynx; procedures","","Nature Research","39181918","2-s2.0-85201977162"
"Nie X.; Zhou X.; Li Z.; Wang L.; Lin X.; Tong T.","Nie, Xingqing (57734381900); Zhou, Xiaogen (57210120226); Li, Zhiqiang (59067610400); Wang, Luoyan (57734668400); Lin, Xingtao (57734193300); Tong, Tong (55625986800)","57734381900; 57210120226; 59067610400; 57734668400; 57734193300; 55625986800","LogTrans: Providing Efficient Local-Global Fusion with Transformer and CNN Parallel Network for Biomedical Image Segmentation","","","","769","776","7","10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152242975&doi=10.1109%2fHPCC-DSS-SmartCity-DependSys57074.2022.00128&partnerID=40&md5=60e730cbd07d16a103cd4bab3eb5c961","Accurate biomedical image segmentation is a prerequisite for excellent computer-aided diagnosis (CAD) systems. A series of researches have shown that convolutional neural networks (CNNs) have made impressive progress in segmentation tasks. Nevertheless, owing to the finite receptive field of CNN-based algorithms, such networks are focused too much on local area features rather than global context. While the Transformer architecture can encode global dependencies information through the self-attention mechanism, this mechanism typically ignores the local pixel-level structural information within each divided patch. Therefore, a better solution is still needed for how to integrate CNN architecture with Transformer architecture efficiently. In this essay, we propose an originative parallel segmentation algorithm called LogTrans. First, in the encoder path, the local details and global contour dependencies on the entire image are captured by the CNN branch and the Transformer branch, respectively. Then these two branches complement each other by a novel separate-combiner (SeCo) module, leading to better fused features. Moreover, we attempt to further enhance the segmentation properties by using a residual stackable dilated (ReSD) block, which applies residual shortcut connections to resolve dimension alterations in the target region and stacks dilated convolutions to capture more spatial information. The proposed LogTrans framework was evaluated on two biomedical datasets, including ISIC-2017 and UITNS-2022 datasets. Collectively, multiple results have indicated that our LogTrans performs superior with other state-of-the-art architectures in both visual comparison and quantitative appraisal.  © 2022 IEEE.","Biomedical image segmentation; Convolutional neural networks; Deep Learning; Global context; Transformer","Bioinformatics; Computer aided diagnosis; Convolution; Deep learning; Image segmentation; Network architecture; Biomedical image segmentation; Computer aided diagnosis systems; Convolutional neural network; Deep learning; Global context; Local areas; Network-based algorithm; Parallel network; Receptive fields; Transformer; Convolutional neural networks","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85152242975"
"Obayya M.; Saeed M.K.; Alruwais N.; Alotaibi S.S.; Assiri M.; Salama A.S.","Obayya, Marwa (6505869929); Saeed, Muhammad Kashif (57202381130); Alruwais, Nuha (58000746700); Alotaibi, Saud S. (57202829227); Assiri, Mohammed (57219344932); Salama, Ahmed S. (56480035100)","6505869929; 57202381130; 58000746700; 57202829227; 57219344932; 56480035100","Hybrid Metaheuristics with Deep Learning-Based Fusion Model for Biomedical Image Analysis","11","","","117149","117158","9","10.1109/ACCESS.2023.3326369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174859346&doi=10.1109%2fACCESS.2023.3326369&partnerID=40&md5=63fe7da16e2472f5531f57306a513e45","Biomedical image analysis has played a pivotal role in modern healthcare by facilitating automated analysis and interpretation of medical images. Biomedical image classification is the process of automatically labelling or categorizing medical images based on their content. In recent years, this field has received considerable attention because of the abundance of bio-medical image data and the potential for deep learning (DL) algorithms to assist medical staff in identifying diseases and making treatment decisions. DL methods are mostly convolutional neural networks (CNN) has illustrated outstanding performance in analyzing and classifying biomedical images. Therefore, this study presents a new Hybrid Metaheuristics with Deep Learning based Fusion Model Biomedical Image Analysis (HMDL-MFMBIA) technique. The HMDL-MFMBIA technique initially performs image pre-processing and Swin-UNet-based segmentation. Besides, a fusion of multiple DL-based feature extractors takes place using Xception and Residual Network (ResNet) model. Moreover, a hybrid salp swarm algorithm (HSSA) was employed for the optimal hyperparameter selection of the DL models. Finally, the gated recurrent unit (GRU) algorithm can be exploited for the detection and classification of bio-medical images. A widespread of simulated is conducted to establish the enhanced biomedical image classification results of the HMDL-MFMBIA method. The simulation outcomes inferred the greater outcome of the HMDL-MFMBIA algorithm over other DL models.  © 2013 IEEE.","Biomedical image analysis; computer vision; deep learning; fusion model; image classification","Bioinformatics; Computer vision; Convolution; Deep learning; Diagnosis; Feature extraction; Heuristic algorithms; Image analysis; Image classification; Image enhancement; Image fusion; Medical image processing; Neural networks; Biological system modeling; Biomedical image analysis; Classification algorithm; Convolutional neural network; Deep learning; Features extraction; Fusion model; Images classification; Images segmentations; Medical diagnostic imaging; Tuning; Image segmentation","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85174859346"
"Sumathy V.; Pretty Diana Cyril C.","Sumathy, V. (57212708697); Pretty Diana Cyril, C. (57222521426)","57212708697; 57222521426","Systematic Literature Review on Early Diagnosis of Oral Squamous Cell Carcinoma by Deep Learning Techniques","","","","","","","10.1109/RMKMATE59243.2023.10369110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183537880&doi=10.1109%2fRMKMATE59243.2023.10369110&partnerID=40&md5=579ea4a0fdf99e1ecbd4722613076a1f","Oral Squamous Cell Carcinoma (OSCC) is the seventh most prevalent type of cancer in the neck and head. The prognosis and survival rate of the patient is significantly improved by early identification of OSCC. Due to tumor heterogeneity, such a diagnosis requires much time and a high-efficiency human experience. As a result, artificial intelligence systems assist professionals and physicians in making precise diagnoses. Recent advances in computer vision-based techniques and Computational Intelligence (CI) improve accuracy in medical images. This study aims to develop hybrid methodologies based on fused features to produce excellent outcomes for the early detection of OSCC. This systematic review aims to estimate deep learning (DL) based algorithms for early diagnosis OSCC to assist clinicians in oral cancer diagnosis and screening. The terms ""squamous cell carcinoma, "" ""early diagnosis, "" ""oral cavity, "" ""histopathological image, "" ""biomarker, "" ""Optical Coherence Tomography (OCT) image, "" and ""deep learning"" were used in a Google Scholar Cochrane and MEDLINE (PubMed), Embase and WoS databases (January 2018 to July 2023) to find relevant articles. The inclusion criteria were the use of deep learning approaches for early diagnosis of OSCC, articles older than 5 years, and publications written in English. Case reports and studies written in foreign languages met the exclusion criteria. 70 publications were chosen to be included in the systematic review out of the 194 studies that were initially found through the search. Deep learning techniques based on hybrid features are examined in evaluating performance metrics and superior results of the present systems employing biomedical images for OSCC diagnosis. It has been established that the deep learning-based early identification method for biomedical images has the ability to offer decision support for efficient oral cancer diagnosis and screening. © 2023 IEEE.","convolutional neural network; deep learning; hybrid method; OCT; Oral Squamous Cell Carcinoma","Cells; Convolutional neural networks; Cytology; Decision support systems; Deep learning; Diseases; Image enhancement; Learning algorithms; Learning systems; Medical imaging; Optical tomography; Cancer diagnosis; Cancer screening; Convolutional neural network; Deep learning; Early diagnosis; Hybrid method; Learning techniques; Oral cancer; Oral squamous cell carcinomata; Systematic Review; Diagnosis","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85183537880"
"Lu H.; Tian S.; Yu L.; Liu L.; Cheng J.; Wu W.; Kang X.; Zhang D.","Lu, Hongchun (57214780414); Tian, Shengwei (35119846500); Yu, Long (55272883600); Liu, Lu (57365898200); Cheng, Junlong (57217079223); Wu, Weidong (57226092151); Kang, Xiaojing (58729267200); Zhang, Dezhi (57274431700)","57214780414; 35119846500; 55272883600; 57365898200; 57217079223; 57226092151; 58729267200; 57274431700","DCACNet: Dual context aggregation and attention-guided cross deconvolution network for medical image segmentation","214","","106566","","","","10.1016/j.cmpb.2021.106566","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120821466&doi=10.1016%2fj.cmpb.2021.106566&partnerID=40&md5=8e7891fddfb51791027b5740e4bd98d8","Background and Objective: Segmentation is a key step in biomedical image analysis tasks. Recently, convolutional neural networks (CNNs) have been increasingly applied in the field of medical image processing; however, standard models still have some drawbacks. Due to the significant loss of spatial information at the coding stage, it is often difficult to restore the details of low-level visual features using simple deconvolution, and the generated feature maps are sparse, which results in performance degradation. This prompted us to study whether it is possible to better preserve the deep feature information of the image in order to solve the sparsity problem of image segmentation models. Methods: In this study, we (1) build a reliable deep learning network framework, named DCACNet, to improve the segmentation performance for medical images; (2) propose a multiscale cross-fusion encoding network to extract features; (3) build a dual context aggregation module to fuse the context features at different scales and capture more fine-grained deep features; and (4) propose an attention-guided cross deconvolution decoding network to generate dense feature maps. We demonstrate the effectiveness of the proposed method on two publicly available datasets. Results: DCACNet was trained and tested on the prepared dataset, and the experimental results show that our proposed model has better segmentation performance than previous models. For 4-class classification (CHAOS dataset), the mean DSC coefficient reached 91.03%. For 2-class classification (Herlev dataset), the accuracy, precision, sensitivity, specificity, and Dice score reached 96.77%, 90.40%, 94.20%, 97.50%, and 97.69%, respectively. The experimental results show that DCACNet can improve the segmentation effect for medical images. Conclusion: DCACNet achieved promising results on the prepared dataset and improved segmentation performance. It can better retain the deep feature information of the image than other models and solve the sparsity problem of the medical image segmentation model. © 2021","Attention mechanism; Convolutional neural network; Cross deconvolution; Dual context aggregation; Medical image segmentation","Attention; Data Collection; Image Processing, Computer-Assisted; Neural Networks, Computer; Convolution; Convolutional neural networks; Deep learning; Image enhancement; Image segmentation; Medical image processing; Attention mechanisms; Convolutional neural network; Cross deconvolution; Deconvolutions; Dual context aggregation; Feature information; Feature map; Medical image segmentation; Segmentation performance; Sparsity problems; Article; convolutional neural network; deconvolution algorithm; deep learning; image segmentation; information processing; sensitivity and specificity; attention; image processing; Classification (of information)","Xinjiang Autonomous Region key research and development project, (2020E0234, 2021B01-002); National Natural Science Foundation of China, NSFC, (62162058, U2003208); National Natural Science Foundation of China, NSFC; Xinjiang Uygur Autonomous Region Department of Education, (XJ2020G072, XJ2020G073); Xinjiang Uygur Autonomous Region Department of Education","Elsevier Ireland Ltd","34890992","2-s2.0-85120821466"
"Yang Q.; Geng C.; Chen R.; Pang C.; Han R.; Lyu L.; Zhang Y.","Yang, Qinghan (57226687891); Geng, Chong (58894356800); Chen, Ruyue (57679297900); Pang, Chen (57242601700); Han, Run (57388803600); Lyu, Lei (57204062203); Zhang, Yuang (24451415400)","57226687891; 58894356800; 57679297900; 57242601700; 57388803600; 57204062203; 24451415400","DMU-Net: Dual-route mirroring U-Net with mutual learning for malignant thyroid nodule segmentation","77","","103805","","","","10.1016/j.bspc.2022.103805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130414984&doi=10.1016%2fj.bspc.2022.103805&partnerID=40&md5=75ff24c29c2638fd1d0d31f0596e285c","It is meaningful for radiologists to segment thyroid nodules in ultrasound images quickly and accurately using an effective segmentation algorithm. With the rise of deep learning in computer vision, many deep learning-based methods have been proposed to assist radiologists in diagnosing thyroid diseases, such as thyroid nodule classification, detection and segmentation, but there exist few methods paying attention to malignant thyroid nodule segmentation. The goal of thyroid nodule segmentation is to identify the type of thyroid nodule. However, the identification of thyroid nodule type has been relatively well developed and the identification work almost can't bother radiologists. The more important for radiologists is to detect the inconspicuous malignant nodules precisely in ultrasonic images, avoiding radiologists confusing tissues and malignant thyroid nodules during their diagnosis. This paper proposes a deep learning-based CAD (Computer-aided diagnosis) method called Dual-route Mirroring U-Net (DMU-Net) to segment malignant thyroid nodules automatically. The method uses two subnets (U-shape subnet, inversed U-shape subnet) and three modules (pyramid attention module (PAM), margin refinement module (MRM), aggregation module (AM)) to extract contextual information of thyroid nodules and margin details in ultrasonic images. Further, the strategy of mutual learning is introduced from the natural image classification task to enhance the performance of DMU-Net. We train and evaluate our method on the self-built Malignant Thyroid Nodule Segmentation (MTNS) dataset. Finally, we compare the DMU-Net with several classical deep learning-based methods on the MTNS dataset and other public datasets. The results show our DMU-Net can achieve superior performance on these datasets. © 2022 Elsevier Ltd","Biomedical image segmentation; Convolutional neural network; Malignant thyroid nodule; Margin details extraction; U-Net","Computer aided instruction; Convolutional neural networks; Deep learning; Image enhancement; Image segmentation; Learning systems; Ultrasonic imaging; Biomedical image segmentation; Convolutional neural network; Details extractions; Dual route; Malignant thyroid nodule; Margin detail extraction; Nodule segmentation; Subnets; Thyroid nodule; U-net; Article; convolutional neural network; deep learning; feature extraction; human; image segmentation; methodology; radiologist; thyroid cancer; thyroid gland; thyroid nodule; ultrasound; Computer aided diagnosis","Jinan Science and technology innovation development Foundation, (202126003); National Natural Science Foundation of China, NSFC, (61976127); National Natural Science Foundation of China, NSFC; Natural Science Foundation of Shandong Province, (ZR2019MF071, ZR2021LZL012); Natural Science Foundation of Shandong Province","Elsevier Ltd","","2-s2.0-85130414984"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","14448 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178549397&partnerID=40&md5=cd53510390634e0e25fb8bc1b0bfb5e0","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178549397"
"Hamzehei S.; Bai J.; Raimondi G.; Tripp R.; Ostroff L.; Nabavi S.","Hamzehei, Sahand (58074812700); Bai, Jun (57221616470); Raimondi, Gianna (57653961200); Tripp, Rebecca (58176501400); Ostroff, Linnaea (6506542847); Nabavi, Sheida (56229091400)","58074812700; 57221616470; 57653961200; 58176501400; 6506542847; 56229091400","3D Biological/Biomedical Image Registration with enhanced Feature Extraction and Outlier Detection","","","1","","","","10.1145/3584371.3612965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175838560&doi=10.1145%2f3584371.3612965&partnerID=40&md5=4d91e845806c9386dec23c04b76eb04f","In various applications, such as computer vision, medical imaging, and robotics, three-dimensional (3D) image registration is a significant step. It enables the alignment of various datasets into a single coordinate system, consequently providing a consistent perspective that allows further analysis. By precisely aligning images, we can compare, analyze, and combine data collected in different situations. This paper presents a novel approach for 3D or z-stack microscopy and medical image registration, utilizing a combination of conventional and deep learning techniques for feature extraction and adaptive likelihood-based methods for outlier detection. The proposed method uses the Scale-invariant Feature Transform (SIFT) and the Residual Network (ResNet50) deep neural learning network to extract effective features and obtain precise and exhaustive representations of image contents. The registration approach also employs the adaptive Maximum Likelihood Estimation SAmple Consensus (MLESAC) method that optimizes outlier detection and increases noise and distortion resistance to improve the efficacy of these combined extracted features. This integrated approach demonstrates robustness, flexibility, and adaptability across a variety of imaging modalities, enabling the registration of complex images with higher precision. Experimental results show that the proposed algorithm outperforms state-of-the-art image registration methods, including conventional SIFT, SIFT with Random Sample Consensus (RANSAC), and Oriented FAST and Rotated BRIEF (ORB) methods, as well as registration software packages such as bUnwrapJ and TurboReg, in terms of Mutual Information (MI), Phase Congruency-Based (PCB) metrics, and Gradiant-based metrics (GBM), using 3D MRI and 3D serial sections of multiplex microscopy images. © 2023 ACM.","3D biomedical images; deep learning; feature extraction; image registration; maximum likelihood estimation sample consensus (MLESAC); scale-invariant feature transform (SIFT); z-stack microscopy images","Anomaly detection; Data handling; Deep neural networks; Extraction; Image enhancement; Image registration; Learning systems; Magnetic resonance imaging; Maximum likelihood estimation; Medical imaging; Polychlorinated biphenyls; Statistics; 3d biomedical image; Biomedical images; Deep learning; Features extraction; Images registration; Invariant feature transforms; Maximum likelihood estimation sample consensus; Maximum-likelihood estimation; Microscopy images; Sample consensus; Scale invariant features; Scale-invariant feature transform; Z-stack microscopy image; Feature extraction","Computer Science and Engineering departmental at UConn; National Institutes of Health, NIH, (RF1MH130472); National Institutes of Health, NIH","Association for Computing Machinery, Inc","","2-s2.0-85175838560"
"Lin Y.; Liang Z.; He Y.; Huang W.; Guan T.","Lin, Yuanhua (58556669500); Liang, Zhendong (57963206100); He, Yonghong (7404941330); Huang, Wenting (57488200300); Guan, Tian (7006929546)","58556669500; 57963206100; 7404941330; 57488200300; 7006929546","End-to-end affine registration framework for histopathological images with weak annotations","241","","107763","","","","10.1016/j.cmpb.2023.107763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169299165&doi=10.1016%2fj.cmpb.2023.107763&partnerID=40&md5=1fb902796ebe9648e81415a57f0e3287","Background and Objective: Histopathological image registration is an essential component in digital pathology and biomedical image analysis. Deep-learning-based algorithms have been proposed to achieve fast and accurate affine registration. Some previous studies assume that the pairs are free from sizeable initial position misalignment and large rotation angles before performing the affine transformation. However, large-rotation angles are often introduced into image pairs during the production process in real-world pathology images. Reliable initial alignment is important for registration performance. The existing deep-learning-based approaches often use a two-step affine registration pipeline because convolutional neural networks (CNNs) cannot correct large-angle rotations. Methods: In this manuscript, a general framework ARoNet is developed to achieve end-to-end affine registration for histopathological images. We use CNNs to extract global features of images and fuse them to construct correspondent information for affine transformation. In ARoNet, a rotation recognition network is implemented to eliminate great rotation misalignment. In addition, a self-supervised learning task is proposed to assist the learning of image representations in an unsupervised manner. Results: We applied our model to four datasets, and the results indicate that ARoNet surpasses existing affine registration algorithms in alignment accuracy when large angular misalignments (e.g., 180 rotation) are present, providing accurate affine initialization for subsequent non-rigid alignments. Besides, ARoNet shows advantages in execution time (0.05 per pair), registration accuracy, and robustness. Conclusion: We believe that the proposed general framework promises to simplify and speed up the registration process and has the potential for clinical applications. © 2023 Elsevier B.V.","Affine estimation; ANHIR; Histopathological image registration","Algorithms; Image Processing, Computer-Assisted; Neural Networks, Computer; Alignment; Convolutional neural networks; Deep learning; Image annotation; Large dataset; Learning systems; Pathology; Rotation; Affine estimations; Affine registration; Affine transformations; ANHIR; Convolutional neural network; End to end; Histopathological image registration; Histopathological images; Images registration; Large rotation angles; affine transform; article; convolutional neural network; deep learning; histopathology; image registration; learning; pipeline; rotation; velocity; algorithm; artificial neural network; image processing; Image registration","Science and Technology Research Program of Shenzhen City, (JCYJ20200109110606054, WDZC20200821141349001); National Natural Science Foundation of China, NSFC, (61875102); National Natural Science Foundation of China, NSFC","Elsevier Ireland Ltd","37634308","2-s2.0-85169299165"
"Alanazi A.A.; Abaker A.O.I.; Abdel-Khalek S.; Alhomayani F.M.; Aripov M.","Alanazi, Adwan A. (57212021340); Abaker, Abdelgalal O. I. (58817476400); Abdel-Khalek, Sayed (6506630609); Alhomayani, Fahad Mohammed (57218996816); Aripov, M. (8880099100)","57212021340; 58817476400; 6506630609; 57218996816; 8880099100","Neutrosophic Logic Empowered Machine Learning Algorithm with Salp Swarm Optimization for Biomedical Image Analysis","23","4","","104","116","12","10.54216/IJNS.230408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193495422&doi=10.54216%2fIJNS.230408&partnerID=40&md5=e69f6bc87ebd3a1cf5560d89ffcd8151","Leukemia recognition and classification contain the identification of dissimilar kinds of leukemia, a group of blood cancers that affects the bone marrow and blood. A classical model containing microscopic analysis of blood smears to classify abnormal cells analytic of leukemia. Leukemia recognition employing a united technique of neutrosophic logic and deep learning (DL) signifies a new and complete approach to handling uncertainty and difficulty in medical data. Neutrosophic logic permits the representation of unstated or imperfect data, which is general in medical analyses. DL mainly convolutional neural networks (CNN) or recurrent neural networks (RNN), which can mechanically remove difficult patterns from medicinal imageries, improving the accuracy of leukemia recognition. The neutrosophic logic module accommodates the characteristic uncertainty in medicinal data, offering a formalism to manage imperfect or inaccurate data linked with the analysis procedure. The combination of these dual techniques generates a robust structure which capable of leveraging both the control of DL in image analysis and the flexibility of neutrosophic logic in dealing with uncertainties, contributing to more trustworthy and interpretable leukemia recognition methods. This study develops a new Salp Swarm Algorithm with a Neutrosophic Logic SVM (SSA-NSVM) model for Leukemia Detection and Classification. The SSA-NSVM technique mainly exploits Neutrosophic Logic (NL) concepts with the DL model for the detection of leukemia. To attain this, the SSA-NSVM model uses bilateral filtering (BF) based image pre-processing. In addition, the SSA-NSVM approach applies a modified densely connected networks (DenseNet) technique for learning complex and intrinsic feature patterns. Besides, the hyperparameter range of the modified DenseNet system takes place utilizing a SSA. At last, the NSVM technique is employed for the detection and identification of leukemia. The performance validation of the SSA-NSVM algorithm is verified utilizing a benchmark medicinal image dataset. The simulation values emphasized that the SSA-NSVM model reaches better detection outcomes than other existing approaches. © 2024, American Scientific Publishing Group (ASPG). All rights reserved.","Blood Cancer; Bone Marrow; Leukemia Detection; Neutrosophic Logic; Salp Swarm Algorithm","","Deanship of Scientific Research, King Khalid University, (RGP2/462/44); Deanship of Scientific Research, King Khalid University","American Scientific Publishing Group (ASPG)","","2-s2.0-85193495422"
"Bhandary S.; Kuhn D.; Babaiee Z.; Fechter T.; Benndorf M.; Zamboglou C.; Grosu A.-L.; Grosu R.","Bhandary, Shrajan (57336379800); Kuhn, Dejan (58251997000); Babaiee, Zahra (57225102627); Fechter, Tobias (55796836400); Benndorf, Matthias (36097606300); Zamboglou, Constantinos (36459419500); Grosu, Anca-Ligia (7005831902); Grosu, Radu (6601973195)","57336379800; 58251997000; 57225102627; 55796836400; 36097606300; 36459419500; 7005831902; 6601973195","Investigation and benchmarking of U-Nets on prostate segmentation tasks","107","","102241","","","","10.1016/j.compmedimag.2023.102241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159431700&doi=10.1016%2fj.compmedimag.2023.102241&partnerID=40&md5=5d8f7f69265085a103be5273c8597539","In healthcare, a growing number of physicians and support staff are striving to facilitate personalized radiotherapy regimens for patients with prostate cancer. This is because individual patient biology is unique, and employing a single approach for all is inefficient. A crucial step for customizing radiotherapy planning and gaining fundamental information about the disease, is the identification and delineation of targeted structures. However, accurate biomedical image segmentation is time-consuming, requires considerable experience and is prone to observer variability. In the past decade, the use of deep learning models has significantly increased in the field of medical image segmentation. At present, a vast number of anatomical structures can be demarcated on a clinician's level with deep learning models. These models would not only unload work, but they can offer unbiased characterization of the disease. The main architectures used in segmentation are the U-Net and its variants, that exhibit outstanding performances. However, reproducing results or directly comparing methods is often limited by closed source of data and the large heterogeneity among medical images. With this in mind, our intention is to provide a reliable source for assessing deep learning models. As an example, we chose the challenging task of delineating the prostate gland in multi-modal images. First, this paper provides a comprehensive review of current state-of-the-art convolutional neural networks for 3D prostate segmentation. Second, utilizing public and in-house CT and MR datasets of varying properties, we created a framework for an objective comparison of automatic prostate segmentation algorithms. The framework was used for rigorous evaluations of the models, highlighting their strengths and weaknesses. © 2023 The Author(s)","Automatic prostate segmentation; Comparison framework; Medical imaging; U-net variations","Algorithms; Benchmarking; Humans; Image Processing, Computer-Assisted; Male; Neural Networks, Computer; Prostate; Prostatic Neoplasms; Computerized tomography; Convolutional neural networks; Deep learning; Image segmentation; Learning systems; Medical imaging; Radiotherapy; Urology; Automatic prostate segmentation; Biomedical image segmentation; Comparison framework; Learning models; Observer variability; Prostate cancers; Prostate segmentation; Radiotherapy planning; Support staff; U-net variation; adult; anatomical concepts; automation; benchmarking; cancer patient; clinician; convolutional neural network; deep learning; human; image segmentation; male; multimodal imaging; nuclear magnetic resonance imaging; prostate cancer; Review; segmentation algorithm; u net; x-ray computed tomography; algorithm; artificial neural network; diagnostic imaging; image processing; procedures; prostate; prostate tumor; Diseases","TU Wien's Faculty of Informatics; TU Wien’s Faculty of Informatics; UAS Technikum Wien; Bundesministerium für Bildung und Forschung, BMBF; Austrian Science Fund, FWF, (I 4718); Austrian Science Fund, FWF","Elsevier Ltd","37201475","2-s2.0-85159431700"
"Jagadesh T.; Kamalesh P.; Kishore A.; Lokin V.; Jaiprakash B.","Jagadesh, T. (56582511400); Kamalesh, P. (57643418800); Kishore, A. (57190295631); Lokin, V. (59223702400); Jaiprakash, B. (59223702500)","56582511400; 57643418800; 57190295631; 59223702400; 59223702500","Oral Cancer Detection Using Convolutional Neural Networks","","","","","","","10.1109/ICONSTEM60960.2024.10568599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198842931&doi=10.1109%2fICONSTEM60960.2024.10568599&partnerID=40&md5=06ba3e9726a885247d2fb4f3b6c22a93","In developing nation oral cancer makes the significant threat to human life. The existing system uses deep learning technique for detection of oral cancer in medical imaging. The two powerful tools of deep learning techniques are Convolutional Neural Networks and Deep Belief Network [1]. PSOBER- Particle Swarm Optimization and AI-Biruni Earth Radius a hybrid optimization algorithm is used to optimize the CNN and DBN. To overcome the outperformance of the existing method standard dataset of biomedical images are used for demonstration of the promising results. To test and validate the significance and stability one-way ANOVA and Wilcoxon signed-rank is used. For screening oral cancer detection in clinical setting this technique is used. However, the accuracy and to find the early detection of oral cancer and to make the less suffering of the patients the further research is needed. The proposed method of oral cancer detection using deep learning technique includes the enhancement of the images. In this method salt and pepper noise detection is used to find the accurate results using segmentation of the cells for thresholding. Back Propagation Neural Networks (BPNN) is used for the classification of the oral cancer. Tumor partition and features extraction are done in the proposed method. Feeding the loss backward through neural networks layers to fine tune the weights and the BPNN involves the error rate of forward propagation. Back propagation neural networks contain two signals. They are Error signal and Back signal.  © 2024 IEEE.","Back propagation; back signal; deep learning; detection; error signal; hybrid optimization; Medical imaging; neural networks; oral cancer; standard dataset; tumor partition","Backpropagation; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Diseases; Image enhancement; Learning systems; Multilayer neural networks; Network layers; Particle swarm optimization (PSO); Salt and pepper noise; Tumors; Back Propagation; Back signal; Deep learning; Detection; Error signal; Hybrid optimization; Neural-networks; Oral cancer; Standard dataset; Tumor partition; Medical imaging","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85198842931"
"Ye S.; Shen L.; Islam M.T.; Xing L.","Ye, Siqi (57200728012); Shen, Liyue (57201327444); Islam, Md Tauhidul (57263730600); Xing, Lei (7103349003)","57200728012; 57201327444; 57263730600; 7103349003","Super-resolution biomedical imaging via reference-free statistical implicit neural representation","68","20","205020","","","","10.1088/1361-6560/acfdf1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175585520&doi=10.1088%2f1361-6560%2facfdf1&partnerID=40&md5=bf8978a5526d0402a0eb039b94eed89f","Objective. Supervised deep learning for image super-resolution (SR) has limitations in biomedical imaging due to the lack of large amounts of low- and high-resolution image pairs for model training. In this work, we propose a reference-free statistical implicit neural representation (INR) framework, which needs only a single or a few observed low-resolution (LR) image(s), to generate high-quality SR images. Approach. The framework models the statistics of the observed LR images via maximum likelihood estimation and trains the INR network to represent the latent high-resolution (HR) image as a continuous function in the spatial domain. The INR network is constructed as a coordinate-based multi-layer perceptron, whose inputs are image spatial coordinates and outputs are corresponding pixel intensities. The trained INR not only constrains functional smoothness but also allows an arbitrary scale in SR imaging. Main results. We demonstrate the efficacy of the proposed framework on various biomedical images, including computed tomography (CT), magnetic resonance imaging (MRI), fluorescence microscopy, and ultrasound images, across different SR magnification scales of 2×, 4×, and 8×. A limited number of LR images were used for each of the SR imaging tasks to show the potential of the proposed statistical INR framework. Significance. The proposed method provides an urgently needed unsupervised deep learning framework for numerous biomedical SR applications that lack HR reference images. © 2023 Institute of Physics and Engineering in Medicine.","biomedical imaging; implicit neural representation; inverse problem; maximum likelihood estimation; multi-scale imaging; super-resolution; unsupervised learning","Algorithms; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Microscopy, Fluorescence; Neural Networks, Computer; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Fluorescence microscopy; Learning systems; Magnetic resonance imaging; Maximum likelihood estimation; Medical imaging; Optical resolving power; Biomedical imaging; High-resolution images; Implicit neural representation; Low resolution images; Maximum-likelihood estimation; Multi-scale imaging; Neural representations; Reference-free; Super resolution imaging; Superresolution; algorithm; artificial neural network; fluorescence microscopy; image processing; nuclear magnetic resonance imaging; procedures; x-ray computed tomography; Inverse problems","National Institutes of Health, NIH, (1R01CA176553, 1R01CA223667, 1R01CA227713); National Institutes of Health, NIH; Shanghai Jiao Tong University, SJTU","Institute of Physics","37757838","2-s2.0-85175585520"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","14452 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190366951&partnerID=40&md5=6ebabd485ea61c047f43d7f7d7fde660","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85190366951"
"Poonia R.C.; Upreti K.; Jafri S.; Parashar J.; Vats P.; Singh J.","Poonia, Ramesh Chandra (56638603100); Upreti, Kamal (57202706345); Jafri, Samreen (57852595500); Parashar, Jyoti (57204113069); Vats, Prashant (56630562900); Singh, Jagendra (56347348900)","56638603100; 57202706345; 57852595500; 57204113069; 56630562900; 56347348900","Biomedical Mammography Image Classification Using Patches-Based Feature Engineering with Deep Learning and Ensemble Classifier","1046 LNNS","","","275","285","10","10.1007/978-3-031-64813-7_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200652501&doi=10.1007%2f978-3-031-64813-7_29&partnerID=40&md5=0ca86de482edf8996bc11e8bb67acd80","In order to reduce the expense of radiologists, deep learning algorithms have recently been used in the mammograms screening field. Deep learning-based methods, like a Convolutional Neural Network (CNN), are now being used to categorize breast lumps. When it involves classifying mammogram imagery, CNN-based systems clearly outperform machine learning-based systems, but they do have certain disadvantages as well. Additional challenges include a dearth of knowledge on feature engineering and the impossibility of feature analysis for the existing patches of pictures, which are challenging to distinguish in low-contrast mammograms. Inaccurate patch assessments, higher calculation costs, inaccurate patch examinations, and non-recovered patched intensity variation are all results of mammogram image patches. This led to evidence that a CNN-based technique for identifying breast masses had poor classification accuracy. Deep Learning-Based Featured Reconstruction is a novel breast mass classification technique that boosts precision on low-contrast pictures (DFN). This system uses random forest boosting techniques together with CNN architectures like VGG 16 and Resnet 50 to characterize breast masses. Using two publicly accessible datasets of mammographic images, the suggested DFN approach is also contrasted with modern classification methods. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Biomedical images; Breast mass classification technique; CNN; Deep learning; Mammography","Classification (of information); Computer aided diagnosis; Convolutional neural networks; Deep learning; Image classification; Learning algorithms; Learning systems; X ray screens; Biomedical images; Breast mass; Breast mass classification technique; Classification technique; Convolutional neural network; Deep learning; Feature engineerings; Low contrast; Mammography images; Mass classifications; Mammography","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85200652501"
"Lu P.; Fang F.; Zhang H.; Ling L.; Hua K.","Lu, Pengyue (57344157100); Fang, Faming (35753184800); Zhang, He (55685593900); Ling, Lei (57221232803); Hua, Keqin (57203187482)","57344157100; 35753184800; 55685593900; 57221232803; 57203187482","AugMS-Net:Augmented multiscale network for small cervical tumor segmentation from MRI volumes","141","","104774","","","","10.1016/j.compbiomed.2021.104774","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119263879&doi=10.1016%2fj.compbiomed.2021.104774&partnerID=40&md5=a1b9308dae00ae26169ce5174ff7bb08","Cervical cancer is one of the leading causes of female-specific cancer death. Tumor region segmentation plays a pivotal role in both the clinical analysis and treatment planning of cervical cancer. Due to the heterogeneity and low contrast of biomedical images, current state-of-the-art tumor segmentation approaches are facing the challenge of the insensitive detection of small lesion regions. To tackle this problem, this paper proposes an augmented multiscale network (AugMS-Net) based on 3D U-Net to automatically segment cervical Magnetic Resonance Imaging (MRI) volumes. Since a multiscale strategy is considered one of the most promising algorithms to tackle small object recognition, we introduce a novel 3D module to explore more granular multiscale representations. Besides, we employ a deep multiscale supervision strategy to doubly supervise the side outputs hierarchically. To demonstrate the generalization of our model, we evaluated AugMS-Net on both a cervical dataset from MRI volumes and a liver dataset from Computerized Tomography (CT) volumes. Our proposed AugMS-Net shows superior performance over baseline models, yielding high accuracy while reducing the number of model parameters by nearly 20%. The source code and trained models are available at https://github.com/Cassieyy/AugMS-Net. © 2021 Elsevier Ltd","Augmented multiscale; Biomedical image; Deep learning; Semantic segmentation","Algorithms; Female; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Uterine Cervical Neoplasms; Computerized tomography; Deep learning; Diseases; Object recognition; Semantic Segmentation; Semantics; Tumors; Augmented multiscale; Biomedical images; Cervical cancers; Clinical analysis; Clinical treatments; Deep learning; Imaging volume; Region segmentation; Semantic segmentation; Tumor segmentation; Article; controlled study; convolutional neural network; deep learning; female; human; image segmentation; liver; liver tumor; nuclear magnetic resonance imaging; quantitative analysis; receptive field; segmentation algorithm; uterine cervix cancer; x-ray computed tomography; algorithm; diagnostic imaging; image processing; nuclear magnetic resonance imaging; procedures; uterine cervix tumor; Magnetic resonance imaging","NSFC-RGC, (61961160734); Science Foundation of Shanghai, (20ZR1416200); National Natural Science Foundation of China, NSFC, (61731009); Shanghai Rising-Star Program, (21QA1402500, 61871185)","Elsevier Ltd","34785076","2-s2.0-85119263879"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","1961 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178608466&partnerID=40&md5=1667dbcda5df4e45fc3ea5633ada31fb","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178608466"
"Wang Z.; Liu Z.; Yu J.; Gao Y.; Liu M.","Wang, Zenan (56695430000); Liu, Zhen (57222562503); Yu, Jianfeng (57694785600); Gao, Yingxin (57212645196); Liu, Ming (58974184300)","56695430000; 57222562503; 57694785600; 57212645196; 58974184300","Multi-scale nested UNet with transformer for colorectal polyp segmentation","25","6","e14351","","","","10.1002/acm2.14351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189627172&doi=10.1002%2facm2.14351&partnerID=40&md5=916f5b4ecff8fea38a278b1c02a9da3f","Background: Polyp detection and localization are essential tasks for colonoscopy. U-shape network based convolutional neural networks have achieved remarkable segmentation performance for biomedical images, but lack of long-range dependencies modeling limits their receptive fields. Purpose: Our goal was to develop and test a novel architecture for polyp segmentation, which takes advantage of learning local information with long-range dependencies modeling. Methods: A novel architecture combining with multi-scale nested UNet structure integrated transformer for polyp segmentation was developed. The proposed network takes advantage of both CNN and transformer to extract distinct feature information. The transformer layer is embedded between the encoder and decoder of a U-shape net to learn explicit global context and long-range semantic information. To address the challenging of variant polyp sizes, a MSFF unit was proposed to fuse features with multiple resolution. Results: Four public datasets and one in-house dataset were used to train and test the model performance. Ablation study was also conducted to verify each component of the model. For dataset Kvasir-SEG and CVC-ClinicDB, the proposed model achieved mean dice score of 0.942 and 0.950 respectively, which were more accurate than the other methods. To show the generalization of different methods, we processed two cross dataset validations, the proposed model achieved the highest mean dice score. The results demonstrate that the proposed network has powerful learning and generalization capability, significantly improving segmentation accuracy and outperforming state-of-the-art methods. Conclusions: The proposed model produced more accurate polyp segmentation than current methods on four different public and one in-house datasets. Its capability of polyps segmentation in different sizes shows the potential clinical application. © 2024 The Authors. Journal of Applied Clinical Medical Physics published by Wiley Periodicals LLC on behalf of American Association of Physicists in Medicine.","colorectal polyp; deep learning; polyp segmentation; transformer","Algorithms; Colonic Polyps; Colonoscopy; Colorectal Neoplasms; Databases, Factual; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Neural Networks, Computer; algorithm; artificial neural network; colon polyp; colonoscopy; colorectal tumor; computer assisted diagnosis; diagnostic imaging; factual database; human; image processing; pathology; procedures","Beijing Municipal Administration of Hospitals, (XXT12); Beijing Municipal Administration of Hospitals","John Wiley and Sons Ltd","38551396","2-s2.0-85189627172"
"Subasi A.","Subasi, Abdulhamit (8327241200)","8327241200","Medical image segmentation using artificial intelligence","","","","377","400","23","10.1016/B978-0-443-22308-2.00004-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193360200&doi=10.1016%2fB978-0-443-22308-2.00004-4&partnerID=40&md5=a1d159a6c188aa5ac0196dc8dc0c2c60","A fundamental problem in medical image analysis, biomedical image segmentation, is essential to many therapeutic applications. To facilitate quantitative analysis and support disease diagnosis, treatment planning, and disease monitoring, it requires partitioning images into different regions or objects of interest. Artificial intelligence (AI) methods, in particular deep learning algorithms, have become effective tools for biomedical picture segmentation in recent years. This chapter presents a biomedical image segmentation application of AI, emphasizing its potential to enhance precision, effectiveness, and therapeutic results. It examines several AI techniques, such as generative models and convolutional neural networks, and how they might be used to tackle the difficulties associated with image segmentation. It emphasizes how using AI algorithms can produce precise and reliable segmentation results. We go over the difficulties with biomedical image segmentation as well as the improvements made feasible by AI methods. We also implement a medical image segmentation example with TransResUNet. The impact of AI on biomedical image segmentation and its promise to alter medical imaging and customized healthcare are highlighted in the chapter's conclusion. © 2024 Elsevier Inc. All rights reserved.","Artificial intelligence; Biomedical image segmentation; Clinical applications; Deep learning; TransResUNet","","","Elsevier","","2-s2.0-85193360200"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","1962 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178564254&partnerID=40&md5=3829318325536acdf7d9f46a8439ef86","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178564254"
"Zheng W.; Chen J.; Zhang K.; Yan J.; Wang J.; Cheng Y.; Du B.; Chen D.Z.; Gao H.; Wu J.; Xu H.","Zheng, Wenhao (57559381700); Chen, Jintai (57211999917); Zhang, Kai (59041130000); Yan, Jiahuan (58023227100); Wang, Jinhong (57407142300); Cheng, Yi (57750482400); Du, Bang (58739979700); Chen, Danny Z. (7405453271); Gao, Honghao (36442463200); Wu, Jian (56197228100); Xu, Hongxia (57222187378)","57559381700; 57211999917; 59041130000; 58023227100; 57407142300; 57750482400; 58739979700; 7405453271; 36442463200; 56197228100; 57222187378","Polygonal Approximation Learning for Convex Object Segmentation in Biomedical Images with Bounding Box Supervision","28","8","","4522","4533","11","10.1109/JBHI.2023.3341699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180309620&doi=10.1109%2fJBHI.2023.3341699&partnerID=40&md5=cadb113a49e750624b7d19918644bbd8","As a common and critical medical image analysis task, deep learning based biomedical image segmentation is hindered by the dependence on costly fine-grained annotations. To alleviate this data dependence, in this article, a novel approach, called Polygonal Approximation Learning (PAL), is proposed for convex object instance segmentation with only bounding-box supervision. The key idea behind PAL is that the detection model for convex objects already contains the necessary information for segmenting them since their convex hulls, which can be generated approximately by the intersection of bounding boxes, are equivalent to the masks representing the objects. To extract the essential information from the detection model, a repeated detection approach is employed on biomedical images where various rotation angles are applied and a dice loss with the projection of the rotated detection results is utilized as a supervised signal in training our segmentation model. In biomedical imaging tasks involving convex objects, such as nuclei instance segmentation, PAL outperforms the known models (e.g., BoxInst) that rely solely on box supervision. Furthermore, PAL achieves comparable performance with mask-supervised models including Mask R-CNN and Cascade Mask R-CNN. Interestingly, PAL also demonstrates remarkable performance on non-convex object instance segmentation tasks, for example, surgical instrument and organ instance segmentation.  © 2013 IEEE.","Biomedical object segmentation; nuclei segmentation; weakly-supervised segmentation","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Supervised Machine Learning; Biological systems; Image segmentation; Medical imaging; Object detection; Annotation; Biological system modeling; Biomedical imaging; Biomedical object segmentation; Biomedical objects; Instance segmentation; Nucleus segmentation; Objects segmentation; Shape; Supervised segmentation; Weakly-supervised segmentation; ablation study of predicting oval segmentation masks from detection models; ablation study on detection models; Article; artificial neural network; biomedical images; biomedical object segmentation; bounding box supervision; box supervised instance segmentation; computer vision; convex object instance segmentation; convolutional neural network; deep learning; human; image analysis; image segmentation; learning algorithm; mask supervised instance segmentation; medical image analysis task; minimum rotating angle ablation study; nuclei segmentation; polygonal approximation learning; segmentation algorithm; segmentation of non-convex objects; transformer-based detector; weakly supervised segmentation; algorithm; deep learning; image processing; procedures; supervised machine learning; Deep learning","","Institute of Electrical and Electronics Engineers Inc.","38090818","2-s2.0-85180309620"
"Zhang Y.; Liu M.; Yu F.; Zeng T.; Wang Y.","Zhang, Yuqiang (57226780797); Liu, Min (55783125200); Yu, Fuhao (57221219160); Zeng, Tieyong (25423412800); Wang, Yaonan (55998880600)","57226780797; 55783125200; 57221219160; 25423412800; 55998880600","An O-Shape Neural Network with Attention Modules to Detect Junctions in Biomedical Images Without Segmentation","26","2","","774","785","11","10.1109/JBHI.2021.3094187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112591760&doi=10.1109%2fJBHI.2021.3094187&partnerID=40&md5=63439a1285baa9d48b15aa31b0daaa7a","Junction plays an important role in biomedical research such as retinal biometric identification, retinal image registration, eye-related disease diagnosis and neuron reconstruction. However, junction detection in original biomedical images is extremely challenging. For example, retinal images contain many tiny blood vessels with complicated structures and low contrast, which makes it challenging to detect junctions. In this paper, we propose an O-shape Network architecture with Attention modules (Attention O-Net), which includes Junction Detection Branch (JDB) and Local Enhancement Branch (LEB) to detect junctions in biomedical images without segmentation. In JDB, the heatmap indicating the probabilities of junctions is estimated and followed by choosing the positions with the local highest value as the junctions, whereas it is challenging to detect junctions when the images contain weak filament signals. Therefore, LEB is constructed to enhance the thin branch foreground and make the network pay more attention to the regions with low contrast, which is helpful to alleviate the imbalance of the foreground between thin and thick branches and to detect the junctions of the thin branch. Furthermore, attention modules are utilized to introduce the feature maps of LEB to JDB, which can establish a complementary relationship and further integrate local features and contextual information between these two branches. The proposed method achieves the highest average F1-scores of 0.82, 0.73 and 0.94 in two retinal datasets and one neuron dataset, respectively. The experimental results confirm that Attention O-Net outperforms other state-of-the-art detection methods, and is helpful for retinal biometric identification.  © 2013 IEEE.","Biomedical images; deep learning; junction detection","Algorithms; Humans; Image Processing, Computer-Assisted; Neural Networks, Computer; Retina; Anthropometry; Biometrics; Blood vessels; Diagnosis; Image segmentation; Network architecture; Neural networks; Ophthalmology; Biomedical research; Biometric identifications; Complementary relationship; Complicated structures; Contextual information; Junction detection; Neuron reconstruction; Retinal image registrations; accuracy; algorithm; Article; artificial neural network; attention; B scan; biometry; deep learning; entropy; feature extraction; human; image analysis; image enhancement; image reconstruction; image segmentation; learning algorithm; machine learning; mathematical model; nerve cell network; normal distribution; optical coherence tomography; retina blood vessel; retina disease; retina image; signal noise ratio; training; algorithm; diagnostic imaging; image processing; procedures; retina; Image enhancement","National Natural Science Foundation of China, NSFC, (61771189, 62073126); Natural Science Foundation of Hunan Province, (2020JJ2008)","Institute of Electrical and Electronics Engineers Inc.","34197332","2-s2.0-85112591760"
"Aggarwal S.; Juneja S.; Rashid J.; Gupta D.; Gupta S.; Kim J.","Aggarwal, Sonam (57224361738); Juneja, Sapna (57210408722); Rashid, Junaid (57203222981); Gupta, Deepali (57208714508); Gupta, Sheifali (57072019200); Kim, Jungeun (56600264800)","57224361738; 57210408722; 57203222981; 57208714508; 57072019200; 56600264800","Protein Subcellular Localization Prediction by Concatenation of Convolutional Blocks for Deep Features Extraction From Microscopic Images","11","","","1057","1073","16","10.1109/ACCESS.2022.3232564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146250862&doi=10.1109%2fACCESS.2022.3232564&partnerID=40&md5=c07546cb43a08edb371f50dd60478f85","Understanding where proteins are located within the cells is essential for proteomics research. Knowledge of protein subcellular location aids in early disease detection and drug targeting treatments. Incorrect localization of proteins can interfere with the functioning of cells and leads to illnesses like cancer. Technological advances have enabled computational methods to detect protein's subcellular location in living organisms. The advent of high-quality microscopy has led to the development of image-based prediction algorithms for protein subcellular localization. Confocal microscopy, which is used by the Human Protein Atlas (HPA), is a great tool for locating proteins. HPA database comprises millions of images which have been procured using confocal microscopy and are annotated with single as well as multi-labels. However, the multi-instance nature of the classification task and the low quality of the images make image-based prediction an extremely difficult problem. There are probably just a few algorithms for automatically predicting protein localization, and most of them are limited to single-label classification. Therefore, it is important to develop a satisfactory automatic multi-label HPA recognition system. The aim of this research is to design a model based on deep learning for automatic recognition system for classifying multi-label HPA. Specifically, a novel Convolutional Neural Network design for classifying protein distribution across 28 subcellular compartments has been presented in this paper. Extensive experiments have been done on the proposed model to achieve the best results for multilabel classification. With the proposed CNN framework as F1-score of 0.77 was achieved which outperformed the latest approaches.  © 2013 IEEE.","biomedical image analysis; convolutional neural network; Deep learning; protein subcellular localization prediction; proteomics","Bioinformatics; Cell engineering; Convolution; Deep neural networks; Diseases; Extraction; Feature extraction; Forecasting; Image processing; Location; Molecular biology; Biomedical image analysis; Convolutional neural network; Deep learning; Features extraction; Location awareness; Protein engineering; Protein subcellular localization prediction; Proteomics; Proteins","Ministry of Education, MOE; Ministry of SMEs and Startups, MSS, (S3033853)","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85146250862"
"Yi D.; Baltov P.; Hua Y.; Philip S.; Sharma P.K.","Yi, Dewei (57189461703); Baltov, Petar (58608894300); Hua, Yining (57206481017); Philip, Sam (12797452800); Sharma, Pradip Kumar (57191076911)","57189461703; 58608894300; 57206481017; 12797452800; 57191076911","Compound Scaling Encoder-Decoder (CoSED) Network for Diabetic Retinopathy Related Bio-Marker Detection","28","4","","1959","1970","11","10.1109/JBHI.2023.3313785","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171797427&doi=10.1109%2fJBHI.2023.3313785&partnerID=40&md5=e3fc6d0995809233411e3d70f0087e39","Biomedical image segmentation plays an important role in Diabetic Retinopathy (DR)-related biomarker detection. DR is an ocular disease that affects the retina in people with diabetes and could lead to visual impairment if management measures are not taken in a timely manner. In DR screening programs, the presence and severity of DR are identified and classified based on various microvascular lesions detected by qualified ophthalmic screeners. Such a detection process is time-consuming and error-prone, given the small size of the microvascular lesions and the volume of images, especially with the increasing prevalence of diabetes. Automated image processing using deep learning methods is recognized as a promising approach to support diabetic retinopathy screening. In this article, we propose a novel compound scaling encoder-decoder network architecture to improve the accuracy and running efficiency of microvascular lesion segmentation. In the encoder phase, we develop a lightweight encoder to speed up the training process, where the encoder network is scaled up in depth, width, and resolution dimensions. In the decoder phase, an attention mechanism is introduced to yield higher accuracy. Specifically, we employ Concurrent Spatial and Channel Squeeze and Channel Excitation (scSE) blocks to fully utilise both spatial and channel-wise information. Additionally, a compound loss function is incorporated with transfer learning to handle the problem of imbalanced data and further improve performance. To assess performance, our method is evaluated on two large-scale lesion segmentation datasets: DDR and FGADR datasets. Experimental results demonstrate the superiority of our method compared to other competent methods.  © 2013 IEEE.","attention mechanism; compound scaling; Diabetic retinopathy; fundus image; lesion segmentation; retinal screening","Blood vessels; Channel coding; Decoding; Deep learning; Diagnosis; Eye protection; Large dataset; Medical imaging; Network architecture; Ophthalmology; Signal encoding; biological marker; Attention mechanisms; Biomedical imaging; Compound; Compound scaling; Decoding; Diabetic retinopathy; Fundus image; Images segmentations; Lesion; Lesion segmentations; Retina; Retinal screening; Scalings; Article; artificial neural network; compound scaling encoder decoder network; controlled study; deep learning; diabetic retinopathy; event related potential; human; image processing; image segmentation; learning algorithm; machine learning; mathematical model; nerve cell network; network analysis; prevalence; quality control; refraction index; training; transfer of learning; visual impairment; Image segmentation","","Institute of Electrical and Electronics Engineers Inc.","37695962","2-s2.0-85171797427"
"Song H.; Wang Y.; Zeng S.; Guo X.; Li Z.","Song, Haojie (57844924600); Wang, Yuefei (57192436981); Zeng, Shijie (57723196300); Guo, Xiaoyan (59289170900); Li, Zheheng (57844408200)","57844924600; 57192436981; 57723196300; 59289170900; 57844408200","OAU-net: Outlined Attention U-net for biomedical image segmentation","79","","104038","","","","10.1016/j.bspc.2022.104038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135930269&doi=10.1016%2fj.bspc.2022.104038&partnerID=40&md5=7f92b6650e927c165c5385eef100507f","In this paper, we propose an Outlined Attention U-network (OAU-net) with bypass branching strategy to solve biomedical image segmentation tasks, which is capable of sensing shallow and deep features. Unlike previous studies, we use residual convolution and res2convolution as encoders. In particular, the outline filter and attention module are embedded in the skip connection part, respectively. Shallow features will enhance the edge information after being processed by the outline filter. Meanwhile, in the depths of the network, to better realize feature fusion, our attention module will simultaneously emphasize the independence between feature map channels (channel attention module) and each position information (spatial attention module), that is, the hybrid domain attention module. Finally, we conducted ablation experiments and comparative experiments according to three public data sets (pulmonary CT lesions, Kaggle 2018 data science bowl, skin lesions), and analyzed them with classical evaluation indexes. Experimental results show that our proposed method improves segmentation accuracy effectively. Our code is public at https://github.com/YF-W/OAU-net. © 2022 Elsevier Ltd","Biomedical image segmentation; Bypass branching strategy; Hybrid attention module; Outlined filter kernel","Computerized tomography; Biomedical image segmentation; Bypass branching strategy; Edge information; Feature map; Features fusions; Hybrid attention module; Hybrid domain; Outlined filter kernel; Position information; Spatial attention; Article; convolution algorithm; deep learning; deep neural network; diagnostic imaging; edge detection; feature extraction; human; image processing; image segmentation; machine learning; outlined attention U network; receptive field; skin defect; visual attention; Image segmentation","","Elsevier Ltd","","2-s2.0-85135930269"
"Zhang Z.; Sun M.","Zhang, Zhaoguan (58666974900); Sun, Muxin (58668351200)","58666974900; 58668351200","Research on Biomedical Image Segmentation Method Based on Full Convolutional Neural Network","","","","1541","1545","4","10.1109/ICSECE58870.2023.10263584","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175075238&doi=10.1109%2fICSECE58870.2023.10263584&partnerID=40&md5=ddd1c3daef2cf152b0990fb520088087","With the continuous progress of deep learning technology, the application of artificial intelligence in the field of smart medical care has been deepened, and many new artificial intelligence algorithms have been applied to the process of medical diagnosis. At present, computed tomography (CT) is the most commonly used method to examine liver tumors, and tumor resection, intervention and radiation are the main treatment methods. Accurately knowing the size, number and location of tumors before surgery can make a scientific and reasonable surgical plan, which is a necessary condition for successful surgery. Product neural network can learn the features that describe the essence of images, and these features can be better used for classification or reconstruction after nonlinear mapping, so as to deal with different medical tasks. Therefore, this paper conducts segmentation research on cell data set and blood vessel data set. Experiments show that, compared with U-Net and RU Net models, this method only uses nearly 2/3 of the training parameters and achieves better segmentation evaluation performance. Among them, Dice coefficient increases by 0.56% and 1.46%, and Jacob coefficient increases by 0.91% and 1.92%. Therefore, compared with U-Net and RU Net models, This method has higher segmentation performance and better generalization performance.  © 2023 IEEE.","Biomedical science; Full Convolutional Neural Network; Image segmentation","Blood vessels; Computerized tomography; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Medical imaging; Surgery; Tumors; Artificial intelligence algorithms; Biomedical image segmentation; Biomedical science; Convolutional neural network; Data set; Full convolutional neural network; Images segmentations; Learning technology; Net model; Segmentation methods; Image segmentation","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85175075238"
"Lee J.Y.; Lee Y.S.; Tae J.H.; Chang I.H.; Kim T.-H.; Myung S.C.; Nguyen T.T.; Lee J.H.; Choi J.; Kim J.H.; Kim J.W.; Choi S.Y.","Lee, Ju Young (59202047900); Lee, Yong Seong (36068330000); Tae, Jong Hyun (56678417400); Chang, In Ho (57203614272); Kim, Tae-Hyoung (57212837594); Myung, Soon Chul (7005796823); Nguyen, Tuan Thanh (57214889585); Lee, Jae Hyeok (57195838934); Choi, Joongwon (57208742789); Kim, Jung Hoon (57207437054); Kim, Jin Wook (57207437351); Choi, Se Young (57209856147)","59202047900; 36068330000; 56678417400; 57203614272; 57212837594; 7005796823; 57214889585; 57195838934; 57208742789; 57207437054; 57207437351; 57209856147","Selection of Convolutional Neural Network Model for Bladder Tumor Classification of Cystoscopy Images and Comparison with Humans","","","","","","","10.1089/end.2024.0250","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197385681&doi=10.1089%2fend.2024.0250&partnerID=40&md5=baf48212e3fed8e0edade970e9d0f0eb","Purpose: An investigation of various convolutional neural network (CNN)-based deep learning algorithms was conducted to select the appropriate artificial intelligence (AI) model for calculating the diagnostic performance of bladder tumor classification on cystoscopy images, with the performance of the selected model to be compared against that of medical students and urologists. Methods: A total of 3,731 cystoscopic images that contained 2,191 tumor images were obtained from 543 bladder tumor cases and 219 normal cases were evaluated. A total of 17 CNN models were trained for tumor classification with various hyperparameters. The diagnostic performance of the selected AI model was compared with the results obtained from urologists and medical students by using the receiver operating characteristic (ROC) curve graph and metrics. Results: EfficientNetB0 was selected as the appropriate AI model. In the test results, EfficientNetB0 achieved a balanced accuracy of 81%, sensitivity of 88%, specificity of 74%, and an area under the curve (AUC) of 92%. In contrast, human-derived diagnostic statistics for the test data showed an average balanced accuracy of 75%, sensitivity of 94%, and specificity of 55%. Specifically, urologists had an average balanced accuracy of 91%, sensitivity of 95%, and specificity of 88%, while medical students had an average balanced accuracy of 69%, sensitivity of 94%, and specificity of 44%. Conclusions: Among the various AI models, we suggest that EfficientNetB0 is an appropriate AI classification model for determining the presence of bladder tumors in cystoscopic images. EfficientNetB0 showed the highest performance among several models and showed high accuracy and specificity compared to medical students. This AI technology will be helpful for less experienced urologists or nonurologists in making diagnoses. Image-based deep learning classifies bladder cancer using cystoscopy images and shows promise for generalized applications in biomedical image analysis and clinical decision making. Copyright 2024, Mary Ann Liebert, Inc., publishers.","artificial intelligence; bladder cancer; convolutional neural network; cystoscopy; deep learning","","National Research Foundation of Korea, NRF; Ministry of Science, ICT and Future Planning, MSIP, (NRF-2022R1F1A1076502); Ministry of Science, ICT and Future Planning, MSIP; Korean Neurological Association, KNA, (KUOS 21-06); Korean Neurological Association, KNA","Mary Ann Liebert Inc.","38877795","2-s2.0-85197385681"
"Samprovalaki M.; Chatzipapadopoulou A.; Moschovis G.; Charalampakos F.; Kaliosis P.; Pavlopoulos J.; Androutsopoulos I.","Samprovalaki, Marina (59281954400); Chatzipapadopoulou, Anna (59281432800); Moschovis, Georgios (57866890500); Charalampakos, Foivos (57232257500); Kaliosis, Panagiotis (58665010800); Pavlopoulos, John (25654146700); Androutsopoulos, Ion (6506068227)","59281954400; 59281432800; 57866890500; 57232257500; 58665010800; 25654146700; 6506068227","AUEB NLP Group at ImageCLEFmedical Caption 2024","3740","","","1729","1745","16","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201578472&partnerID=40&md5=6aa8863378db2fa81e7c8a00d481a064","This article describes the approaches that the AUEB NLP Group experimented with during its participation in the 8th edition of the ImageCLEFmedical Caption evaluation campaign, including both Concept Detection and Caption Prediction tasks. The objective of Concept Detection is to automatically categorize biomedical images into a set of one or more concepts. In contrast, the Caption Prediction task focuses on generating a precise and meaningful diagnostic caption that describes the medical conditions depicted in the image. Building on our prior research for the Concept Detection task, we utilized a diverse set of Convolutional Neural Network (CNN) encoders, followed by a Feed-Forward Neural Network. Additionally, we implemented two versions of the retrieval-based k-NN algorithm: a version that assigned concepts based on statistical frequency and a weighted version that took into account the order of the retrieved neighbors. Both models used the CNN image encoders to improve their retrieval capabilities. Regarding the Caption Prediction task, we fine-tuned the InstructBLIP model to generate initial captions and then enhanced it by employing rephrasing techniques with further pre-trained models. We also used synthesizing techniques that incorporated information from similar neighboring images in the training set to refine these captions. Additionally, we employed “Distance from Median Maximum Concept Similarity” (DMMCS), a novel guided-decoding approach that drives the model's behaviour throughout the decoding process, aiming to integrate information from the predicted concepts of Concept Detection. We explored the application of DMMCS to all of our developed systems. Our group ranked 2nd in Concept Detection and 4th in Caption Prediction. © 2024 Copyright for this paper by its authors.","Biomedical Images; Caption Generation; Computer Vision; Convolutional Neural Networks; Deep Learning; Generative Models; Multi-Label Classification; Natural Language Processing; Transformers","Deep neural networks; Feedforward neural networks; Generative adversarial networks; Image coding; Image enhancement; Network coding; Biomedical images; Caption generation; Convolutional neural network; Deep learning; Generative model; Language processing; Multi-label classifications; Natural language processing; Natural languages; Transformer; Convolutional neural networks","","CEUR-WS","","2-s2.0-85201578472"
"Khouy M.; Jabrane Y.; Ameur M.; Hajjam El Hassani A.","Khouy, Mohammed (58627999800); Jabrane, Younes (22937642900); Ameur, Mustapha (57201741115); Hajjam El Hassani, Amir (26429325600)","58627999800; 22937642900; 57201741115; 26429325600","Medical Image Segmentation Using Automatic Optimized U-Net Architecture Based on Genetic Algorithm","13","9","1298","","","","10.3390/jpm13091298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172868048&doi=10.3390%2fjpm13091298&partnerID=40&md5=184c8c0c9e72dc997378cc1d81d92615","Image segmentation is a crucial aspect of clinical decision making in medicine, and as such, it has greatly enhanced the sustainability of medical care. Consequently, biomedical image segmentation has become a prominent research area in the field of computer vision. With the advent of deep learning, many manual design-based methods have been proposed and have shown promising results in achieving state-of-the-art performance in biomedical image segmentation. However, these methods often require significant expert knowledge and have an enormous number of parameters, necessitating substantial computational resources. Thus, this paper proposes a new approach called GA-UNet, which employs genetic algorithms to automatically design a U-shape convolution neural network with good performance while minimizing the complexity of its architecture-based parameters, thereby addressing the above challenges. The proposed GA-UNet is evaluated on three datasets: lung image segmentation, cell nuclei segmentation in microscope images (DSB 2018), and liver image segmentation. Interestingly, our experimental results demonstrate that the proposed method achieves competitive performance with a smaller architecture and fewer parameters than the original U-Net model. It achieves an accuracy of 98.78% for lung image segmentation, 95.96% for cell nuclei segmentation in microscope images (DSB 2018), and 98.58% for liver image segmentation by using merely 0.24%, 0.48%, and 0.67% of the number of parameters in the original U-Net architecture for the lung image segmentation dataset, the DSB 2018 dataset, and the liver image segmentation dataset, respectively. This reduction in complexity makes our proposed approach, GA-UNet, a more viable option for deployment in resource-limited environments or real-world implementations that demand more efficient and faster inference times. © 2023 by the authors.","convolutional neural networks (CNNs); genetic algorithms (GAs); medical image segmentation; U-Net","article; cell nucleus; convolutional neural network; genetic algorithm; image segmentation; liver; lung; microscope image; resource limited setting","","Multidisciplinary Digital Publishing Institute (MDPI)","","2-s2.0-85172868048"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","1963 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178637916&partnerID=40&md5=586fffd2441e9387dc354a41897227bc","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178637916"
"Aydın M.; Kiraz B.; Eren F.; Uysalh Y.; Morova B.; Can Ozcan S.; Acilan C.; Kiraz A.","Aydın, Musa (56369220000); Kiraz, Berna (36959472600); Eren, Furkan (57226398182); Uysalh, Yiğit (57460004300); Morova, Berna (57195804504); Can Ozcan, Selahattin (57460004400); Acilan, Ceyda (16240700600); Kiraz, Alper (58903933900)","56369220000; 36959472600; 57226398182; 57460004300; 57195804504; 57460004400; 16240700600; 58903933900","A Deep Learning Model for Automated Segmentation of Fluorescence Cell images","2191","1","012003","","","","10.1088/1742-6596/2191/1/012003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124988437&doi=10.1088%2f1742-6596%2f2191%2f1%2f012003&partnerID=40&md5=964ead13f966850d6125924ff08691aa","Deep learning techniques bring together key advantages in biomedical image segmentation. They speed up the process, increase the reproducibility, and reduce the workload in segmentation and classifcation. Deep learning techniques can be used for analysing cell concentration, cell viability, as well as the size and form of each cell. In this study, we develop a deep learning model for automated segmentation of fuorescence cell images, and apply it to fuorescence images recorded with a home-built epi-fuorescence microscope. A deep neural network model based on U-Net architecture was built using a publicly available dataset of cell nuclei images [1]. A model accuracy of 97.3% was reached at the end of model training. Fluorescence cell images acquired with our home-built microscope were then segmented using the developed model. 141 of 151 cells in 5 images were successfully segmented, revealing a segmentation success rate of 93.4%. This deep learning model can be extended to the analysis of diferent cell types and cell viability.  © 2021 Published under licence by IOP Publishing Ltd.","","Cells; Cytology; Deep neural networks; Fluorescence; Image segmentation; Automated segmentation; Biomedical image segmentation; Cell images; Cell viability; Fluorescence cell; Home-built; Learning models; Learning techniques; Reproducibilities; Speed up; Learning algorithms","KOSGEB; TÜBA; TÜBİTAK, (7190434); Türkiye Bilimler Akademisi","IOP Publishing Ltd","","2-s2.0-85124988437"
"Navaneethakrishnan M.; Anand M.V.; Vasavi G.; Rani V.V.","Navaneethakrishnan, M. (57219354649); Anand, M. Vijay (57751198900); Vasavi, G. (57201994187); Rani, V. Vasudha (57209498941)","57219354649; 57751198900; 57201994187; 57209498941","Deep Fuzzy SegNet-based lung nodule segmentation and optimized deep learning for lung cancer detection","26","3","","1143","1159","16","10.1007/s10044-023-01135-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148643156&doi=10.1007%2fs10044-023-01135-1&partnerID=40&md5=3ae0ca1d2b5223f2110b7e7edbc2668f","Globally, lung cancer has a high fatality rate and is a lethal disease. Since lung cancer affects both men and women, it requires extra consideration when evaluating various diseases. Furthermore, early detection is even more important in order to increase the survival percentage of affected patients. There are many methods for detecting lung cancer, but it can be difficult to locate the affected area due to low visibility of the tumor section and imaging failure rates. Due to poor image quality, which distorts the segmentation process, the standard strategies failed to increase the accuracy rate. In order to diagnose lung cancer disease, this research created an approach known as Bat Deer Hunting Optimization Algorithm-based Deep Convolutional Neural Network (BDHOA-based DCNN). Here, Computed Tomography pictures are used to predict the presence of lung cancer. The Bat Algorithm (BA) and Deer Hunting Optimization Algorithm have been integrated into the newly developed BDHOA algorithm (DHOA). To execute the lung cancer detection and classification, the lung lobe and nodule region is segmented from the lung picture. With accuracy, sensitivity, and specificity scores of 0.9243, 0.9421, and 0.8915, the suggested approach performed better. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Biomedical image processing; DEEP fuzzy clustering; Deep learning; DEER hunting optimization algorithm; Lung cancer; Lung nodule segmentation","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85148643156"
"Nanammal V.S.R.; Jayagopalan V.G.","Nanammal, Venkata Samy Raja (56586269000); Jayagopalan, Venu Gopalakrishnan (57696453800)","56586269000; 57696453800","A secured biomedical image processing scheme to detect pneumonia disease using dynamic learning principles","30","3","","245","252","7","10.1177/1063293X221097447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130227794&doi=10.1177%2f1063293X221097447&partnerID=40&md5=431ba77a0b124ad8739c7d03a27c28e4","Now-a-days, the medical industry is growing a lot with the adaptation of latest technologies as well as the logical evaluation and security norms provides a robust platform to enhance the effectiveness of the industry at a drastic level. In this paper, a digital bio-medical image processing based Pneumonia disease identification system is introduced with enhanced security features. Due to improving the efficiency of the application, a well-known watermarking based security constraint is included to provide the protection to the respective hospital environment and patients as well. To avoid these issues, some sort of security aspects need to be followed so that this paper included watermarking based security to provide a rich level of protection to the images going to be tested. The main intention of this paper is to introduce a novel security enabled digital image processing scheme to identify the Pneumonic disease in earlier stages with respect to the proper classification principles. In this paper, a novel deep learning algorithm is introduced called enhanced Dynamic Learning Neural Network in which it is a hybrid algorithm with the combinations of conventional DLNN algorithm and the Support Vector Classification algorithm. This proposed approach effectively identifies the Pneumonia disease in earlier stages but the security inspection on the testing stage is so important to analyze the disease. The respective testing image is properly watermarked with the logo of the corresponding hospital; the image is processed otherwise the proposed approach skips the image to process. These kinds of security features emphasize the medical industry and boost up the levels more as well as the patients can get an appropriate error free care with the help of such technology. A proper Chest X-Ray based Kaggle dataset is considered to process the system as well as which contains 5856 Chest X-Ray images under two different categories such as Pneumonia and Normal. With respect to processing these images and identifying the Pneumonia disease effectively as well as the proposed watermarking enabled security features provide a good impact in the medical field protection system. The resulting section provides the proper proof to the effectiveness of the proposed approach and its prediction efficiency. © The Author(s) 2022.","deep learning; enhanced dynamic learning neural network; pneumonia; security; support vector classification; watermarking","Deep learning; Efficiency; Hospitals; Image classification; Image watermarking; Learning algorithms; Learning systems; Medical imaging; Network security; Security systems; Support vector machines; Watermarking; Deep learning; Dynamic learning; Enhanced dynamic learning neural network; Latest technology; Learning neural networks; Medical industries; Pneumonia; Security; Security features; Support vector classification; Image enhancement","","SAGE Publications Ltd","","2-s2.0-85130227794"
"Çiğ H.; Güllüoğlu M.T.; Er M.B.; Kuran U.; Kuran E.C.","Çiğ, Harun (57200138132); Güllüoğlu, Mehmet Tahir (6603160891); Er, Mehmet Bilal (57200138180); Kuran, Umut (57200140755); Kuran, Emre Can (57226394399)","57200138132; 6603160891; 57200138180; 57200140755; 57226394399","Enhanced Disease Detection Using Contrast Limited Adaptive Histogram Equalization and Multi-Objective Cuckoo Search in Deep Learning","40","3","","915","925","10","10.18280/ts.400308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166331049&doi=10.18280%2fts.400308&partnerID=40&md5=b8b773a898167f7271dcea6056e57f92","Delayed diagnosis of numerous diseases often results in postponed treatment, adversely affecting patient outcomes. By analyzing biological signals and patient photographs, critical information about an individual's health or the severity of a medical condition can be obtained for various diseases. Signals from Electroencephalography (EEG), Electrocardiography (ECG), and Electrooculography (EOG) can be used to predict and diagnose disorders related to the brain, heart, eyes, muscles, and nervous system. Additionally, biomedical images acquired through X-ray, ultrasound, and magnetic resonance imaging can be utilized for disease diagnosis and detection with the help of image processing techniques, artificial intelligence, and deep learning methods. In this study, we propose a novel approach that combines the Contrast Limited Adaptive Histogram Equalization (CLAHE) algorithm and Multi-Objective Cuckoo Search (MOCS) with Convolutional neural networks (CNNs) to achieve highly accurate disease classification using chest X-ray images. Our method begins by applying a contrast enhancement strategy, specifically, the CLAHE algorithm, with MOCS for optimal parameter selection to attain the highest classification performance. Subsequently, contrast-enhanced images are fed into the CNNs to further improve image quality and classification accuracy. Our approach is employed to categorize three types of chest X-ray images, namely, unhealthy, normal (healthy), and pneumonia. To assess the performance of our proposed method, we utilize the widely-used ""COVID-19 Radiography"" dataset. Experimental results yield an accuracy rate of 99.16%, a precision rate of 99.20%, and a sensitivity rate of 98.99%. These findings demonstrate that our proposed model outperforms existing techniques in the literature and can be effectively employed for disease detection and classification. © 2023 Lavoisier. All rights reserved.","Convolutional neural network (CNN); hybrid CNN; multi-objective cuckoo search algorithm optimization (MOCS)","Biomedical signal processing; Convolution; Convolutional neural networks; Deep learning; Electrocardiography; Electrophysiology; Equalizers; Graphic methods; Image enhancement; Learning algorithms; Learning systems; Medical imaging; Multiobjective optimization; Patient treatment; Adaptive histograms; Algorithms optimizations; Convolutional neural network; Cuckoo search algorithms; Disease detection; Hybrid convolutional neural network; Multi objective; Multi-objective cuckoo search algorithm optimization; Electroencephalography","","International Information and Engineering Technology Association","","2-s2.0-85166331049"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","14451 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178583888&partnerID=40&md5=007ceaaaf0db55b4cc3502c42b9f5b5c","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178583888"
"Hamdi M.; Senan E.M.; Jadhav M.E.; Olayah F.; Awaji B.; Alalayah K.M.","Hamdi, Mohammed (57201749980); Senan, Ebrahim Mohammed (57222957501); Jadhav, Mukti E. (57201156883); Olayah, Fekry (39161803000); Awaji, Bakri (57219144774); Alalayah, Khaled M. (57190568317)","57201749980; 57222957501; 57201156883; 39161803000; 57219144774; 57190568317","Hybrid Models Based on Fusion Features of a CNN and Handcrafted Features for Accurate Histopathological Image Analysis for Diagnosing Malignant Lymphomas","13","13","2258","","","","10.3390/diagnostics13132258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164710227&doi=10.3390%2fdiagnostics13132258&partnerID=40&md5=7dfc2ae8a8d9cce7cb9467623c2261ff","Malignant lymphoma is one of the most severe types of disease that leads to death as a result of exposure of lymphocytes to malignant tumors. The transformation of cells from indolent B-cell lymphoma to B-cell lymphoma (DBCL) is life-threatening. Biopsies taken from the patient are the gold standard for lymphoma analysis. Glass slides under a microscope are converted into whole slide images (WSI) to be analyzed by AI techniques through biomedical image processing. Because of the multiplicity of types of malignant lymphomas, manual diagnosis by pathologists is difficult, tedious, and subject to disagreement among physicians. The importance of artificial intelligence (AI) in the early diagnosis of malignant lymphoma is significant and has revolutionized the field of oncology. The use of AI in the early diagnosis of malignant lymphoma offers numerous benefits, including improved accuracy, faster diagnosis, and risk stratification. This study developed several strategies based on hybrid systems to analyze histopathological images of malignant lymphomas. For all proposed models, the images and extraction of malignant lymphocytes were optimized by the gradient vector flow (GVF) algorithm. The first strategy for diagnosing malignant lymphoma images relied on a hybrid system between three types of deep learning (DL) networks, XGBoost algorithms, and decision tree (DT) algorithms based on the GVF algorithm. The second strategy for diagnosing malignant lymphoma images was based on fusing the features of the MobileNet-VGG16, VGG16-AlexNet, and MobileNet-AlexNet models and classifying them by XGBoost and DT algorithms based on the ant colony optimization (ACO) algorithm. The color, shape, and texture features, which are called handcrafted features, were extracted by four traditional feature extraction algorithms. Because of the similarity in the biological characteristics of early-stage malignant lymphomas, the features of the fused MobileNet-VGG16, VGG16-AlexNet, and MobileNet-AlexNet models were combined with the handcrafted features and classified by the XGBoost and DT algorithms based on the ACO algorithm. We concluded that the performance of the two networks XGBoost and DT, with fused features between DL networks and handcrafted, achieved the best performance. The XGBoost network based on the fused features of MobileNet-VGG16 and handcrafted features resulted in an AUC of 99.43%, accuracy of 99.8%, precision of 99.77%, sensitivity of 99.7%, and specificity of 99.8%. This highlights the significant role of AI in the early diagnosis of malignant lymphoma, offering improved accuracy, expedited diagnosis, and enhanced risk stratification. This study highlights leveraging AI techniques and biomedical image processing; the analysis of whole slide images (WSI) converted from biopsies allows for improved accuracy, faster diagnosis, and risk stratification. The developed strategies based on hybrid systems, combining deep learning networks, XGBoost and decision tree algorithms, demonstrated promising results in diagnosing malignant lymphoma images. Furthermore, the fusion of handcrafted features with features extracted from DL networks enhanced the performance of the classification models. © 2023 by the authors.","ACO; deep learning; DT; fusion features; GVF; malignant lymphoma; XGBoost","alexnet; ant colony optimization; Article; artificial intelligence; biopsy; cancer classification; cancer diagnosis; cancer staging; classifier; controlled study; convolutional neural network; decision tree; deep learning; diagnostic accuracy; diagnostic test accuracy study; discrete wavelet transform; early cancer; early diagnosis; evaluation study; feature extraction; feature extraction algorithm; gradient vector flow algorithm; gray level cooccurrence matrix; handcrafted feature; histopathology; human; human tissue; image analysis; image processing; local binary pattern; lymphocyte; lymphoma; machine learning; mobilenet; radiomics; risk assessment; segmentation algorithm; sensitivity and specificity; XGBoost algorithm","Najran University, NU; Deanship of Scientific Research, University of Jordan, DSR, (NU/DRP/SERC/12/17)","Multidisciplinary Digital Publishing Institute (MDPI)","","2-s2.0-85164710227"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","1969 CCIS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178557826&partnerID=40&md5=c23286954f90d2afc18b7ed624564f69","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85178557826"
"Arvidsson M.; Rashed S.K.; Aits S.","Arvidsson, Malou (58001558500); Rashed, Salma Kazemi (57188972941); Aits, Sonja (23468829600)","58001558500; 57188972941; 23468829600","An annotated high-content fluorescence microscopy dataset with Hoechst 33342-stained nuclei and manually labelled outlines","46","","108769","","","","10.1016/j.dib.2022.108769","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143768599&doi=10.1016%2fj.dib.2022.108769&partnerID=40&md5=813b6ef950ef5bba6ced06a44fdbc79e","Automated detection of cell nuclei in fluorescence microscopy images is a key task in bioimage analysis. It is essential for most types of microscopy-based high-throughput drug and genomic screening and is often required in smaller scale experiments as well. To develop and evaluate algorithms and neural networks that perform instance or semantic segmentation for detecting nuclei, high quality annotated data is essential. Here we present a benchmarking dataset of fluorescence microscopy images with Hoechst 33342-stained nuclei together with annotations of nuclei, nuclear fragments and micronuclei. Images were randomly selected from an RNA interference screen with a modified U2OS osteosarcoma cell line, acquired on a Thermo Fischer CX7 high-content imaging system at 20x magnification. Labelling was performed by a single annotator and reviewed by a biomedical expert. The dataset, called Aitslab-bioimaging1, contains 50 images showing over 2000 labelled nuclear objects in total, which is sufficiently large to train well-performing neural networks for instance or semantic segmentation. The dataset is split into training, development and test set for user convenience. © 2022","Biomedical image analysis; Computer vision; Deep learning training and evaluation; Fluorescence microscopy; High-content screening; Instance segmentation","Cell culture; Computer vision; Deep learning; Fluorescence; Image analysis; Large dataset; Medical imaging; Quality control; Semantic Segmentation; Semantics; Statistical tests; Automated detection; Biomedical image analysis; Deep learning training and evaluation; Fluorescence microscopy images; High-content; High-content screening; Hoechst; Instance segmentation; Neural-networks; Semantic segmentation; Fluorescence microscopy","Fabrikant Einar Willumsen's Memorial Fund; Längmanska Cultural Fund; National Bioinformatics Infrastructure Sweden; Sigurd & Elsa Golje's Memorial Fund; Swedish Research Council for Sustainable Development; Thora and Viggo Grove's Memorial Fund; Kræftens Bekæmpelse, DCS; Svenska Forskningsrådet Formas, (2019-01554); Crafoordska Stiftelsen; Lunds Universitet; Hjärnfonden; Knut och Alice Wallenbergs Stiftelse, (2018-05973); Vetenskapsrådet, VR, (2016-02003); Kungliga Fysiografiska Sällskapet i Lund; Thorsten och Elsa Segerfalks Stiftelse; Science for Life Laboratory, SciLifeLab","Elsevier Inc.","","2-s2.0-85143768599"
"Balasubramanian K.; Ramya K.; Gayathri Devi K.","Balasubramanian, Kishore (57188969156); Ramya, K. (57733230300); Gayathri Devi, K. (56574176700)","57188969156; 57733230300; 56574176700","Improved swarm optimization of deep features for glaucoma classification using SEGSO and VGGNet","77","","103845","","","","10.1016/j.bspc.2022.103845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131408028&doi=10.1016%2fj.bspc.2022.103845&partnerID=40&md5=a24d8d07273f53bcbe4313d2938230cf","Efficient classification of glaucoma from fundus images remains crucial and a challenging task as the retinal anatomical structure is so complex in nature with varying contrast and boundaries. As a result, there is a chance that expert systems will misclassify the data. As a way to reduce the misclassification rate, a methodology wherein a deep learning approach integrated with an evolutionary algorithm is proposed. First, the relevant features are extracted using a pre-trained ImageNet model, the VGGNet. The features extorted are subsequently filtered using statistically enhanced Glow-worm Swarm Optimization (SEGSO). The algorithm identifies the most important and relevant features, while excluding those that are noisy or highly correlated. The efficiency of this fully automated system is evaluated on public and private retinal fundus image databases (totally 18,879 images) and the experiments demonstrated a high accuracy of 99.6% with less computational complexity, better sensitivity and specificity. SEGSO algorithm selected comparatively lesser features than the similar algorithms and when, employed with VGGNet outperform several other convolutional network models. The proposed method is robust against salt-pepper noise and achieved an accuracy of 97.2% when applied on degraded images. Feature extraction using Convolutional Neural Network and SEGSO feature optimization could prove to be a good combination to be used for other biomedical image classification processes. © 2022 Elsevier Ltd","Classification; CNN; Deep learning; Fundus image; Glaucoma; Swarm intelligence","Automation; Classification (of information); Convolution; Deep learning; Evolutionary algorithms; Image classification; Image enhancement; Ophthalmology; Swarm intelligence; Anatomical structures; CNN; Deep learning; Fundus image; Highly-correlated; Important features; Learning approach; Misclassification rates; Relevant features; Swarm optimization; anatomical concepts; Article; cancer classification; comparative study; controlled study; convolutional neural network; data availability; deep learning; diagnostic test accuracy study; evolutionary algorithm; expert system; eye fundus; feature extraction; feature selection; genetic algorithm; glaucoma; image processing; nonhuman; particle swarm optimization; pattern recognition; sensitivity and specificity; Complex networks","","Elsevier Ltd","","2-s2.0-85131408028"
"Hasan M.E.; Wagler A.","Hasan, Md Easin (57223897299); Wagler, Amy (37062272800)","57223897299; 37062272800","A novel deep learning graph attention network for Alzheimer's disease image segmentation","5","","100310","","","","10.1016/j.health.2024.100310","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185316951&doi=10.1016%2fj.health.2024.100310&partnerID=40&md5=ac69f48e82dc50e1e87a9324d385860f","Neuronal cell segmentation identifies and separates individual neurons in an image, typically to study their properties or analyze their organization in the nervous system. This is significant because neurological problems and diseases can only be treated effectively when the structure and function of neurons are understood. The proposed method is based on convolutional neural networks (CNNs) and graph attention networks (GATs) for segmenting biomedical images. A contracting path built upon a couple of convolution layers and max pooling is included in the architecture to capture context. After that, the GATs are applied to the captured context. In GATs, each node in the graph is associated with a vector of hidden features, and the model calculates attention coefficients between pairs of nodes. These attention coefficients are learned during training and can be used to weigh the contribution of each node's features to the representation of the graph. An expanding path that utilizes the outputs generated by GATs paves the way for exact segmentation. The dataset comprises 606 microscopic images, mainly categorized into different cell types (astrocytes, cortex, and SHSY5Y). By implementing our proposed U-GAT algorithm, we obtained the highest accuracy of 86.5% and an F1 score of 0.719 compared to the CNN, U-Net, SegResNet, SegNet VGG16, and GAT benchmarking algorithms. This proposed method could help researchers in the biotech industry develop novel drugs since a more accurate deep-learning method is essential for segmenting complex images like neuronal images. © 2024 The Authors","Convolutional neural networks; Deep learning; Graph attention networks; Image segmentation; Neuronal cells; U-Net","accuracy; Alzheimer disease; Article; attention network; benchmarking; cells by body anatomy; convolutional neural network; deep learning; human; image segmentation; imaging algorithm; nerve cell; process development; research gap","","Elsevier Inc.","","2-s2.0-85185316951"
"Habib G.; Qureshi S.","Habib, Gousia (57221589277); Qureshi, Shaima (26325864200)","57221589277; 26325864200","Compressed lightweight deep learning models for resource-constrained Internet of things devices in the healthcare sector","","","","","","","10.1111/exsy.13269","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150632978&doi=10.1111%2fexsy.13269&partnerID=40&md5=98df5bbde753379f963657f0054f5de0","The performance of convolutional neural networks (CNNs) in image classification and object detection has been remarkable, even though they contain millions and billions of parameters. This over-parameterization of CNN makes them both memory-intensive and computationally complex and exhaustive. This greatly hinders the application of CNNs in resource-constrained environments such as Internet of things (IoT) and edge devices. This poses a critical challenge for CNNs in deploying these powerful computer vision tools to mobile devices, which needs immediate attention. In this study, we have proposed a novel technique based on non-convex optimization, max-norm regularization. The max-norm will structurally prune the number of parameters without compromising the model's performance. The proximal gradient descent algorithm is used for network optimization while using this non-convex regularizer. The max-norm is combined with the channel pruning to achieve more sparse CNN networks. Later, the pruned network can be easily deployed in the resource-constrained application environment. The proposed technique is tested on several benchmark datasets for validation. In addition, in this study, the sparsified CNNs are used for biomedical image analysis using the BRAIN MRI dataset. This sparsely trained CNN model can later serve as the best lightweight model applicable in the IoT healthcare sector for detecting and classifying three types of brain tumours, one of the most life-threatening diseases whose early detection can save the costly lives of human beings. This is the first paper to propose the novel max-norm regularizer to enforce sparse learning through CNNs. The paper provides a detailed analysis of convex and non-convex regularizers before presenting the proposed novel max-norm regularizer. Finally, the paper compares the proposed max-norm regularizer with existing regularization methods using state-of-the-art CNN models. © 2023 John Wiley & Sons Ltd.","CNN; FLOPS; infinity norm; max-norm; NLP; regularization; VGG-19; weight pruning","Convex optimization; Convolutional neural networks; Deep learning; Gradient methods; Health care; Magnetic resonance imaging; Object detection; Convolutional neural network; FLOPS; Healthcare sectors; Infinity norm; Max-norms; Neural network model; Regularisation; Regularizer; VGG-19; Weight pruning; Internet of things","","John Wiley and Sons Inc","","2-s2.0-85150632978"
"Maqsood S.; Damaševičius R.; Maskeliūnas R.","Maqsood, Sarmad (57212142651); Damaševičius, Robertas (6603451290); Maskeliūnas, Rytis (27467587600)","57212142651; 6603451290; 27467587600","TTCNN: A Breast Cancer Detection and Classification towards Computer-Aided Diagnosis Using Digital Mammography in Early Stages","12","7","3273","","","","10.3390/app12073273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127380874&doi=10.3390%2fapp12073273&partnerID=40&md5=853c3ce2c58f2fc4f4d87679354d58a6","Breast cancer is a major research area in the medical image analysis field; it is a dangerous disease and a major cause of death among women. Early and accurate diagnosis of breast cancer based on digital mammograms can enhance disease detection accuracy. Medical imagery must be detected, segmented, and classified for computer-aided diagnosis (CAD) systems to help the radiologists for accurate diagnosis of breast lesions. Therefore, an accurate breast cancer detection and classification approach is proposed for screening of mammograms. In this paper, we present a deep learning system that can identify breast cancer in mammogram screening images using an “end-to-end” training strategy that efficiently uses mammography images for computer-aided breast cancer recognition in the early stages. First, the proposed approach implements the modified contrast enhancement method in order to refine the detail of edges from the source mammogram images. Next, the transferable texture convolutional neural network (TTCNN) is presented to enhance the performance of classification and the energy layer is integrated in this work to extract the texture features from the convolutional layer. The proposed approach consists of only three layers of convolution and one energy layer, rather than the pooling layer. In the third stage, we analyzed the performance of TTCNN based on deep features of convolutional neural network models (InceptionResNet-V2, Inception-V3, VGG-16, VGG-19, GoogLeNet, ResNet-18, ResNet-50, and ResNet-101). The deep features are extracted by determining the best layers which enhance the classification accuracy. In the fourth stage, by using the convolutional sparse image decomposition approach, all the extracted feature vectors are fused and, finally, the best features are selected by using the entropy controlled firefly method. The proposed approach employed on DDSM, INbreast, and MIAS datasets and attained the average accuracy of 97.49%. Our proposed transferable texture CNN-based method for classifying screening mammograms has outperformed prior methods. These findings demonstrate that automatic deep learning algorithms can be easily trained to achieve high accuracy in diverse mammography images, and can offer great potential to improve clinical tools to minimize false positive and false negative screening mammography results. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","biomedical image processing; breast cancer detection; computer aided diagnosis; deep learning; digital mammograms","","","MDPI","","2-s2.0-85127380874"
"Güler M.; Namlı E.","Güler, Mustafa (58984022900); Namlı, Ersin (55499104800)","58984022900; 55499104800","Brain Tumor Detection with Deep Learning Methods’ Classifier Optimization Using Medical Images","14","2","642","","","","10.3390/app14020642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192528413&doi=10.3390%2fapp14020642&partnerID=40&md5=257d5f684d2698f674ea73f7946980ed","It is known that, with the development of artificial intelligence science in recent years, it has started to be used in all areas of life. Due to the increase in diseases that threaten human life, such as epidemics and cancer, more attention has been paid to research in this field. Especially in the field of biomedical image processing, very successful results have been obtained in recent years with the use of deep learning methods. For this study, MR images are utilized to diagnose brain tumors. To assist doctors and radiologists in automatic brain tumor diagnosis and to overcome the need for manual diagnosis, a brain MR image automated classification system is being developed. The data used in the study are open access data obtained from the Kaggle library. This paper presents a novel approach for classifying brain MR images utilizing a dataset of 7022 MR images. To give an unbiased evaluation of the dataset, it is divided into a 40% test and 60% training set. Respectively, VGG, ResNet, DenseNet and SqueezeNet architectures are trained and used for feature extraction from brain MRI images. In order to classify the extracted features, machine learning methods (Support Vector Machines, K-Nearest Neighbors, Naive Bayes, Decision Tree, Linear Regression Analysis) are applied first, then an ensemble learning method is applied and the best validation method is selected. In addition, parameter optimization is applied to the trained CNN algorithms. In order to develop the proposed methods, the Python software program was used in the training and testing phases of the models, and the classification success rates were mutually evaluated. Among the results found, it can see that the ResNet architecture reached 100% accuracy. The data obtained as a result of the study were compared with the results of similar studies. In conclusion, the techniques and methods applied highlight their effectiveness in accurately classifying brain MRI images and their potential to improve diagnostic capabilities. © 2024 by the authors.","brain tumor; classification; convolutional neural networks; deep learning; image processing","","Istanbul University-Cerrahpaşa Scientific Research Projects Coordination Unit, (35916)","Multidisciplinary Digital Publishing Institute (MDPI)","","2-s2.0-85192528413"
"Rabie K.; Karthik C.; Chowdhury S.; Dutta P.K.","Rabie, Khaled (55884933100); Karthik, Chandran (57226546597); Chowdhury, Subrata (57200565797); Dutta, Pushan Kumar (7202355384)","55884933100; 57226546597; 57200565797; 7202355384","Deep learning in medical image processing and analysis","","","","1","358","357","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178972591&partnerID=40&md5=f0ab8a9c4f6734e6ac2cd3e208a91804","Medical images, in various formats, are used by clinicians to identify abnormalities or markers associated with certain conditions, such as cancers, diseases, abnormalities or other adverse health conditions. Deep learning algorithms use vast volumes of data to train the computer to recognise certain features in the images that are associated with the disease or condition that you wish to identify. Whilst analysing the images by eye can take a lot of time, deep learning algorithms have the benefit of reviewing medical images at a faster rate than a human can, which aids the clinician, speeding up diagnoses and freeing up clinicians' time for other duties. Deep Learning in Medical Image Processing and Analysis introduces the fundamentals of deep learning for biomedical image analysis for applications including ophthalmology, cancer detection and heart disease. The book considers the principles of multi-instance feature selection, swarm optimisation, parallel processing models, artificial neural networks, support vector machines, as well as their design and optimisation, in biomedical applications. Topics such as data security, patient confidentiality, effectiveness and reliability will also be discussed. Written by an international team of experts, this edited book covers principles and applications for industry and academic researchers, scientists, engineers, developers, and designers in the fields of machine learning, deep learning, AI, image processing, signal processing, computer science or related fields. It will also be of interest to standards bodies and regulators, and clinicians using deep learning models. © The Institution of Engineering and Technology 2023. All rights reserved.","","","","Institution of Engineering and Technology","","2-s2.0-85178972591"
"Shin M.; Seo M.; Lee K.; Yoon K.","Shin, Minwoo (57222380433); Seo, Minjee (58778680400); Lee, Kyunghyun (58945415900); Yoon, Kyungho (57208559577)","57222380433; 58778680400; 58945415900; 57208559577","Super-resolution techniques for biomedical applications and challenges","14","3","","465","496","31","10.1007/s13534-024-00365-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188073218&doi=10.1007%2fs13534-024-00365-4&partnerID=40&md5=306ec4d8fff655a7829bfe31c2deec94","Super-resolution (SR) techniques have revolutionized the field of biomedical applications by detailing the structures at resolutions beyond the limits of imaging or measuring tools. These techniques have been applied in various biomedical applications, including microscopy, magnetic resonance imaging (MRI), computed tomography (CT), X-ray, electroencephalogram (EEG), ultrasound, etc. SR methods are categorized into two main types: traditional non-learning-based methods and modern learning-based approaches. In both applications, SR methodologies have been effectively utilized on biomedical images, enhancing the visualization of complex biological structures. Additionally, these methods have been employed on biomedical data, leading to improvements in computational precision and efficiency for biomedical simulations. The use of SR techniques has resulted in more detailed and accurate analyses in diagnostics and research, essential for early disease detection and treatment planning. However, challenges such as computational demands, data interpretation complexities, and the lack of unified high-quality data persist. The article emphasizes these issues, underscoring the need for ongoing development in SR technologies to further improve biomedical research and patient care outcomes. © Korean Society of Medical and Biological Engineering 2024.","Biomedical imaging; Biomedical simulation; CT; Deep learning; ECG; EEG; Elastography; Microscopy; MRI; MRS; PET; Spectrometry; Spectroscopy; Super-resolution; Thermography; Ultrasound; X-ray","Bioinformatics; Computational efficiency; Computerized tomography; Deep learning; Electroencephalography; Image enhancement; Medical applications; Medical imaging; Optical resolving power; Ultrasonic applications; bisoprolol fumarate; tracer; Biomedical applications; Biomedical imaging; Biomedical simulation; Computed tomography; Deep learning; Elastography; MRS; Resolution techniques; Superresolution; Thermography; artificial neural network; biomedical application; breast cancer; computer assisted tomography; convolutional neural network; deep learning; deep neural network; diagnostic procedure; elastography; electrocardiogram; electroencephalography; electromagnetic radiation; electromyography; electrophysiology; feature extraction; histology; human; image analysis; image processing; image quality; image reconstruction; image segmentation; learning algorithm; machine learning; mass spectrometry; medical technology; microbubble; microscopy; molecular imaging; morphology; myography; neuroimaging; neurologic disease; nuclear magnetic resonance imaging; nuclear magnetic resonance spectroscopy; particle image velocimetry; positron emission tomography; proteomics; Review; scanning electron microscopy; signal noise ratio; signal processing; single molecule force spectroscopy; stimulated emission depletion microscopy; structured illumination microscopy; super-resolution technique; thermography; three-dimensional imaging; transmission electron microscopy; ultrasound; viscoelasticity; X ray; Magnetic resonance imaging","National Research Foundation of Korea, NRF; Ministry of Science, ICT and Future Planning, MSIP, (RS-2023-00220762); Ministry of Science, ICT and Future Planning, MSIP; Yonsei University Research Fund, (2023-12-0018)","Springer Verlag","","2-s2.0-85188073218"
"Choi S.J.; Kim D.K.; Kim B.S.; Cho M.; Jeong J.; Jo Y.H.; Song K.J.; Kim Y.J.; Kim S.","Choi, Seung Jae (58032704200); Kim, Dae Kon (57216822391); Kim, Byeong Soo (57365979400); Cho, Minwoo (56783471200); Jeong, Joo (39061606100); Jo, You Hwan (25822597600); Song, Kyoung Jun (57037616400); Kim, Yu Jin (56658847500); Kim, Sungwan (27169083000)","58032704200; 57216822391; 57365979400; 56783471200; 39061606100; 25822597600; 57037616400; 56658847500; 27169083000","Mask R-CNN based multiclass segmentation model for endotracheal intubation using video laryngoscope","9","","","","","","10.1177/20552076231211547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176430215&doi=10.1177%2f20552076231211547&partnerID=40&md5=98a109508f241780296a9ddba0a8b5f8","Objective: Endotracheal intubation (ETI) is critical to secure the airway in emergent situations. Although artificial intelligence algorithms are frequently used to analyze medical images, their application to evaluating intraoral structures based on images captured during emergent ETI remains limited. The aim of this study is to develop an artificial intelligence model for segmenting structures in the oral cavity using video laryngoscope (VL) images. Methods: From 54 VL videos, clinicians manually labeled images that include motion blur, foggy vision, blood, mucus, and vomitus. Anatomical structures of interest included the tongue, epiglottis, vocal cord, and corniculate cartilage. EfficientNet-B5 with DeepLabv3+, EffecientNet-B5 with U-Net, and Configured Mask R-Convolution Neural Network (CNN) were used; EffecientNet-B5 was pretrained on ImageNet. Dice similarity coefficient (DSC) was used to measure the segmentation performance of the model. Accuracy, recall, specificity, and F1 score were used to evaluate the model's performance in targeting the structure from the value of the intersection over union between the ground truth and prediction mask. Results: The DSC of tongue, epiglottis, vocal cord, and corniculate cartilage obtained from the EfficientNet-B5 with DeepLabv3+, EfficientNet-B5 with U-Net, and Configured Mask R-CNN model were 0.3351/0.7675/0.766/0.6539, 0.0/0.7581/0.7395/0.6906, and 0.1167/0.7677/0.7207/0.57, respectively. Furthermore, the processing speeds (frames per second) of the three models stood at 3, 24, and 32, respectively. Conclusions: The algorithm developed in this study can assist medical providers performing ETI in emergent situations. © The Author(s) 2023.","Biomedical image processing; convolutional neural networks; deep learning; image segmentation; intubation","","National Research Foundation of Korea, NRF, (2021R1C1C101035213)","SAGE Publications Inc.","","2-s2.0-85176430215"
"Parihar S.; Kukker A.; Dhar S.; Amitabh V.; Singh V.; Krishna V.","Parihar, Sushma (57211908398); Kukker, Amit (57200143782); Dhar, Supriyo (58765446700); Amitabh, Varun (58765639800); Singh, Varun (58830446400); Krishna, Vamsi (59267164900)","57211908398; 57200143782; 58765446700; 58765639800; 58830446400; 59267164900","Biomedical Image Classification using Deep Reinforcement Learning","","","","","","","10.1109/ICAECT60202.2024.10468733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190115796&doi=10.1109%2fICAECT60202.2024.10468733&partnerID=40&md5=c62b01c01c27c8eb54bdf91b6d5b771f","The amalgamated tool of two renowned tools deep learning and reinforcement learning is a powerful representation for deep neural networks that improves the basic reinforcement learning framework. With the use of deep learning's representational power, it learns from the agent's activities on how to increase the expected reward. Recent work has shown a lot of success of deep reinforcement learning in different domains such as video games, robotics, finance, medical and computer vision. In this project, various DRL models and methods for planning medical image analysis are discussed. This study covers the fundamentals of reinforcement learning. DRL algorithms can address the problems with limited and inconsistent annotated medical imaging data, which has been a major obstacle to the implementation of deep learning models in clinical settings. DRL algorithms support these models for the reward function, interactions between agents, and the environment. There has been an extensive amount of research being done in this area, and it has the potential to enhance the utilisation of deep learning in medical imaging.  © 2024 IEEE.","Convolutional neural network; Deep learning; Machine learning; Reinforcement learning","Computer games; Convolutional neural networks; Deep neural networks; Image classification; Learning systems; Medical imaging; Medical problems; Agent activities; Biomedical images; Convolutional neural network; Deep learning; Images classification; Learn+; Learning frameworks; Machine-learning; Power; Reinforcement learnings; Reinforcement learning","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85190115796"
"Manoharan T.; Velvizhi R.; Juluru T.K.; Kamal S.; Mallick S.; Puliyanjalil E.","Manoharan, Thiyagarajan (58995607200); Velvizhi, Ramalingam (57210977000); Juluru, Tarun Kumar (57218311197); Kamal, Shoaib (57188986928); Mallick, Shrabani (56366477500); Puliyanjalil, Ezudheen (58892168300)","58995607200; 57210977000; 57218311197; 57188986928; 56366477500; 58892168300","Biomedical image classification using seagull optimization with deep learning for colon and lung cancer diagnosis","35","3","","1670","1679","9","10.11591/ijeecs.v35.i3.pp1670-1679","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197930832&doi=10.11591%2fijeecs.v35.i3.pp1670-1679&partnerID=40&md5=e3c3c8ff19fafe4934af0c4c72184408","Traditional health care relies on biomedical image categorization to identify and treat various medical conditions. In machine learning and medical imaging, biomedical image classification for colon and lung cancer diagnosis is significant. The work focuses on building novel models and algorithms to accurately detect and categorize tumorous lesions using computer tomography (CT) scans and histopathology slides. These systems use image processing, deep learning (DL), and convolutional neural networks (CNN) to assist medical professionals diagnose cancer sooner and improve patient outcomes. Biomedical image classification using seagull optimization with deep learning (BIC-SGODL) addresses colon and lung cancer diagnosis. The BIC-SGODL method improves cancer diagnosis using hyperparameter optimized DL model. BIC-SGODL utilizes DenseNet to learn complicated features. The convolutional long short-term memory (CLSTM) standard captures spatiotemporal information in sequential picture data. Finally, the SGO method adjusts hyperparameters to improve model performance and generalization. BIC-SGODL performs well with biomedical image dataset simulations. Thus, medical picture cancer diagnosis may be automated using BIC-SGODL. © 2024 Institute of Advanced Engineering and Science. All rights reserved.","Deep learning; Magnetic resonance imaging; Medical imaging; Seagull optimization algorithm; X-ray","","","Institute of Advanced Engineering and Science","","2-s2.0-85197930832"
"","","","30th International Conference on Neural Information Processing, ICONIP 2023","14447 LNCS","","","","","3459","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182011176&partnerID=40&md5=895edbcfa16594160d146efaa02e87d0","The proceedings contain 256 papers. The special focus in this conference is on Neural Information Processing. The topics include: RPUC: Semi-supervised 3D Biomedical Image Segmentation Through Rectified Pyramid Unsupervised Consistency; a Causality-Based Interpretable Cognitive Diagnosis Model; a Deep Learning Framework with Pruning RoI Proposal for Dental Caries Detection in Panoramic X-ray Images; ensemble of Randomized Neural Network and Boosted Trees for Eye-Tracking-Based Driver Situation Awareness Recognition and Interpretation; task Scheduling with Improved Particle Swarm Optimization in Cloud Data Center; Naturalistic Emotion Recognition Using EEG and Eye Movements; A DNN-Based Learning Framework for Continuous Movements Segmentation; RPF3D: Range-Pillar Feature Deep Fusion 3D Detector for Autonomous Driving; CMCI: A Robust Multimodal Fusion Method for Spiking Neural Networks; neighborhood Learning for Artificial Bee Colony Algorithm: A Mini-survey; channel Attention Separable Convolution Network for Skin Lesion Segmentation; correlated Online k-Nearest Neighbors Regressor Chain for Online Multi-output Regression; neural-Symbolic Recommendation with Graph-Enhanced Information; evolutionary Computation for Berth Allocation Problems: A Survey; user Stance Aware Network for Rumor Detection Using Semantic Relation Inference and Temporal Graph Convolution; multi-task Learning Network for Automatic Pancreatic Tumor Segmentation and Classification with Inter-Network Channel Feature Fusion; Fast and Efficient Brain Extraction with Recursive MLP Based 3D UNet; privacy-Preserving Travel Time Prediction for Internet of Vehicles: A Crowdsensing and Federated Learning Approach; block-Matching Multi-pedestrian Tracking; An Improved Target Searching and Imaging Method for CSAR; RMPE:Reducing Residual Membrane Potential Error for Enabling High-Accuracy and Ultra-low-latency Spiking Neural Networks; A Fine-Grained Domain Adaptation Method for Cross-Session Vigilance Estimation in SSVEP-Based BCI; a Hip-Knee Joint Coordination Evaluation System in Hemiplegic Individuals Based on Cyclogram Analysis; domain-Invariant Task Optimization for Cross-domain Recommendation; FLDNet: A Foreground-Aware Network for Polyp Segmentation Leveraging Long-Distance Dependencies; contrastive Hierarchical Gating Networks for Rating Prediction; preface.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85182011176"
"Ajai A.K.; Anitha A.","Ajai, Ajni K. (57191488323); Anitha, A. (57211773955)","57191488323; 57211773955","Clustering based lung lobe segmentation and optimization based lung cancer classification using CT images","78","","103986","","","","10.1016/j.bspc.2022.103986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134694723&doi=10.1016%2fj.bspc.2022.103986&partnerID=40&md5=34c52ed65431eba6e3d0a5b112132750","A serious condition with a high death and morbidity rate worldwide is lung cancer. To increase the likelihood that a person will survive, early diagnosis is urgently required. Various existing approaches are modeled to detect lung cancer, but low visibility of tumor region and the negative rates of images still result a complex task to recognize infected regions. Also, the traditional methods failed to enhance the accuracy of the lung cancer classification. Hence, this research developed a method named Shuffled Social Sky Optimizer-based Multi-Object Rectified Attention Network (SSSO-based MORAN) to effectively classify lung cancer disease. The proposed SSSO algorithm is the integration of the Shuffled Shepherd Optimization Algorithm (SSOA) and social ski-driver (SSD) algorithm, respectively. The input computed tomography (CT) image is supplied to the pre-processing phase, where the Gaussian filtering is employed to pre-process the image, and thereby the Region of Interest (ROI) is acquired from the input image. Then, the lung lobes are segmented using the proposed Deep Renyi entropy fuzzy clustering (DREFC). With the segmented lung lobes, the nodule region is identified from the lung image, and the process of cancer classification is done based on features. The features considered for the lung cancer classification are Local Gabor XOR Pattern (LGXP), Gray-Level Co-occurrence Matrix (GLCM) features, Global Binary Pattern (GBP), Tetrolet transform, and statistical features. The proposed algorithm effectively showed higher performance of accuracy, Mean Absolute Error (MAE), sensitivity, and specificity of 0.896, 0.104, 0.8969, and 0.845, respectively. © 2022","Biomedical image processing; Deep learning; Diagnosis system; Lung cancer; Lung lobe segmentation","Biological organs; Classification (of information); Computer aided diagnosis; Computerized tomography; Deep learning; Image classification; Image segmentation; Local binary pattern; Cancer classification; Clusterings; Computed tomography images; Condition; Deep learning; Diagnose system; Early diagnosis; Lung Cancer; Lung lobe segmentations; Optimisations; Article; attention network; cancer classification; clustering algorithm; comparative study; computer assisted tomography; contrast enhancement; deep renyi entropy fuzzy clustering; diagnostic accuracy; feasibility study; feature extraction; fuzzy c means clustering; fuzzy clustering; global binary pattern; gray level co occurrence matrix; human; human tissue; image processing; image segmentation; kernel method; local gabor xor pattern; lung cancer; lung lobe; lung nodule; lung parenchyma; mean absolute error; multi object rectified attention network; recurrent neural network; sensitivity and specificity; shuffled shepherd optimization algorithm; shuffled social sky optimizer; social ski driver algorithm; tetrolet transform; Diseases","","Elsevier Ltd","","2-s2.0-85134694723"
"McConnell N.; Ndipenoch N.; Cao Y.; Miron A.; Li Y.","McConnell, Niccolò (57472609800); Ndipenoch, Nchongmaje (58064883400); Cao, Yu (58730971100); Miron, Alina (57214473917); Li, Yongmin (56717319800)","57472609800; 58064883400; 58730971100; 57214473917; 56717319800","Exploring advanced architectural variations of nnUNet","560","","126837","","","","10.1016/j.neucom.2023.126837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173447520&doi=10.1016%2fj.neucom.2023.126837&partnerID=40&md5=fd1e645613616dfe30af7bdec3983364","The nnUNet is a state-of-the-art deep learning based segmentation framework which automatically and systematically configures the entire network training pipeline. We extend the network architecture component of the nnUNet framework by newly integrating mechanisms from advanced U-Net variations including residual, dense, and inception blocks as well as three forms of the attention mechanism. We propose the following extensions to nnUNet, namely Residual-nnUNet, Dense-nnUNet, Inception-nnUNet, Spatial-Single-Attention-nnUNet, Spatial- Multi-Attention-nnUNet, and Channel-Spatial-Attention-nnUNet. Furthermore, within Channel-Spatial- Attention-nnUNet we integrate our newly proposed variation of the channel-attention mechanism. We demonstrate that use of the nnUNet allows for consistent and transparent comparison of U-Net architectural modifications, while maintaining network architecture as the sole independent variable across experiments with respect to a dataset. The proposed variants are evaluated on eight medical imaging datasets consisting of 20 anatomical regions which is the largest collection of datasets on which attention U-Net variants have been compared in a single work. Our results suggest that attention variants are effective at improving performance when applied to tumour segmentation tasks consisting of two or more target anatomical regions, and that segmentation performance is influenced by use of the deep supervision architectural feature. © 2023 Elsevier B.V.","Attention; Biomedical image segmentation; Dense; Inception; nnUnet; Residual","Deep learning; Image segmentation; Medical imaging; Anatomical regions; Attention; Attention mechanisms; Biomedical image segmentation; Dense; Inception; Nnunet; Residual; Spatial attention; State of the art; Article; artificial neural network; automation; deep learning; image analysis; image processing; information processing; mathematical model; segmentation algorithm; Network architecture","","Elsevier B.V.","","2-s2.0-85173447520"
"Chen H.; Gao J.; Zhao D.; Wang H.; Song H.; Su Q.","Chen, Hongyang (57935194000); Gao, Jingyang (55995325700); Zhao, Di (56701350400); Wang, Hongzhi (57193402519); Song, Hong (7404037613); Su, Qinghua (50362000500)","57935194000; 55995325700; 56701350400; 57193402519; 7404037613; 50362000500","Review of the research progress in deep learning and biomedical image analysis till 2020; [深度学习与生物医学图像分析2020年综述]","26","3","","475","486","11","10.11834/jig.200351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104664544&doi=10.11834%2fjig.200351&partnerID=40&md5=c4631c28d4b66b831314279da402a26f","Medical big data mainly include electronic health record data, such as medical imaging data and genetic information data, among which medical imaging data takes up the most of medical data currently. One of the problems that researchers in computer science are greatly concerned about is how to apply medical big data in clinical practice.Artificial intelligence (AI) provides a good way to address this problem. AI algorithms, particularly deep learning, have demonstrated remarkable progress in image-recognition tasks. Historically, in radiology practice, trained physicians visually assess medical images for the detection, characterization, and monitoring of diseases. AI methods excel at automatically recognizing complex patterns in imaging data and providing quantitative, rather than qualitative, assessments of radiographic characteristics. Methods ranging from convolutional neural networks to variational autoencoders have found myriad applications in the medical image analysis field, propelling it forward at a rapid pace. In this review, by combining recent work and the latest research progress of big data analysis of medical images until 2020, we have summarized the theory, main process, and evaluation results of multiple deep learning algorithms in some fields of medical image analysis, including magnetic resonance imaging (MRI), pathology imaging, ultrasound imaging, electrical signals, digital radiography, molybdenum target, and diabetic eye imaging, using deep learning. MRI is one of the main research areas of medical image analysis. The existing research literature includes Alzheimer's disease MRI, Parkinson's disease MRI, brain tumor MRI, prostate cancer MRI, and cardiac MRI. MRI is also divided into two-dimensional and three-dimensional image analysis, especially for three-dimensional data, where insufficient data volume leads to problems such as overfitting, large calculations, and slow training. Medical ultrasound (also known as diagnostic sonography or ultrasonography) is a diagnostic imaging technique or therapeutic application of ultrasound. It is used to create an image of internal body structures such as tendons, muscles, joints, blood vessels, and internal organs. It aims to find the source of a disease or to exclude pathology. The practice of examining pregnant women using ultrasound is called obstetric ultrasonography and was an early development and application of clinical ultrasonography. Ultrasonography uses sound waves with higher frequencies than those audible to humans (>20 000 Hz). Ultrasonic images, also known as sonograms, are made by sending ultrasound pulses into the tissue using a probe. The ultrasound pulses echo off tissues with different reflection properties and are recorded and displayed as an image. Many different types of images can be formed. The most common is a B-mode image (brightness), which displays the acoustic impedance of a two-dimensional cross-section of a tissue. Other types can display blood flow, tissue motion over time, the location of blood, the presence of specific molecules, the stiffness of a tissue, or the anatomy of a three-dimensional region. Pathology is the gold standard for diagnosing some diseases, especially digital image of pathology.We specifically discuss AI combined with digital pathology images for diagnosis. Electroencephalography (EEG) is an electrophysiological monitoring method to record the electrical activity of the brain. It is typically noninvasive, with the electrodes placed along the scalp. However, invasive electrodes are sometimes used, for example in electrocorticography, sometimes called intracranial EEG. EEG is most often used to diagnose epilepsy, which causes abnormalities in EEG readings. It is also used to diagnose sleep disorders, depth of anesthesia, coma, encephalopathies, and brain death. EEG used to be a first-line method of diagnosis for tumors, stroke, and other focal brain disorders, but its use has decreased with the advent of high-resolution anatomical imaging techniques such as MRI and computed tomography (CT). Despite limited spatial resolution, EEG continues to be a valuable tool for research and diagnosis. It is one of the few mobile techniques available and offers millisecond-range temporal resolution, which is not possible with CT, positron emission tomography (PET), or MRI. Electrocardiography(ECG or EKG) is the process of producing an electrocardiogram. It is a graph of voltage versus time of the electrical activity of the heart using electrodes placed on the skin. These electrodes detect small electrical changes that are a consequence of cardiac muscle depolarization followed by repolarization during each cardiac cycle (heartbeat). Changes in the normal ECG pattern occur in numerous cardiac abnormalities, including cardiac rhythm disturbances (e.g., atrial fibrillation and ventricular tachycardia), inadequate coronary artery blood flow (e.g., myocardial ischemia and myocardial infarction), and electrolyte disturbances (e.g., hypokalemia and hyperkalemia).We analyzed the advantages and disadvantages of existing algorithms and the important and difficult points in the field of medical imaging, and introduced the application of intelligent imaging and deep learning in the field of big data analysis and early disease diagnosis. The current algorithms in the field of medical imaging have made considerable progress, but there is still a lot of room for development. We also focus on the optimization and improvement of different algorithms in different sub-fields under a variety of segmentation and classification indicators (e.g., Dice, IoU, accuracy and recall rate), and we look forward to the future development hotspots in this field. Deep learning has developed rapidly in the field of medical imaging and has broad prospects for development. It plays an important role in the early diagnosis of diseases. It can effectively improve the work efficiency of doctors and reduce their burden. Moreover, it has important theoretical research and practical application value. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.","Deep learning; Magnetic resonance imaging(MRI); Pathology; Review; Target segmentation; Ultrasound","","","Editorial and Publishing Board of JIG","","2-s2.0-85104664544"
"Gadosey P.K.; Li Y.; Agyekum E.A.; Zhang T.; Liu Z.; Yamak P.T.; Essaf F.","Gadosey, Pius Kwao (57201334954); Li, Yujian (26642995500); Agyekum, Enock Adjei (57215589307); Zhang, Ting (57198705645); Liu, Zhaoying (55672356900); Yamak, Peter T. (57208780170); Essaf, Firdaous (57212878980)","57201334954; 26642995500; 57215589307; 57198705645; 55672356900; 57208780170; 57212878980","SD-UNET: Stripping down U-net for segmentation of biomedical images on platforms with low computational budgets","10","2","110","","","","10.3390/diagnostics10020110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081253571&doi=10.3390%2fdiagnostics10020110&partnerID=40&md5=a971286937330d8ec35aa6a56c47e524","During image segmentation tasks in computer vision, achieving high accuracy performance while requiring fewer computations and faster inference is a big challenge. This is especially important in medical imaging tasks but one metric is usually compromised for the other. To address this problem, this paper presents an extremely fast, small and computationally effective deep neural network called Stripped-Down UNet (SD-UNet), designed for the segmentation of biomedical data on devices with limited computational resources. By making use of depthwise separable convolutions in the entire network, we design a lightweight deep convolutional neural network architecture inspired by the widely adapted U-Net model. In order to recover the expected performance degradation in the process, we introduce a weight standardization algorithm with the group normalization method. We demonstrate that SD-UNet has three major advantages including: (i) smaller model size (23x smaller than U-Net); (ii) 8x fewer parameters; and (iii) faster inference time with a computational complexity lower than 8M floating point operations (FLOPs). Experiments on the benchmark dataset of the Internatioanl Symposium on Biomedical Imaging (ISBI) challenge for segmentation of neuronal structures in electron microscopic (EM) stacks and the Medical Segmentation Decathlon (MSD) challenge brain tumor segmentation (BRATs) dataset show that the proposed model achieves comparable and sometimes better results compared to the current state-of-the-art. © 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","Biomedical image segmentation; Computer vision; Depthwise separable convolutions; Group normalization; Weight standardization","algorithm; Article; brain tumor; computer vision; convolutional neural network; deep learning; deep neural network; diagnostic imaging; electron microscopy; image analysis; image segmentation; nerve cell; stripped down unet; structure analysis; u net; weight","Chaoyang Postdoctoral Foundation of Beijing, (2019zz-35); National Natural Science Foundation of China, NSFC, (61806013, 61876010, 61906005)","Multidisciplinary Digital Publishing Institute (MDPI)","","2-s2.0-85081253571"
"Zahia S.; Sierra-Sosa D.; Garcia-Zapirain B.; Elmaghraby A.","Zahia, Sofia (57201091335); Sierra-Sosa, Daniel (37076014100); Garcia-Zapirain, Begonya (35732954700); Elmaghraby, Adel (7004230200)","57201091335; 37076014100; 35732954700; 7004230200","Tissue classification and segmentation of pressure injuries using convolutional neural networks","159","","","51","58","7","10.1016/j.cmpb.2018.02.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043369305&doi=10.1016%2fj.cmpb.2018.02.018&partnerID=40&md5=aab242960976e1122e2b5ddd9e25baca","Background and Objectives: This paper presents a new approach for automatic tissue classification in pressure injuries. These wounds are localized skin damages which need frequent diagnosis and treatment. Therefore, a reliable and accurate systems for segmentation and tissue type identification are needed in order to achieve better treatment results. Methods: Our proposed system is based on a Convolutional Neural Network (CNN) devoted to performing optimized segmentation of the different tissue types present in pressure injuries (granulation, slough, and necrotic tissues). A preprocessing step removes the flash light and creates a set of 5x5 sub-images which are used as input for the CNN network. The network output will classify every sub-image of the validation set into one of the three classes studied. Results: The metrics used to evaluate our approach show an overall average classification accuracy of 92.01%, an average total weighted Dice Similarity Coefficient of 91.38%, and an average precision per class of 97.31% for granulation tissue, 96.59% for necrotic tissue, and 77.90% for slough tissue. Conclusions: Our system has been proven to make recognition of complicated structures in biomedical images feasible. © 2018 Elsevier B.V.","Convolutional neural networks; Deep learning; Image segmentation; Pressure injuries; Tissue type classification","Algorithms; Databases, Factual; Humans; Image Processing, Computer-Assisted; Models, Anatomic; Models, Statistical; Necrosis; Neural Networks (Computer); Pressure Ulcer; Reproducibility of Results; Sensitivity and Specificity; Tomography, X-Ray Computed; Wound Healing; Wounds and Injuries; Convolution; Deep learning; Granulation; Image segmentation; Neural networks; Tissue engineering; Classification accuracy; Complicated structures; Convolutional neural network; Convolutional Neural Networks (CNN); Optimized segmentation; Similarity coefficients; Tissue classification; Tissue types; Article; automated pattern recognition; clinical evaluation; constants and coefficients; controlled study; convolutional neural network; decubitus; dice similarity coefficient; granulation tissue; image analysis; image processing; image segmentation; machine learning; measurement accuracy; measurement precision; pathological tissue; sensitivity and specificity; slough tissue; tissue characterization; tissue injury; tissue necrosis; validation process; algorithm; anatomic model; artificial neural network; decubitus; diagnostic imaging; factual database; human; injury; necrosis; reproducibility; statistical model; wound healing; x-ray computed tomography; Tissue","Department of Electricial and Computer Engineering, Boston University, (IT905-16); University of Louisville, UL","Elsevier Ireland Ltd","29650318","2-s2.0-85043369305"
"Shrivastava A.; Chakkaravathy M.; Shah M.A.","Shrivastava, Anurag (58035982500); Chakkaravathy, Midhun (58175875900); Shah, Mohd Asif (58090397100)","58035982500; 58175875900; 58090397100","A Comprehensive Analysis of Machine Learning Techniques in Biomedical Image Processing Using Convolutional Neural Network","","","","1363","1369","6","10.1109/IC3I56241.2022.10072911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152086993&doi=10.1109%2fIC3I56241.2022.10072911&partnerID=40&md5=910d2a83febf45b399f1ab034c9fc34b","Deep learning is a branch of machine learning that has grown by leaps and bounds since it was first used in computer vision. The 'Olympics' of computer vision, ImageNet Classification, was won by a system that used deep learning and convolutional neural networks in December 2012. Because of how important it is in the field, this competition is sometimes called the 'Olympics' of computer vision. (CNN). Since then, people in many different fields, such as medical image analysis, have looked into deep learning. We are going to look into whether or not it would be possible to use deep learning algorithms to analyse medical images. This poll asked people what they thought about the four following topics related to machine learning: 1) How it is now used in computer vision, 2) How machine learning has changed before and after deep learning, 3) What role ML models play in deep learning, and 4) How deep learning can be used to analyse medical photos. Before the invention of deep learning, most machine learning systems relied on inputs called 'features.' This type of machine learning is called feature-based ML by some (also known as feature-based ML). Studying photographic data can be used to learn through deep learning without the need to separate objects or pull out features. The main difference between the two was this. This was pretty clear when we looked at MLs made before and after deep learning became very popular. This part, along with the model's huge scope, makes deep learning work well. Even though the term 'deep learning' is still new, a study on the topic found that photo-input deep-learning algorithms have been available in the field of machine learning for a long time. Even though 'deep learning' is a term that has only been around for a short time, this was seen. Even though the idea of 'deep learning' is still in its early stages, discoveries like this one have been made. Even before the term 'deep learning' was invented, machine learning techniques that used pictures as input were already showing promise for solving a wide range of medical image interpretation problems. Even before the term 'deep learning' was made up, this was the case. One of these jobs is to Figure out how lesions are different from other organs and tissues. To solve the problem, an approach to machine learning that is based on images was used. In the next few decades, it is expected that deep learning will completely replace all of the traditional ways that medical images are currently interpreted. This is because applying deep learning and other machine learning techniques to the study of picture data could make medical image analysis much better. 'Deep learning,' which is the process of teaching computers to 'learn' from images, is one of the most promising and quickly growing areas of medical image analysis. Traditional ways of figuring out what a medical image means are likely to be replaced in the next few decades by machine learning that works from pictures.  © 2022 IEEE.","Analysis of medical images; CNN - Convolutional neural network; Deep and Machine learning; Medical image","Computer vision; Convolution; Deep neural networks; Image analysis; Learning algorithms; Learning systems; Medical imaging; Analyse of medical image; CNN - convolutional neural network; Convolutional neural network; Deep and machine learning; Feature-based; Machine learning techniques; Machine-learning; Medical image; Medical image analysis; Olympics; Convolutional neural networks","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85152086993"
"Heena A.; Biradar N.; Maroof N.M.","Heena, Ayesha (57215537131); Biradar, Nagashettappa (56267698900); Maroof, Najmuddin M. (57215192261)","57215537131; 56267698900; 57215192261","Machine Learning Based Detection and Classification of Heart Abnormalities","300 LNNS","","","15","22","7","10.1007/978-3-030-84760-9_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115630582&doi=10.1007%2f978-3-030-84760-9_2&partnerID=40&md5=777633047b8d07d3bf869a22a39ab80a","Various types of heart abnormalities require various parameters of consideration for effective detection, analysis, processing and classification of heart abnormalities. Like any other disease, prevention is the key to avoid heart diseases. Heart abnormalities are very common not only in India but all over the world, but with better understanding of different symptoms of heart problems, proper diagnosis and prognosis is possible, so that early and optimal treatment is initiated. Particularly in these Pandemic situations of COVID 19 which led to more stress and as a consequence many heart related issues. Deep learning is also vastly employed technique in recent researches for classification of heart images and biomedical images in general. Neural network and support vector machine (SVM) algorithms are also frequently used in classification because of higher accuracy in results. The use of machine learning resulted in improved accuracy and reduced variability in comparison to manual quantification of echocardiographic parameters. A hybrid algorithm (Image enhancement and denoising both carried out in preprocessing task) is developed in this article which can efficiently and effectively classify the heart abnormalities by detecting whether the image is normal or abnormal, if abnormal whether mild stage or critical stage. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Classification; Detection; Gradient modulation; Intensity preservation dynamic histogram equalization; Luminance modulation; Neural network; Support vector machine algorithm","","BKIT Bhalki; KBN College of Engineering; VTU Belagavi and family","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85115630582"
"Behura A.","Behura, Aradhana (57216374591)","57216374591","Congruence of Deep Learning in Medical Image Processing: Future Prospects and Challenges","936","","","197","221","24","10.1007/978-981-33-4698-7_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102080369&doi=10.1007%2f978-981-33-4698-7_10&partnerID=40&md5=6dcb672ef762524d0d59f0f1bf9f1f1b","Machine Learning and deep learning procedures, in particular deep reinforcement neural networks, have quickly become a smart approach for scrutinizing medical signal and image datasets. The perilous problem like Cancer takes place when the cellular reproduction procedure goes out of control when some parts of the human body’s cells arise to spread into contiguous fleshy tissue and divide without discontinuing which may be a clue to death. This fatal cancer is a dangerous disease categorized by undesirable, uncontrolled, and uncoordinated cell division. So early cancer diagnosis can protect a patient. Here, various types of deep learning techniques are applied for optimized feature extraction, normalization or dataset pre-processing (used to eliminate null value, noises, and outlier), data segmentation, accurate classification, and the common description of flow chart is described in Figs. 1 and 7. The survey of deep learning is used for image classification, carotid ultrasound data investigation, cardi tocography, intravascular ultrasound report, lung CT report, brain tumor prediction from the MRI report, object detection, segmentation, breast cancer prediction, ECG (electrocardiogram) signal, EEG (electroencephalogram), PPG signal registration and psoriasis skin disease as well as cancer detection. Concise summaries are delivered of trainings per application zone: pulmonary, musculoskeletal neuro, digital pathology, abdominal, retinal, breast, cardiac. There are various type of deep learning techniques are present to improve accuracy of the medical dataset. Deep reinforcement learning, Recursive neural network, Multilayer perceptron, Recurrent neural network, Boltzmann machine, Convolution neural network are different types of deep learning techniques used to train the image and signal dataset. Generative adversarial network, Auto encoder and deep belief neural network are coming under unsupervised pretrained neural network. Some well known architectural models of convolution neural networks are ResNet (2015), VGGNet (2014), GoogLeNet (2014), ZFNet (2013) is introduced as the visualization concept of the De-convolutional network, AlexNet (2012) and LeNet are basically used to train image dataset, LSTM technique (long short term memory) is used to train signalized dataset and RHSBoost, genetically optimized neural network are used for multiple classification of datasets efficiently. Dimensionality reduction, feature extraction, overfitting, underfitting and normalization problems can be solved using various types of optimization algorithm. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Attention module; Biomedical image and signal processing; Brain tumor; Breast cancer; Data prediction; Deep learning; Hyper-parameter; Hypercolumn technique; Magnetic resonance image","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85102080369"
"Pang S.; Du A.; He X.; Díez J.; Orgun M.A.","Pang, Shuchao (55639762100); Du, Anan (56167972000); He, Xiaoli (57218575078); Díez, Jorge (7201552665); Orgun, Mehmet A. (6603681610)","55639762100; 56167972000; 57218575078; 7201552665; 6603681610","Fast and accurate lung tumor spotting and segmentation for boundary delineation on CT slices in a coarse-to-fine framework","1142 CCIS","","","589","597","8","10.1007/978-3-030-36808-1_64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083005148&doi=10.1007%2f978-3-030-36808-1_64&partnerID=40&md5=93f0717bb39997a65cf80cd949d02c2d","Label noise and class imbalance are two of the critical challenges when training image-based deep neural networks, especially in the biomedical image processing domain. Our work focuses on how to address the two challenges effectively and accurately in the task of lesion segmentation from biomedical/medical images. To address the pixel-level label noise problem, we propose an advanced transfer training and learning approach with a detailed DICOM pre-processing method. To address the tumor/non-tumor class imbalance problem, we exploit a self-adaptive fully convolutional neural network with an automated weight distribution mechanism to spot the Radiomics lung tumor regions accurately. Furthermore, an improved conditional random field method is employed to obtain sophisticated lung tumor contour delineation and segmentation. Finally, our approach has been evaluated using several well-known evaluation metrics on the Lung Tumor segmentation dataset used in the 2018 IEEE VIP-CUP Challenge. Experimental results show that our weakly supervised learning algorithm outperforms other deep models and state-of-the-art approaches. © Springer Nature Switzerland AG 2019.","Boundary delineation; Fully convolutional neural networks; Lung tumor segmentation","Biological organs; Computerized tomography; Convolutional neural networks; Deep learning; Deep neural networks; Image segmentation; Learning systems; Noise pollution; Petroleum reservoir evaluation; Processing; Transfer learning; Tumors; Boundary delineation; Class imbalance problems; Conditional random field; Critical challenges; Lesion segmentations; Pre-processing method; State-of-the-art approach; Weight distributions; Learning algorithms","","Springer","","2-s2.0-85083005148"
"Yi F.; Park S.; Moon I.","Yi, Faliu (36560720900); Park, Seonghwan (57222426113); Moon, Inkyu (55388941800)","36560720900; 57222426113; 55388941800","High-throughput label-free cell detection and counting from diffraction patterns with deep fully convolutional neural networks","26","3","","","","","10.1117/1.JBO.26.3.036001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102710347&doi=10.1117%2f1.JBO.26.3.036001&partnerID=40&md5=cde0d3a0b06953e5a6a86af21803741a","SIGNIFICANCE: Digital holographic microscopy (DHM) is a promising technique for the study of semitransparent biological specimen such as red blood cells (RBCs). It is important and meaningful to detect and count biological cells at the single cell level in biomedical images for biomarker discovery and disease diagnostics. However, the biological cell analysis based on phase information of images is inefficient due to the complexity of numerical phase reconstruction algorithm applied to raw hologram images. New cell study methods based on diffraction pattern directly are desirable. AIM: Deep fully convolutional networks (FCNs) were developed on raw hologram images directly for high-throughput label-free cell detection and counting to assist the biological cell analysis in the future. APPROACH: The raw diffraction patterns of RBCs were recorded by use of DHM. Ground-truth mask images were labeled based on phase images reconstructed from RBC holograms using numerical reconstruction algorithm. A deep FCN, which is UNet, was trained on the diffraction pattern images to achieve the label-free cell detection and counting. RESULTS: The implemented deep FCNs provide a promising way to high-throughput and label-free counting of RBCs with a counting accuracy of 99% at a throughput rate of greater than 288 cells per second and 200  μm  ×  200  μm field of view at the single cell level. Compared to convolutional neural networks, the FCNs can get much better results in terms of accuracy and throughput rate. CONCLUSIONS: High-throughput label-free cell detection and counting were successfully achieved from diffraction patterns with deep FCNs. It is a promising approach for biological specimen analysis based on raw hologram directly.","cell counting; deep learning; digital holographic microscopy; holography application; optical information processing; red blood cell analysis","Algorithms; Erythrocytes; Holography; Neural Networks, Computer; algorithm; erythrocyte; holography","","NLM (Medline)","33686845","2-s2.0-85102710347"
"Zhang H.; Li Q.; Guan X.","Zhang, Hengliang (57222557855); Li, Qiang (56312497400); Guan, Xin (57192257319)","57222557855; 56312497400; 57192257319","An Improved Three-Dimensional Dual-Path Brain Tumor Image Segmentation Network; [一种改进的三维双路径脑肿瘤图像分割网络]","41","3","0310002","","","","10.3788/AOS202141.0310002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103215412&doi=10.3788%2fAOS202141.0310002&partnerID=40&md5=ba575ce5a2595d458b5aec43fc165686","In recent years, the application of deep learning in biomedical image processing has received widespread attention. Based on the basic theories of deep learning and medical applications, this paper proposes an improved three-dimensional dual-path brain tumor image segmentation network to improve the detection accuracy of brain tumors in nuclear magnetic resonance imaging sequences. The proposed algorithm is based on 3D-UNet. First, the improved dual-path network unit is used to form the encoder-decoder structure similar to UNet. While retaining the original features, the network unit can also generate new features in texture, shape, and edge of the brain tumor to improve the accuracy of network segmentation. Second, the multi-fiber structure is added to the dual-path network module, which reduces the amount of parameters while ensuring the accuracy of the segmentation. Finally, after the group convolution in each network module, the channel random mixing module is added to solve the problem of accuracy reduction caused by group convolution, and the weighted Tversky loss function is used to replace the Dice loss function to improve the segmentation accuracy of small targets. The average Dice_ET, Dice_WT, and Dice_TC of the proposed model are better than 3D-ESPNet, DeepMedic, DMFNet, and other algorithms. The research results have certain practical significance and application prospects. © 2021, Chinese Lasers Press. All right reserved.","Brain tumor image segmentation; Dual-path network; Image processing; Neural networks; Weighted-loss function","Brain; Convolution; Deep learning; Image segmentation; Magnetic resonance imaging; Medical applications; Medical imaging; Textures; Three dimensional computer graphics; Tumors; Application prospect; Detection accuracy; Encoder-decoder; Loss functions; Network segmentation; Research results; Segmentation accuracy; Small targets; Image enhancement","","Chinese Optical Society","","2-s2.0-85103215412"
"Reyes A.A.; Paheding S.; Deo M.; Audette M.","Reyes, Abel A. (57669722600); Paheding, Sidike (56585990900); Deo, Makarand (7102166133); Audette, Michel (57195774826)","57669722600; 56585990900; 7102166133; 57195774826","Gabor Filter-Embedded U-Net with Transformer-Based Encoding for Biomedical Image Segmentation","13594 LNCS","","","76","88","12","10.1007/978-3-031-18814-5_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141829849&doi=10.1007%2f978-3-031-18814-5_8&partnerID=40&md5=5eef604edfb2d00d84fc28f7e3d3da2d","Medical image segmentation involves a process of categorization of target regions that are typically varied in terms of shape, orientation and scales. This requires highly accurate algorithms as marginal segmentation errors in medical images may lead to inaccurate diagnosis in subsequent procedures. The U-Net framework has become one of the dominant deep neural network architectures for medical image segmentation. Due to complex and irregular shape of objects involved in medical images, robust feature representations that correspond to various spatial transformations are key to achieve successful results. Although U-Net-based deep architectures can perform feature extraction and localization, the design of specialized architectures or layer modifications is often an intricate task. In this paper, we propose an effective solution to this problem by introducing Gabor filter banks into the U-Net encoder, which has not yet been well explored in existing U-Net-based segmentation frameworks. In addition, global self-attention mechanisms and Transformer layers are also incorporated into the U-Net framework to capture global contexts. Through extensive testing on two benchmark datasets, we show that the Gabor filter-embedded U-Net with Transformer encoders can enhance the robustness of deep-learned features, and thus achieve a more competitive performance. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Biomedical image; Deep learning; Gabor filters; Segmentation; U-Net; Vision transformers","Benchmarking; Deep neural networks; Diagnosis; Encoding (symbols); Image segmentation; Medical imaging; Network architecture; Signal encoding; Biomedical image segmentation; Biomedical images; Deep learning; Encodings; Medical image segmentation; NET framework; Segmentation; Target regions; U-net; Vision transformer; Gabor filters","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85141829849"
"Wahid A.; Shah J.A.; Khan A.U.; Ullah M.; Ayob M.Z.","Wahid, Abdul (58028307700); Shah, Jawad Ali (54930956400); Khan, Adnan Umar (57188694672); Ullah, Mukhtar (57192412884); Ayob, Mohd Zaki (24463629400)","58028307700; 54930956400; 57188694672; 57192412884; 24463629400","Multi-layered basis pursuit algorithms for classification of MR images of Knee ACL tear","8","","","205424","205435","11","10.1109/ACCESS.2020.3037745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102800545&doi=10.1109%2fACCESS.2020.3037745&partnerID=40&md5=2d987b3b1c1d71cb6ff6cb4277fcb5d3","Deep learning architectures have been extensively used in recent years for the classification of biomedical images to assist clinicians for diagnosis and treatment management of patients with different health conditions. These architectures have demonstrated expert level diagnosis, and in some cases, surpassed human experts in diagnosing health conditions. The automation tools based on deep learning frameworks have the potential to transform all stages of medical imaging pipeline from image acquisition to interpretation and analysis. One of the most common areas where these techniques are applied is knee MR image classification for different types of Anterior Cruciate Ligament (ACL) tears. If properly and timely managed, the diagnosis and treatment of ACL tear can avoid further degradation of patients' knee joints and can also help slow the process of subsequent knee arthritis. In this work, we have implemented a novel classification framework based on multilayered basis pursuit algorithms inspired from recent research work in the area of the theoretical foundation of deep learning with the help of celebrated sparse coding theory. We implement an optimal multi-layered Convolutional Sparse Coding (ML-CSC) framework for classification of a labelled dataset of knee MR images with the coronal view and compare the results with traditional convolutional neural network (CNN) based classifiers. Empirical results demonstrate the effectiveness of the ML-CSC framework and show that the framework can successfully learn distinct features on a small dataset and achieve a good efficiency of more than 92% without employing regularization techniques and extensive training on large datasets. In addition to 95% average accuracy on the presence and absence of ACL tears, the framework also performs well on the imbalanced and challenging classification of partial ACL tear with 85% accuracy. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Basis pursuit; Iterative shrinkage algorithms; Knee MR image classification; Multi-layer convolutional sparse coding","Classification (of information); Computer aided diagnosis; Computer programming; Convolution; Convolutional neural networks; Deep learning; Image coding; Joints (anatomy); Large dataset; Magnetic resonance imaging; Medical imaging; Multilayer neural networks; Network architecture; Patient monitoring; Patient treatment; Anterior cruciate ligament; Classification framework; Learning architectures; Learning frameworks; Pursuit algorithms; Regularization technique; Theoretical foundations; Treatment management; Image classification","British Malaysian Institute, Universiti Kuala Lumpur, BMI, UniKL, (FRGS/1/2019/TK04/UNIKL/02/6); British Malaysian Institute, Universiti Kuala Lumpur, BMI, UniKL","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85102800545"
"Ryoo J.; Fan M.; Tang X.; Jiang H.; Arunachalam M.; Naveen S.; Kandemir M.T.","Ryoo, Jihyun (57159124500); Fan, Mengran (57215213163); Tang, Xulong (57013793800); Jiang, Huaipan (56451943700); Arunachalam, Meena (57188576053); Naveen, Sharada (57215213244); Kandemir, Mahmut T. (35549787100)","57159124500; 57215213163; 57013793800; 56451943700; 57188576053; 57215213244; 35549787100","Architecture-Centric Bottleneck Analysis for Deep Neural Network Applications","","","8990516","205","214","9","10.1109/HiPC.2019.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080144759&doi=10.1109%2fHiPC.2019.00034&partnerID=40&md5=bcd37f22c8fbea225ae24f3089f81cdd","The ever-growing complexity and popularity of machine learning and deep learning applications have motivated an urgent need of effective and efficient support for these applications on contemporary computing systems. In this paper, we thoroughly analyze the various DNN algorithms on three widely used architectures (CPU, GPU, and Xeon Phi). The DNN algorithms we choose for evaluation include i) Unet-for biomedical image segmentation, based on Convolutional Neural Network (CNN), ii) NMT-for neural machine translation based on Recurrent Neural Network (RNN), iii) ResNet-50, and iv) DenseNet-both for image processing based on CNNs. The ultimate goal of this paper is to answer four fundamental questions: i) whether the different DNN networks exhibit similar behavior on a given execution platform? ii) whether, across different platforms, a given DNN network exhibits different behaviors? iii) for the same execution platform and the same DNN network, whether different execution phases have different behaviors? and iv) are the current major general-purpose platforms tuned sufficiently well for different DNN algorithms? Motivated by these questions, we conduct an in-depth investigation of running DNN applications on modern systems. Specifically, we first identify the most time-consuming functions (hotspot functions) across different networks and platforms. Next, we characterize performance bottlenecks and discuss them in detail. Finally, we port selected hotspot functions to a cycle-accurate simulator, and use the results to direct architectural optimizations to better support DNN applications. © 2019 IEEE.","Characterization; CPU; DNN; GPU; Xeon Phi","Bioinformatics; Convolutional neural networks; Graphics processing unit; Image segmentation; Network architecture; Program processors; Recurrent neural networks; Architecture-centric; Biomedical image segmentation; Cycle-accurate simulators; Machine translations; Neural network application; Performance bottlenecks; Recurrent neural network (RNN); Xeon Phi; Deep neural networks","National Science Foundation, NSF, (1439057, 1526750, 1629129, 1629915, 1763681, 1822923, 1908793, 1931531); Intel Corporation","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85080144759"
"Ge Y.; Li B.; Zhao Y.; Yan W.","Ge, Yunhao (57195494229); Li, Bin (57199787081); Zhao, Yanzheng (36017835600); Yan, Weixin (24367497900)","57195494229; 57199787081; 36017835600; 24367497900","HH-Net: Image driven microscope fast auto-focus with deep neural network","","","","180","185","5","10.1145/3326172.3326225","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069223888&doi=10.1145%2f3326172.3326225&partnerID=40&md5=32f9450d2aeb94d8598fce046d5d9e0c","Computer aid auto-focus system is necessary for accurate microscope diagnosis, especially for the high precision microscope, which leaves little physical distance for focus adjusting manually. We proposed an image-driven microscope fast auto-focus system with a deep neural network. There are two main contributions. First, combining the high-level feature learning ability advantages of convolution neural network (CNN) and the handcraft feature selection ability of statistical learning, we proposed a High-level-Handcraft Neural Network (HH-Net) to accurately determine the distance index between microscope lens and cell smear by evaluating the image focus quality. It deployed 13 layers CNN for the high-level feature extraction from image patches. While the handcraft features which provide global information from the raw image were extracted by statistical algorithms and merged into CNN features. Finally, the combined features are utilized by the fully connected layers in the network to obtain the final distance index by classifying the biomedical image focus quality. Second, cooperated with the HH-Net, we propose an end to end image driven microscope fast auto-focus system, which can learn auto-focus policies from visual input and finish at a clear spot automatically. The accuracy of our patch level focus quality prediction is 92.4% with HH-Net, while the real-time image level focus quality predication can be 99.99% with 0.025s cost time by certainty voting strategy. Our auto-focus system can also cooperate with the X-Y Micro platform to automatically scan the whole cell smear and get the real-time best-in-focus image of a microscope with fast response, accuracy, and robustness. © 2019 Association for Computing Machinery.","Convolutional neural network; Deep neural network; Fast auto-focus; Handcraft features; High-level features; Image focus quality; Microscope","Biomedical engineering; Convolution; Convolutional neural networks; Deep learning; Feature extraction; Image quality; Microscopes; Network layers; Auto focus; Convolution neural network; Handcraft features; High-level feature extractions; High-level features; Image focus; Statistical algorithm; Statistical learning; Deep neural networks","","Association for Computing Machinery","","2-s2.0-85069223888"
"Park I.; Lee U.","Park, Ingyu (57195070543); Lee, Unjoo (55598165900)","57195070543; 55598165900","Automatic, qualitative scoring of the clock drawing test (Cdt) based on u‐net, cnn and mobile sensor data","21","15","5239","","","","10.3390/s21155239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111697363&doi=10.3390%2fs21155239&partnerID=40&md5=3af1a334615e426a559482b7b8b15a5c","The Clock Drawing Test (CDT) is a rapid, inexpensive, and popular screening tool for cognitive functions. In spite of its qualitative capabilities in diagnosis of neurological diseases, the assessment of the CDT has depended on quantitative methods as well as manual paper based methods. Furthermore, due to the impact of the advancement of mobile smart devices imbedding several sensors and deep learning algorithms, the necessity of a standardized, qualitative, and automatic scoring system for CDT has been increased. This study presents a mobile phone application, mCDT, for the CDT and suggests a novel, automatic and qualitative scoring method using mobile sensor data and deep learning algorithms: CNN, a convolutional network, U‐Net, a convolutional network for biomedical image segmentation, and the MNIST (Modified National Institute of Standards and Technology) database. To obtain DeepC, a trained model for segmenting a contour image from a hand drawn clock image, U‐Net was trained with 159 CDT hand‐drawn images at 128 × 128 resolu-tion, obtained via mCDT. To construct DeepH, a trained model for segmenting the hands in a clock image, U‐Net was trained with the same 159 CDT 128 × 128 resolution images. For obtaining DeepN, a trained model for classifying the digit images from a hand drawn clock image, CNN was trained with the MNIST database. Using DeepC, DeepH and DeepN with the sensor data, parameters of contour (0–3 points), numbers (0–4 points), hands (0–5 points), and the center (0–1 points) were scored for a total of 13 points. From 219 subjects, performance testing was completed with images and sensor data obtained via mCDT. For an objective performance analysis, all the images were scored and crosschecked by two clinical experts in CDT scaling. Performance test analysis derived a sensitivity, specificity, accuracy and precision for the contour parameter of 89.33, 92.68, 89.95 and 98.15%, for the hands parameter of 80.21, 95.93, 89.04 and 93.90%, for the numbers parameter of 83.87, 95.31, 87.21 and 97.74%, and for the center parameter of 98.42, 86.21, 96.80 and 97.91%, respec-tively. From these results, the mCDT application and its scoring system provide utility in differentiating dementia disease subtypes, being valuable in clinical practice and for studies in the field. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Automatic scoring; Clock drawing test; CNN; Deep learning; MNIST; U‐Net; Wearable sensor","Algorithms; Cognition; Humans; Mass Screening; Neuropsychological Tests; Research Design; Bioinformatics; Classification (of information); Clocks; Convolution; Convolutional neural networks; Deep learning; Diagnosis; Learning algorithms; Learning systems; Accuracy and precision; Biomedical image segmentation; Convolutional networks; Mobile phone applications; Mobile smart devices; National Institute of Standards and Technology; Neurological disease; Performance analysis; algorithm; cognition; human; mass screening; methodology; neuropsychological test; Image segmentation","Basic Science Research, (2020R1F1A1048281); Hallym University, Hallym, (HRF‐202003‐021)","MDPI AG","34372476","2-s2.0-85111697363"
"Goswami M.","Goswami, Mayank (55636509800)","55636509800","Deep learning models for benign and malign ocular tumor growth estimation","93","","101986","","","","10.1016/j.compmedimag.2021.101986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115792448&doi=10.1016%2fj.compmedimag.2021.101986&partnerID=40&md5=fc369388af10c8443dda0db183aa6ab7","Relatively abundant availability of medical imaging data has provided significant support in the development and testing of Neural Network based image processing methods. Clinicians often face issues in selecting suitable image processing algorithm for medical imaging data. A strategy for the selection of a proper model is presented here. The training data set comprises optical coherence tomography (OCT) and angiography (OCT-A) images of 50 mice eyes with more than 100 days follow-up. The data contains images from treated and untreated mouse eyes. Four deep learning variants are tested for automatic (a) differentiation of tumor region with healthy retinal layer and (b) segmentation of 3D ocular tumor volumes. Exhaustive sensitivity analysis of deep learning models is performed with respect to the number of training and testing images using eight performance indices to study accuracy, reliability/reproducibility, and speed. U-net with UVgg16 is best for malign tumor data set with treatment (having considerable variation) and U-net with Inception backbone for benign tumor data (with minor variation). Loss value and root mean square error (R.M.S.E.) are found most and least sensitive performance indices, respectively. The performance (via indices) is found to be exponentially improving regarding a number of training images. The segmented OCT-Angiography data shows that neovascularization drives the tumor volume. Image analysis shows that photodynamic imaging-assisted tumor treatment protocol is transforming an aggressively growing tumor into a cyst. An empirical expression is obtained to help medical professionals choose a particular model given the number of images and types of characteristics. We recommend that the presented exercise should be taken as standard practice before employing a particular deep learning model for biomedical image analysis. © 2021 Elsevier Ltd","Cancer growth; Deep CNN; Image segmentation; OCT angiography; OCT imaging","Animals; Deep Learning; Image Processing, Computer-Assisted; Mice; Neoplasms; Neural Networks, Computer; Reproducibility of Results; Tomography, Optical Coherence; Angiography; Bayesian networks; Deep learning; Digital storage; Image analysis; Image enhancement; Image quality; Mammals; Mean square error; Ophthalmology; Optical tomography; Reliability analysis; Sensitivity analysis; Statistical tests; Tumors; Cancer growth; Deep CNN; Images segmentations; Imaging data; Learning models; Ocular tumor; Optical coherence tomography angiography; Optical coherence tomography imaging; Tomography imaging; Tumor volumes; A scan; animal experiment; animal model; antineoplastic protocol; Article; B scan; benign neoplasm; cancer growth; cancer size; classifier; convolutional neural network; deep learning; depth perception; diagnostic accuracy; eye cancer; eye tumor; follow up; image analysis; image segmentation; mouse; neovascularization (pathology); nonhuman; ocular blood vessel; optical coherence tomography; optical coherence tomography angiography; photodynamic therapy; reliability; reproducibility; three-dimensional imaging; tumor differentiation; tumor growth; tumor volume; tumor xenograft; animal; image processing; neoplasm; Image segmentation","BT/IITR; IMPRINT-II; UCDavis","Elsevier Ltd","34509705","2-s2.0-85115792448"
"Pang S.; Orgun M.A.; Yu Z.","Pang, Shuchao (55639762100); Orgun, Mehmet A. (6603681610); Yu, Zhezhou (8938987700)","55639762100; 6603681610; 8938987700","A novel biomedical image indexing and retrieval system via deep preference learning","158","","","53","69","16","10.1016/j.cmpb.2018.02.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041721081&doi=10.1016%2fj.cmpb.2018.02.003&partnerID=40&md5=83daf49352eb3580b74fd70ba252d771","Background and Objectives: The traditional biomedical image retrieval methods as well as content-based image retrieval (CBIR) methods originally designed for non-biomedical images either only consider using pixel and low-level features to describe an image or use deep features to describe images but still leave a lot of room for improving both accuracy and efficiency. In this work, we propose a new approach, which exploits deep learning technology to extract the high-level and compact features from biomedical images. The deep feature extraction process leverages multiple hidden layers to capture substantial feature structures of high-resolution images and represent them at different levels of abstraction, leading to an improved performance for indexing and retrieval of biomedical images. Methods: We exploit the current popular and multi-layered deep neural networks, namely, stacked denoising autoencoders (SDAE) and convolutional neural networks (CNN) to represent the discriminative features of biomedical images by transferring the feature representations and parameters of pre-trained deep neural networks from another domain. Moreover, in order to index all the images for finding the similarly referenced images, we also introduce preference learning technology to train and learn a kind of a preference model for the query image, which can output the similarity ranking list of images from a biomedical image database. To the best of our knowledge, this paper introduces preference learning technology for the first time into biomedical image retrieval. Results: We evaluate the performance of two powerful algorithms based on our proposed system and compare them with those of popular biomedical image indexing approaches and existing regular image retrieval methods with detailed experiments over several well-known public biomedical image databases. Based on different criteria for the evaluation of retrieval performance, experimental results demonstrate that our proposed algorithms outperform the state-of-the-art techniques in indexing biomedical images. Conclusions: We propose a novel and automated indexing system based on deep preference learning to characterize biomedical images for developing computer aided diagnosis (CAD) systems in healthcare. Our proposed system shows an outstanding indexing ability and high efficiency for biomedical image retrieval applications and it can be used to collect and annotate the high-resolution images in a biomedical database for further biomedical image research and applications. © 2018 Elsevier B.V.","Biomedical image retrieval; Convolutional neural network; Deep learning; Preference learning","Algorithms; Databases, Factual; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Information Storage and Retrieval; Machine Learning; Neural Networks (Computer); Radiology Information Systems; Bioinformatics; Computer aided diagnosis; Computer aided instruction; Content based retrieval; Convolution; Database systems; Deep learning; Deep neural networks; Efficiency; Image enhancement; Indexing (of information); Medical computing; Network layers; Neural networks; Query processing; Biomedical image database; Biomedical images; Computer Aided Diagnosis(CAD); Content-Based Image Retrieval; Convolutional neural network; Convolutional Neural Networks (CNN); Preference learning; State-of-the-art techniques; article; diagnosis; diagnostic test accuracy study; extraction; image retrieval; learning; nervous system; algorithm; artificial neural network; diagnostic imaging; factual database; human; image processing; information retrieval; machine learning; procedures; radiology information system; Search engines","Science and Technology Development Plan of Jilin Province, (20150204007GX); National Natural Science Foundation of China, NSFC, (51409117, 51679105, 61702214); National Natural Science Foundation of China, NSFC; China Scholarship Council, CSC; Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP, (20120061110045); Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP","Elsevier Ireland Ltd","29544790","2-s2.0-85041721081"
"Mou L.; Zhao Y.; Fu H.; Liu Y.; Cheng J.; Zheng Y.; Su P.; Yang J.; Chen L.; Frangi A.F.; Akiba M.; Liu J.","Mou, Lei (57211999350); Zhao, Yitian (56583188900); Fu, Huazhu (35317209500); Liu, Yonghuai (7410228990); Cheng, Jun (57535555300); Zheng, Yalin (55948134900); Su, Pan (55507687000); Yang, Jianlong (57212326066); Chen, Li (57192579689); Frangi, Alejandro F. (7005249248); Akiba, Masahiro (35868367900); Liu, Jiang (23389932700)","57211999350; 56583188900; 35317209500; 7410228990; 57535555300; 55948134900; 55507687000; 57212326066; 57192579689; 7005249248; 35868367900; 23389932700","CS2-Net: Deep learning segmentation of curvilinear structures in medical imaging","67","","101874","","","","10.1016/j.media.2020.101874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095451000&doi=10.1016%2fj.media.2020.101874&partnerID=40&md5=b009f6bc25ab7c596e88855ddb43479e","Automated detection of curvilinear structures, e.g., blood vessels or nerve fibres, from medical and biomedical images is a crucial early step in automatic image interpretation associated to the management of many diseases. Precise measurement of the morphological changes of these curvilinear organ structures informs clinicians for understanding the mechanism, diagnosis, and treatment of e.g. cardiovascular, kidney, eye, lung, and neurological conditions. In this work, we propose a generic and unified convolution neural network for the segmentation of curvilinear structures and illustrate in several 2D/3D medical imaging modalities. We introduce a new curvilinear structure segmentation network (CS2-Net), which includes a self-attention mechanism in the encoder and decoder to learn rich hierarchical representations of curvilinear structures. Two types of attention modules - spatial attention and channel attention - are utilized to enhance the inter-class discrimination and intra-class responsiveness, to further integrate local features with their global dependencies and normalization, adaptively. Furthermore, to facilitate the segmentation of curvilinear structures in medical images, we employ a 1×3 and a 3×1 convolutional kernel to capture boundary features. Besides, we extend the 2D attention mechanism to 3D to enhance the network's ability to aggregate depth information across different layers/slices. The proposed curvilinear structure segmentation network is thoroughly validated using both 2D and 3D images across six different imaging modalities. Experimental results across nine datasets show the proposed method generally outperforms other state-of-the-art algorithms in various metrics. © 2020","Attention mechanism; Blood vessel; Curvilinear structure; Deep neural network; Nerve fiber; Segmentation","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Neural Networks, Computer; Blood vessels; Convolution; Deep learning; Diagnosis; Image segmentation; Attention mechanisms; Convolution neural network; Curvilinear structures; Hierarchical representation; Image interpretation; Morphological changes; Precise measurements; State-of-the-art algorithms; Article; convolutional neural network; deep learning; diagnostic accuracy; diagnostic imaging; human; image analysis; image segmentation; priority journal; systematic review; three-dimensional imaging; two-dimensional imaging; algorithm; image processing; Medical imaging","Leeds Radiotherapy Research Centre of Excellence, (CRUK RadNetC19942/A28832); Ningbo “2025 S&T Megaprojects, (2019B10033, 2019B10061); Shenzhen Ministry of Education; Horizon 2020 Framework Programme, H2020, (777119); Key Technology Research and Development Program of Shandong, (2020C03036); Cancer Research UK, CRUK, (C19942/A28832); National Natural Science Foundation of China, NSFC, (61906181); Natural Science Foundation of Zhejiang Province, ZJNSF, (LQ20F030002, LZ19F010001); Horizon 2020, (SC1-PM-16-2017-777119); Shenzhen University, SZU","Elsevier B.V.","33166771","2-s2.0-85095451000"
"Dhar S.; Shamir L.","Dhar, Sanchari (57408095800); Shamir, Lior (8906230500)","57408095800; 8906230500","Evaluation of the benchmark datasets for testing the efficacy of deep convolutional neural networks","5","3","","92","101","9","10.1016/j.visinf.2021.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122645738&doi=10.1016%2fj.visinf.2021.10.001&partnerID=40&md5=b91cbee058e7ab1be4e83952a91a98ac","In the past decade, deep neural networks, and specifically convolutional neural networks (CNNs), have been becoming a primary tool in the field of biomedical image analysis, and are used intensively in other fields such as object or face recognition. CNNs have a clear advantage in their ability to provide superior performance, yet without the requirement to fully understand the image elements that reflect the biomedical problem at hand, and without designing specific algorithms for that task. The availability of easy-to-use libraries and their non-parametric nature make CNN the most common solution to problems that require automatic biomedical image analysis. But while CNNs have many advantages, they also have certain downsides. The features determined by CNNs are complex and unintuitive, and therefore CNNs often work as a “Black Box”. Additionally, CNNs learn from any piece of information in the pixel data that can provide a discriminative signal, making it more difficult to control what the CNN actually learns. Here we follow common practices to test whether CNNs can classify biomedical image datasets, but instead of using the entire image we use merely parts of the images that do not have biomedical content. The experiments show that CNNs can provide high classification accuracy even when they are trained with datasets that do not contain any biomedical information, or can be systematically biased by irrelevant information in the image data. The presence of such consistent irrelevant data is difficult to identify, and can therefore lead to biased experimental results. Possible solutions to this downside of CNNs can be control experiments, as well as other protective practices to validate the results and avoid biased conclusions based on CNN-generated annotations. © 2021 The Author(s)","Convolutional neural networks; Data acquisition bias; Deep learning; Experimental design","Bioinformatics; Classification (of information); Convolution; Convolutional neural networks; Deep neural networks; Face recognition; Image analysis; Benchmark datasets; Biomedical image analysis; Biomedical problems; Convolutional neural network; Data acquisition bias; Deep learning; Image elements; Learn+; Nonparametrics; Performance; Data acquisition","Zhejiang University Press; National Science Foundation, NSF, (AST-1903823)","Elsevier B.V.","","2-s2.0-85122645738"
"Alhudhaif A.; Cömert Z.; Polat K.","Alhudhaif, Adi (56404673400); Cömert, Zafer (36543652400); Polat, Kemal (8945093900)","56404673400; 36543652400; 8945093900","Otitis media detection using tympanic membrane images with a novel multi-class machine learning algorithm","7","","","1","22","21","10.7717/PEERJ-CS.405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102847468&doi=10.7717%2fPEERJ-CS.405&partnerID=40&md5=d579a118956eff6bd2f0fd6cb9d67610","Background: Otitis media (OM) is the infection and inflammation of the mucous membrane covering the Eustachian with the airy cavities of the middle ear and temporal bone. OM is also one of the most common ailments. In clinical practice, the diagnosis of OM is carried out by visual inspection of otoscope images. This vulnerable process is subjective and error-prone. Methods: In this study, a novel computer-aided decision support model based on the convolutional neural network (CNN) has been developed. To improve the generalized ability of the proposed model, a combination of the channel and spatial model (CBAM), residual blocks, and hypercolumn technique is embedded into the proposed model. All experiments were performed on an open-access tympanic membrane dataset that consists of 956 otoscopes images collected into five classes. Results: The proposed model yielded satisfactory classification achievement. The model ensured an overall accuracy of 98.26%, sensitivity of 97.68%, and specificity of 99.30%. The proposed model produced rather superior results compared to the pre-trained CNNs such as AlexNet, VGG-Nets, GoogLeNet, and ResNets. Consequently, this study points out that the CNN model equipped with the advanced image processing techniques is useful for OM diagnosis. The proposed model may help to field specialists in achieving objective and repeatable results, decreasing misdiagnosis rate, and supporting the decision-making processes. © 2021. Alhudhaif et al.","Biomedical image processing; Convolutional neural networks; Decision support system; Deep learning; Otitis media","Convolutional neural networks; Decision making; Decision support systems; Image processing; Learning algorithms; Clinical practices; Computer-aided decision supports; Decision making process; Image processing technique; Misdiagnosis rate; Overall accuracies; Repeatable results; Tympanic membranes; Machine learning","Prince Sattam bin Abdulaziz University, Alkharj, Saudi Arabia; Deanship of Scientific Research, King Saud University","PeerJ Inc.","","2-s2.0-85102847468"
"Zheng Z.; Yan H.; Setzer F.C.; Shi K.J.; Mupparapu M.; Li J.","Zheng, Zhiyang (57219469626); Yan, Hao (56276514800); Setzer, Frank C. (19934334800); Shi, Katherine J. (57216731760); Mupparapu, Mel (7003536251); Li, Jing (37081011600)","57219469626; 56276514800; 19934334800; 57216731760; 7003536251; 37081011600","Anatomically Constrained Deep Learning for Automating Dental CBCT Segmentation and Lesion Detection","18","2","9219218","603","614","11","10.1109/TASE.2020.3025871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092913468&doi=10.1109%2fTASE.2020.3025871&partnerID=40&md5=b9e40c8229bff18c5891786f55f21b96","Compared with the rapidly growing artificial intelligence (AI) research in other branches of healthcare, the pace of developing AI capacities in dental care is relatively slow. Dental care automation, especially the automated capability for dental cone beam computed tomography (CBCT) segmentation and lesion detection, is highly needed. CBCT is an important imaging modality that is experiencing ever-growing utilization in various dental specialties. However, little research has been done for segmenting different structures, restorative materials, and lesions using deep learning. This is due to multifold challenges such as content-rich oral cavity and significant within-label variation on each CBCT image as well as the inherent difficulty of obtaining many high-quality labeled images for training. On the other hand, oral-Anatomical knowledge exists in dentistry, which shall be leveraged and integrated into the deep learning design. In this article, we propose a novel anatomically constrained Dense U-Net for integrating oral-Anatomical knowledge with data-driven Dense U-Net. The proposed algorithm is formulated as a regularized or constrained optimization and solved using mean-field variational approximation to achieve computational efficiency. Mathematical encoding for transforming descriptive knowledge into a quantitative form is also proposed. Our experiment demonstrates that the proposed algorithm outperforms the standard Dense U-Net in both lesion detection accuracy and dice coefficient (DICE) indices in multilabel segmentation. Benefited from the integration with anatomical domain knowledge, our algorithm performs well with data from a small number of patients included in the training. Note to Practitioners-This article proposes a novel deep learning algorithm to enable the automated capability for cone beam computed tomography (CBCT) segmentation and lesion detection. Despite the growing adoption of CBCT in various dental specialties, such capability is currently lacking. The proposed work will provide tools to help reduce subjectivity and human errors, as well as streamline and expedite the clinical workflow. This will greatly facilitate dental care automation. Furthermore, due to the capacity of integrating oral-Anatomical knowledge into the deep learning design, the proposed algorithm does not require many high-quality labeled images to train. The algorithm can provide good accuracy under limited training samples. This ability is highly desirable for practitioners by saving labor-intensive, costly labeling efforts, and enjoying the benefits provided by AI.  © 2004-2012 IEEE.","Biomedical image segmentation; healthcare automation; machine learning; neural networks","Approximation algorithms; Computational efficiency; Computerized tomography; Constrained optimization; Data integration; Dentistry; Knowledge management; Cone-beam computed tomography; Dice coefficient; Different structure; Domain knowledge; Imaging modality; Lesion detection; Restorative materials; Variational approximation; Deep learning","NSF DMS, (1830363, 1903135)","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85092913468"
"Gupta H.; Jin K.H.; Nguyen H.Q.; McCann M.T.; Unser M.","Gupta, Harshit (57213136047); Jin, Kyong Hwan (55153576800); Nguyen, Ha Q. (57219758824); McCann, Michael T. (55617614400); Unser, Michael (7102049045)","57213136047; 55153576800; 57219758824; 55617614400; 7102049045","CNN-Based Projected Gradient Descent for Consistent CT Image Reconstruction","37","6","","1440","1453","13","10.1109/TMI.2018.2832656","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046484652&doi=10.1109%2fTMI.2018.2832656&partnerID=40&md5=8a89ac9acbadc64cfa2118f00e090f92","We present a new image reconstruction method that replaces the projector in a projected gradient descent (PGD) with a convolutional neural network (CNN). Recently, CNNs trained as image-to-image regressors have been successfully used to solve inverse problems in imaging. However, unlike existing iterative image reconstruction algorithms, these CNN-based approaches usually lack a feedback mechanism to enforce that the reconstructed image is consistent with the measurements. We propose a relaxed version of PGD wherein gradient descent enforces measurement consistency, while a CNN recursively projects the solution closer to the space of desired reconstruction images. We show that this algorithm is guaranteed to converge and, under certain conditions, converges to a local minimum of a non-convex inverse problem. Finally, we propose a simple scheme to train the CNN to act like a projector. Our experiments on sparse-view computed-tomography reconstruction show an improvement over total variation-based regularization, dictionary learning, and a state-of-the-art deep learning-based direct reconstruction technique. © 2017 IEEE.","biomedical image reconstruction; Deep learning; inverse problems; low-dose computed tomography","Algorithms; Deep Learning; Humans; Image Processing, Computer-Assisted; Signal-To-Noise Ratio; Tomography, X-Ray Computed; Computerized tomography; Deep learning; Differential equations; Functions; Inverse problems; Iterative methods; Neural networks; Problem solving; Biomedical measurements; Convex functions; Convolutional Neural Networks (CNN); Image reconstruction methods; Iterative image reconstruction algorithm; Low dose; Reconstruction techniques; Tomography reconstruction; article; computer assisted tomography; feedback system; image reconstruction; learning; nervous system; algorithm; human; image processing; procedures; signal noise ratio; x-ray computed tomography; Image reconstruction","European Union’s Horizon 2020 Frame-work Programme; H2020-ERC; National Institute of Biomedical Imaging and Bioengineering, NIBIB; Mayo Clinic; Nvidia; American Association of Physicists in Medicine, AAPM; Canadian Light Source, CLS; Horizon 2020 Framework Programme, H2020, (665667, 692726); European Research Council, ERC; Paul Scherrer Institut, PSI","Institute of Electrical and Electronics Engineers Inc.","29870372","2-s2.0-85046484652"
"Liu C.; Wu S.; Wu S.; Wang Z.; Xiao K.","Liu, Chang (57157480800); Wu, Shaozhi (35172143800); Wu, Su (57208176651); Wang, Ziheng (57208178955); Xiao, Kai (55129739300)","57157480800; 35172143800; 57208176651; 57208178955; 55129739300","Reliable Automatic Organ Segmentation from CT Images using Deep CNN","","","8859477","368","374","6","10.1109/QRS-C.2019.00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073881185&doi=10.1109%2fQRS-C.2019.00075&partnerID=40&md5=70cd0096e99cb72ccc03fbec851b9a78","In the field of biomedical image analysis, segmentation is critical for disease diagnosis and treatment planning. While manual segmentation is tedious, time consuming and subjective due to the large shape and appearance variance among different subject, accurate and reliable segmentation is very challenging for automatic segmentation methods at the same time. In this paper, we present our recent effort on developing a reliable segmentation algorithm in the form of a convolutional neural network. Our network architecture is inspired by the popular U-Net and its variation (3D U-Net) and has been carefully modified to maximize bladder and rectum segmentation performance. We transfer our data to four channels to augment the data and prevent overfitting. The Dice similarity coefficient (DSC) is used to evaluate the network's performance. The outcome of experiments demonstrates the superiority of the proposed method. © 2019 IEEE.","CNN; CT; deep learning; Dice similarity coefficient; segmentation","C (programming language); Computer software selection and evaluation; Computerized tomography; Deep learning; Diagnosis; Network architecture; Neural networks; Software reliability; Automatic segmentations; Biomedical image analysis; Convolutional neural network; Manual segmentation; Organ segmentation; Segmentation algorithms; Segmentation performance; Similarity coefficients; Image segmentation","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85073881185"
"Guo N.; Bai Z.","Guo, Ning (58966932800); Bai, Zhengyao (23388661700)","58966932800; 23388661700","The integration of attention mechanism and dense atrous convolution for lung image segmentation; [注意力机制下密集空洞卷积的肺部图像分割]","26","9","","2146","2155","9","10.11834/jig.200429","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115214474&doi=10.11834%2fjig.200429&partnerID=40&md5=448243ac44323510cf898d7e1dfe3628","Objective: As an important criterion for the diagnosis of early-stage lung cancer, chest computed tomography (CT) images-based pulmonary nodules detection have been implemented via location observation, scope and shape of the lesions. The CT image has been analyzed lung organizational structures like the lung parenchyma and the contextual part, such as hydrops, trachea, bronchus, and ribs. CT images-based lung parenchyma has been hard to interpret automatically and precisely. The precise extraction of lung parenchyma has played a vital role in lung-based diseases analyses. Most of lung segmentation have been conducted based on regular image processing algorithms like threshold or morphological operation. The convolutional neural networks (CNNs) have been used in computerized pulmonary disease analysis. CNN-driven lung segmentation algorithms have been adopted in computer-aided diagnosis (CAD). The U-shape structure has been designed for medical image segmentation based on end-to-end fully convolutional network (FCN) structure. The credibility for biomedical image segmentations have been realized based on the encoding and decoding symmetric network structure. A novel convolutional neural network based on U-Net architecture has been illustrated via integrating attention mechanism and dense atrous convolution (DAC). Method: The network has contained an encoder and a decoder. The encoder has consisted of convolution and down sampling. The deductible spatial dimension of feature maps have been used to learn more semantic information. And the attention mechanism decoder has been implemented for de-convolution and up-sampling to re-configure the spatial dimension of the feature maps. The decoding mode using attention mechanism has been manipulated to make the target area output more effectively. Meanwhile, the algorithm of lung image segmentation has been used to identify the target-oriented neural network's attention using transmitted skip-connection to improve the weight of the salient feature. The feature resolution capability has been enhanced to the requirements for intensive spatial prediction via pooling consecutive operations and convolution striding. The DAC block has been deployed between the encoder and the decoder to extract multi-scale information of the context sufficiently. The advantages of Inception, ResNet and atrous convolution for the block have been inherited to capture multi-sized features consequently. The max-pooling and up-sampling operators have been utilized to reduce and increase the resolution of feature maps intensively based on the classic U-Net framework, which could lead to feature loss and accuracy reduced problems during training. The original max-pooling and up-sampling operators have been replaced via down-sample and up-sample block with inception structure to widen the multi-filters network and avoid feature loss. The Dice coefficient loss function has been used instead of the cross entropy loss to identify the gap between prediction and ground-truth. The deep learning framework Pytorch have been used on a server with two NVIDIA GeForce RTX 2080Ti graphics cards and each GPU has 11 Gigabyte memory. At the experimental stage, the original images have been resized to 256×256 pixels and 80% of these for training besides the test remaining. The proposed model has been trained for 120 epochs. Based on an initial learning rate of 0.000 1, the Adam has been opted as the optimization algorithm. Result: In order to verify the efficiency of the proposed method, we conduct multi-compatible verifications called FCN-8 s, U-Net, UNet++, ResU-Net and CE-Net (context encoder network) have been conducted. Four segmentation metrics have been adopted to assess the segmentation. These metrics has evolved the Dice similarity coefficient (DSC), the intersection over union (IoU), sensitivity (SE) and accuracy (ACC). The experimental results on the LUNA16 dataset have demonstrated the priorities in terms of all metrics results. The average Dice similarity coefficient has reached 0.985 9, which has 0.443% higher than the segmentation results of the second-performing CE-Net. The model consequence has achieved 0.972 2, 0.993 8, and 0.982 2 each in terms of IoU, ACC and SE. This second qualified segmentation performance has reached: 0.272%, 0.512% and 0.374% each (more better). Compared with other algorithms, the predictable results of modeling has closer to the label made. The adhesive difficulties on the left and right lung cohesion issue have been resolved well. Conclusion: An encoded/decoded structure in novel convolutional neural network has been integrated via attention mechanism and dense atrous convolution for lungs segmentation. The experiment results have illustrated that the qualified and effective framework for segmenting the lung parenchyma area have its own priority. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.","Attention mechanism; Computer-aided diagnosis(CAD); Convolutional neural networks(CNN); Dense atrous convolution(DAC); Lung segmentation","","","Editorial and Publishing Board of JIG","","2-s2.0-85115214474"
"Sharma A.; Kumar R.","Sharma, Ajay (57210974822); Kumar, Raj (57217189034)","57210974822; 57217189034","Recent Advancement and Challenges in Deep Learning, Big Data in Bioinformatics","105","","","251","284","33","10.1007/978-3-030-95419-2_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127835715&doi=10.1007%2f978-3-030-95419-2_12&partnerID=40&md5=fb261fefcffcf2e94b989f3ecd06ceda","More data have been produced in recent years than in the thousands of years of human history. This data represents an important gold mine for policymakers in terms of commercial value and reference material. But much of this value is untapped, worse, wrongly comprehended as long as it is impossible to use the tools needed to process the stunning amount of information. In this book chapter, we will examine how machine learning can give us a glimpse of the patterns in Big Data and obtain key information in all fields of biology, healthcare. An analysis, ineffectiveness storage, and depth of learning algorithms in this field are essential to the electronic equipment which generates an anonymous scale of data referring to diversity and veracity. The architecture of Hadoop-based maps and deep learning algorithms like Convolutional Neural Network, Recurrent Neural Network have transformed the way we analyze massive data. The role, impact, and prospect of deep learning algorithms, reinforcement learning to manage big data in the area of bioinformatics, computer aided drug design, structural biology and computational biology are discussed in this book chapter. In last section author has discussed about the role of deep learning in next generation sequencing, biomedical image processing and drug discovery and molecular modelling and dynamics studies. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Big Data; Bioinformatics; Convolutional neural network (CNN); Deep learning; Drug design; Hadoop; Healthcare; Map-reduce; Reinforcement learning; Structural biology","Bioinformatics; Convolution; Convolutional neural networks; Deep neural networks; Digital storage; Health care; Image processing; Information management; Learning algorithms; Oscillators (electronic); Recurrent neural networks; Reinforcement learning; Amount of information; Convolutional neural network; Deep learning; Drug Design; Hadoop; Map-reduce; Policy makers; Reference material; Structural biology; Big data","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85127835715"
"Kermany D.S.; Goldbaum M.; Cai W.; Valentim C.C.S.; Liang H.; Baxter S.L.; McKeown A.; Yang G.; Wu X.; Yan F.; Dong J.; Prasadha M.K.; Pei J.; Ting M.; Zhu J.; Li C.; Hewett S.; Dong J.; Ziyar I.; Shi A.; Zhang R.; Zheng L.; Hou R.; Shi W.; Fu X.; Duan Y.; Huu V.A.N.; Wen C.; Zhang E.D.; Zhang C.L.; Li O.; Wang X.; Singer M.A.; Sun X.; Xu J.; Tafreshi A.; Lewis M.A.; Xia H.; Zhang K.","Kermany, Daniel S. (57193116279); Goldbaum, Michael (7005893154); Cai, Wenjia (57196088938); Valentim, Carolina C.S. (57200758379); Liang, Huiying (35334583200); Baxter, Sally L. (57200760006); McKeown, Alex (55880755400); Yang, Ge (57200758769); Wu, Xiaokang (57200754293); Yan, Fangbing (57200756883); Dong, Justin (57200757776); Prasadha, Made K. (57200757714); Pei, Jacqueline (55913141300); Ting, Magdalena (57195422417); Zhu, Jie (56297070000); Li, Christina (57200752315); Hewett, Sierra (57211733435); Dong, Jason (57200757774); Ziyar, Ian (57200761977); Shi, Alexander (57200750760); Zhang, Runze (57194446671); Zheng, Lianghong (56828486500); Hou, Rui (59032425700); Shi, William (56888195600); Fu, Xin (58832881500); Duan, Yaou (55331946100); Huu, Viet A.N. (56473600000); Wen, Cindy (55913674200); Zhang, Edward D. (57194448343); Zhang, Charlotte L. (57202885027); Li, Oulan (7003521973); Wang, Xiaobo (57221484941); Singer, Michael A. (54915646600); Sun, Xiaodong (23482893500); Xu, Jie (58009380800); Tafreshi, Ali (59026773600); Lewis, M. Anthony (57224603791); Xia, Huimin (56533028500); Zhang, Kang (56418957000)","57193116279; 7005893154; 57196088938; 57200758379; 35334583200; 57200760006; 55880755400; 57200758769; 57200754293; 57200756883; 57200757776; 57200757714; 55913141300; 57195422417; 56297070000; 57200752315; 57211733435; 57200757774; 57200761977; 57200750760; 57194446671; 56828486500; 59032425700; 56888195600; 58832881500; 55331946100; 56473600000; 55913674200; 57194448343; 57202885027; 7003521973; 57221484941; 54915646600; 23482893500; 58009380800; 59026773600; 57224603791; 56533028500; 56418957000","Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning","172","5","","1122","1131.e9","","10.1016/j.cell.2018.02.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042389905&doi=10.1016%2fj.cell.2018.02.010&partnerID=40&md5=e83d2ef0a11cfa54b6663a859ef708fe","The implementation of clinical-decision support algorithms for medical imaging faces challenges with reliability and interpretability. Here, we establish a diagnostic tool based on a deep-learning framework for the screening of patients with common treatable blinding retinal diseases. Our framework utilizes transfer learning, which trains a neural network with a fraction of the data of conventional approaches. Applying this approach to a dataset of optical coherence tomography images, we demonstrate performance comparable to that of human experts in classifying age-related macular degeneration and diabetic macular edema. We also provide a more transparent and interpretable diagnosis by highlighting the regions recognized by the neural network. We further demonstrate the general applicability of our AI system for diagnosis of pediatric pneumonia using chest X-ray images. This tool may ultimately aid in expediting the diagnosis and referral of these treatable conditions, thereby facilitating earlier treatment, resulting in improved clinical outcomes. Video Abstract: [Figure presented] Image-based deep learning classifies macular degeneration and diabetic retinopathy using retinal optical coherence tomography images and has potential for generalized applications in biomedical image interpretation and medical decision making. © 2018 Elsevier Inc.","age-related macular degeneration; artificial intelligence; choroidal neovascularization; deep learning; diabetic macular edema; diabetic retinopathy; optical coherence tomography; pneumonia; screening; transfer learning","Child; Deep Learning; Diagnostic Imaging; Humans; Neural Networks (Computer); Pneumonia; Reproducibility of Results; ROC Curve; Tomography, Optical Coherence; Article; artificial intelligence; bacterial pneumonia; bacterium detection; clinical outcome; comparative effectiveness; diabetic macular edema; diabetic retinopathy; diagnostic accuracy; diagnostic imaging; drusen; learning algorithm; macular degeneration; medical decision making; nerve cell network; optical coherence tomography; pathology; pneumonia; priority journal; retina disease; subretinal neovascularization; thorax radiography; virus pneumonia; artificial neural network; child; human; pneumonia; receiver operating characteristic; reproducibility","Dick and Carol Hertzberg Fund; Guangzhou Women and Children’s Medical Center; Michael Martin Fund; Richard Annesser Fund; National Natural Science Foundation of China, NSFC, (81700882, 81771629); National Natural Science Foundation of China, NSFC; National Key Research and Development Program of China, NKRDPC, (2017YFC1104600); National Key Research and Development Program of China, NKRDPC; Guangzhou Regenerative Medicine and Health Guangdong Laboratory, GRMH-GDL","Cell Press","29474911","2-s2.0-85042389905"
"Pelka O.; Friedrich C.M.; Seco de Herrera A.G.; Müller H.","Pelka, Obioma (57190736323); Friedrich, Christoph M. (35232936500); Seco de Herrera, Alba G. (57348565300); Müller, Henning (8501863000)","57190736323; 35232936500; 57348565300; 8501863000","Overview of the ImageCLEFmed 2020 Concept Prediction Task: Medical Image Understanding","2696","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121819918&partnerID=40&md5=70f5ae79f59c26b2d08e01a59db04cf5","This paper describes the ImageCLEFmed 2020 Concept Detection Task. After first being proposed at ImageCLEF 2017, the medical task is in its 4th edition this year, as the automatic detection from medical images still remains a challenging task. In 2020, the format remained the same as in 2019, with a single sub-task. The concept detection task is part of the medical tasks, alongside the tuberculosis and visual question and answering tasks. Similar to the 2019 edition, the data set focuses on radiology images rather than biomedical images, however with an increased number of images. The distributed images were extracted from the biomedical open access literature (PubMed Central). The development data consists of 65,753 training and 15,970 validation images. Each image has corresponding Unified Medical Language System (UMLS™) concepts, that were extracted from the original article image captions. In this edition, additional imaging acquisition technique labels were included in the distributed data, which were adopted for pre-filtering steps, concept selection and ensemble algorithms. Most applied approaches for the automatic detection of concepts were deep learning based architectures. Long short-term memory (LSTM) recurrent neural networks (RNN), adversarial auto-encoder, convolutional neural networks (CNN) image encoders and transfer learning-based multi-label classification models were adopted. The performances of the submitted models (best score 0.3940) were evaluated using F1-scores computed per image and averaged across all 3,534 test images. Copyright © 2020 for this paper by its authors.","Computer vision; Concept detection; Image modality; Image understanding; ImageCLEF 2020; Radiology","Classification (of information); Computer vision; Image understanding; Long short-term memory; Medical imaging; Radiation; Signal encoding; Automatic Detection; Concept detection; Data set; Detection tasks; Image modality; ImageCLEF; ImageCLEF 2020; Medical image understanding; Prediction tasks; Subtask; Radiology","","CEUR-WS","","2-s2.0-85121819918"
"Alsaade F.W.; Alzahrani M.S.","Alsaade, Fawaz Waselallah (22937047900); Alzahrani, Mohammed Saeed (57483011800)","22937047900; 57483011800","Classification and Detection of Autism Spectrum Disorder Based on Deep Learning Algorithms","2022","","8709145","","","","10.1155/2022/8709145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126076335&doi=10.1155%2f2022%2f8709145&partnerID=40&md5=8c4de86b15f3a2ce9a831dd6f8e79852","Autism spectrum disorder (ASD) is a type of mental illness that can be detected by using social media data and biomedical images. Autism spectrum disorder (ASD) is a neurological disease correlated with brain growth that later impacts the physical impression of the face. Children with ASD have dissimilar facial landmarks, which set them noticeably apart from typically developed (TD) children. Novelty of the proposed research is to design a system that is based on autism spectrum disorder detection on social media and face recognition. To identify such landmarks, deep learning techniques may be used, but they require a precise technology for extracting and producing the proper patterns of the face features. This study assists communities and psychiatrists in experimentally detecting autism based on facial features, by using an uncomplicated web application based on a deep learning system, that is, a convolutional neural network with transfer learning and the flask framework. Xception, Visual Geometry Group Network (VGG19), and NASNETMobile are the pretrained models that were used for the classification task. The dataset that was used to test these models was collected from the Kaggle platform and consisted of 2,940 face images. Standard evaluation metrics such as accuracy, specificity, and sensitivity were used to evaluate the results of the three deep learning models. The Xception model achieved the highest accuracy result of 91%, followed by VGG19 (80%) and NASNETMobile (78%). © 2022 Fawaz Waselallah Alsaade and Mohammed Saeed Alzahrani.","","Algorithms; Autism Spectrum Disorder; Brain; Child; Deep Learning; Humans; Neural Networks, Computer; Convolutional neural networks; Deep learning; Face recognition; Learning algorithms; Social networking (online); Statistical tests; Autism spectrum disorders; Biomedical images; Children with autisms; Data images; Facial landmark; Learning techniques; Mental illness; Neurological disease; Social media; Social media datum; algorithm; autism; brain; child; human; Diseases","","Hindawi Limited","35265118","2-s2.0-85126076335"
"Ashok M.; Gupta A.","Ashok, Malvika (57219146342); Gupta, Abhishek (55430473100)","57219146342; 55430473100","Comparative Study of TRANS - GAN Architecture for Bio-Medical Image Semantic Segmentation","","","","1564","1570","6","10.1109/ICCES54183.2022.9835992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136319840&doi=10.1109%2fICCES54183.2022.9835992&partnerID=40&md5=dbf693663a1d3e649cd47a4e7a57e494","In the area of biomedical image processing, medical image segmentation plays a crucial role. Today due to the deep sculptures of deep neural networks and innovative by-passes like the Transformers this field has rejuvenated. This paper analyzes various algorithmic advancements regarding Transformers and Generative Adversarial Networks (GAN) which have paved the anatomy of image segmentation. The GAN network is not only able to regenerate feature spaces but also can transpose the inputs from the transformer. These algorithms are not only at par with the bifurcation of networks like U-net and ResNet but showcase a strong and more intuitive idea of human neural intelligence. Finally, all methods are compared based on accuracy, dice score, architectural evaluation, etc. The ability of these networks are deduced to regenerate and recreate the feature spaces for the given input image and thus can segment high features for prediction.  © 2022 IEEE.","Automatic segmentation; Bio-Medical Imaging; CT segmentation; Deep learning; Generative Adversarial Networks Convolutional Neural Network; Medical modalities; Supervised and Unsupervised Transformers; Traditional Architecture; Transformers","Computerized tomography; Convolutional neural networks; Deep neural networks; Medical imaging; Network architecture; Semantic Segmentation; Semantics; Automatic segmentations; Bio-medical; Bio-medical imaging; Convolutional neural network; CT segmentation; Deep learning; Generative adversarial network convolutional neural network; Medical modality; Supervised and unsupervised transformer; Traditional architecture; Transformer; Generative adversarial networks","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85136319840"
"Gao Y.; Zhang Y.; Jiang X.","Gao, Yalan (57218452855); Zhang, Yanqiong (57205725582); Jiang, Xianwei (57211990320)","57218452855; 57205725582; 57211990320","An Optimized Convolutional Neural Network with Combination Blocks for Chinese Sign Language Identification","132","1","","95","117","22","10.32604/cmes.2022.019970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138463147&doi=10.32604%2fcmes.2022.019970&partnerID=40&md5=dbf1db6cfa369b745c128c141ccd9992","(Aim) Chinese sign language is an essential tool for hearing-impaired to live, learn and communicate in deaf communities. Moreover, Chinese sign language plays a significant role in speech therapy and rehabilitation. Chinese sign language identification can provide convenience for those hearing impaired people and eliminate the communication barrier between the deaf community and the rest of society. Similar to the research of many biomedical image processing (such as automatic chest radiograph processing, diagnosis of chest radiological images, etc.), with the rapid development of artificial intelligence, especially deep learning technologies and algorithms, sign language image recognition ushered in the spring. This study aims to propose a novel sign language image recognition method based on an optimized convolutional neural network. (Method) Three different combinations of blocks: Conv-BN-ReLU-Pooling, Conv-BN-ReLU, Conv-BN-ReLU-BN were employed, including some advanced technologies such as batch normalization, dropout, and Leaky ReLU. We proposed an optimized convolutional neural network to identify 1320 sign language images, which was called as CNN-CB method. Totally ten runs were implemented with the hold-out randomly set for each run. (Results) The results indicate that our CNN-CB method gained an overall accuracy of 94.88 ± 0.99%. (Conclusion) Our CNN-CB method is superior to thirteen state-of-the-art methods: eight traditional machine learning approaches and five modern convolutional neural network approaches. © 2022 Tech Science Press. All rights reserved.","batch normalization; Chinese sign language; combination blocks; Convolutional neural network; dropout; Leaky ReLU; M-fold cross-validation","Audition; Bioinformatics; Convolution; Deep learning; Image processing; Image recognition; Learning systems; Natural language processing systems; Batch normalization; Chinese sign language; Combination block; Convolutional neural network; Cross validation; Dropout; Leaky ReLU; M-fold cross-validation; Normalisation; Sign language image; Convolutional neural networks","WITH Foundation, (20BTQ065); Philosophy and Social Science Foundation of Hunan Province","Tech Science Press","","2-s2.0-85138463147"
"Seum A.; Raj A.H.; Sakib S.; Hossain T.","Seum, Ashek (57223048161); Raj, Amir Hossain (57223044264); Sakib, Shadman (56296982100); Hossain, Tonmoy (57208082515)","57223048161; 57223044264; 56296982100; 57208082515","A comparative study of CNN transfer learning classification algorithms with segmentation for COVID-19 detection from CT scan images","","","9393129","234","237","3","10.1109/ICECE51571.2020.9393129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104673230&doi=10.1109%2fICECE51571.2020.9393129&partnerID=40&md5=3297d86c230010e2d5eedfee1fc208f6","After it's inception, COVID-19 has spread rapidly all across the globe. Considering this outbreak, by far, it is the most decisive task to detect early and isolate the patients quickly to contain the spread of this virus. In such cases, artificial intelligence and machine learning or deep learning methods can come to aid. For that purpose, we have conducted a qualitative investigation to inspect 12 off-the-shelf Convolution Neural Network (CNN) architectures in classifying COVID-19 from CT scan images. Furthermore, a segmentation algorithm for biomedical images - U-Net, is analyzed to evaluate the performance of the CNN models. A publicly available dataset (SARS-COV-2 CT-Scan) containing a total of 2481 CT scan images is employed for the performance evaluation. In terms of feature extraction by excluding the segmentation technique, a performance of 88.60% as the F1 Score and 89.31% as accuracy is achieved by training DenseNet169 architecture. Adopting the U-Net segmentation method, we accomplished the most optimal accuracy and F1 Scores as 89.92% and 89.67% respectively on DenseNet201 model. Furthermore, evaluating the performances, we can affirm that a combination of a Transfer Learning architecture with a segmentation technique (U-Net) enhances the performance of the classification model. © 2020 IEEE.","CNN; COVID-19; CT scan; DenseNet; Transfer learning; U-Net","Bioinformatics; Deep learning; Diseases; Image classification; Image segmentation; Learning algorithms; Learning systems; Network architecture; Transfer learning; Classification algorithm; Classification models; Comparative studies; Convolution neural network; Learning architectures; Segmentation algorithms; Segmentation methods; Segmentation techniques; Computerized tomography","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85104673230"
"Wang L.; Wang S.; Chen R.; Qu X.; Chen Y.; Huang S.; Liu C.","Wang, Liansheng (36740418500); Wang, Shuxin (57208402040); Chen, Rongzhen (57189524400); Qu, Xiaobo (22958150800); Chen, Yiping (56233739200); Huang, Shaohui (55851000700); Liu, Changhua (57092307400)","36740418500; 57208402040; 57189524400; 22958150800; 56233739200; 55851000700; 57092307400","Nested dilation networks for brain tumor segmentation based on magnetic resonance imaging","13","APR","285","","","","10.3389/fnins.2019.00285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068225715&doi=10.3389%2ffnins.2019.00285&partnerID=40&md5=d457c3b5142be4b8c5426545da71ad93","Aim: Brain tumors are among the most fatal cancers worldwide. Diagnosing and manually segmenting tumors are time-consuming clinical tasks, and success strongly depends on the doctor's experience. Automatic quantitative analysis and accurate segmentation of brain tumors are greatly needed for cancer diagnosis. Methods:This paper presents an advanced three-dimensional multimodal segmentation algorithm called nested dilation networks (NDNs). It is inspired by the U-Net architecture, a convolutional neural network (CNN) developed for biomedical image segmentation and is modified to achieve better performance for brain tumor segmentation. Thus, we propose residual blocks nested with dilations (RnD) in the encoding part to enrich the low-level features and use squeeze-and-excitation (SE) blocks in both the encoding and decoding parts to boost significant features. To prove the reliability of the network structure, we compare our results with those of the standard U-Net and its transmutation networks. Different loss functions are considered to cope with class imbalance problems to maximize the brain tumor segmentation results. A cascade training strategy is employed to run NDNs for coarse-to-fine tumor segmentation. This strategy decomposes the multiclass segmentation problem into three binary segmentation problems and trains each task sequentially. Various augmentation techniques are utilized to increase the diversity of the data to avoid overfitting. Results: This approach achieves Dice similarity scores of 0.6652, 0.5880, and 0.6682 for edema, non-enhancing tumors, and enhancing tumors, respectively, in which the Dice loss is used for single-pass training. After cascade training, the Dice similarity scores rise to 0.7043, 0.5889, and 0.7206, respectively. Conclusion: Experiments show that the proposed deep learning algorithm outperforms other U-Net transmutation networks for brain tumor segmentation. Moreover, applying cascade training to NDNs facilitates better performance than other methods. The findings of this study provide considerable insight into the automatic and accurate segmentation of brain tumors. Copyright © 2019 Wang, Wang, Chen, Qu, Chen, Huang and Liu. This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.","Brain tumor segmentation; Coarse-to-fine; Nested dilation networks; Residual blocks nested with dilations; Squeeze-and-excitation blocks","Article; artificial neural network; brain edema; brain tumor; deep learning; diagnostic accuracy; diagnostic value; glioma; human; image processing; image segmentation; information processing; intermethod comparison; learning algorithm; multimodal imaging; nested dilation network; neuroimaging; nuclear magnetic resonance imaging; three dimensional imaging; tumor diagnosis","Dominant Disciplines’ Talent Team Development Scheme of Higher Education of Shandong Province; Scientific Research Foundation of Binzhou Medical University, (BY2016KYQD01); Taishan Scholars Construction Engineering of Shandong Province; Yantai High-End Talent Introduction Plan; National Natural Science Foundation of China, NSFC, (31870338, 61571380, 61601392, 61671399, 81602556, 81872162); Natural Science Foundation of Shandong Province, (ZR2017JL030); National Basic Research Program of China (973 Program), (2017YFC0108703); Fundamental Research Funds for the Central Universities, (20720180056)","Frontiers Media S.A.","","2-s2.0-85068225715"
"Liu X.; Song L.; Liu S.; Zhang Y.","Liu, Xiangbin (15077163000); Song, Liping (57221765586); Liu, Shuai (56434677500); Zhang, Yudong (35786830100)","15077163000; 57221765586; 56434677500; 35786830100","A review of deep-learning-based medical image segmentation methods","13","3","1224","1","29","28","10.3390/su13031224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100085131&doi=10.3390%2fsu13031224&partnerID=40&md5=14135b26ced230c5cdc28001ad7dd3eb","As an emerging biomedical image processing technology, medical image segmentation has made great contributions to sustainable medical care. Now it has become an important research direction in the field of computer vision. With the rapid development of deep learning, medical image processing based on deep convolutional neural networks has become a research hotspot. This paper focuses on the research of medical image segmentation based on deep learning. First, the basic ideas and characteristics of medical image segmentation based on deep learning are introduced. By explaining its research status and summarizing the three main methods of medical image segmentation and their own limitations, the future development direction is expanded. Based on the discussion of different pathological tissues and organs, the specificity between them and their classic segmentation algorithms are summarized. Despite the great achievements of medical image segmentation in recent years, medical image segmentation based on deep learning has still encountered difficulties in research. For example, the segmentation accuracy is not high, the number of medical images in the data set is small and the resolution is low. The inaccurate segmentation results are unable to meet the actual clinical requirements. Aiming at the above problems, a comprehensive review of current medical image segmentation methods based on deep learning is provided to help researchers solve existing problems. © 2021 by the authors.","Convolutional neural network; Deep learning; Image segmentation; Medical image","accuracy assessment; algorithm; artificial neural network; computer vision; image processing; image resolution; numerical method; segmentation","Scientific Research Fund of Hunan Provincial Education, (14C0710); Natural Science Foundation of Hunan Province, (2020JJ4434); Education Department of Henan Province, (19A312); Science and Technology Program of Hunan Province, (2018RS3065, 2018TP1018)","MDPI","","2-s2.0-85100085131"
"Seo H.; Badiei Khuzani M.; Vasudevan V.; Huang C.; Ren H.; Xiao R.; Jia X.; Xing L.","Seo, Hyunseok (56125023000); Badiei Khuzani, Masoud (55390716200); Vasudevan, Varun (57209329840); Huang, Charles (55890598500); Ren, Hongyi (57215971063); Xiao, Ruoxiu (57212428138); Jia, Xiao (57192916619); Xing, Lei (7103349003)","56125023000; 55390716200; 57209329840; 55890598500; 57215971063; 57212428138; 57192916619; 7103349003","Machine learning techniques for biomedical image segmentation: An overview of technical aspects and introduction to state-of-art applications","47","5","","e148","e167","19","10.1002/mp.13649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084860873&doi=10.1002%2fmp.13649&partnerID=40&md5=349f96d644e266fdafe4e9e0a0995596","In recent years, significant progress has been made in developing more accurate and efficient machine learning algorithms for segmentation of medical and natural images. In this review article, we highlight the imperative role of machine learning algorithms in enabling efficient and accurate segmentation in the field of medical imaging. We specifically focus on several key studies pertaining to the application of machine learning methods to biomedical image segmentation. We review classical machine learning algorithms such as Markov random fields, k-means clustering, random forest, etc. Although such classical learning models are often less accurate compared to the deep-learning techniques, they are often more sample efficient and have a less complex structure. We also review different deep-learning architectures, such as the artificial neural networks (ANNs), the convolutional neural networks (CNNs), and the recurrent neural networks (RNNs), and present the segmentation results attained by those learning models that were published in the past 3 yr. We highlight the successes and limitations of each machine learning paradigm. In addition, we discuss several challenges related to the training of different machine learning models, and we present some heuristics to address those challenges. © 2019 American Association of Physicists in Medicine","deep learning; machine learning; medical Image; overview; segmentation","Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Decision trees; Image segmentation; K-means clustering; Learning algorithms; Markov processes; Medical imaging; Biomedical image segmentation; Deep learning; Learning models; Machine learning algorithms; Machine learning techniques; Machine-learning; Medical image; Overview; Segmentation; Technical aspects; conference paper; controlled study; convolutional neural network; deep learning; diagnostic imaging; heuristics; image segmentation; k means clustering; Markov random field; random forest; recurrent neural network; diagnostic imaging; human; image processing; machine learning; procedures; Recurrent neural networks","National Institutes of Health, NIH; National Cancer Institute, NCI, (R01CA176553); National Cancer Institute, NCI; Google; Varian Medical Systems","John Wiley and Sons Ltd","32418337","2-s2.0-85084860873"
"Topiwala A.; Al-Zogbi L.; Fleiter T.; Krieger A.","Topiwala, Anirudh (57215272056); Al-Zogbi, Lidia (57209216829); Fleiter, Thorsten (6701460715); Krieger, Axel (57201238593)","57215272056; 57209216829; 6701460715; 57201238593","Adaptation and evaluation of deep learning techniques for skin segmentation on novel abdominal dataset","","","8941944","752","759","7","10.1109/BIBE.2019.00141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078574668&doi=10.1109%2fBIBE.2019.00141&partnerID=40&md5=7bc1b5319e4fee368fb934229d6ef1ce","Skin segmentation plays an important role in a wide variety of biomedical image processing applications, such as skin cancer identification, skin lesion detection, and wound isolation. However, contemporary research has been mainly based on facial and hand skin datasets, with no other body regions considered for skin pixels sampling. Segmenting skin specifically in the abdominal region can aid in robotic abdominal surgeries and treatment procedures, such as robot-assisted laparoscopic surgeries and abdominal ultrasounds. A robust and highly accurate abdominal skin detection technique thus becomes imperative. To this end, we compiled a novel dataset of 1,400 segmented abdominal pictures and adapted and compared four abdominal skin segmentation techniques: one based on thresholding and three deep learning techniques, namely a fully connected neural network for pixel-level classification, and two convolution-based networks, U-Net and Mask-RCNN. We show that the U-Net model outperforms the other segmentation techniques, resulting in a pixel-to-pixel mean cross-validation accuracy of 95.51% on our Abdominal dataset. The incorporation of the Abdominal dataset in the training helped improve the abdominal skin segmentation accuracy by 10.19%. The U-Net model proved to be computationally the fastest, enabling real time skin segmentation with a processing rate of 37 frames per second. © 2019 IEEE.","Deep Learning; Semantic Skin Dataset; Semantic Skin Segmentation","Bioinformatics; Classification (of information); Dermatology; Image segmentation; Learning algorithms; Object recognition; Pixels; Robotic surgery; Semantics; Surgery; Abdominal surgery; Biomedical images; Frames per seconds; Fully connected neural network; Laparoscopic surgery; Learning techniques; Segmentation techniques; Skin segmentation; Deep learning","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85078574668"
"Ahmed I.; Balestrieri E.; Carni D.L.; Lamonaca F.","Ahmed, Imran (58833622300); Balestrieri, Eulalia (8105381900); Carni, Domenico Luca (6603245529); Lamonaca, Francesco (21933997900)","58833622300; 8105381900; 6603245529; 21933997900","Comparison of U -NET backbones for morphometric measurements of white blood cell","","","","","","","10.1109/MeMeA54994.2022.9856479","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137890022&doi=10.1109%2fMeMeA54994.2022.9856479&partnerID=40&md5=1ff791e8664687a79a450099fc64f552","Measurements of Morphometric Parameters of Blood Cells (MPBC) playa key role in haematological examination, and it is considered as one of the principal needs for clinicians in the diagnosis of various diseases in human and animals. Obliviously, the correctness of the diagnosis, and, as a consequence, the effectiveness of clinician actions is highly dependent on the accuracy of MPBC measurements. In this context, deep learning based MPBC measurement systems are a promising solution. In recent studies, researchers have applied semantic segmentation with various backbone networks for white blood cell measurements. Vice versa, few investigations were done about the achieved accuracy. Indeed, accurate segmentation of white blood cell remains a challenging task because of the complex nature of cell images, staining techniques, and imaging conditions which strongly affects the accuracy of the MPBC measurements. This paper presents a comparison among the segmentation performance carried out by U-Net deep learning algorithm with different backbones typically used for MPBC. The goal is to make a first step towards a whole MPBC measurement system capable of evaluating the effects of the influencing magnitudes, attenuate them (if possible), and evaluate the accuracy of the measurements. The aims are to increase measurement reliability and to give clinicians further information to take their decisions.  © 2022 IEEE.","backbone networks; biomedical image segmentation; convolution neural network; morphometric measurement of blood cells; U-Net; white blood cell size measurement","Blood; Cells; Cytology; Deep learning; Learning algorithms; Semantic Segmentation; Semantics; Back-bone network; Biomedical image segmentation; Blood cells; Cell-size; Convolution neural network; Measurements of; Morphometric measurement of blood cell; Morphometric measurements; Size measurements; U-net; White blood cell size measurement; White blood cells; Diagnosis","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85137890022"
"Li H.; Yin Z.","Li, Haohan (56352698800); Yin, Zhaozheng (36351279000)","56352698800; 36351279000","Attention, suggestion and annotation: A deep active learning framework for biomedical image segmentation","12261 LNCS","","","3","13","10","10.1007/978-3-030-59710-8_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093106221&doi=10.1007%2f978-3-030-59710-8_1&partnerID=40&md5=7ee6b521db4ef10095a9b800a9f75f32","Despite the great success, deep learning based segmentation methods still face a critical obstacle: the difficulty in acquiring sufficient training data due to high annotation costs. In this paper, we propose a deep active learning framework that combines the attention gated fully convolutional network (ag-FCN) and the distribution discrepancy based active learning algorithm (dd-AL) to significantly reduce the annotation effort by iteratively annotating the most informative samples to train the ag-FCN for the better segmentation performance. Our framework is evaluated on 2015 MICCAI Gland Segmentaion dataset and 2017 MICCAI 6-month infant brain MRI Segmentation dataset. Experiment results show that our framework can achieve state-of-the-art segmentation performance by using only a portion of the training data. © Springer Nature Switzerland AG 2020.","","Convolutional neural networks; Deep learning; Image annotation; Image segmentation; Iterative methods; Magnetic resonance imaging; Medical computing; Medical imaging; Active Learning; Active-learning algorithm; Biomedical image segmentation; Convolutional networks; Learning-based segmentation; Segmentation performance; State of the art; Training data; Learning algorithms","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85093106221"
"Toğaçar M.; Ergen B.; Cömert Z.","Toğaçar, Mesut (57205581917); Ergen, Burhan (6508022484); Cömert, Zafer (36543652400)","57205581917; 6508022484; 36543652400","Application of breast cancer diagnosis based on a combination of convolutional neural networks, ridge regression and linear discriminant analysis using invasive breast cancer images processed with autoencoders","135","","109503","","","","10.1016/j.mehy.2019.109503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075195028&doi=10.1016%2fj.mehy.2019.109503&partnerID=40&md5=58e8df55c2b555f9f2e258a668d99ec8","Invasive ductal carcinoma cancer, which invades the breast tissues by destroying the milk channels, is the most common type of breast cancer in women. Approximately, 80% of breast cancer patients have invasive ductal carcinoma and roughly 66.6% of these patients are older than 55 years. This situation points out a powerful relationship between the type of breast cancer and progressed woman age. In this study, the classification of invasive ductal carcinoma breast cancer is performed by using deep learning models, which is the sub-branch of artificial intelligence. In this scope, convolutional neural network models and the autoencoder network model are combined. In the experiment, the dataset was reconstructed by processing with the autoencoder model. The discriminative features obtained from convolutional neural network models were utilized. As a result, the most efficient features were determined by using the ridge regression method, and classification was performed using linear discriminant analysis. The best success rate of classification was achieved as 98.59%. Consequently, the proposed approach can be admitted as a successful model in the classification. © 2019 Elsevier Ltd","Autoencoder network; Biomedical image processing; Decision support; Deep learning; Feature selection; Invasive breast cancer","Algorithms; Artificial Intelligence; Breast Neoplasms; Carcinoma, Ductal, Breast; Diagnosis, Computer-Assisted; Discriminant Analysis; Female; Humans; Image Processing, Computer-Assisted; Linear Models; Machine Learning; Neoplasm Invasiveness; Neural Networks, Computer; Programming Languages; Reproducibility of Results; Sensitivity and Specificity; Software; adult; Article; artificial intelligence; autoencoder; breast carcinoma; cancer diagnosis; controlled study; convolutional neural network; deep learning; discriminant analysis; feature selection; female; human; human tissue; image processing; information processing; major clinical study; middle aged; tumor classification; algorithm; breast tumor; computer assisted diagnosis; computer language; discriminant analysis; image processing; machine learning; Paget nipple disease; procedures; reproducibility; sensitivity and specificity; software; statistical model; tumor invasion","","Churchill Livingstone","31760247","2-s2.0-85075195028"
"Dobratulin K.; Gaidel A.; Kapishnikov A.; Ivleva A.; Aupova I.; Zelter P.","Dobratulin, Konstantin (57219685346); Gaidel, Andrey (55652819400); Kapishnikov, Aleksandr (6507900025); Ivleva, Anna (57216846125); Aupova, Irina (57241900300); Zelter, Pavel (56512149200)","57219685346; 55652819400; 6507900025; 57216846125; 57241900300; 56512149200","The efficiency of deep learning algorithms for detecting anatomical reference points on radiological images of the head profile","","","9253067","","","","10.1109/ITNT49337.2020.9253067","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097611242&doi=10.1109%2fITNT49337.2020.9253067&partnerID=40&md5=e7b6e0cbb37d2c59bbf5d8be4b76d6f9","In this article we investigate the efficiency of deep learning algorithms in solving the task of detecting anatomical reference points on radiological images of the head in lateral projection using a fully convolutional neural network and a fully convolutional neural network with an extended architecture for biomedical image segmentation - U-Net. A comparison is made for the results of detection anatomical reference points for each of the selected neural network architectures and their comparison with the results obtained when orthodontists detected anatomical reference points. Based on the obtained results, it was concluded that a U-Net neural network allows performing the detection of anatomical reference points more accurately than a fully convolutional neural network. The results of the detection of anatomical reference points by the U-Net neural network are closer to the average results of the detection of reference points by agroupoforthodontists. © 2020 IEEE.","biomedical imagery; convolution neural networks; deep learning; image processing; localization; orthodontic; radiological images; radiology; u-net","Bioinformatics; Convolution; Convolutional neural networks; Deep learning; Efficiency; Image segmentation; Nanotechnology; Network architecture; Biomedical image segmentation; Radiological images; Reference points; Learning algorithms","RF Ministry of Science and Higher Education, (007-GZ/Ch3363/26); Russian Foundation for Basic Research, РФФИ, (18-07-01390, 19-29-01135, 19-29-01235)","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85097611242"
"Zhang W.; Li Z.; Sun Z.; Jia K.; Feng J.","Zhang, Wanlong (57561548600); Li, Zhe (57040021800); Sun, Zhonghua (56035911600); Jia, Kebin (8659887500); Feng, Jinchao (55990624400)","57561548600; 57040021800; 56035911600; 8659887500; 55990624400","A novelty convolutional neural network based direct reconstruction for MRI guided diffuse optical tomography","11952","","119520B","","","","10.1117/12.2606836","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129183459&doi=10.1117%2f12.2606836&partnerID=40&md5=cf7215310351b7ae79cd081de91e5689","Diffuse Optical Tomography (DOT) is a promising non-invasive and relatively low-cost biomedical image technology. The aim of DOT is to reconstruct optical properties of the tissue from boundary measurements. However, the DOT reconstruction is a severely ill-posed problem. To reduce the ill-posedness of DOT and to improve image quality, imageguided DOT has attracted more attention. In this paper, a reconstruction algorithm for DOT is proposed based on the convolutional neural network (CNN). It uses both optical measurements and magnetic resonance imaging (MRI) images as the input of the CNN, and directly reconstructs the distribution of absorption coefficient. The merits of the proposed algorithm are without segmenting MRI images and modeling light propagation. The performance of the proposed algorithm is evaluated using numerical simulation experiments. Our results reveal that the proposed method can achieve superior performance compared with conventional reconstruction algorithms and other deep learning methods. Our result shows that the average SSIM of reconstructed images is above 0.88, and the average PSNR is more than 35 dB.  © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","Convolutional neural network; Deep learning; Diffuse optical tomography; Image-guided reconstruction","Convolution; Convolutional neural networks; Deep learning; Image enhancement; Image reconstruction; Image segmentation; Optical data processing; Optical properties; Optical tomography; Biomedical images; Convolutional neural network; Deep learning; Diffuse optical tomography; Image-guided; Image-guided reconstruction; Low-costs; Network-based; Performance; Reconstruction algorithms; Magnetic resonance imaging","National Natural Science Foundation of China, NSFC, (82171992)","SPIE","","2-s2.0-85129183459"
"Pang S.; Du A.; Orgun M.A.; Yu Z.","Pang, Shuchao (55639762100); Du, Anan (56167972000); Orgun, Mehmet A. (6603681610); Yu, Zhezhou (8938987700)","55639762100; 56167972000; 6603681610; 8938987700","A novel fused convolutional neural network for biomedical image classification","57","1","","107","121","14","10.1007/s11517-018-1819-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049792899&doi=10.1007%2fs11517-018-1819-y&partnerID=40&md5=8ca3352a38bcbdb12e2a314503d6dec5","With the advent of biomedical imaging technology, the number of captured and stored biomedical images is rapidly increasing day by day in hospitals, imaging laboratories and biomedical institutions. Therefore, more robust biomedical image analysis technology is needed to meet the requirement of the diagnosis and classification of various kinds of diseases using biomedical images. However, the current biomedical image classification methods and general non-biomedical image classifiers cannot extract more compact biomedical image features or capture the tiny differences between similar images with different types of diseases from the same category. In this paper, we propose a novel fused convolutional neural network to develop a more accurate and highly efficient classifier for biomedical images, which combines shallow layer features and deep layer features from the proposed deep neural network architecture. In the analysis, it was observed that the shallow layers provided more detailed local features, which could distinguish different diseases in the same category, while the deep layers could convey more high-level semantic information used to classify the diseases among the various categories. A detailed comparison of our approach with traditional classification algorithms and popular deep classifiers across several public biomedical image datasets showed the superior performance of our proposed method for biomedical image classification. In addition, we also evaluated the performance of our method in modality classification of medical images using the ImageCLEFmed dataset. [Figure not available: see fulltext.]. © 2018, International Federation for Medical and Biological Engineering.","Biomedical image classification; Convolutional neural networks; Deep feature; Deep learning; Shallow feature","Bioinformatics; Classification (of information); Classifiers; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Medical imaging; Network architecture; Neural networks; Semantics; Biomedical image analysis; Biomedical imaging; Classification algorithm; Classification methods; Convolutional neural network; Deep feature; High level semantics; Shallow feature; Article; classification algorithm; convolutional neural network; digital imaging and communications in medicine; diseases; feature extraction; human; image analysis; intermethod comparison; k nearest neighbor; learning algorithm; machine learning; nuclear magnetic resonance imaging; priority journal; support vector machine; Image classification","","Springer Verlag","","2-s2.0-85049792899"
"Habib G.; Qureshi S.","Habib, Gousia (57221589277); Qureshi, Shaima (26325864200)","57221589277; 26325864200","Biomedical Image Classification using CNN by Exploiting Deep Domain Transfer Learning","10","1","","1075","1083","8","10.12785/ijcds/100197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122768002&doi=10.12785%2fijcds%2f100197&partnerID=40&md5=f3f6430ee3623ef8a7289af25c067020","Accurate biomedical image classification is essential for the clinical investigation of different hazardous maladies. A fair diagnosis of the disease is essential to provide proper treatment and to save precious human lives. Classification methods that support handcrafted features and use artificial neural networks trained with restricted data-set cannot viably enhance the precision rate and meet the stipulations for classification of biomedical images End-to-End deep learning machines empowers direct mapping from crude information to the desired output, eliminating the need for handcrafted features. Deep learning has proven as a powerful classification method as evidenced by its success in recent computer vision competitions. A unique deep convolutional neural network (CNN) model for brain tumor classification has been proposed in this paper. The model tested on the OASIS MRI data-set and gives an average accuracy of 90:84%. The present model is based on a pre- trained vgg-19 model on a large Image-Net database. Novel CNN model does not require training from scratch wasting weeks or days, rather uses transfer learning for knowledge distillation. Also to further enhance the training acceleration other optimization methods have been used, weights are initialized by the Gaussian initialization method followed by the ReLu activation function. ADAMS SGD optimization has been used and a drop-out algorithm is implemented to get rid of the overfitting of the model. The model when implemented on the biomedical image dataset has achieved the highest classification accuracy rate, outperforming all existing techniques with lesser training time. © 2021 University of Bahrain. All rights reserved.","ADAMS; CNN; CONVONET; FC; HOG; LRN; MRI; OASIS; PHT; ReLu; SGD; SIFT; Soft-max","","","University of Bahrain","","2-s2.0-85122768002"
"Xie Y.; Xing F.; Shi X.; Kong X.; Su H.; Yang L.","Xie, Yuanpu (56903340500); Xing, Fuyong (38461688800); Shi, Xiaoshuang (56029222900); Kong, Xiangfei (55613407300); Su, Hai (44661704600); Yang, Lin (55771607100)","56903340500; 38461688800; 56029222900; 55613407300; 44661704600; 55771607100","Efficient and robust cell detection: A structured regression approach","44","","","245","254","9","10.1016/j.media.2017.07.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026880496&doi=10.1016%2fj.media.2017.07.003&partnerID=40&md5=d73d834859cceefb038129b72398e8cb","Efficient and robust cell detection serves as a critical prerequisite for many subsequent biomedical image analysis methods and computer-aided diagnosis (CAD). It remains a challenging task due to touching cells, inhomogeneous background noise, and large variations in cell sizes and shapes. In addition, the ever-increasing amount of available datasets and the high resolution of whole-slice scanned images pose a further demand for efficient processing algorithms. In this paper, we present a novel structured regression model based on a proposed fully residual convolutional neural network for efficient cell detection. For each testing image, our model learns to produce a dense proximity map that exhibits higher responses at locations near cell centers. Our method only requires a few training images with weak annotations (just one dot indicating the cell centroids). We have extensively evaluated our method using four different datasets, covering different microscopy staining methods (e.g., H & E or Ki-67 staining) or image acquisition techniques (e.g., bright-filed image or phase contrast). Experimental results demonstrate the superiority of our method over existing state of the art methods in terms of both detection accuracy and running time. © 2017","Biomedical image analysis; Cell detection; Deep learning; Structured regression","Algorithms; Bone Marrow Cells; Breast Neoplasms; Cytological Techniques; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Neural Networks (Computer); Neuroendocrine Tumors; Reproducibility of Results; Sensitivity and Specificity; Uterine Cervical Neoplasms; Cells; Computer aided analysis; Computer aided diagnosis; Cytology; Deep learning; Neural networks; Regression analysis; eosin; hematoxylin; Biomedical image analysis; Cell detection; Computer Aided Diagnosis(CAD); Convolutional neural network; Detection accuracy; Processing algorithms; State-of-the-art methods; Structured regression; Article; breast cancer; cell detection; controlled study; image analysis; microscopy; neuroendocrine tumor; phase contrast microscopy; priority journal; procedures concerning cells; staining; uterine cervix cancer; algorithm; artificial neural network; bone marrow cell; breast tumor; computer assisted diagnosis; cytology; female; human; pathology; procedures; reproducibility; sensitivity and specificity; uterine cervix tumor; Image analysis","National Institutes of Health, NIH; National Institute of Arthritis and Musculoskeletal and Skin Diseases, NIAMS, (R01AR065479)","Elsevier B.V.","28797548","2-s2.0-85026880496"
"Ashraf R.; Habib M.A.; Akram M.; Latif M.A.; Malik M.S.A.; Awais M.; Dar S.H.; Mahmood T.; Yasir M.; Abbas Z.","Ashraf, Rehan (56704783800); Habib, Muhammad Asif (35772504100); Akram, Muhammad (57217541926); Latif, Muhammad Ahsan (58583401200); Malik, Muhammad Sheraz Arshad (57505246800); Awais, Muhammad (57224215215); Dar, Saadat Hanif (57203841811); Mahmood, Toqeer (56081146500); Yasir, Muhammad (57215783658); Abbas, Zahoor (57217381928)","56704783800; 35772504100; 57217541926; 58583401200; 57505246800; 57224215215; 57203841811; 56081146500; 57215783658; 57217381928","Deep Convolution Neural Network for Big Data Medical Image Classification","8","","9104735","105659","105670","11","10.1109/ACCESS.2020.2998808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087166459&doi=10.1109%2fACCESS.2020.2998808&partnerID=40&md5=c58fd8faf01b060649a0a0b898d1a6dc","Deep learning is one of the most unexpected machine learning techniques which is being used in many applications like image classification, image analysis, clinical archives and object recognition. With an extensive utilization of digital images as information in the hospitals, the archives of medical images are growing exponentially. Digital images play a vigorous role in predicting the patient disease intensity and there are vast applications of medical images in diagnosis and investigation. Due to recent developments in imaging technology, classifying medical images in an automatic way is an open research problem for researchers of computer vision. For classifying the medical images according to their relevant classes a most suitable classifier is most important. Image classification is beneficial to predict the appropriate class or category of unknown images. The less discriminating ability and domain-specific categorization are the main drawbacks of low-level features. A semantic gap that exists between features of low-level as machine understanding and features of human understanding as high-level perception. In this research, a novel image representation method is proposed where the algorithm is trained for classifying medical images by deep learning technique. A pre-trained deep convolution neural network method with the fine-tuned approach is applied to the last three layers of deep neural network. The results of the experiment exhibit that our method is best suited to classify various medical images for various body organs. In this manner, data can sum up to other medical classification applications which supports radiologist's efforts for improving diagnosis. © 2013 IEEE.","big data; biomedical image processing; convolution neural network; deep learning; image analysis; image enhancement; Medical image classification; pre-trained DCNN","Big data; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Learning algorithms; Learning systems; Medical imaging; Multilayer neural networks; Object recognition; Semantics; Convolution neural network; Discriminating abilities; Human understanding; Image representations; Learning techniques; Machine learning techniques; Machine understanding; Medical classification; Image classification","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85087166459"
"Hamidinekoo A.; Denton E.; Rampun A.; Honnor K.; Zwiggelaar R.","Hamidinekoo, Azam (56568239100); Denton, Erika (55578429200); Rampun, Andrik (55785202900); Honnor, Kate (57201680128); Zwiggelaar, Reyer (6701923709)","56568239100; 55578429200; 55785202900; 57201680128; 6701923709","Deep learning in mammography and breast histology, an overview and future trends","47","","","45","67","22","10.1016/j.media.2018.03.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045702232&doi=10.1016%2fj.media.2018.03.006&partnerID=40&md5=cb6ae23f2661ac7180281abecb6e371b","Recent improvements in biomedical image analysis using deep learning based neural networks could be exploited to enhance the performance of Computer Aided Diagnosis (CAD) systems. Considering the importance of breast cancer worldwide and the promising results reported by deep learning based methods in breast imaging, an overview of the recent state-of-the-art deep learning based CAD systems developed for mammography and breast histopathology images is presented. In this study, the relationship between mammography and histopathology phenotypes is described, which takes biological aspects into account. We propose a computer based breast cancer modelling approach: the Mammography–Histology–Phenotype–Linking–Model, which develops a mapping of features/phenotypes between mammographic abnormalities and their histopathological representation. Challenges are discussed along with the potential contribution of such a system to clinical decision making and treatment management. © 2018","Breast histopathology; Computer Aided Diagnosis; Deep learning; Mammography","Algorithms; Breast Neoplasms; Deep Learning; Diagnosis, Computer-Assisted; Female; Forecasting; Humans; Mammography; Neural Networks (Computer); Phenotype; Radiographic Image Interpretation, Computer-Assisted; Sensitivity and Specificity; Computer aided analysis; Computer aided diagnosis; Computer aided instruction; Decision making; Diseases; Histology; Image enhancement; Mammography; Medical imaging; Biological aspects; Biomedical image analysis; Breast histopathology; Breast imaging; Clinical decision making; Computer Aided Diagnosis(CAD); Learning-based methods; Treatment management; Article; breast cancer; cancer screening; clinical decision making; computer assisted diagnosis; computer model; histopathology; human; image analysis; image processing; learning algorithm; mammography; phenotype; priority journal; algorithm; artificial neural network; breast tumor; diagnostic imaging; female; forecasting; pathology; procedures; sensitivity and specificity; Deep learning","","Elsevier B.V.","29679847","2-s2.0-85045702232"
"Arif M.; Ajesh F.; Shamsudheen S.; Geman O.; Izdrui D.; Vicoveanu D.","Arif, Muhammad (56452459100); Ajesh, F. (57217016287); Shamsudheen, Shermin (57223927301); Geman, Oana (53863372800); Izdrui, Diana (57223106792); Vicoveanu, Dragos (25522574300)","56452459100; 57217016287; 57223927301; 53863372800; 57223106792; 25522574300","Brain Tumor Detection and Classification by MRI Using Biologically Inspired Orthogonal Wavelet Transform and Deep Learning Techniques","2022","","2693621","","","","10.1155/2022/2693621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123674522&doi=10.1155%2f2022%2f2693621&partnerID=40&md5=13187cc309127b2c3f702af6de30b723","Radiology is a broad subject that needs more knowledge and understanding of medical science to identify tumors accurately. The need for a tumor detection program, thus, overcomes the lack of qualified radiologists. Using magnetic resonance imaging, biomedical image processing makes it easier to detect and locate brain tumors. In this study, a segmentation and detection method for brain tumors was developed using images from the MRI sequence as an input image to identify the tumor area. This process is difficult due to the wide variety of tumor tissues in the presence of different patients, and, in most cases, the similarity within normal tissues makes the task difficult. The main goal is to classify the brain in the presence of a brain tumor or a healthy brain. The proposed system has been researched based on Berkeley's wavelet transformation (BWT) and deep learning classifier to improve performance and simplify the process of medical image segmentation. Significant features are extracted from each segmented tissue using the gray-level-co-occurrence matrix (GLCM) method, followed by a feature optimization using a genetic algorithm. The innovative final result of the approach implemented was assessed based on accuracy, sensitivity, specificity, coefficient of dice, Jaccard's coefficient, spatial overlap, AVME, and FoM.  © 2022 Muhammad Arif et al.","","Algorithms; Brain; Brain Neoplasms; Deep Learning; Humans; Magnetic Resonance Imaging; Wavelet Analysis; Biomimetics; Brain; Deep learning; Genetic algorithms; Histology; Image enhancement; Image segmentation; Learning systems; Medical imaging; Tumors; Wavelet transforms; Biologically-inspired; Brain tumors; Detection methods; Learning techniques; Medical science; MRI sequences; Orthogonal wavelet transforms; Segmentation methods; Tumor classification; Tumour detection; adult; Article; brain tumor; classification; classifier; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; feature extraction; genetic algorithm; human; image processing; image segmentation; major clinical study; nuclear magnetic resonance imaging; sensitivity and specificity; support vector machine; tumor diagnosis; wavelet transform; algorithm; brain; brain tumor; diagnostic imaging; nuclear magnetic resonance imaging; procedures; wavelet analysis; Magnetic resonance imaging","","Hindawi Limited","35047149","2-s2.0-85123674522"
"Waly M.I.; Sikkandar M.Y.; Aboamer M.A.; Kadry S.; Thinnukool O.","Waly, Mohamed Ibrahim (57196075534); Sikkandar, Mohamed Yacin (57202716139); Aboamer, Mohamed Abdelkader (56073053400); Kadry, Seifedine (55906598300); Thinnukool, Orawit (56146494600)","57196075534; 57202716139; 56073053400; 55906598300; 56146494600","Optimal deep convolution neural network for cervical cancer diagnosis model","70","2","","3297","3309","12","10.32604/cmc.2022.020713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115993107&doi=10.32604%2fcmc.2022.020713&partnerID=40&md5=1dafd35e4d4d7422b32fcedd812b6d64","Biomedical imaging is an effective way of examining the internal organ of the human body and its diseases. An important kind of biomedical image is Pap smear image that is widely employed for cervical cancer diagnosis. Cervical cancer is a vital reason for increased women's mortality rate. Proper screening of pap smear images is essential to assist the earlier identification and diagnostic process of cervical cancer. Computer-aided systems for cancerous cell detection need to be developed using deep learning (DL) approaches. This study introduces an intelligent deep convolutional neural network for cervical cancer detection and classification (IDCNN-CDC) model using biomedical pap smear images. The proposed IDCNN-CDC model involves four major processes such as preprocessing, segmentation, feature extraction, and classification. Initially, the Gaussian filter (GF) technique is applied to enhance data through noise removal process in the Pap smear image. The Tsallis entropy technique with the dragonfly optimization (TE-DFO) algorithm determines the segmentation of an image to identify the diseased portions properly. The cell images are fed into the DL based SqueezeNet model to extract deep-learned features. Finally, the extracted features from SqueezeNet are applied to the weighted extreme learning machine (ELM) classification model to detect and classify the cervix cells. For experimental validation, the Herlev database is employed. The database was developed at Herlev University Hospital (Denmark). The experimental outcomes make sure that higher performance of the proposed technique interms of sensitivity, specificity, accuracy, and F-Score. © 2022 Tech Science Press. All rights reserved.","Biomedical images; Cervical cancer; Computer aided diagnosis; Deep learning; Herlev database; Pap smear images","Computer aided diagnosis; Computer aided instruction; Convolution; Convolutional neural networks; Database systems; Diseases; Feature extraction; Image enhancement; Image segmentation; Medical imaging; Biomedical images; Cancer classification; Cancer detection; Cancer diagnosis; Cervical cancers; Classification models; Deep learning; Detection models; Herlev database; Pap smear images; Deep neural networks","Majmaah University, MU, (R-2021-164)","Tech Science Press","","2-s2.0-85115993107"
"Pietka E.; Gertych A.","Pietka, Ewa (6603704848); Gertych, Arkadiusz (7801318586)","6603704848; 7801318586","Advances in biomedical image processing","89","","101891","","","","10.1016/j.compmedimag.2021.101891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102633947&doi=10.1016%2fj.compmedimag.2021.101891&partnerID=40&md5=dc14c6ea9665445cdac379ec846b0ccc","[No abstract available]","","Image Processing, Computer-Assisted; abdominal viscera; Alzheimer disease; anatomical concepts; atopic dermatitis; biomedical engineering; classification; computer assisted tomography; convolutional neural network; data analysis; deep learning; diagnostic imaging; digital imaging; echography; Editorial; feature extraction; functional link artificial neural network; high frequency ultrasound; human; image processing; image segmentation; imaging algorithm; machine learning; mild cognitive impairment; multimodal imaging; nuclear magnetic resonance imaging; particle swarm optimization; priority journal; wound healing","","Elsevier Ltd","33744791","2-s2.0-85102633947"
"Kar M.K.; Nath M.K.; Neog D.R.","Kar, Mithun Kumar (37087476200); Nath, Malaya Kumar (26423133700); Neog, Debanga Raj (37087579900)","37087476200; 26423133700; 37087579900","A Review on Progress in Semantic Image Segmentation and Its Application to Medical Images","2","5","397","","","","10.1007/s42979-021-00784-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128319580&doi=10.1007%2fs42979-021-00784-5&partnerID=40&md5=98d28f4b102eba15a7f2b1f6ce0ee806","Semantic image segmentation is a popular image segmentation technique where each pixel in an image is labeled with an object class. This technique has become a vital part of image analysis nowadays as it facilitates the description, categorization, and visualization of the regions of interest in an image. The recent developments in computer vision algorithms and the increasing availability of large datasets have made semantic image segmentation very popular in the field of computer vision. Motivated by the human visual system which can identify objects in a complex scene very efficiently, researchers are interested in building a model that can semantically segment an image into meaningful object classes. This paper reviews deep learning-based semantic segmentation techniques that use deep neural network architectures for image segmentation of biomedical images. We have provided a discussion on the fundamental concepts related to deep learning methods used in semantic segmentation for the benefit of readers. The standard datasets and existing deep network architectures used in both medical and non-medical fields are discussed with their significance. Finally, this paper concludes by discussing the challenges and future research directions in the field of deep learning-based semantic segmentation for applications in the medical field. © 2021, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.","Automated medical image analysis; Convolution neural network; Deep learning; Deep neural network; Recurrent neural network; Semantic segmentation","","National Institute of Technology Srinagar, NITSRI","Springer","","2-s2.0-85128319580"
"Cardoso I.; Almeida E.; Allende-Cid H.; Frery A.C.; Rangayyan R.M.; Azevedo-Marques P.M.; Ramos H.S.","Cardoso, Isadora (57191339334); Almeida, Eliana (8295156100); Allende-Cid, Hector (57208732887); Frery, Alejandro C. (7003561251); Rangayyan, Rangaraj M. (7005319550); Azevedo-Marques, Paulo M. (57218760488); Ramos, Heitor S. (25655377800)","57191339334; 8295156100; 57208732887; 7003561251; 7005319550; 57218760488; 25655377800","Analysis of Machine Learning Algorithms for Diagnosis of Diffuse Lung Diseases","57","5-6","","272","279","7","10.1055/s-0039-1681086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062992252&doi=10.1055%2fs-0039-1681086&partnerID=40&md5=d012875b4843abe14c00b5e756e5098f","Computational Intelligence Re-meets Medical Image Processing A Comparison of Some Nature-Inspired Optimization Metaheuristics Applied in Biomedical Image Registration Summary Background Diffuse lung diseases (DLDs) are a diverse group of pulmonary disorders, characterized by inflammation of lung tissue, which may lead to permanent loss of the ability to breathe and death. Distinguishing among these diseases is challenging to physicians due their wide variety and unknown causes. Computer-aided diagnosis (CAD) is a useful approach to improve diagnostic accuracy, by combining information provided by experts with Machine Learning (ML) methods. Objectives Exploring the potential of dimensionality reduction combined with ML methods for diagnosis of DLDs; improving the classification accuracy over state-of-the-art methods. Methods A data set composed of 3252 regions of interest (ROIs) was used, from which 28 features were extracted per ROI. We used Principal Component Analysis, Linear Discriminant Analysis, and Stepwise Selection - Forward, Backward, and Forward-Backward to reduce feature dimensionality. The feature subsets obtained were used as input to the following ML methods: Support Vector Machine, Gaussian Mixture Model, k-Nearest Neighbor, and Deep Feedforward Neural Network. We also applied a Deep Convolutional Neural Network directly to the ROIs. Results We achieved the maximum reduction from 28 to 5 dimensions using LDA. The best classification results were obtained by DFNN, with 99.60% of overall accuracy. Conclusions This work contributes to the analysis and selection of features that can efficiently characterize the DLDs studied. © 2018 Georg Thieme Verlag KG Stuttgart. New York.","Deep learning; diffuse lung diseases; dimensionality reduction; machine learning","Algorithms; Diagnosis, Computer-Assisted; Discriminant Analysis; Humans; Lung Diseases; Machine Learning; Principal Component Analysis; Time Factors; algorithm; computer assisted diagnosis; discriminant analysis; human; lung disease; machine learning; principal component analysis; time factor","SEFAZ-AL; Fondo Nacional de Desarrollo Científico y Tecnológico, FONDECYT, (11150248); Conselho Nacional de Desenvolvimento Científico e Tecnológico, CNPq","Georg Thieme Verlag","30875707","2-s2.0-85062992252"
"Ke J.; Liu C.; Lu Y.; Jing N.; Liang X.; Jiang F.","Ke, Jing (57193131816); Liu, Changchang (59287406600); Lu, Yizhou (57200809307); Jing, Naifeng (35100372900); Liang, Xiaoyao (7401735951); Jiang, Fusong (56178389400)","57193131816; 59287406600; 57200809307; 35100372900; 7401735951; 56178389400","FIMIL: A high-throughput deep learning model for abnormality detection with weak annotation in microscopy images","","","a34","","","","10.1145/3373017.3373051","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079848157&doi=10.1145%2f3373017.3373051&partnerID=40&md5=c3874c01d4cd33cc8e165d2d245df7af","Automatic computer-aided detection plays an important role in biomedical image analysis. Many studies have focused on weak supervised learning as annotation tasks are time-consuming and tedious. Compared with pixel-wise annotation by particular software on the scanned digital high-resolution images, an alternative method of marking out of suspicious regions on microscopy slides is significantly more convenient for pathologists. Additionally, with a focus on dysplasias in the central area, there is a high likelihood of the similar tissues to be found around in clusters. In this paper, for weak annotation on microscopy images, we propose an efficient Foveated Imaging based Multiple Instance Learning (FIMIL) framework to classify weakly-labeled microscopy images. The model also provides multi-scale algorithm for arbitrary image size, in which the patches with highest possibility to contain dysplasia are considered as ""fixation points"" in the image. The developed model combines deep convolutional neural networks (CNNs) with multiple instance learning (MIL) for dysplasias detection with only image-level labeling. The benchmark tests are carried out on the marked regions of 40x magnified whole-slide cytology images and the normal/abnormal label and their corresponding possibilities are predicted. Evaluated on the real-life clinical data, our proposed model shows high accuracy and efficiency by weakly-supervised learning. 1 © 2020 ACM.","foveated imaging; microscopy image; multiple instance learning; performance acceleration","Benchmarking; Computer aided analysis; Convolutional neural networks; Cytology; Deep neural networks; Image annotation; Learning systems; Supervised learning; Biomedical image analysis; Computer aided detection; Foveated imaging; High resolution image; Microscopy images; Multiple instance learning; Performance acceleration; Weakly supervised learning; Deep learning","Science and Technology and Economic Commission of Shanghai Pudong","Association for Computing Machinery","","2-s2.0-85079848157"
"Dhivya P.; Kumaresan T.; Subramanian P.; Gunasekaran K.; Kumar G.S.","Dhivya, P. (56448997200); Kumaresan, T. (56878942000); Subramanian, P. (57387323700); Gunasekaran, K. (57219427870); Kumar, G. Sathish (57217065933)","56448997200; 56878942000; 57387323700; 57219427870; 57217065933","HYBRID FIREFLY META OPTIMIZATION FOR BIO MEDICAL IMAGE PROCESSING USING DEEP LEARNING","13","4","","1199","1209","10","10.47750/pnr.2022.13.04.169","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143281766&doi=10.47750%2fpnr.2022.13.04.169&partnerID=40&md5=03e21276b811afec63a51b88dbc89d27","Signal and image processing is a part of biomedical science. In that, Biomedical image processing have a great value such as recognition, segmentation and classification for disease diagnosis. In one part of biomedical science, brain tumor classification is considered with Magnetic Resonance Images (MRI) images using state of art models. Initially, the Convolutional Neural Network (CNN), Fast Convolutional Neural Network (FCNN), U-Net and M-Net model was considered for classification. Further, the Hybrid Firefly Meta Optimization (HFMO) is proposed for the better prediction purpose. The proposed work has three phases like normalization with augmentation, deep attention segmentation and classification. In the first phase, data augmentation is applied to increase the scope of the dataset. In the second phase, a deep attention technique is applied to concentrate on hotspot in the image during segmentation. Finally, a hybrid firefly optimization is applied to enhance the performance of the model in convolution neural network by backtracking the process. The measuring parameters like Dice coefficient, Jaccard index, Positive Projected Value (PPV), True Positive Rate and False Positive Rate were evaluated. The comparative analysis of various state of art models with proposed classifier were demonstrated. Thus the proposed technique produces the training accuracy as 98.62%, testing accuracy as 95.31 % and 1 % of loss. © 2022 Wolters Kluwer Medknow Publications. All rights reserved.","Augmentation; Central Nervous System; Dice Coefficient,Firefly optimization; Jaccard Index; Meta Learning; MRI","Article; classification; classifier; comparative study; controlled study; convolutional neural network; deep learning; diagnostic accuracy; diagnostic imaging; diagnostic test accuracy study; false negative result; false positive result; firefly algorithm; glioma; human; hypophysis tumor; image processing; image segmentation; meningioma; nuclear magnetic resonance imaging","","ResearchTrentz Academy Publishing Education Services","","2-s2.0-85143281766"
"Deleruyelle A.; Klein J.; Versari C.","Deleruyelle, Arnaud (57456693200); Klein, John (57199428576); Versari, Cristian (16647629300)","57456693200; 57199428576; 16647629300","SODA: SELF-ORGANIZING DATA AUGMENTATION IN DEEP NEURAL NETWORKS - APPLICATION TO BIOMEDICAL IMAGE SEGMENTATION TASKS","2022-May","","","6517","6521","4","10.1109/ICASSP43922.2022.9747744","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134063176&doi=10.1109%2fICASSP43922.2022.9747744&partnerID=40&md5=3a9bcf614616aa6c26f26e392bc89196","In practice, data augmentation is assigned a predefined budget in terms of newly created samples per epoch. When using several types of data augmentation, the budget is usually uniformly distributed over the set of augmentations but one can wonder if this budget should not be allocated to each type in a more efficient way. This paper leverages online learning to allocate on the fly this budget as part of neural network training. This meta-algorithm can be run at almost no extra cost as it exploits gradient based signals to determine which type of data augmentation should be preferred. Experiments suggest that this strategy can save computation time and thus goes in the way of greener machine learning practices. © 2022 IEEE","data augmentation; deep learning; HEDGE; online learning; segmentation","Budget control; E-learning; Image segmentation; Biomedical image segmentation; Data augmentation; Deep learning; HEDGE; Neural network application; Neural networks trainings; On-the-fly; Online learning; Segmentation; Self-organising; Deep neural networks","GENCI-IDRIS","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85134063176"
"Subasi A.; Kapadnis M.N.; Bulbul A.K.","Subasi, Abdulhamit (8327241200); Kapadnis, Manav Nitin (57323545600); Bulbul, Ayse Kosal (57709399500)","8327241200; 57323545600; 57709399500","Alzheimer’s disease detection using artificial intelligence","","","","53","74","21","10.1016/B978-0-323-90037-9.00011-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130669432&doi=10.1016%2fB978-0-323-90037-9.00011-4&partnerID=40&md5=7730a86310b8d0a53bbba8083bffc6b5","Biomedical data relevant to several diseases are generally employed to diagnose precise physiological or pathological conditions. The objective of biomedical image analysis is exact modeling by using Artificial Intelligence (AI) algorithms to diagnose different diseases. Alzheimer’s disease (AD) is one of the most widespread dementia forms influencing the elderly people. On-time diagnosis of Alzheimer’s disease is crucial to discover innovative methods for AD treatment. AI is an efficient approach for AD detection since it can be utilized as a Computer-aided decision support systems approach in medical procedures and play a critical role to detect changes in the brain images to identify AD. This chapter presents the recent studies and advances in AI used for medical image analysis and image processing in AD detection. The main focus is to have a consistent but easy and quick model for automated AD detection relied on the application of AI methods. Hence, the focus will be on AI techniques for AD detection from brain images. Moreover, some of the AI techniques, which were utilized for AD detection is overviewed. Then a simple AD detection approach using deep learning models will be presented. The results show that CNN achieved a testing accuracy of 95.70% accuracy and a validation accuracy of 99.71% for the diagnosis of AD from brain MRI scans. The chapter will be completed with a review of the current state-of-the-art, a discussion of new trends and open challenges for potential investigation. © 2022 Elsevier Inc. All rights reserved.","Alzheimer’s disease detection; Artificial intelligence; Convolutional neural networks; Deep learning; Transfer learning","","","Elsevier","","2-s2.0-85130669432"
"Escorcia-Gutierrez J.; Mansour R.F.; Beleño K.; Jiménez-Cabas J.; Pérez M.; Madera N.; Velasquez K.","Escorcia-Gutierrez, José (57191268293); Mansour, Romany F. (36960713000); Beleño, Kelvin (57410276900); Jiménez-Cabas, Javier (57202833550); Pérez, Meglys (59159121200); Madera, Natasha (57278705000); Velasquez, Kevin (57410862700)","57191268293; 36960713000; 57410276900; 57202833550; 59159121200; 57278705000; 57410862700","Automated Deep Learning Empowered Breast Cancer Diagnosis Using Biomedical Mammogram Images","71","2","","4221","4235","14","10.32604/cmc.2022.022322","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122769222&doi=10.32604%2fcmc.2022.022322&partnerID=40&md5=3ae0821a195d4ca5af59d02370f64fa6","Biomedical image processing is a hot research topic which helps to majorly assist the disease diagnostic process. At the same time, breast cancer becomes the deadliest disease among women and can be detected by the use of different imaging techniques. Digital mammograms can be used for the earlier identification and diagnostic of breast cancer to minimize the death rate. But the proper identification of breast cancer has mainly relied on the mammography findings and results to increased false positives. For resolving the issues of false positives of breast cancer diagnosis, this paper presents an automated deep learning based breast cancer diagnosis (ADL-BCD) model using digital mammograms. The goal of the ADL-BCD technique is to properly detect the existence of breast lesions using digital mammograms. The proposed model involves Gaussian filter based pre-processing and Tsallis entropy based image segmentation. In addition, Deep Convolutional Neural Network based Residual Network (ResNet 34) is applied for feature extraction purposes. Specifically, a hyper parameter tuning process using chimp optimization algorithm (COA) is applied to tune the parameters involved in ResNet 34 model. The wavelet neural network (WNN) is used for the classification of digital mammograms for the detection of breast cancer. The ADL-BCD method is evaluated using a benchmark dataset and the results are analyzed under several performance measures. The simulation outcome indicated that the ADL-BCD model outperforms the state of art methods in terms of different measures. © 2022 Tech Science Press. All rights reserved.","Breast cancer; Deep learning; Digital mammograms; Disease diagnosis; Resnet 34; Wavelet neural network","Benchmarking; Computer aided diagnosis; Convolutional neural networks; Deep neural networks; Diseases; E-learning; Image segmentation; X ray screens; Breast Cancer; Breast cancer diagnosis; Deep learning; Diagnosis model; Digital mammograms; Disease diagnosis; False positive; Neural-networks; Resnet 34; Wavelet neural network; Mammography","","Tech Science Press","","2-s2.0-85122769222"
"Duhayyim M.A.; Malibari A.A.; Obayya M.; Nour M.K.; Salama A.S.; Eldesouki M.I.; Zamani A.S.; Rizwanullah M.","Duhayyim, Mesfer Al (57204360566); Malibari, Areej A. (6506143515); Obayya, Marwa (6505869929); Nour, Mohamed K. (56027613700); Salama, Ahmed S. (56480035100); Eldesouki, Mohamed I. (57581134200); Zamani, Abu Sarwar (57295189700); Rizwanullah, Mohammed (57263769000)","57204360566; 6506143515; 6505869929; 56027613700; 56480035100; 57581134200; 57295189700; 57263769000","Metaheuristic with Deep Learning Enabled Biomedical Bone Age Assessment and Classification Model","73","3","","5473","5489","16","10.32604/cmc.2022.031976","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135077555&doi=10.32604%2fcmc.2022.031976&partnerID=40&md5=8f4b1016dcb8dd673d74cfec2064c5f6","The skeletal bone age assessment (BAA) was extremely implemented in development prediction and auxiliary analysis of medicinal issues. X-ray images of hands were detected from the estimation of bone age, whereas the ossification centers of epiphysis and carpal bones are important regions. The typical skeletal BAA approaches remove these regions for predicting the bone age, however, few of them attain suitable efficacy or accuracy. Automatic BAA techniques with deep learning (DL) methods are reached the leading efficiency on manual and typical approaches. Therefore, this study introduces an intellectual skeletal bone age assessment and classification with the use of metaheuristic with deep learning (ISBAAC-MDL) model. The presented ISBAAC-MDL technique majorly focuses on the identification of bone age prediction and classification process. To attain this, the presented ISBAAC-MDL model derives a mask Region-related Convolutional Neural Network (Mask-RCNN) with MobileNet as baseline model to extract features. Followed by, the whale optimization algorithm (WOA) is implemented for hyperparameter tuning of the MobileNet method. At last, Deep Feed-Forward Module (DFFM) based age prediction and Radial Basis Function Neural Network (RBFNN) based stage classification approach is utilized. The experimental evaluation of the ISBAAC-MDL model is tested using benchmark dataset and the outcomes are assessed over distinct factors. The experimental outcomes reported the better performances of the ISBAAC-MDL model over recent approaches with maximum accuracy of 0.9920. © 2022 Tech Science Press. All rights reserved.","age prediction; Biomedical images; bone age assessment; computer vision; deep learning; image classification","Computer vision; Convolutional neural networks; Deep learning; Forecasting; Learning systems; Musculoskeletal system; Radial basis function networks; Age predictions; Assessment models; Biomedical images; Bone age; Bone age assessment; Classification models; Deep learning; Images classification; Learning models; Metaheuristic; Image classification","Deanship of Scientific Research at Umm Al-Qura University, (22UQU4310373DSR17)","Tech Science Press","","2-s2.0-85135077555"
"Pavone A.M.; Benfante V.; Stefano A.; Mamone G.; Milazzo M.; Di Pizza A.; Parenti R.; Maruzzelli L.; Miraglia R.; Comelli A.","Pavone, Anna Maria (57578504900); Benfante, Viviana (57211284401); Stefano, Alessandro (35794207900); Mamone, Giuseppe (17135015700); Milazzo, Mariapina (7005837543); Di Pizza, Ambra (57841731700); Parenti, Rosalba (57792357200); Maruzzelli, Luigi (23989257600); Miraglia, Roberto (23390480200); Comelli, Albert (57104982700)","57578504900; 57211284401; 35794207900; 17135015700; 7005837543; 57841731700; 57792357200; 23989257600; 23390480200; 57104982700","Automatic Liver Segmentation in Pre-TIPS Cirrhotic Patients: A Preliminary Step for Radiomics Studies","13373 LNCS","","","408","418","10","10.1007/978-3-031-13321-3_36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135838559&doi=10.1007%2f978-3-031-13321-3_36&partnerID=40&md5=3e01e600c6ffbc8932fb8ce5fb41e578","The aim of this study is to present a deep learning (DL) algorithm for accurate liver delineation in high-resolution computed tomography (CT) images of pre-transjugular intrahepatic portosystemic shunt (TIPS) cirrhotic patients. In this way, we aim to improve the methodology performed by medical physicians in radiomics studies where the use of operator-independent segmentation methods is mandatory to correctly identify the target and to obtain accurate predictive models. Two DL models were investigated: UNet, the most widely used DL network for biomedical image segmentation, and the innovative customized efficient neural network (C-ENet). 111 patients with liver contrast-enhanced CT examinations before TIPS procedure were considered. The performance of the two DL networks was evaluated in terms of the similarity of their segmentations to the gold standard. The results show that C-ENet can be used to obtain accurate (dice similarity coefficient = 87.70%) segmentation of the liver region outperforming UNet (dice similarity coefficient = 85.33%). In conclusion, we demonstrated that DL can be efficiently applied to rapidly segment cirrhotic liver images, without any radiologist supervision, to produce user-independent results useful for subsequent radiomics studies. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","C-ENet; Cirrhosis; Deep learning; Liver; Segmentation; TIPS; UNet","Computerized tomography; Image segmentation; Medical imaging; Cirrhosis; Customized efficient neural network; Deep learning; Learning network; Liver segmentation; Neural-networks; Segmentation; Similarity coefficients; Transjugular intrahepatic portosystemic shunt; Unet; Deep learning","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85135838559"
"Malibari A.A.; Alzahrani J.S.; Obayya M.; Negm N.; Al-Hagery M.A.; Salama A.S.; Hilal A.M.","Malibari, Areej A. (6506143515); Alzahrani, Jaber S. (57221867248); Obayya, Marwa (6505869929); Negm, Noha (57224513486); Al-Hagery, Mohammed Abdullah (57203986293); Salama, Ahmed S. (56480035100); Hilal, Anwer Mustafa (57202837434)","6506143515; 57221867248; 6505869929; 57224513486; 57203986293; 56480035100; 57202837434","Biomedical Osteosarcoma Image Classification Using Elephant Herd Optimization and Deep Learning","73","3","","6443","6459","16","10.32604/cmc.2022.031324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135064194&doi=10.32604%2fcmc.2022.031324&partnerID=40&md5=06624d2d75c400bbb5175c7ed0816ad9","Osteosarcoma is a type of malignant bone tumor that is reported across the globe. Recent advancements in Machine Learning (ML) and Deep Learning (DL) models enable the detection and classification of malignancies in biomedical images. In this regard, the current study introduces a new Biomedical Osteosarcoma Image Classification using Elephant Herd Optimization and Deep Transfer Learning (BOIC-EHODTL) model. The presented BOIC-EHODTL model examines the biomedical images to diagnose distinct kinds of osteosarcoma. At the initial stage, Gabor Filter (GF) is applied as a pre-processing technique to get rid of the noise from images. In addition, Adam optimizer with MixNet model is also employed as a feature extraction technique to generate feature vectors. Then, EHO algorithm is utilized along with Adaptive Neuro-Fuzzy Classifier (ANFC) model for recognition and categorization of osteosarcoma. EHO algorithm is utilized to fine-tune the parameters involved in ANFC model which in turn helps in accomplishing improved classification results. The design of EHO with ANFC model for classification of osteosarcoma is the novelty of current study. In order to demonstrate the improved performance of BOIC-EHODTL model, a comprehensive comparison was conducted between the proposed and existing models upon benchmark dataset and the results confirmed the better performance of BOIC-EHODTL model over recent methodologies. © 2022 Tech Science Press. All rights reserved.","Biomedical imaging; deep transfer learning parameter tuning; fuzzy logic; osteosarcoma classification","Benchmarking; Deep learning; Fuzzy inference; Fuzzy neural networks; Gabor filters; Learning systems; Medical imaging; Biomedical imaging; Deep transfer learning parameter tuning; Fuzzy-Logic; Images classification; Learning parameters; Optimisations; Osteosarcoma classification; Osteosarcomas; Parameters tuning; Transfer learning; Image classification","Deanship of Scientific Research at Umm Al-Qura University, (22UQU4340237DSR16); Deanship of Scientific Research, King Faisal University, DSR, KFU, (42/43); Deanship of Scientific Research, King Faisal University, DSR, KFU","Tech Science Press","","2-s2.0-85135064194"
"Isler I.; Lisle C.; Rineer J.; Kelly P.; Turgut D.; Ricci J.; Bagci U.","Isler, Ilkin (57453663000); Lisle, Curtis (6602758735); Rineer, Justin (6504459710); Kelly, Patrick (56365080700); Turgut, Damla (6603176290); Ricci, Jacob (57247420600); Bagci, Ulas (24176491700)","57453663000; 6602758735; 6504459710; 56365080700; 6603176290; 57247420600; 24176491700","Enhancing Organ at Risk Segmentation with Improved Deep Neural Networks","12032","","1203233","","","","10.1117/12.2611498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131961819&doi=10.1117%2f12.2611498&partnerID=40&md5=86cf31b60bc4531c526d9e126d1a699e","Organ at risk (OAR) segmentation is a crucial step for treatment planning and outcome determination in radiotherapy treatments of cancer patients. Several deep learning based segmentation algorithms have been developed in recent years, however, U-Net remains the de facto algorithm designed specifically for biomedical image segmentation and has spawned many variants with known weaknesses. In this study, our goal is to present simple architectural changes in U-Net to improve its accuracy and generalization properties. Unlike many other available studies evaluating their algorithms on single center data, we thoroughly evaluate several variations of U-Net as well as our proposed enhanced architecture on multiple data sets for an extensive and reliable study of the OAR segmentation problem. Our enhanced segmentation model includes (a)architectural changes in the loss function, (b)optimization framework, and (c)convolution type. Testing on three publicly available multi-object segmentation data sets, we achieved an average of 80% dice score compared to the baseline U-Net performance of 63%. © 2022 SPIE.","Generalization; Multi-object segmentation; Organ at risk segmentation; Radiation Oncology; U-Net","Bioinformatics; Computer aided diagnosis; Image segmentation; Medical imaging; Oncology; Radiotherapy; Architectural changes; Generalisation; Multi-object segmentation; Organ at risk segmentation; Organs at risks; Radiation oncology; Radiotherapy treatment; Treatment outcomes; Treatment planning; U-net; Deep neural networks","National Institutes of Health, NIH, (R01-CA240639, R01-CA246704)","SPIE","","2-s2.0-85131961819"
"","","","14th International conference on Pattern Recognition and Information Processing, PRIP 2019","1055 CCIS","","","","","311","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076698019&partnerID=40&md5=d739f08078244e0340f18c86d8a47bbb","The proceedings contain 25 papers. The special focus in this conference is on Pattern Recognition and Information Processing. The topics include: Brands and Caps Labeling Recognition in Images Using Deep Learning; influence of Control Parameters and the Size of Biomedical Image Datasets on the Success of Adversarial Attacks; performance of Sequential Tests for Random Data Monitoring Under Distortion; equipment Condition Identification Based on Telemetry Signal Clustering; robots’ Vision Humanization Through Machine-Learning Based Artificial Visual Attention; automatic Analysis of Moving Particles by Total Internal Reflection Fluorescence Microscopy; fuzzy Morphological Filters for Processing of Printed Circuit Board Images; Detection of Bulbar Dysfunction in ALS Patients Based on Running Speech Test; thresholding Neural Network Image Enhancement Based on 2-D Non-separable Quaternionic Filter Bank; method of Creating the 3D Face Model of Character Based on Textures Maps Module; shadow Detection in Satellite Images by Computing Its Characteristics; nearest Convex Hull Classifier with Simplified Proximity Measurement; image Semantic Segmentation Based on Convolutional Neural Networks for Monitoring Agricultural Vegetation; reliability Analysis Based on Incompletely Specified Data; semantic-Based Linguistic Platform for Big Data Processing; cell Nuclei Counting and Segmentation for Histological Image Analysis; robust Person Tracking Algorithm Based on Convolutional Neural Network for Indoor Video Surveillance Systems; modeling of Intelligent Systems Architecture Based on the Brain Topology; temporal Convolutional and Recurrent Networks for Image Captioning; Video-Based Content Extraction Algorithm from Bank Cards for iOS Mobile Devices; FPGA Based Arbiter Physical Unclonable Function Implementation with Reduced Hardware Overhead; preface.","","","","Springer","","2-s2.0-85076698019"
"Contreras G.; Pabon J.; Garcia H.; Rojas F.; Arguello H.","Contreras, Ghiordy (57422578400); Pabon, Jhon (57422727600); Garcia, Hans (57192275191); Rojas, Fernando (58625491200); Arguello, Henry (44061135000)","57422578400; 57422727600; 57192275191; 58625491200; 44061135000","Correction of Designed Compressive Spectral Imaging Measurements Using a Deep Learning-Based Method","","","","","","","10.1109/STSIVA53688.2021.9592024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123319777&doi=10.1109%2fSTSIVA53688.2021.9592024&partnerID=40&md5=c67ee5a3b1b27a6fb2787f03ff39a407","Spectral imaging offers useful additional information to improve or expand imaging applications such as biomedical images, identification of cultures, and surveillance. These applications take advantage of features involved in a spectral scene captured using, for instance, the Coded Aperture Snapshot Spectral Imagers (CASSI), that naturally embodies the compressing sensing principles, whose potential is diminished because in practice, sensing matrix loses the ideal characteristics. This paper uses a deep learning based method in order to correct the real-compressed measurements and estimate the ideal-corrected measurements. The correction is estimated from a matrix form of compressed measurements, with the representation of compressed spatial dimensions and the number of projections captured as shots. The performance of the model is measured using peak signal-To-noise ratio, and the structural similarity index, upon the recovered data cube with the gradient projection for sparse reconstruction algorithm. The outcomes show how the deep learning-based method improves the quality in reconstruction against image ground truth when the noise is not concerning. © 2021 IEEE.","compressing sensing; convolutional neural network; cost function; deep learning; real calibration; Sensing matrix","Convolutional neural networks; Cost functions; Deep learning; Image enhancement; Matrix algebra; Signal to noise ratio; Compressing sensing; Convolutional neural network; Cost-function; Deep learning; Imaging measurements; Learning-based methods; matrix; Real calibration; Sensing matrix; Spectral imaging; Spectroscopy","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85123319777"
"Gastounioti A.; Rathore S.; Maghsoudi O.H.; Conant E.F.; Kontos D.; Bakas S.","Gastounioti, Aimilia (36604342100); Rathore, Saima (55000220500); Maghsoudi, Omid Haji (56132015900); Conant, Emily F. (7004184822); Kontos, Despina (6602886901); Bakas, Spyridon (55366125000)","36604342100; 55000220500; 56132015900; 7004184822; 6602886901; 55366125000","Computational imaging applications in brain and breast cancer","","","","29","45","16","10.1016/B978-0-12-819872-8.00009-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150132641&doi=10.1016%2fB978-0-12-819872-8.00009-4&partnerID=40&md5=7855fa8ac75bd120048c710dba93439a","The rapid development of advanced computational algorithms from the domain of machine learning has shown promise for application in the clinical environment to (1) assist clinicians with tedious daily tasks and allow them to focus more on complex or urgent patient management, (2) offer second reads or opinions on tasks that require specialized training, as well as (3) assist in the training and education of new clinical experts. This chapter offers an overview of the state-of-the-art deep learning applications in the field of brain and breast cancer, as well as challenges and potential methods to improve the reproducibility of deep learning algorithms in biomedical image analysis of brain and breast cancer patients. The included references should not be considered as an exhaustive literature review but as studies serving as examples for the points made in this chapter. © 2023 Elsevier Inc. All rights reserved.","brain cancer; breast cancer; convolutional neural networks; Deep learning","","","Elsevier","","2-s2.0-85150132641"
"Pan Y.","Pan, Yangyi (57830222900)","57830222900","Influence of different image preprocessing methods on bone age prediction","","","","632","636","4","10.1109/CVIDLICCEA56201.2022.9825218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135397871&doi=10.1109%2fCVIDLICCEA56201.2022.9825218&partnerID=40&md5=2e79d59ceaae582d689b0d5e84b4c727","In medical image recognition represented by bone age prediction, image samples need to be preprocessed to improve the quality of image samples and improve the learning efficiency of deep learning. This paper aims to compare the effects of different image preprocessing methods on the performance of the neural network. In this paper, the method of control experiment is used. Without pretreatment, the structure and framework of the neural network are controlled to remain unchanged, to make the conclusion more objective. This paper mainly discusses three pretreatment methods. 1 Conventional image filtering; 2. Use u-net network specially used for biomedical image segmentation to segment hand bones in X-ray; 3. The control group did not undergo image preprocessing. At the same time, this paper proposes to mark the gender of the owner of hand bone X-ray film in the form of a white background mark on the original image and control the gender weight by adjusting the size of the mark. U-net network preprocessing does not significantly improve the accuracy of the neural network, but this method makes the effect of deep neural network and shallow neural network almost the same, so it can be used as an effective method to prevent overfitting of neural networks. The main innovation of this paper is to explore the effectiveness of preprocessing algorithms in preventing the overfitting of medical image models by comparing the bone age prediction under various preprocessing methods. © 2022 IEEE.","bone age prediction; deep learning; grayscale histogram equalization; network lightweight; over-fitting; preprocessing; U-Net network","Equalizers; Forecasting; Image enhancement; Image recognition; Image segmentation; Medical imaging; X ray films; Age predictions; Bone age; Bone age prediction; Deep learning; Gray scale; Grayscale histogram equalization; Histogram equalizations; Net networks; Network lightweight; Overfitting; Preprocessing; U-net network; Deep neural networks","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85135397871"
"Durkee M.S.; Abraham R.; Clark M.R.; Giger M.L.","Durkee, Madeleine S. (56677655800); Abraham, Rebecca (57215870962); Clark, Marcus R. (56664601700); Giger, Maryellen L. (7103040897)","56677655800; 57215870962; 56664601700; 7103040897","Artificial Intelligence and Cellular Segmentation in Tissue Microscopy Images","191","10","","1693","1701","8","10.1016/j.ajpath.2021.05.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115163423&doi=10.1016%2fj.ajpath.2021.05.022&partnerID=40&md5=133006568dbba9637ee8804579e5d488","With applications in object detection, image feature extraction, image classification, and image segmentation, artificial intelligence is facilitating high-throughput analysis of image data in a variety of biomedical imaging disciplines, ranging from radiology and pathology to cancer biology and immunology. Specifically, a growth in research on deep learning has led to the widespread application of computer-visualization techniques for analyzing and mining data from biomedical images. The availability of open-source software packages and the development of novel, trainable deep neural network architectures has led to increased accuracy in cell detection and segmentation algorithms. By automating cell segmentation, it is now possible to mine quantifiable cellular and spatio-cellular features from microscopy images, providing insight into the organization of cells in various pathologies. This mini-review provides an overview of the current state of the art in deep learning– and artificial intelligence–based methods of segmentation and data mining of cells in microscopy images of tissue. © 2021 American Society for Investigative Pathology","","Animals; Artificial Intelligence; Cells; Deep Learning; Humans; Image Processing, Computer-Assisted; Microscopy; Organ Specificity; artificial intelligence; artificial neural network; data mining; deep learning; deep neural network; generative adversarial network; high throughput analysis; human; image analysis; image processing; image quality; image segmentation; immunofluorescence; immunohistochemistry; microscopy; Review; selection bias; signal noise ratio; animal; antibody specificity; cells; cytology","Median Technologies; Mitsubishi; Riverain Technologies LLC; National Institutes of Health, NIH, (U19 AI082724); U.S. Department of Defense, DOD, (LR180083); National Institute of Allergy and Infectious Diseases, NIAID; National Institute of Arthritis and Musculoskeletal and Skin Diseases, NIAMS, (R01AR055646); University of Chicago; Medical Research Council, MRC, (R01 AI148705, R01 AR055646, U01 CA195564)","Elsevier Inc.","34129842","2-s2.0-85115163423"
"Schouten J.P.E.; Matek C.; Jacobs L.F.P.; Buck M.C.; Bošnački D.; Marr C.","Schouten, Jens P. E. (57222963224); Matek, Christian (55368586300); Jacobs, Luuk F. P. (57222959002); Buck, Michèle C. (57222016114); Bošnački, Dragan (6602212448); Marr, Carsten (10539477500)","57222963224; 55368586300; 57222959002; 57222016114; 6602212448; 10539477500","Tens of images can suffice to train neural networks for malignant leukocyte detection","11","1","7995","","","","10.1038/s41598-021-86995-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104271125&doi=10.1038%2fs41598-021-86995-5&partnerID=40&md5=1e4d8774280e1317394d6c05afd480c8","Convolutional neural networks (CNNs) excel as powerful tools for biomedical image classification. It is commonly assumed that training CNNs requires large amounts of annotated data. This is a bottleneck in many medical applications where annotation relies on expert knowledge. Here, we analyze the binary classification performance of a CNN on two independent cytomorphology datasets as a function of training set size. Specifically, we train a sequential model to discriminate non-malignant leukocytes from blast cells, whose appearance in the peripheral blood is a hallmark of leukemia. We systematically vary training set size, finding that tens of training images suffice for a binary classification with an ROC-AUC over 90%. Saliency maps and layer-wise relevance propagation visualizations suggest that the network learns to increasingly focus on nuclear structures of leukocytes as the number of training images is increased. A low dimensional tSNE representation reveals that while the two classes are separated already for a few training images, the distinction between the classes becomes clearer when more training images are used. To evaluate the performance in a multi-class problem, we annotated single-cell images from a acute lymphoblastic leukemia dataset into six different hematopoietic classes. Multi-class prediction suggests that also here few single-cell images suffice if differences between morphological classes are large enough. The incorporation of deep learning algorithms into clinical practice has the potential to reduce variability and cost, democratize usage of expertise, and allow for early detection of disease onset and relapse. Our approach evaluates the performance of a deep learning based cytology classifier with respect to size and complexity of the training data and the classification task. © 2021, The Author(s).","","Databases as Topic; Humans; Image Processing, Computer-Assisted; Leukocytes; Lymphocytes; Neural Networks, Computer; data base; human; image processing; leukocyte; lymphocyte; pathology","Deutsche Jose Carreras-Leukämie Stiftung; German Science Foundation DFG, (SFB 1243); Horizon 2020 Framework Programme, H2020, (866411); European Research Council, ERC; Deutsche Forschungsgemeinschaft, DFG","Nature Research","33846442","2-s2.0-85104271125"
"Behura A.","Behura, Aradhana (57216374591)","57216374591","Congruence of deep learning in biomedical engineering: Future prospects and challenges","","","","1","24","23","10.1016/B978-0-12-823014-5.00003-X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120533343&doi=10.1016%2fB978-0-12-823014-5.00003-X&partnerID=40&md5=cd6cccaedb7efa110557dcb904ca376b","Deep learning models have opened up many prospects in medical images for achieving unprecedented performance, for example, classification of tissues and division or segmentation are a few medical outcomes. This chapter evaluates and describes the convolutional neural network (CNN) intended for characterization of tissue in clinical imaging, which is applied for segregating essential metastatic liver tumors from diffusion-weighted magnetic resonance imaging information. Advancement in the field of deep learning for normal pictures has provoked a surge of enthusiasm for applying comparative strategies to clinical images. Most of the initial attempts replaced the input of a deep CNN with medical images, which does not consider the basic contrasts between these two kinds of pictures. In particular, fine details are fundamental in clinical pictures, unlike regular images where coarse structures are very important. This distinction makes it difficult to utilize the current organized models created for common pictures, because they chip away at downscaled medical images to decrease the memory prerequisites. These subtleties are important to provide accurate detection. Furthermore, a medical test in clinical imaging regularly accompanies many perspectives, which must be intertwined to arrive at the right conclusion. A survey of deep learning is used for image classification, carotid ultrasound data investigations, cardiotocography, intravascular ultrasound reports, lung computed tomography reports, brain tumor prediction, coronavirus prediction (COVID-19) object detection, segmentation, breast cancer prediction, electrocardiogram signals, electroencephalograms, photoplethysmographic signal registration, psoriasis skin disease, as well as cancer detection. Concise summaries are delivered of trainings per application zone: pulmonary, musculoskeletal neuro, digital pathology, abdominal, retinal, breast, and cardiac. There are various types of deep learning techniques present to improve the accuracy of the medical dataset. Deep reinforcement learning, recursive neural network, multilayer perceptron, recurrent neural network, Boltzmann machine, and CNN are different types of deep learning techniques used to train the image and signal dataset. Generative adversarial network (GAN), autoencoder, and deep belief neural network are subcategories of unsupervised pretrained neural network. Some well-known architectural models of CNNs are ResNet (2015), VGGNet (2014), SqueezeNet (2016), GoogLeNet (2014), and ZFNet (2013) and are the visualization concept of the deconvolutional network; AlexNet (2012) and LeNet (Peng et al., 2009; Mitchell; Bengio, 2012; Dutkowski et al., 2015; Han et al., 2020 [16-20]) are basically used to train image datasets; the long short-term memory technique is used to train signalized datasets; and RHSBoost and genetically optimized neural network are used for efficient multiple classification of datasets. Dimensionality reduction, feature extraction, overfitting, underfitting, and normalization problems can be solved using various types of optimization algorithm. Image security is another important part, and by using an autoencoder, GAN network, and CNN we can prevent alteration in the medical image. Minor alteration of the medical image is very dangerous to patient life. By using deep learning and steganography, we can first compress as well as train the dataset, then security can be preserved after embedding of watermarks (which is a secret image visible to the human eye that cannot be altered; this steganography concept is called watermarking). © 2021 Elsevier Inc. All rights reserved.","Biomedical image and signal processing; Breast cancer; Deep learning; Image segmentation; Unsupervised feature learning","","","Elsevier","","2-s2.0-85120533343"
"McCann M.T.; Unser M.","McCann, M.T. (55617614400); Unser, M. (7102049045)","55617614400; 7102049045","Biomedical image reconstruction: From the foundations to deep neural networks","13","3","","283","359","76","10.1561/2000000101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086604683&doi=10.1561%2f2000000101&partnerID=40&md5=7ff436fd7de566a2454876d2f4fb855e","This tutorial covers biomedical image reconstruction, from the foundational concepts of system modeling and direct reconstruction to modern sparsity and learning-based approaches. Imaging is a critical tool in biological research and medicine, and most imaging systems necessarily use an image reconstruction algorithm to create an image; the design of these algorithms has been a topic of research since at least the 1960's. In the last few years, machine learning-based approaches have shown impressive performance on image reconstruction problems, triggering a wave of enthusiasm and creativity around the paradigm of learning. Our goal is to unify this body of research, identifying common principles and reusable building blocks across decades and among diverse imaging modalities. We first describe system modeling, emphasizing how a few building blocks can be used to describe a broad range of imaging modalities. We then discuss reconstruction algorithms, grouping them into three broad generations. The first are the classical direct methods, including Tikhonov regularization; the second are the variational methods based on sparsity and the theory of compressive sensing; and the third are the learning-based (also called data-driven) methods, especially those using deep convolutional neural networks. There are strong links between these generations: classical (first-generation) methods appear as modules inside the latter two, and the former two are used to inspire new designs for learning-based (third-generation) methods. As a result, a solid understanding of all three generations is necessary for the design of state-of-the-art algorithms. © M. T. McCann and M. Unser (2019)","","Bioinformatics; Convolutional neural networks; Deep learning; Deep neural networks; Learning systems; Compressive sensing; Image reconstruction algorithm; Learning-based approach; Reconstruction algorithms; Reconstruction problems; State-of-the-art algorithms; Tikhonov regularization; Variational methods; Image reconstruction","European Union's Horizon 2020 Research and Innovation Program; Louis-Jeantet Foundations; University Hospitals of Geneva; Vaud University Hospital Centre; Horizon 2020 Framework Programme, H2020, (692726); European Research Council, ERC; École Polytechnique Fédérale de Lausanne, EPFL; Louis-Jeantet Foundation; Hôpitaux Universitaires de Genève, HUG; Université de Genève, UNIGE; Université de Lausanne, UNIL; Centre d'Imagerie BioMédicale, CIBM","Now Publishers Inc","","2-s2.0-85086604683"
"","","","10th International Workshop on Clinical Image-Based Procedures, CLIP 2021, 2nd MICCAI Workshop on Distributed and Collaborative Learning, DCL 2021, 1st MICCAI Workshop, LL-COVID19, 1st Secure and Privacy-Preserving Machine Learning for Medical Imaging Workshop and Tutorial, PPML 2021, held in conjunction with 24th International Conference on Medical Image Computing and Computer Assisted Intervention, MICCAI 2021","12969 LNCS","","","","","188","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120670667&partnerID=40&md5=d2d8d0fe0bacf848b549c7c0113ca065","The proceedings contain 17 papers. The special focus in this conference is on Clinical Image-Based Procedures. The topics include: DCL preface; LL-COVID-19 preface; PPML preface; intestine Segmentation with Small Computational Cost for Diagnosis Assistance of Ileus and Intestinal Obstruction; multi-task Federated Learning for Heterogeneous Pancreas Segmentation; federated Learning in the Cloud for Analysis of Medical Images - Experience with Open Source Frameworks; on the Fairness of Swarm Learning in Skin Lesion Classification; Lessons Learned from the Development and Application of Medical Imaging-Based AI Technologies for Combating COVID-19: Why Discuss, What Next; The Role of Pleura and Adipose in Lung Ultrasound AI; DuCN: Dual-Children Network for Medical Diagnosis and Similar Case Recommendation Towards COVID-19; data Imputation and Reconstruction of Distributed Parkinson’s Disease Clinical Assessments: A Comparative Evaluation of Two Aggregation Algorithms; defending Medical Image Diagnostics Against Privacy Attacks Using Generative Methods: Application to Retinal Diagnostics; generation of Patient-Specific, Ligamentoskeletal, Finite Element Meshes for Scoliosis Correction Planning; Bayesian Graph Neural Networks for EEG-Based Emotion Recognition; ViTBIS: Vision Transformer for Biomedical Image Segmentation; Attention-Guided Pancreatic Duct Segmentation from Abdominal CT Volumes; development of the Next Generation Hand-Held Doppler with Waveform Phasicity Predictive Capabilities Using Deep Learning; learning from Mistakes: An Error-Driven Mechanism to Improve Segmentation Performance Based on Expert Feedback.","","","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85120670667"
"Zhang R.; Guo Z.; Sun Y.; Lu Q.; Xu Z.; Yao Z.; Duan M.; Liu S.; Ren Y.; Huang L.; Zhou F.","Zhang, Ruochi (57196041167); Guo, Zhehao (57219109743); Sun, Yue (57221122033); Lu, Qi (57219110127); Xu, Zijian (57219109575); Yao, Zhaomin (57192304471); Duan, Meiyu (57212005263); Liu, Shuai (57200844289); Ren, Yanjiao (57201310055); Huang, Lan (55770288600); Zhou, Fengfeng (55634210800)","57196041167; 57219109743; 57221122033; 57219110127; 57219109575; 57192304471; 57212005263; 57200844289; 57201310055; 55770288600; 55634210800","COVID19XrayNet: A Two-Step Transfer Learning Model for the COVID-19 Detecting Problem Based on a Limited Number of Chest X-Ray Images","12","4","","555","565","10","10.1007/s12539-020-00393-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091267952&doi=10.1007%2fs12539-020-00393-5&partnerID=40&md5=0573121222167824ca5b815cf49aedb4","The novel coronavirus severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a major pandemic outbreak recently. Various diagnostic technologies have been under active development. The novel coronavirus disease (COVID-19) may induce pulmonary failures, and chest X-ray imaging becomes one of the major confirmed diagnostic technologies. The very limited number of publicly available samples has rendered the training of the deep neural networks unstable and inaccurate. This study proposed a two-step transfer learning pipeline and a deep residual network framework COVID19XrayNet for the COVID-19 detection problem based on chest X-ray images. COVID19XrayNet firstly tunes the transferred model on a large dataset of chest X-ray images, which is further tuned using a small dataset of annotated chest X-ray images. The final model achieved 0.9108 accuracy. The experimental data also suggested that the model may be improved with more training samples being released. Graphic abstract: COVID19XrayNet, a two-step transfer learning framework designed for biomedical images.[Figure not available: see fulltext.] © 2020, International Association of Scientists in the Interdisciplinary Areas.","COVID19XrayNet; Feature extraction layer (FEL); Feature smoothing layer (FSL); ResNet34; Two-step transfer learning","Algorithms; Betacoronavirus; Clinical Laboratory Techniques; Coronavirus; Coronavirus Infections; Databases, Factual; Datasets as Topic; Deep Learning; Humans; Lung; Machine Learning; Models, Biological; Neural Networks, Computer; Pandemics; Pneumonia; Pneumonia, Viral; Radiography; Reference Values; Tomography, X-Ray Computed; X-Rays; algorithm; Betacoronavirus; biological model; complication; Coronavirinae; Coronavirus infection; diagnostic imaging; factual database; human; information processing; laboratory technique; lung; machine learning; pandemic; pneumonia; procedures; radiography; reference value; virology; virus pneumonia; X ray; x-ray computed tomography","High Performance Computing Center of Jilin University; Jilin Provincial Key Laboratory of Big Data Intelligent Computing, (20180622002JC); Jilin University, JLU, (BMCPP-2018-001); Education Department of Jilin Province, (JJKH20180145KJ); Fundamental Research Funds for the Central Universities","Springer Science and Business Media Deutschland GmbH","32959234","2-s2.0-85091267952"
"Davamani K.A.; Robin C.R.R.; Amudha S.; Anbarasi L.J.","Davamani, K. Anita (57210209037); Robin, C.R. Rene (57189274646); Amudha, S. (57217088432); Anbarasi, L. Jani (57222292455)","57210209037; 57189274646; 57217088432; 57222292455","Biomedical image segmentation by deep learning methods","","","","131","154","23","10.1002/9781119785750.ch6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124250605&doi=10.1002%2f9781119785750.ch6&partnerID=40&md5=cc0abfe09b19cd3507ae7f3acb36ecff","Deep learning methods have been employed to predict and analyse various application in medical imaging. Deep Learning technology is a computational algorithm that learns by itself to demonstrate a desired behaviours. Neural network processes the input neurons according to the corresponding types of networks based on algorithm provided and passes it to the hidden layer. Finally, it outputs the result through output layer. Deep learning algorithms tend to be more useful in different applications. It plays important role in biomedical image segmentations such as identifying skin cancer, lung cancer, brain tumour, skin psoriasis, etc. Deep learning includes algorithms like Convolutional Neural Network (CNN), Restricted Boltzmann Machine (RBM), Generative Adversarial Network (GAN), Recurrent Neural Network (RNN), U-Net, V-net, Fully Convolutional Attention Network (FCANET), Docker- powered based deep learning, ResNet18, ResNet50, SqueezeNet and DenseNet-121 which processes on medical images and helps in identifying the defect in earlier stage by helping the physician to start the treatment process. This paper is about the review of deep learning algorithms using medical image segmentation. Future implementations can be performed through additional feature for the existing algorithm with better performance. © 2021 Scrivener Publishing LLC. All rights reserved.","Convolution neural network; Deep learning; Image processing; Image segmentation","","","wiley","","2-s2.0-85124250605"
"Greeshma K.V.; Viji Gripsy J.","Greeshma, K.V. (57207827443); Viji Gripsy, J. (56153136500)","57207827443; 56153136500","A Review on Classification and Retrieval of Biomedical Images Using Artificial Intelligence","","","","47","66","19","10.1007/978-3-030-75220-0_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113298343&doi=10.1007%2f978-3-030-75220-0_3&partnerID=40&md5=8a60c66169c30ef76a75dd4c257d5b3c","Image retrieval and classification are the most prominent area of research in computer vision. Nowadays, bounteous medical images are generated through different types of medical imaging modalities in healthcare systems. It is often very difficult for researchers and doctors to access manage and retrieve images easily. The efficient and effective analysis and usage of heterogeneous biomedical images growing rapidly are a tedious task. Content-based image retrieval (CBIR) is one of the most widely used methods for automatic retrieval of images and widely used in medical images. Abundant research articles are published in different domain of applications related to CBIR and classification. The aim of this study is to provide a road map for researchers by exploring the various approaches, techniques, and algorithms used for medical image retrieval and classification. Feature extraction is the main subject for improving the performance of image classification and retrieval. Bag of visual words techniques and deep convolutional neural networks are widely used in content-based medical image retrieval (CBMIR). The state-of-the-art methods presented in this review are well suited to classify and retrieve multimodal medical images for different body organs. The methods include preprocessing of images, feature extraction, classification, and retrieval steps to develop an efficient biomedical image retrieval system. This chapter briefly reviews the various techniques used for biomedical images, and different methods adopted in classification and retrieval are focused. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Artificial intelligence; Bag of visual words; BoVW; CBIR; CBMIR; CNN; Content-based image retrieval; Content-based medical image retrieval; CT; Deep learning; Image classification; Internet of medical things; IoMT; IOT; Machine learning; MRI; Support vector machine","Biomedical signal processing; Classification (of information); Content based retrieval; Convolutional neural networks; Deep neural networks; Extraction; Feature extraction; Image classification; Image enhancement; Medical imaging; Automatic retrieval; Bag-of-visual-words; Content based medical image retrieval; Content-Based Image Retrieval; Effective analysis; Multimodal medical images; Preprocessing of image; State-of-the-art methods; Search engines","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85113298343"
"Baum Z.M.C.; Hu Y.; Barratt D.C.","Baum, Zachary M. C. (6506021565); Hu, Yipeng (24512208500); Barratt, Dean C. (7005201740)","6506021565; 24512208500; 7005201740","Multimodality Biomedical Image Registration Using Free Point Transformer Networks","12437 LNCS","","","116","125","9","10.1007/978-3-030-60334-2_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092739402&doi=10.1007%2f978-3-030-60334-2_12&partnerID=40&md5=8afaf86e10aa2821ae3b2c6801e94a7c","We describe a point-set registration algorithm based on a novel free point transformer (FPT) network, designed for points extracted from multimodal biomedical images for registration tasks, such as those frequently encountered in ultrasound-guided interventional procedures. FPT is constructed with a global feature extractor which accepts unordered source and target point-sets of variable size. The extracted features are conditioned by a shared multilayer perceptron point transformer module to predict a displacement vector for each source point, transforming it into the target space. The point transformer module assumes no vicinity or smoothness in predicting spatial transformation and, together with the global feature extractor, is trained in a data-driven fashion with an unsupervised loss function. In a multimodal registration task using prostate MR and sparsely acquired ultrasound images, FPT yields comparable or improved results over other rigid and non-rigid registration methods. This demonstrates the versatility of FPT to learn registration directly from real, clinical training data and to generalize to a challenging task, such as the interventional application presented. © 2020, Springer Nature Switzerland AG.","Deep-learning; Point-set registration; Prostate cancer","Bioinformatics; Computer aided analysis; Geometry; Image enhancement; Medical imaging; Metadata; Multilayer neural networks; Pediatrics; Ultrasonics; Vector spaces; Biomedical image registration; Clinical training; Displacement vectors; Interventional procedures; Multimodal registration; Nonrigid registration method; Point-set registrations; Spatial transformation; Image analysis","Centre for Interventional and Surgical Sciences, (203145Z/16/Z); Natural Sciences and Engineering Research Council of Canada, NSERC; University College London, UCL","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85092739402"
"Larrazabal A.J.; Martínez C.; Glocker B.; Ferrante E.","Larrazabal, Agostina J. (57208260242); Martínez, César (8118083200); Glocker, Ben (23396784900); Ferrante, Enzo (55892013900)","57208260242; 8118083200; 23396784900; 55892013900","Post-DAE: Anatomically Plausible Segmentation via Post-Processing with Denoising Autoencoders","39","12","9126830","3813","3820","7","10.1109/TMI.2020.3005297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092739004&doi=10.1109%2fTMI.2020.3005297&partnerID=40&md5=2370e176dd25be3b12b72b563fed9c85","We introduce Post-DAE, a post-processing method based on denoising autoencoders (DAE) to improve the anatomical plausibility of arbitrary biomedical image segmentation algorithms. Some of the most popular segmentation methods (e.g. based on convolutional neural networks or random forest classifiers) incorporate additional post-processing steps to ensure that the resulting masks fulfill expected connectivity constraints. These methods operate under the hypothesis that contiguous pixels with similar aspect should belong to the same class. Even if valid in general, this assumption does not consider more complex priors like topological restrictions or convexity, which cannot be easily incorporated into these methods. Post-DAE leverages the latest developments in manifold learning via denoising autoencoders. First, we learn a compact and non-linear embedding that represents the space of anatomically plausible segmentations. Then, given a segmentation mask obtained with an arbitrary method, we reconstruct its anatomically plausible version by projecting it onto the learnt manifold. The proposed method is trained using unpaired segmentation mask, what makes it independent of intensity information and image modality. We performed experiments in binary and multi-label segmentation of chest X-ray and cardiac magnetic resonance images. We show how erroneous and noisy segmentation masks can be improved using Post-DAE. With almost no additional computation cost, our method brings erroneous segmentations back to a feasible space. © 1982-2012 IEEE.","Anatomical segmentation; autoencoders; convolutional neural networks; learning representations; post-processing","Algorithms; Brain; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Neural Networks, Computer; Bioinformatics; Convolutional neural networks; Decision trees; Image enhancement; Learning systems; Magnetic resonance; Magnetic resonance imaging; Processing; Biomedical image segmentation; Cardiac magnetic resonance images; Connectivity constraints; Intensity information; Latest development; Postprocessing methods; Random forest classifier; Segmentation methods; Article; cardiovascular magnetic resonance; deep learning; denoising autoencoder; human; image processing; image segmentation; quantitative analysis; random forest; segmentation algorithm; thorax radiography; algorithm; brain; diagnostic imaging; image processing; nuclear magnetic resonance imaging; Image segmentation","ANPyCT, (PICT 2016-0651, PICT 2018-03907); AXA Research Fund, AXA; Agencia Nacional de Promoción Científica y Tecnológica, ANPCyT; Universidad Nacional del Litoral, UNL, (CAID-PIC-50220140100084LI, CAID-PIC-50420150100098LI)","Institute of Electrical and Electronics Engineers Inc.","32746125","2-s2.0-85092739004"
"Xing F.; Xie Y.; Su H.; Liu F.; Yang L.","Xing, Fuyong (38461688800); Xie, Yuanpu (56903340500); Su, Hai (44661704600); Liu, Fujun (55541334700); Yang, Lin (55771607100)","38461688800; 56903340500; 44661704600; 55541334700; 55771607100","Deep Learning in Microscopy Image Analysis: A Survey","29","10","8118310","4550","4568","18","10.1109/TNNLS.2017.2766168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035790459&doi=10.1109%2fTNNLS.2017.2766168&partnerID=40&md5=116e43fd3ab898ab2901ec2b8bfdb2a8","Computerized microscopy image analysis plays an important role in computer aided diagnosis and prognosis. Machine learning techniques have powered many aspects of medical investigation and clinical practice. Recently, deep learning is emerging as a leading machine learning tool in computer vision and has attracted considerable attention in biomedical image analysis. In this paper, we provide a snapshot of this fast-growing field, specifically for microscopy image analysis. We briefly introduce the popular deep neural networks and summarize current deep learning achievements in various tasks, such as detection, segmentation, and classification in microscopy image analysis. In particular, we explain the architectures and the principles of convolutional neural networks, fully convolutional networks, recurrent neural networks, stacked autoencoders, and deep belief networks, and interpret their formulations or modelings for specific tasks on various microscopy images. In addition, we discuss the open challenges and the potential trends of future research in microscopy image analysis using deep learning. © 2012 IEEE.","Classification; deep learning; detection; microscopy image analysis; segmentation","Algorithms; Deep Learning; Diagnosis, Computer-Assisted; Female; Humans; Image Processing, Computer-Assisted; Male; Microscopy; Neural Networks (Computer); Surveys and Questionnaires; Classification (of information); Computer aided analysis; Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Error detection; Image segmentation; Learning systems; Medical imaging; Microscopic examination; Neural networks; Recurrent neural networks; Biomedical image analysis; Biomedical imaging; Convolutional networks; Convolutional neural network; Deep belief networks; Learning achievement; Machine learning techniques; Microscopy image analysis; algorithm; artificial neural network; computer assisted diagnosis; female; human; image processing; male; microscopy; procedures; questionnaire; Image analysis","","Institute of Electrical and Electronics Engineers Inc.","29989994","2-s2.0-85035790459"
"Abunadi I.; Senan E.M.","Abunadi, Ibrahim (57189636917); Senan, Ebrahim Mohammed (57222957501)","57189636917; 57222957501","Deep learning and machine learning techniques of diagnosis dermoscopy images for early detection of skin diseases","10","24","3158","","","","10.3390/electronics10243158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121285366&doi=10.3390%2felectronics10243158&partnerID=40&md5=936d2ea8f1d49477b6cd71aec8feb454","With the increasing incidence of severe skin diseases, such as skin cancer, endoscopic medical imaging has become urgent for revealing the internal and hidden tissues under the skin. Diagnostic information to help doctors make an accurate diagnosis is provided by endoscopy devices. Nonetheless, most skin diseases have similar features, which make it challenging for dermatologists to diagnose patients accurately. Therefore, machine and deep learning techniques can have a critical role in diagnosing dermatoscopy images and in the accurate early detection of skin diseases. In this study, systems for the early detection of skin lesions were developed. The performance of the machine learning and deep learning was evaluated on two datasets (e.g., the International Skin Imaging Collaboration (ISIC 2018) and Pedro Hispano (PH2)). First, the proposed system was based on hybrid features that were extracted by three algorithms: local binary pattern (LBP), gray level co-occurrence matrix (GLCM), and wavelet transform (DWT). Such features were then integrated into a feature vector and classified using artificial neural network (ANN) and feedforward neural network (FFNN) classifiers. The FFNN and ANN classifiers achieved superior results compared to the other methods. Accuracy rates of 95.24% for diagnosing the ISIC 2018 dataset and 97.91% for diagnosing the PH2 dataset were achieved using the FFNN algorithm. Second, convolutional neural networks (CNNs) (e.g., ResNet-50 and AlexNet models) were applied to diagnose skin diseases using the transfer learning method. It was found that the ResNet-50 model fared better than AlexNet. Accuracy rates of 90% for diagnosing the ISIC 2018 dataset and 95.8% for the PH2 dataset were reached using the ResNet-50 model. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Biomedical image processing; Deep learning; Dermoscopy images; Machine learning; Melanoma; Skin diseases","","Prince Sultan University, PSU","MDPI","","2-s2.0-85121285366"
"Zeng C.; Nan Y.; Xu F.; Lei Q.; Li F.; Chen T.; Liang S.; Hou X.; Lv B.; Liang D.; Luo W.; Lv C.; Li X.; Xie G.; Liu Z.","Zeng, Caihong (57202571023); Nan, Yang (57217028826); Xu, Feng (56527573800); Lei, Qunjuan (57215660069); Li, Fengyi (57217029448); Chen, Tingyu (57208481340); Liang, Shaoshan (55173691300); Hou, Xiaoshuai (56982264100); Lv, Bin (58717185000); Liang, Dandan (57188857554); Luo, WeiLi (57217735405); Lv, Chuanfeng (57216090925); Li, Xiang (56044095900); Xie, Guotong (14042931500); Liu, Zhihong (56118017700)","57202571023; 57217028826; 56527573800; 57215660069; 57217029448; 57208481340; 55173691300; 56982264100; 58717185000; 57188857554; 57217735405; 57216090925; 56044095900; 14042931500; 56118017700","Identification of glomerular lesions and intrinsic glomerular cell types in kidney diseases via deep learning","252","1","","53","64","11","10.1002/path.5491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087566915&doi=10.1002%2fpath.5491&partnerID=40&md5=1a9dfe409d8733da80f37831df2f0886","Identification of glomerular lesions and structures is a key point for pathological diagnosis, treatment instructions, and prognosis evaluation in kidney diseases. These time-consuming tasks require a more accurate and reproducible quantitative analysis method. We established derivation and validation cohorts composed of 400 Chinese patients with immunoglobulin A nephropathy (IgAN) retrospectively. Deep convolutional neural networks and biomedical image processing algorithms were implemented to locate glomeruli, identify glomerular lesions (global and segmental glomerular sclerosis, crescent, and none of the above), identify and quantify different intrinsic glomerular cells, and assess a network-based mesangial hypercellularity score in periodic acid–Schiff (PAS)-stained slides. Our framework achieved 93.1% average precision and 94.9% average recall for location of glomeruli, and a total Cohen's kappa of 0.912 [95% confidence interval (CI), 0.892–0.932] for glomerular lesion classification. The evaluation of global, segmental glomerular sclerosis, and crescents achieved Cohen's kappa values of 1.0, 0.776, 0.861, and 95% CI of (1.0, 1.0), (0.727, 0.825), (0.824, 0.898), respectively. The well-designed neural network can identify three kinds of intrinsic glomerular cells with 92.2% accuracy, surpassing the about 5–11% average accuracy of junior pathologists. Statistical interpretation shows that there was a significant difference (P value < 0.0001) between this analytic renal pathology system (ARPS) and four junior pathologists for identifying mesangial and endothelial cells, while that for podocytes was similar, with P value = 0.0602. In addition, this study indicated that the ratio of mesangial cells, endothelial cells, and podocytes within glomeruli from IgAN was 0.41:0.36:0.23, and the performance of mesangial score assessment reached a Cohen's kappa of 0.42 and 95% CI (0.18, 0.69). The proposed computer-aided diagnosis system has feasibility for quantitative analysis and auxiliary recognition of glomerular pathological features. © 2020 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of Pathological Society of Great Britain and Ireland. © 2020 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of Pathological Society of Great Britain and Ireland.","computational pathology; glomerular lesion classification; IgAN; intrinsic glomerular cells identification; mesangial hypercellularity score assessment","Adult; Deep Learning; Diagnosis, Computer-Assisted; Female; Glomerulonephritis, IGA; Humans; Kidney Diseases; Kidney Glomerulus; Male; Mesangial Cells; Neural Networks, Computer; Podocytes; adult; Article; cellular distribution; Chinese; cohort analysis; convolutional neural network; deep learning; diagnostic accuracy; diagnostic test accuracy study; feasibility study; female; focal glomerulosclerosis; glomerular structure; glomerulopathy; glomerulus epithelium cell; histopathology; human; human tissue; imaging algorithm; immunoglobulin A nephropathy; major clinical study; male; mesangium cell; pathologist; periodic acid Schiff stain; podocyte; priority journal; quantitative analysis; rapidly progressive glomerulonephritis; retrospective study; sensitivity and specificity; validation study; computer assisted diagnosis; glomerulus; immunoglobulin A nephropathy; kidney disease; mesangium cell; pathology; podocyte","Science, Technology and Education of Jiangsu Province Medical Key Talent, (ZDRCA2016098); National Natural Science Foundation of China, NSFC, (81570644); National Natural Science Foundation of China, NSFC; National Key Research and Development Program of China, NKRDPC, (2016YFC0901202); National Key Research and Development Program of China, NKRDPC","John Wiley and Sons Ltd","32542677","2-s2.0-85087566915"
"Mergin A.A.; Premi M.S.G.","Mergin, A. Ancy (57202237260); Premi, M. S. Godwin (36809617400)","57202237260; 36809617400","Convolutional Neural Networks (CNN) with Quantum-Behaved Particle Swarm Optimization (QPSO)-Based Medical Image Fusion","","","2340005","","","","10.1142/S0219467823400053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136595001&doi=10.1142%2fS0219467823400053&partnerID=40&md5=cab94aca071858a08e6ef09a744c0f3f","Medical imaging fusion is the process of combining pictures from various imaging modalities to create a single image that may be used in clinical settings. Robust methods for merging image data from several modalities are being developed in the field of multimodal medical imaging. Deep learning (DL) has been widely researched in two areas: pattern recognition and image processing. We will demonstrate a multimodal image fusion with DL implementation that considers the characteristics of medical diagnostic imaging as well as the demands of clinical practice. For the past three years, pixel-level picture fusion has been a hot topic. This paper proposes a new multimodal medical picture fusion technique for a wide range of medical diagnostic challenges. Image fusion is crucial in biomedical research and clinical diagnostics for biomedical image processing and therapy planning. The most convincing argument for fusion is obtaining a significant amount of critical information from the input photographs. We show how a well-organized multimodal medical image fusion technique can be utilized to integrate computed tomography (CT) and magnetic resonance imaging (MRI) data in this study. Using convolutional neural networks (CNNs), the quantum-behaved particle swarm optimization (QPSO) algorithm was used to create a method for integrating multimodal medical pictures. In order to improve the overall quality and efficiency of QPSO, it was chosen to add the metrics of image entropy, standard deviation, average gradient (AG), spatial frequency (SF), and visual information fidelity (VIF). In experiments, multimodal medical images are utilized to evaluate a variety of parameters, including performance and algorithm stability. When compared to the other possibilities, the recommended technique outperformed them in the evaluations. On a range of quantitative metrics, this method outperforms the alternatives.  © 2023 World Scientific Publishing Company.","Convolutional neural networks (CNN); image entropy (EN); image fusion; MRI; QPSO; visual information fidelity (VIF)","","","World Scientific","","2-s2.0-85136595001"
"Kamrul Hasan S.M.; Linte C.A.","Kamrul Hasan, S.M. (57188664990); Linte, Cristian A. (57202997616)","57188664990; 57202997616","A Modified U-Net Convolutional Network Featuring a Nearest-neighbor Re-sampling-based Elastic-Transformation for Brain Tissue Characterization and Segmentation","","","8576421","","","","10.1109/WNYIPW.2018.8576421","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060302593&doi=10.1109%2fWNYIPW.2018.8576421&partnerID=40&md5=fa5af0a5b01453035d8474470fe52b2e","The detection and segmentation of brain tumors from Magnetic Resonance Imaging (MRI) is a very challenging task, despite the availability of modern medical image processing tools. Neuro-radiologists still diagnose deadly brain cancers such as even glioblastoma using manual segmentation. This approach is not only tedious, but also highly variable, featuring limited accuracy and precision, and hence raising the need for more robust, automated techniques. Deep learning methods such as the U-Net deep convolutional neural networks have been widely used in biomedical image segmentation. Although this model was demonstrated to yield desirable results on the BRATS 2015 dataset by using a pixel-wise segmentation map of the input image as an auto-encoder, which assures best segmentation accuracy, the output only showed limited accuracy and robustness for a number of cases. The goal of this work was to improve the U-net model by replacing the de-convolution component with an up-sampled by the Nearest-neighbor algorithm and also employing an elastic transformation to augment the training dataset to render the model more robust, especially for the segmentation of low-grade tumors. The proposed Nearest-Neighbor Re-sampling Based Elastic-Transformed (NNRET) U-net Deep CNN framework has been trained on 285 glioma patients BRATS 2017 MR dataset available through the MICCAI 2017 grand challenge. The framework has been tested on 146 patients using Dice similarity coefficient (DSC) Intersection over Union (IoU) performance metrics and outweighed the classic U-net model. © 2018 IEEE.","Brain tissue segmentation; deep convolutional networks; modified U-net; nearest-neighbor interpolation","Brain; Convolution; Deep neural networks; Magnetic resonance imaging; Medical imaging; Neural networks; Tumors; Biomedical image segmentation; Brain tissue segmentations; Convolutional networks; Deep convolutional neural networks; Magnetic Resonance Imaging (MRI); modified U-net; Nearest neighbor algorithm; Nearest neighbor interpolation; Image segmentation","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85060302593"
"Alassaf A.; Sikkandar M.Y.","Alassaf, Ahmad (57191228351); Sikkandar, Mohamed Yacin (57202716139)","57191228351; 57202716139","Intelligent Deep Transfer Learning Based Malaria Parasite Detection and Classification Model Using Biomedical Image","72","3","","5273","5285","12","10.32604/cmc.2022.025577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128662756&doi=10.32604%2fcmc.2022.025577&partnerID=40&md5=10a96545be2818f071bdb082445ac197","Malaria is a severe disease caused by Plasmodium parasites, which can be detected through blood smear images. The early identification of the disease can effectively reduce the severity rate. Deep learning (DL) models can be widely employed to analyze biomedical images, thereby minimizing the misclassification rate. With this objective, this study developed an intelligent deep-transfer-learning-based malaria parasite detection and classification (IDTL-MPDC) model on blood smear images. The proposed IDTL-MPDC technique aims to effectively determine the presence ofmalarial parasites in blood smear images. In addition, the IDTL-MPDC technique derives median filtering (MF) as a pre-processing step. In addition, a residual neural network (Res2Net) model was employed for the extraction of feature vectors, and its hyperparameters were optimally adjusted using the differential evolution (DE) algorithm. The k-nearest neighbor (KNN) classifier was used to assign appropriate classes to the blood smear images. The optimal selection of Res2Net hyperparameters by the DE model helps achieve enhanced classification outcomes. A wide range of simulation analyses of the IDTL-MPDC technique are carried out using a benchmark dataset, and its performance seems to be highly accurate (95.86%), highly sensitive (95.82%), highly specific (95.98%), with a high F1 score (95.69%), and high precision (95.86%), and it has been proven to be better than the other existing methods. © 2022 Tech Science Press. All rights reserved.","biomedical images; blood smear images; Computer-aided diagnosis; deep learning; malaria parasites","Benchmarking; Blood; Computer aided diagnosis; Computer aided instruction; Deep learning; Evolutionary algorithms; Image classification; Median filters; Nearest neighbor search; Biomedical images; Blood smear image; Blood smears; Classification models; Classification technique; Deep learning; Detection models; Hyper-parameter; Malaria parasite; Transfer learning; Diseases","Majmaah University, MU, (R-2022-76)","Tech Science Press","","2-s2.0-85128662756"
"Onofrey J.A.; Staib L.H.; Huang X.; Zhang F.; Papademetris X.; Metaxas D.; Rueckert D.; Duncan J.S.","Onofrey, John A. (55823011300); Staib, Lawrence H. (7005557159); Huang, Xiaojie (55500290600); Zhang, Fan (57199243418); Papademetris, Xenophon (6602197282); Metaxas, Dimitris (7006359060); Rueckert, Daniel (7004895812); Duncan, James S. (57203363835)","55823011300; 7005557159; 55500290600; 57199243418; 6602197282; 7006359060; 7004895812; 57203363835","Sparse Data-Driven Learning for Effective and Efficient Biomedical Image Segmentation","22","","","127","153","26","10.1146/annurev-bioeng-060418-052147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086052462&doi=10.1146%2fannurev-bioeng-060418-052147&partnerID=40&md5=3b2a39eb9a6e2673471e12f4a78eb877","Sparsity is a powerful concept to exploit for high-dimensional machine learning and associated representational and computational efficiency. Sparsity is well suited for medical image segmentation. We present a selection of techniques that incorporate sparsity, including strategies based on dictionary learning and deep learning, that are aimed at medical image segmentation and related quantification. © 2020 by Annual Reviews. All rights reserved.","dictionary learning; image representation; image segmentation; machine learning; medical image analysis; Sparsity","Algorithms; Animals; Brain; Deep Learning; Dogs; Echocardiography; Heart Ventricles; Humans; Image Processing, Computer-Assisted; Imaging, Three-Dimensional; Machine Learning; Models, Theoretical; Neural Networks, Computer; Tomography, X-Ray Computed; Computational efficiency; Deep learning; Medical image processing; Biomedical image segmentation; Dictionary learning; High-dimensional; Sparse data; deep learning; image analysis; image segmentation; review; algorithm; animal; brain; diagnostic imaging; dog; echocardiography; heart ventricle; human; image processing; machine learning; procedures; theoretical model; three-dimensional imaging; x-ray computed tomography; Image segmentation","National Institutes of Health, NIH, (R01CA206180, R41CA224888); National Institutes of Health, NIH; National Heart, Lung, and Blood Institute, NHLBI, (R01HL121226); National Heart, Lung, and Blood Institute, NHLBI","Annual Reviews Inc.","32169002","2-s2.0-85086052462"
"Anusha C.; Avadhani P.S.","Anusha, Chamarty (57211622942); Avadhani, P.S. (57204399665)","57211622942; 57204399665","Optimal accuracy zone identification in object detection technique-a learning rate methodology","9","1","","6470","6476","6","10.35940/ijeat.A2258.109119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074655906&doi=10.35940%2fijeat.A2258.109119&partnerID=40&md5=00034cb65b7b053da8703fb28736ad43","In the recent past, Deep Learning models [1] are predominantly being used in Object Detection algorithms due to their accurate Image Recognition capability. These models extract features from the input images and videos [2] for identification of objects present in them. Various applications of these models include Image Processing, Video analysis, Speech Recognition, Biomedical Image Analysis, Biometric Recognition, Iris Recognition, National Security applications, Cyber Security, Natural Language Processing [3], Weather Forecasting applications, Renewable Energy Generation Scheduling etc. These models utilize the concept of Convolutional Neural Network (CNN) [3], which constitutes several layers of artificial neurons. The accuracy of Deep Learning models [1] depends on various parameters such as ‘Learning-rate’, ‘Training batch size’, ‘Validation batch size’, ‘Activation Function’, ‘Drop-out rate’ etc. These parameters are known as Hyper-Parameters. Object detection accuracy depends on selection of Hyper-parameters and these in-turn decides the optimum accuracy. Hence, finding the best values for these parameters is a challenging task. Fine-Tuning is a process used for selection of a suitable Hyper-Parameter value for improvement of object detection accuracy. Selection of an inappropriate Hyper-Parameter value, leads to Over-Fitting or Under-Fitting of data. Over-Fitting is a case, when training data is larger than the required, which results in learning noise and inaccurate object detection. Under-fitting is a case, when the model is unable to capture the trend of the data and which leads to more erroneous results in testing or training data. In this paper, a balance between Over-fitting and Under-fitting is achieved by varying the ‘Learning rate’ of various Deep Learning models. Four Deep Learning Models such as VGG16, VGG19, InceptionV3 and Xception are considered in this paper for analysis purpose. The best zone of Learning-rate for each model, in respect of maximum Object Detection accuracy, is analyzed. In this paper a dataset of 70 object classes is taken and the prediction accuracy is analyzed by changing the ‘Learning-rate’ and keeping the rest of the Hyper-Parameters constant. This paper mainly concentrates on the impact of ‘Learning-rate’ on accuracy and identifies an optimum accuracy zone in Object Detection. © BEIESP.","Convolution neural network; Deep learning; Hyper-parameter; InceptionV3; Learning-rate; Object detection; VGG-16; VGG-19; Xception","","","Blue Eyes Intelligence Engineering and Sciences Publication","","2-s2.0-85074655906"
"Azran A.; Schclar A.; Saabni R.","Azran, Adi (57234967700); Schclar, Alon (8319691800); Saabni, Raid (35198993400)","57234967700; 8319691800; 35198993400","Text line extraction using deep learning and minimal sub seams","","","3474941","","","","10.1145/3469096.3474941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113610367&doi=10.1145%2f3469096.3474941&partnerID=40&md5=c41fc70ea9926e11e979de88c2cd9cdf","Accurate text line extraction is a vital prerequisite for efficient and successful text recognition systems ranging from keywords/phrases searching to complete conversion to text. In many cases, the proposed algorithms target binary pre-processed versions of the image, which may cause insufficient results due to poor quality document images. Recently, more papers present solutions that work directly on gray-level images [1,2,7,12,15]. In this paper, we present a novel robust, and efficient algorithm to extract text-lines directly from gray-level document images. The proposed approach uses a combination of two variants of Convolutional Neural Network (CNNs), followed by minimal energy seam extraction. The first ConvNet is a modified version of the autoencoder used for biomedical image segmentation [8]. The second is a deep convolutional Neural Network, working on overlapping vertical slices of the original image. The two variants are combined to one neural net after re-attaching the resulting slices of the second net. The merged results of the two nets are used as a preprocessed image to obtain an energy map for a second phase. In the second step, we use the algorithm presented in [2], to track minimal energy sub-seams accumulated to perform a full local minimal/maximal separating and medial seam defining the text baselines and the text line regions. We have tested our approach on multi-lingual various datasets written at a range of image quality based on the ICDAR datasets.  © 2021 ACM.","convolutional neural networks; historical document image analysis; image processing; line extraction; local projection profile; minimal seams; seam carving; text line extraction","Character recognition; Convolution; Convolutional neural networks; Deep neural networks; Digital image storage; Extraction; Image segmentation; Biomedical image segmentation; Document images; Gray level image; Minimal energy; Original images; Text recognition; Text-line extractions; Vertical slices; Deep learning","","Association for Computing Machinery, Inc","","2-s2.0-85113610367"
"Guo K.; Wu J.; Wan W.; Li L.; Wang T.; Zhu X.; Qu L.","Guo, Kaixuan (57215183906); Wu, Jun (57266847900); Wan, Wan (57285346200); Li, Longfei (57223305256); Wang, Tao (58736748500); Zhu, Xingliang (57215524940); Qu, Lei (36175185400)","57215183906; 57266847900; 57285346200; 57223305256; 58736748500; 57215524940; 36175185400","Biomedical image segmentation based on classification supervision","","","","22","27","5","10.1145/3473258.3473262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121702646&doi=10.1145%2f3473258.3473262&partnerID=40&md5=bc8916f30d4067e7b93d1ddfecd0f51f","Convolutional neural networks (CNN) has been widely used in the biomedical image segmentation (BIS) for their remarkable feature representation capability. However, there are often segmentation errors and missing segmentation problems in biomedical image segmentation based on deep learning. In this paper, we propose a full convolutional neural network, which is assisted by classification supervision based on segmentation network. The algorithm first obtains a segmentation result through a basic segmentation network. Then a Classification Supervision Module (CSM) is designed to enable the network to judge whether each slicer contains lesions from the perspective of classification. In this way we allow the network to take advantage of more global information. Experimental results on several available databases demonstrate the effectiveness and advancement of the proposed method.  © 2021 ACM.","Biomedical image; Classification supervision; Convolutional neural network; Image segmentation","Convolution; Convolutional neural networks; Deep learning; Image classification; Biomedical image segmentation; Biomedical images; Classification supervision; Convolutional neural network; Feature representation; Global informations; Images segmentations; Segmentation error; Segmentation results; Image segmentation","University Synergy Innovation Program of Anhui Province, (GXXT-2019-008); National Natural Science Foundation of China, NSFC, (61871411, 61901003); Natural Science Foundation of Anhui Province, (1908085QF255)","Association for Computing Machinery","","2-s2.0-85121702646"
"Račić L.; Popović T.; Čakić S.; Šandi S.","Račić, Luka (57223008261); Popović, Tomo (7006324784); Čakić, Stevan (57216726692); Šandi, Stevan (57193401703)","57223008261; 7006324784; 57216726692; 57193401703","Pneumonia Detection Using Deep Learning Based on Convolutional Neural Network","","","9390137","","","","10.1109/IT51528.2021.9390137","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104431624&doi=10.1109%2fIT51528.2021.9390137&partnerID=40&md5=220b902e2ad99c28a98cb623fc75984f","Artificial intelligence has found its use in various fields during the course of its development, especially in recent years with the enormous increase in available data. Its main task is to assist making better, faster and more reliable decisions. Artificial intelligence and machine learning are increasingly finding their application in medicine. This is especially true for medical fields that utilize various types of biomedical images and where diagnostic procedures rely on collecting and processing a large number of digital images. The application of machine learning in processing of medical images helps with consistency and boosts accuracy in reporting. This paper describes the use of machine learning algorithms to process chest X-ray images in order to support the decision making process in determining the correct diagnosis. Specifically, the research is focused on the use of deep learning algorithm based on convolutional neural network in order to build a processing model. This model has the task to help with a classification problem that is detecting whether a chest X-ray shows changes consistent with pneumonia or not, and classifying the X-ray images in two groups depending on the detection results.  © 2021 IEEE.","artificial intelligence; artificial intelligence; convolutional neural network; deep learning; image processing; convolutional neural network; deep learning; image processing, machine learning; machine learning; pneumonia detection; pneumonia detection","Convolution; Convolutional neural networks; Decision making; Deep learning; Diagnosis; Learning systems; Medical image processing; Biomedical images; Chest X-ray image; Chest x-rays; Decision making process; Diagnostic procedure; Digital image; Medical fields; Processing model; Learning algorithms","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85104431624"
"Ali M.; Gilani S.O.; Waris A.; Zafar K.; Jamil M.","Ali, Mahnoor (57221004265); Gilani, Syed Omer (57194679489); Waris, Asim (54894010500); Zafar, Kashan (57215656557); Jamil, Mohsin (57616931600)","57221004265; 57194679489; 54894010500; 57215656557; 57616931600","Brain Tumour Image Segmentation Using Deep Networks","8","","9171998","153589","153598","9","10.1109/ACCESS.2020.3018160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090585705&doi=10.1109%2fACCESS.2020.3018160&partnerID=40&md5=5d761bd6584806739c5d451e25b10e58","Automated segmentation of brain tumour from multimodal MR images is pivotal for the analysis and monitoring of disease progression. As gliomas are malignant and heterogeneous, efficient and accurate segmentation techniques are used for the successful delineation of tumours into intra-tumoural classes. Deep learning algorithms outperform on tasks of semantic segmentation as opposed to the more conventional, context-based computer vision approaches. Extensively used for biomedical image segmentation, Convolutional Neural Networks have significantly improved the state-of-the-art accuracy on the task of brain tumour segmentation. In this paper, we propose an ensemble of two segmentation networks: a 3D CNN and a U-Net, in a significant yet straightforward combinative technique that results in better and accurate predictions. Both models were trained separately on the BraTS-19 challenge dataset and evaluated to yield segmentation maps which considerably differed from each other in terms of segmented tumour sub-regions and were ensembled variably to achieve the final prediction. The suggested ensemble achieved dice scores of 0.750, 0.906 and 0.846 for enhancing tumour, whole tumour, and tumour core, respectively, on the validation set, performing favourably in comparison to the state-of-the-art architectures currently available. © 2013 IEEE.","BraTS; CNN; Deep learning; ensembling; medical imaging; segmentation; U-Net","Brain; Convolutional neural networks; Deep learning; Image enhancement; Learning algorithms; Magnetic resonance imaging; Predictive analytics; Semantics; Tumors; Accurate prediction; Automated segmentation; Biomedical image segmentation; Disease progression; Segmentation map; Segmentation techniques; Semantic segmentation; State of the art; Image segmentation","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85090585705"
"Isensee F.; Jaeger P.F.; Kohl S.A.A.; Petersen J.; Maier-Hein K.H.","Isensee, Fabian (57194378532); Jaeger, Paul F. (57201075948); Kohl, Simon A. A. (57204142298); Petersen, Jens (56343682900); Maier-Hein, Klaus H. (55647018100)","57194378532; 57201075948; 57204142298; 56343682900; 55647018100","nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation","18","2","","203","211","8","10.1038/s41592-020-01008-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097254681&doi=10.1038%2fs41592-020-01008-z&partnerID=40&md5=ec84e152cb0adba256bd723c59b59329","Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training. © 2020, The Author(s), under exclusive licence to Springer Nature America, Inc.","","Algorithms; Deep Learning; Image Processing, Computer-Assisted; Neural Networks, Computer; article; competition; deep learning; image segmentation; algorithm; image processing; procedures","","Nature Research","33288961","2-s2.0-85097254681"
"Wang Y.; He Z.; Xie P.; Yang C.; Zhang Y.; Li F.; Chen X.; Lu K.; Li T.; Zhou J.; Zuo K.","Wang, Yuan (57219774374); He, Zhiyou (57191858920); Xie, Peizhen (57218281149); Yang, Canqun (13408914200); Zhang, Yu (59072202600); Li, Fangfang (56039980600); Chen, Xiang (57212086254); Lu, Kai (8685091500); Li, Tao (56965840800); Zhou, Jiao (57218285366); Zuo, Ke (24588344100)","57219774374; 57191858920; 57218281149; 13408914200; 59072202600; 56039980600; 57212086254; 8685091500; 56965840800; 57218285366; 24588344100","Segment Medical Image Using U-Net Combining Recurrent Residuals and Attention","633 LNEE","","","77","86","9","10.1007/978-981-15-5199-4_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088573030&doi=10.1007%2f978-981-15-5199-4_8&partnerID=40&md5=1e6a6402f1c7e5647e76b659c5f9b5eb","Medical image segmentation is the key to decide the issue of medical images in clinical practice that can provide a reliable basis. The development of medical image segmentation technology not only affects the development of other related technologies in medical image processing, such as visualization 3D reconstruction, but in the analysis of biomedical images also occupies an extremely important position. With the application of deep learning algorithms in medical image segmentation, medical image segmentation technology has made significant progress. In this paper, we discuss the segmentation method of 2D medical images about U-net variant network. Use the U-net combing recurrent residual model and attention model to segmented the image can get better result. © 2020, Springer Nature Singapore Pte Ltd.","Attention; Medical image; Residual; Segmentation; U-net","Computer aided diagnosis; Engineering education; Image segmentation; Learning algorithms; Recurrent neural networks; Three dimensional computer graphics; 3D reconstruction; Attention model; Biomedical images; Clinical practices; Residual model; Segmentation methods; Medical image processing","","Springer","","2-s2.0-85088573030"
"Godec P.; Pančur M.; Ilenič N.; Čopar A.; Stražar M.; Erjavec A.; Pretnar A.; Demšar J.; Starič A.; Toplak M.; Žagar L.; Hartman J.; Wang H.; Bellazzi R.; Petrovič U.; Garagna S.; Zuccotti M.; Park D.; Shaulsky G.; Zupan B.","Godec, Primož (56377091000); Pančur, Matjaž (6505935502); Ilenič, Nejc (57211229867); Čopar, Andrej (56248208600); Stražar, Martin (55603807500); Erjavec, Aleš (26036093300); Pretnar, Ajda (57209645602); Demšar, Janez (55075851300); Starič, Anže (55884822000); Toplak, Marko (35118222500); Žagar, Lan (36100591700); Hartman, Jan (57211229987); Wang, Hamilton (57211227150); Bellazzi, Riccardo (58709404600); Petrovič, Uroš (55917218200); Garagna, Silvia (7004583165); Zuccotti, Maurizio (56256935600); Park, Dongsu (8437663600); Shaulsky, Gad (7003920656); Zupan, Blaž (7003934784)","56377091000; 6505935502; 57211229867; 56248208600; 55603807500; 26036093300; 57209645602; 55075851300; 55884822000; 35118222500; 36100591700; 57211229987; 57211227150; 58709404600; 55917218200; 7004583165; 56256935600; 8437663600; 7003920656; 7003934784","Democratized image analytics by visual programming through integration of deep models and small-scale machine learning","10","1","4551","","","","10.1038/s41467-019-12397-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073058466&doi=10.1038%2fs41467-019-12397-x&partnerID=40&md5=3a477570104ac85aa863c7641f976fe8","Analysis of biomedical images requires computational expertize that are uncommon among biomedical scientists. Deep learning approaches for image analysis provide an opportunity to develop user-friendly tools for exploratory data analysis. Here, we use the visual programming toolbox Orange (http://orange.biolab.si) to simplify image analysis by integrating deep-learning embedding, machine learning procedures, and data visualization. Orange supports the construction of data analysis workflows by assembling components for data preprocessing, visualization, and modeling. We equipped Orange with components that use pre-trained deep convolutional networks to profile images with vectors of features. These vectors are used in image clustering and classification in a framework that enables mining of image sets for both novel and experienced users. We demonstrate the utility of the tool in image analysis of progenitor cells in mouse bone healing, identification of developmental competence in mouse oocytes, subcellular protein localization in yeast, and developmental morphology of social amoebae. © 2019, The Author(s).","","Animals; Computational Biology; Dictyostelium; Green Fluorescent Proteins; Image Processing, Computer-Assisted; Internet; Life Cycle Stages; Machine Learning; Mice, Transgenic; Neural Networks, Computer; Oocytes; Reproducibility of Results; Saccharomyces cerevisiae; Saccharomyces cerevisiae Proteins; green fluorescent protein; Saccharomyces cerevisiae protein; algorithm; biochemical composition; data assimilation; data mining; image analysis; machine learning; numerical model; protein; visualization; animal cell; animal experiment; animal model; Article; cellular distribution; convolutional neural network; data analysis; data classification; data clustering; data mining; data processing; data visualization; deep learning; Dictyostelium discoideum; embedding; female; fracture healing; image analysis; model; mouse; nonhuman; oocyte; protein localization; stem cell; workflow; yeast; animal; biology; cytology; Dictyostelium; genetics; growth, development and aging; image processing; Internet; life cycle stage; machine learning; metabolism; procedures; reproducibility; Saccharomyces cerevisiae; transgenic mouse","National Institute of General Medical Sciences, NIGMS, (R35GM118016)","Nature Publishing Group","31591416","2-s2.0-85073058466"
"Tang X.; Spaink H.A.J.; Wijk R.C.V.; Verbeek F.J.","Tang, Xiaoqin (58836185400); Spaink, Hermes A. J. (57761041300); Wijk, Rob C. Van (57194397640); Verbeek, Fons J. (6701677480)","58836185400; 57761041300; 57194397640; 6701677480","Segmentation-Driven Optimization for Iterative Reconstruction in Optical Projection Tomography: An Exploration","6","","9262061","1537","1547","10","10.1109/TCI.2020.3038489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097195004&doi=10.1109%2fTCI.2020.3038489&partnerID=40&md5=62b1094292dfb8fbb83d2e8175c03a5b","Three-dimensional reconstruction of tomograms from optical projection microscopy is confronted with several drawbacks. In this paper we employ iterative reconstruction algorithms to avoid streak artefacts in the reconstruction and explore possible ways to optimize two parameters of the algorithms, i.e., iteration number and initialization, in order to improve the reconstruction performance. As benchmarks for direct reconstruction evaluation in optical projection tomography are absent, we consider the assessment through the performance of the segmentation on the 3D reconstruction. In our explorative experiments we use the zebrafish model system which is a typical specimen for use in optical projection tomography system; and as such frequently used. In this manner data can be easily obtained from which a benchmark set can be built. For the segmentation approach we apply a two-dimensional U-net convolutional neural network because it is recognized to have a good performance in biomedical image segmentation. In order to prevent the training from getting stuck in local minima, a novel learning rate schema is proposed. This optimization achieves a lower training loss during the training process, as compared to an optimal constant learning rate. Our experiments demonstrate that the approach to the benchmarking of iterative reconstruction via results of segmentation is very useful. It contributes an important tool to the development of computational tools for optical projection tomography.  © 2015 IEEE.","Convolutional neural network; Deep learning; Image reconstruction; Image segmentation; OPT","Benchmarking; Computerized tomography; Convolutional neural networks; Image segmentation; Iterative methods; Optical projectors; Biomedical image segmentation; Computational tools; Iteration numbers; Iterative reconstruction; Iterative reconstruction algorithms; Optical projection tomography; Optical projections; Three-dimensional reconstruction; Image reconstruction","China Scholarship Council, CSC","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85097195004"
"Xiang S.; Liang Q.; Hu Y.; Tang P.; Coppola G.; Zhang D.; Sun W.","Xiang, Shao (57203872779); Liang, Qiaokang (35174463400); Hu, Yucheng (57205548591); Tang, Pen (57209741175); Coppola, Gianmarc (36134250400); Zhang, Dan (58846287300); Sun, Wei (57161531200)","57203872779; 35174463400; 57205548591; 57209741175; 36134250400; 58846287300; 57161531200","AMC-Net: Asymmetric and multi-scale convolutional neural network for multi-label HPA classification","178","","","275","287","12","10.1016/j.cmpb.2019.07.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068552534&doi=10.1016%2fj.cmpb.2019.07.009&partnerID=40&md5=97a5af5007322b59ccd7e20ac6640481","Background and objectives: The multi-label Human Protein Atlas (HPA) classification can yield a better understanding of human diseases and help doctors to enhance the automatic analysis of biomedical images. The existing automatic protein recognition methods have been limited to single pattern. Therefore, an automatic multi-label human protein atlas recognition system with satisfactory performance should be conducted. This work aims to build an automatic recognition system for multi-label human protein atlas classification based on deep learning. Methods: In this work, an automatic feature extraction and multi-label classification framework is proposed. Specifically, an asymmetric and multi-scale convolutional neural network is designed for HPA classification. Furthermore, this work introduces a combined loss that consists of the binary cross-entropy and F1-score losses to improve identification performance. Results: Rigorous experiments are conducted to estimate the proposed system. In particular, unlike the current automatic identification systems, which focus on a limited number of patterns, the proposed method is capable of classifying mixed patterns of proteins in microscope images and can handle the subcellular multi-label protein classification task including 28 subcellular localization patterns. The proposed framework based on deep convolutional neural network outperformed the existing approaches with a F1-score of 0.823, which illustrates the robustness and effectiveness of the proposed system. Conclusion: This study proposed a high-performance recognition system for protein atlas classification based on deep learning, and it achieved an automatic multi-label human protein atlas identification framework with superior performance than previous studies. © 2019 Elsevier B.V.","Convolutional neural network; Deep learning; Human protein atlas; Multi-label classification","Algorithms; Cell Nucleus; Databases, Protein; False Positive Reactions; Humans; Image Processing, Computer-Assisted; Microscopy; Microscopy, Fluorescence; Microtubules; Neural Networks, Computer; Pattern Recognition, Automated; Phenotype; Probability; Proteins; Reproducibility of Results; Automation; Classification (of information); Convolution; Deep learning; Image enhancement; Neural networks; Proteins; protein; Automatic feature extraction; Automatic identification system; Automatic recognition system; Convolutional neural network; Human proteins; Multi label classification; Multi-label proteins; Subcellular localizations; Article; autoanalysis; cellular distribution; classification algorithm; data analysis; deep learning; feature extraction; human protein atlas; microscope image; protein analysis; qualitative analysis; receptive field; algorithm; automated pattern recognition; cell nucleus; chemistry; false positive result; fluorescence microscopy; human; image processing; metabolism; microscopy; microtubule; phenotype; physiology; probability; procedures; protein database; reproducibility; Deep neural networks","Chang-Zhu-Tan National Indigenous Innovation Demonstration Zone Project, (2017XK2102); National Nature Science Foundation of China; National Natural Science Foundation of China, NSFC, (61673163); National Natural Science Foundation of China, NSFC; Changzhou Key Laboratory of Special Robot and Intelligent Technology, (IRT2018003); Changzhou Key Laboratory of Special Robot and Intelligent Technology","Elsevier Ireland Ltd","31416555","2-s2.0-85068552534"
"Siregar O.R.; Sasongko P.S.; Endah S.N.","Siregar, Obed Reinhard (58062863800); Sasongko, Priyo Sidik (56027168300); Endah, Sukmawati Nur (35731392400)","58062863800; 56027168300; 35731392400","Optic Disc Segmentation on Eye Retinal Image with U-Net Convolutional Neural Network Architecture","2021-November","","","69","74","5","10.1109/ICICoS53627.2021.9651795","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146199704&doi=10.1109%2fICICoS53627.2021.9651795&partnerID=40&md5=2178038a33b09bf16207307879114e6f","Glaucoma is a disease that causes blindness of the eye. This blindness occurs due to failure of tissue embryogenesis in the eye drainage structure. There are various approaches to early detection of glaucoma. One of them is the optic disc and optic cup segmentation. However, the delineation of the boundaries of the optic disc and the optic cup by experts is highly subjective, time-consuming, and impractical. On the other hand, the automatic segmentation approach using computers is a more attractive method because it can be more objective and faster than human segmentation. Therefore, automatic segmentation using computers is the right solution. U-Net is one of the first convolutional networks designed specifically for biomedical image segmentation. This study only performs semantic optic disc segmentation on eye retinal images using U-Net architecture. This network optimization is done by looking for the parameters of the U-Net architecture which include image size, epoch value, learning rate value, and dropout value. The data used consisted of three public retinal eye image datasets, namely the DRIONS-DB, Drishti-GS, and RIM-ONE dataset. The total data distribution was 287 training data, 16 validation data, and 16 test data. The training and data testing process resulted in the highest Intersection over Union (IoU) score of 93.34% and the highest F1-Score of 96.56%. These results were obtained using epochs 100, learning rate 0.0001, dropout 0.3, and image size 256×256.  © 2021 IEEE.","deep learning; glaucoma; optic disc; semantic segmentation; u-net","Convolution; Convolutional neural networks; Deep learning; Eye protection; Learning algorithms; Network architecture; Ophthalmology; Semantics; Automatic segmentations; Deep learning; Glaucoma; Learning rates; NET architecture; Optic cups; Optic disks; Retinal image; Semantic segmentation; U-net; Semantic Segmentation","","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85146199704"
"Shirazi A.Z.; Fornaciari E.; McDonnell M.D.; Yaghoobi M.; Cevallos Y.; Tello-Oquendo L.; Inca D.; Gomez G.A.","Shirazi, Amin Zadeh (55320828900); Fornaciari, Eric (57215673150); McDonnell, Mark D. (7102564709); Yaghoobi, Mahdi (56234245700); Cevallos, Yesenia (57209662798); Tello-Oquendo, Luis (56028218500); Inca, Deysi (57209652996); Gomez, Guillermo A. (7202293576)","55320828900; 57215673150; 7102564709; 56234245700; 57209662798; 56028218500; 57209652996; 7202293576","The application of deep convolutional neural networks to brain cancer images: A survey","10","4","224","1","27","26","10.3390/jpm10040224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096146619&doi=10.3390%2fjpm10040224&partnerID=40&md5=f5b07afb73940044dc85caaf111a4e0b","In recent years, improved deep learning techniques have been applied to biomedical image processing for the classification and segmentation of different tumors based on magnetic resonance imaging (MRI) and histopathological imaging (H&E) clinical information. Deep Convolutional Neural Networks (DCNNs) architectures include tens to hundreds of processing layers that can extract multiple levels of features in image-based data, which would be otherwise very difficult and time-consuming to be recognized and extracted by experts for classification of tumors into different tumor types, as well as segmentation of tumor images. This article summarizes the latest studies of deep learning techniques applied to three different kinds of brain cancer medical images (histology, magnetic resonance, and computed tomography) and highlights current challenges in the field for the broader applicability of DCNN in personalized brain cancer care by focusing on two main applications of DCNNs: classification and segmentation of brain cancer tumors images. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Brain cancer; Classification; Convolutional neural networks; DCNN; Deep learning; Histology; MRI; Segmentation","accuracy; algorithm; artificial neural network; brain cancer; convolutional neural network; deep learning; diagnostic accuracy; histopathology; human; human tissue; image processing; image segmentation; learning algorithm; measurement accuracy; neuroimaging; nuclear magnetic resonance imaging; Review; sensitivity and specificity; support vector machine; total quality management; training; tumor microenvironment","Cancer Council; National Health and Medical Research Council of Australia, (1067405, 1123816); Australian Research Council, ARC, (FT160100366); Neurosurgical Research Foundation, NRF; University of South Australia, UniSA; Cure Brain Cancer Foundation, CBCF","MDPI AG","","2-s2.0-85096146619"
"de Pinho Pinheiro C.A.; Nedjah N.; de Macedo Mourelle L.","de Pinho Pinheiro, Cesar Affonso (57207830460); Nedjah, Nadia (6701673657); de Macedo Mourelle, Luiza (6602182066)","57207830460; 6701673657; 6602182066","Detection and classification of pulmonary nodules using deep learning and swarm intelligence","79","21-22","","15437","15465","28","10.1007/s11042-019-7473-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062995200&doi=10.1007%2fs11042-019-7473-z&partnerID=40&md5=dc2efe422c1efa76ab5db998fd632447","Cancer diagnosis is usually an arduous task in medicine, especially when it comes to pulmonary cancer, which is one of the most deadly and hard to treat types of that disease. Early detecting pulmonary cancerous nodules drastically increases surviving chances but also makes it an even harder problem to solve, as it mostly depends on a visual inspection of tomography scans. In order to help improving cancer detection and surviving rates, engineers and scientists have been developing computer-aided diagnosis systems, similar to the one presented in this paper. These systems are used as second opinions, to help health professionals during the diagnosis of numerous diseases. This work uses computational intelligence techniques to propose a new approach towards solving the problem of detecting pulmonary carcinogenic nodules in computed tomography scans. The applied technology consists of using Deep Learning and Swarm Intelligence to develop different nodule detection and classification models. We exploit seven different swarm intelligence algorithms and convolutional neural networks, prepared for biomedical image segmentation, to find and classify cancerous pulmonary nodules in the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) databases. The aim of this work is to use swarm intelligence to train convolutional neural networks and verify whether this approach brings more efficiency than the classic training algorithms, such as back-propagation and gradient descent methods. As main contribution, this work confirms the superiority of swarm-trained models over the back-propagation-based model for this application, as three out of the seven algorithms are proved to be superior regarding all four performance metrics, which are accuracy, precision, sensitivity, and specificity, as well as training time, where the best swarm-trained model operates 25% faster than the back-propagation model. The performed experiments show that the developed models can achieve up to 93.71% accuracy, 93.53% precision, 92.96% sensitivity, and 98.52% specificity. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Convolutional neural networks; Deep learning; Nodule detection; Swarm intelligence","Backpropagation algorithms; Bioinformatics; Classification (of information); Computer aided diagnosis; Computerized tomography; Convolution; Database systems; Deep learning; Deep neural networks; Diseases; Gradient methods; Image segmentation; Neural networks; Biomedical image segmentation; Computational intelligence techniques; Computed tomography scan; Computer aided diagnosis systems; Convolutional neural network; Gradient Descent method; Nodule detection; Swarm intelligence algorithms; Swarm intelligence","","Springer","","2-s2.0-85062995200"
"Mahanty M.; Bhattacharyya D.; Midhunchakkaravarthy D.","Mahanty, Mohan (57220483702); Bhattacharyya, Debnath (57216142572); Midhunchakkaravarthy, Divya (56380232700)","57220483702; 57216142572; 56380232700","Su-net based colorectal polyp segmentation from colon cancer morphology images","8","4","","649","659","10","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119325222&partnerID=40&md5=43e1216cf0665997590d3c2ab0adec9b","Precise demarcation of glands from clinical histology images are pre-requirement for accurate medical diagnosis. Colorectal polyps that originate and expandsover the rectum or colon membrane are the decisive reason for colorectal Cancer(CRC). The early-stage recognition and of polyps and treatment can decrease the mortality rate. To lower the polyp miss-rate in colonoscopy, a Computer-Aided Medical Diagnosing(CAD) system with high accuracy is needed. In recent times, researchers develop deep learning models for accurate polyp detection from histomorphology images, but accuracy is still the most requisite factor for reliable results. In this paper, we propose to develop and test a Convolutional Neural Network(CNN) based U-shape network (SU-NET) model for semantic segmentation of colorectal polyps from colonoscopy images.SU-NET is an Encoder-Decoder-based architecture, inspired by the popular segmentation architectures SegNet and U-Net for improved colon polyp segmentation. In the proposed model the top most layers transfer the Pooling indices whereas the lower-level layers transfer the feature-maps to incorporate fine multiscale information for better colon polyp contour identification.We evaluated the proposed algorithm in contrast with various prominentdeep learning architectures across multi-modal biomedical image segmentation tasks to segment polyps from the colonoscopy and histopathology images.For evaluating the proposed model, an accredited and publicly available colonoscopy image dataset CVC-ColonDB is employed. The model achieves a recall of 91.3%, F1-Score of 90.81%, F2-Score of 86.39%, Precision of 89.21%, and the Dice similarity coefficient of 0.895 outshines the existing advanced deep learning CNN models. © 2021, Badebio Biotechnololgy Ltd. All rights reserved.","Colonoscopy; Colorectal cancer; Deep convolutional neural network; Medical image analysis; Polyp semantic segmentation; SU-NET","","","Badebio Biotechnololgy Ltd","","2-s2.0-85119325222"
"Hoar D.; Lee P.Q.; Guida A.; Patterson S.; Bowen C.V.; Merrimen J.; Wang C.; Rendon R.; Beyea S.D.; Clarke S.E.","Hoar, David (57247745000); Lee, Peter Q. (57208753589); Guida, Alessandro (57201347780); Patterson, Steven (57543543500); Bowen, Chris V. (7103158567); Merrimen, Jennifer (13610935600); Wang, Cheng (57208751752); Rendon, Ricardo (6602247041); Beyea, Steven D. (7005347832); Clarke, Sharon E. (7402969177)","57247745000; 57208753589; 57201347780; 57543543500; 7103158567; 13610935600; 57208751752; 6602247041; 7005347832; 7402969177","Combined Transfer Learning and Test-Time Augmentation Improves Convolutional Neural Network-Based Semantic Segmentation of Prostate Cancer from Multi-Parametric MR Images","210","","106375","","","","10.1016/j.cmpb.2021.106375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114302101&doi=10.1016%2fj.cmpb.2021.106375&partnerID=40&md5=0181490d89442e17b0ad0bd9e1eddfa8","Purpose: Multiparametric MRI (mp-MRI) is a widely used tool for diagnosing and staging prostate cancer. The purpose of this study was to evaluate whether transfer learning, unsupervised pre-training and test-time augmentation significantly improved the performance of a convolutional neural network (CNN) for pixel-by-pixel prediction of cancer vs. non-cancer using mp-MRI datasets. Methods: 154 subjects undergoing mp-MRI were prospectively recruited, 16 of whom subsequently underwent radical prostatectomy. Logistic regression, random forest and CNN models were trained on mp-MRI data using histopathology as the gold standard. Transfer learning, unsupervised pre-training and test-time augmentation were used to boost CNN performance. Models were evaluated using Dice score and area under the receiver operating curve (AUROC) with leave-one-subject-out cross validation. Permutation feature importance testing was performed to evaluate the relative value of each MR contrast to CNN model performance. Statistical significance (p<0.05) was determined using the paired Wilcoxon signed rank test with Benjamini-Hochberg correction for multiple comparisons. Results: Baseline CNN outperformed logistic regression and random forest models. Transfer learning and unsupervised pre-training did not significantly improve CNN performance over baseline; however, test-time augmentation resulted in significantly higher Dice scores over both baseline CNN and CNN plus either of transfer learning or unsupervised pre-training. The best performing model was CNN with transfer learning and test-time augmentation (Dice score of 0.59 and AUROC of 0.93). The most important contrast was apparent diffusion coefficient (ADC), followed by Ktrans and T2, although each contributed significantly to classifier performance. Conclusions: The addition of transfer learning and test-time augmentation resulted in significant improvement in CNN segmentation performance in a small set of prostate cancer mp-MRI data. Results suggest that these techniques may be more broadly useful for the optimization of deep learning algorithms applied to the problem of semantic segmentation in biomedical image datasets. However, further work is needed to improve the generalizability of the specific model presented herein. © 2021 Elsevier B.V.","Computer aided diagnosis; Convolutional neural network; Machine learning; MRI; Prostate cancer; Segmentation","Humans; Image Processing, Computer-Assisted; Machine Learning; Magnetic Resonance Imaging; Male; Neural Networks, Computer; Prostatic Neoplasms; Semantics; Calcium compounds; Computer aided diagnosis; Computer aided instruction; Convolution; Convolutional neural networks; Decision trees; Deep learning; Diseases; Image enhancement; Image segmentation; Learning algorithms; Medical imaging; Pixels; Regression analysis; Semantics; Surface diffusion; Urology; fleet enema; gadobenate dimeglumine; Computer-aided; Convolutional neural network; Learning time; Machine-learning; Performance; Pre-training; Prostate cancers; Segmentation; Test time; Transfer learning; adult; aged; apparent diffusion coefficient; Article; cancer diagnosis; cancer patient; cancer surgery; classifier; comparative study; computer assisted diagnosis; controlled study; convolutional neural network; data analysis software; diagnostic accuracy; diagnostic test accuracy study; diffusion weighted imaging; dynamic contrast-enhanced magnetic resonance imaging; false positive result; gold standard; histopathology; human; human tissue; image segmentation; leave one out cross validation; logistic regression analysis; machine learning; major clinical study; male; multiparametric magnetic resonance imaging; prospective study; prostate cancer; prostatectomy; random forest; receiver operating characteristic; test time augmentation; transfer of learning; unsupervised machine learning; diagnostic imaging; image processing; machine learning; nuclear magnetic resonance imaging; prostate tumor; semantics; Magnetic resonance imaging","Atlantic Innovation Fund; Google Cloud; Radiology Research Foundation; GE Healthcare","Elsevier Ireland Ltd","34500139","2-s2.0-85114302101"
"Shahraki F.F.; Saadatifard L.; Berisha S.; Lotfollahi M.; Mayerich D.; Prasad S.","Shahraki, Farideh Foroozandeh (57033991400); Saadatifard, Leila (57202704612); Berisha, Sebastian (56642641000); Lotfollahi, Mahsa (57195399716); Mayerich, David (7801383946); Prasad, Saurabh (14018500100)","57033991400; 57202704612; 56642641000; 57195399716; 7801383946; 14018500100","Deep learning for hyperspectral image analysis, part II: Applications to remote sensing and biomedicine","","","","69","115","46","10.1007/978-3-030-38617-7_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085170932&doi=10.1007%2f978-3-030-38617-7_4&partnerID=40&md5=aa38ad3027ef17466d28e97cfee68daf","Deep neural networks are emerging as a popular choice for hyperspectral image analysis—compared with other machine learning approaches, they are more effective for a variety of applications in hyperspectral imaging. Part I (Chap. 3) introduces the fundamentals of deep learning algorithms and techniques deployed with hyperspectral images. In this chapter (Part II), we focus on application-specific nuances and design choices with respect to deploying such networks for robust analysis of hyperspectral images. We provide quantitative and qualitative results with a variety of deep learning architectures, and compare their performance to baseline state-of-the-art methods for both remote sensing and biomedical image analysis tasks. In addition to surveying recent developments in these areas, our goal in these two chapters is to provide guidance on how to utilize such algorithms for multichannel optical imagery. With that goal, we also provide code and example datasets used in this chapter. © 2020, Springer Nature Switzerland AG.","","","","Springer","","2-s2.0-85085170932"
"Liang Q.; Nan Y.; Coppola G.; Zou K.; Sun W.; Zhang D.; Wang Y.; Yu G.","Liang, Qiaokang (35174463400); Nan, Yang (57217028826); Coppola, Gianmarc (36134250400); Zou, Kunglin (58447764100); Sun, Wei (57161531200); Zhang, Dan (58846287300); Wang, Yaonan (55998880600); Yu, Guanzhen (7403528362)","35174463400; 57217028826; 36134250400; 58447764100; 57161531200; 58846287300; 55998880600; 7403528362","Weakly supervised biomedical image segmentation by reiterative learning","23","3","8394987","1205","1214","9","10.1109/JBHI.2018.2850040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049063548&doi=10.1109%2fJBHI.2018.2850040&partnerID=40&md5=5cbed3aeee7beb49a64dd13b416c09bd","Recent advances in deep learning have produced encouraging results for biomedical image segmentation; however, outcomes rely heavily on comprehensive annotation. In this paper, we propose a neural network architecture and a new algorithm, known as overlapped region forecast, for the automatic segmentation of gastric cancer images. To the best of our knowledge, this report for the first time describes that deep learning has been applied to the segmentation of gastric cancer images. Moreover, a reiterative learning framework that achieves superior performance without pretraining or further manual annotation is presented to train a simple network on weakly annotated biomedical images. We customize the loss function to make the model converge faster while avoiding becoming trapped in local minima. Patch boundary errors were eliminated by our overlapped region forecast algorithm. By studying the characteristics of the model trained using two different patch extraction methods, we train iteratively and integrate predictions and weak annotations to improve the quality of the training data. Using these methods, a mean Intersection over Union coefficient of 0.883 and a mean accuracy of 91.09% were achieved on the partially labeled dataset, thereby securing a win in the 2017 China Big Data and Artificial Intelligence Innovation and Entrepreneurship Competition. © 2018 IEEE.","biomedical image segmentation; deep neural networks; gastric histopathology; Reiterative learning","Algorithms; Histological Techniques; Humans; Image Interpretation, Computer-Assisted; Neural Networks, Computer; Stomach Neoplasms; Supervised Machine Learning; Deep learning; Deep neural networks; Diseases; Forecasting; Iterative methods; Large dataset; Network architecture; Neural networks; Automatic segmentations; Biomedical image segmentation; Biomedical images; Forecast algorithm; gastric histopathology; Learning frameworks; Manual annotation; Reiterative learning; accuracy; Article; histopathology; image preprocessing; image processing; image quality; image segmentation; imaging; inflammation; learning; machine learning; mathematical parameters; necrosis; nerve cell network; recall; reiterative learning; stomach cancer; stomach tumor; training; tumor growth; algorithm; computer assisted diagnosis; diagnostic imaging; histology; human; procedures; supervised machine learning; Image segmentation","Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing; National Natural Science Foundation of China, NSFC, (61673163); National Natural Science Foundation of China, NSFC; Hunan Provincial Science and Technology Department, HSTD, (2016JJ3045); Hunan Provincial Science and Technology Department, HSTD; Natural Science Foundation of Hunan Province; Changzhou Key Laboratory of Special Robot and Intelligent Technology, (IRT2018003); Changzhou Key Laboratory of Special Robot and Intelligent Technology","Institute of Electrical and Electronics Engineers Inc.","29994489","2-s2.0-85049063548"
"Dawson M.; Zisserman A.; Nellåker C.","Dawson, Mitchell (57196047258); Zisserman, Andrew (7006619672); Nellåker, Christoffer (57209053608)","57196047258; 7006619672; 57209053608","Mining faces from biomedical literature using deep learning","","","","562","567","5","10.1145/3107411.3107476","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031329267&doi=10.1145%2f3107411.3107476&partnerID=40&md5=edb1812a35b91b0d72dc4654076c7c20","Gaining access to large, labelled sets of relevant images is crucial for the development and testing of biomedical imaging algorithms. Using images found in biomedical research articles would contribute some way towards a solution to this problem. However, this approach critically depends on being able to identify the most relevant images from very large sets of potentially useful figures. In this paper a deep convolutional neural network (CNN) classifier is trained using only synthetic data, to rapidly and accurately label raw images taken from biomedical articles. We apply this method in the context of detecting faces in biomedical images; and show that the classifier is able to retrieve figures containing faces with an average precision of 94.8%, from a dataset of over 31,000 images taken from articles held in the PubMed database. The utility of the classifier is then demonstrated through a case study, by aiding the mining of photographs of patients with rare genetic disorders from targeted articles. This approach is readily adaptable to facilitate the retrieval of other categories of biomedical images.","Biomedical data mining; Computer vision; Convolutional neural network; Deep learning; Image classification; Machine learning","Classification (of information); Computer vision; Convolution; Data mining; Deep learning; Deep neural networks; Image classification; Learning systems; Medical imaging; Neural networks; Biomedical data; Biomedical images; Biomedical imaging; Biomedical literature; Biomedical research; Convolutional neural network; Development and testing; Genetic disorders; Bioinformatics","EPSRC Systems Biology DTC, (EP/G03706X/1); Medical Research Council, MRC, (MR/M014568/1); Engineering and Physical Sciences Research Council, EPSRC, (EP/M013774/1)","Association for Computing Machinery, Inc","","2-s2.0-85031329267"
"Du J.; Fang M.; Yu Y.; Lu G.","Du, Jiao (55416429400); Fang, Meie (56266034300); Yu, Yufeng (57192163579); Lu, Gang (57709221200)","55416429400; 56266034300; 57192163579; 57709221200","An adaptive two-scale biomedical image fusion method with statistical comparisons","196","","105603","","","","10.1016/j.cmpb.2020.105603","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086575506&doi=10.1016%2fj.cmpb.2020.105603&partnerID=40&md5=a989b2bcfe7fb7f9f06f6b3d4dee296d","Two-scale image representation of base and detail in the spatial-domain is a well-known decomposition scheme for its lower computational complexity than that performed in the transform-domain in the field of image fusion. Unfortunately, for a pseudo-colour input image, the base and detail images in the spatial-domain obtained via image decomposition scheme always display in greyscale. In this paper, a two-scale image fusion method with adaptive threshold obtained by Otsu's method is proposed for pseudo-colour image in the colour space domain. For greyscale image, detail and base image are obtained using structural information extracted from the difference image between a global and a local patch size. Consequently, local edge-preserving filter for preserving luminance information and local energy with the discussed window size are adopted to combine base and detail image. Experimental results show that structural and luminance information has been better preserved in terms of subjective and objective evaluations for medical image and protein image fusion. Specially, a two-step non-parametric statistical test (Friedman test and Nemenyi post-hoc test) with p-values is adopted to analysis the statistical significant of the relative difference between the proposed and compared methods in terms of values of objective metrics including 30 co-registered pairs of imaging data. © 2020","Adaptive two-scale representation; Base and detail; Friedman test; Otsu's method; Statistical significant analysis","Algorithms; Color; Luminance; Medical imaging; Decomposition scheme; Edge-preserving filter; Image fusion methods; Image representations; Non-parametric statistical tests; Statistical comparisons; Structural information; Subjective and objective evaluations; Article; blood flow; comparative study; controlled study; convolutional neural network; decomposition; deep learning; Friedman test; human; image analysis; image processing; image quality; luminance; neuroimaging; nuclear magnetic resonance imaging; positron emission tomography; pulse coupled neural network; signal noise ratio; single photon emission computed tomography; statistical analysis; wavelet transform; algorithm; Image fusion","National Natural Science Foundation of China, NSFC, (61772164, 61802148); Natural Science Foundation of Guangdong Province, (2019A1515011266)","Elsevier Ireland Ltd","32570007","2-s2.0-85086575506"
"Hammam A.A.; Elmousalami H.H.; Hassanien A.E.","Hammam, Ahmed A. (57212442079); Elmousalami, Haytham H. (57196150503); Hassanien, Aboul Ella (57192178208)","57212442079; 57196150503; 57192178208","Stacking Deep Learning for Early COVID-19 Vision Diagnosis","78","","","297","307","10","10.1007/978-3-030-55258-9_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105991222&doi=10.1007%2f978-3-030-55258-9_18&partnerID=40&md5=ffadd5964b78e7837d9856add11198a1","early and accurate COVID-19 diagnosis prediction plays a crucial role for helping radiologists and health care workers to take reliable corrective actions for classify patients and detecting the COVID 19 confirmed cases. Prediction and classification accuracy are critical for COVID-19 diagnosis application. Current practices for COVID-19 images classification are mostly built upon convolutional neural network (CNNs) where CNN is a single algorithm. On the other hand, ensemble machine learning models produce higher accuracy than a single machine leaning. Therefore, this study conducts stacking deep learning methodology to produce the highest results of COVID-19 classification. The stacked ensemble deep learning model accuracy has produced 98.6% test accuracy. Accordingly, the stacked ensemble deep learning model produced superior performance than any single model. Accordingly, ensemble machine learning evolves as a future trend due to its high scalability, stability, and prediction accuracy. © 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.","Biomedical image processing; Classification; COVID-19; Deep learning; Ensemble learning; Stacking","Computer aided diagnosis; Convolutional neural networks; Deep learning; Forecasting; Image classification; Learning systems; Classification accuracy; Convolutional neural network; Corrective actions; Current practices; Deep learning; Ensemble learning; Health care workers; Learning models; Prediction accuracy; Stackings; COVID-19","","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85105991222"
"Shen Y.; Ji Z.; Gao M.","Shen, Yan (57204107888); Ji, Zhanghexuan (57212001918); Gao, Mingchen (55424598500)","57204107888; 57212001918; 55424598500","An End-to-End Learnable Flow Regularized Model for Brain Tumor Segmentation","12436 LNCS","","","532","541","9","10.1007/978-3-030-59861-7_54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092733086&doi=10.1007%2f978-3-030-59861-7_54&partnerID=40&md5=1fd84a4d1a8470ff684418218d80cfa8","Many segmentation tasks for biomedical images can be modeled as the minimization of an energy function and solved by a class of max-flow and min-cut optimization algorithms. However, the segmentation accuracy is sensitive to the contrasting of semantic features of different segmenting objects, as the traditional energy function usually uses hand-crafted features in their energy functions. To address these limitations, we propose to incorporate end-to-end trainable neural network features into the energy functions. Our deep neural network features are extracted from the down-sampling and up-sampling layers with skip-connections of a U-net. In the inference stage, the learned features are fed into the energy functions. And the segmentations are solved in a primal-dual form by ADMM solvers. In the training stage, we train our neural networks by optimizing the energy function in the primal form with regularizations on the min-cut and flow-conservation functions, which are derived from the optimal conditions in the dual form. We evaluate our methods, both qualitatively and quantitatively, in a brain tumor segmentation task. As the energy minimization model achieves a balance on sensitivity and smooth boundaries, we would show how our segmentation contours evolve actively through iterations as ensemble references for doctor diagnosis. © 2020, Springer Nature Switzerland AG.","","Bioinformatics; Brain; Computer aided instruction; Deep learning; Deep neural networks; Diagnosis; Image segmentation; Medical imaging; Multilayer neural networks; Semantics; Signal sampling; Tumors; Brain tumor segmentation; Down sampling and up samplings; Energy minimization; Neural network features; Optimal conditions; Optimization algorithms; Segmentation accuracy; Semantic features; Learning systems","National Science Foundation, NSF, (1910492)","Springer Science and Business Media Deutschland GmbH","","2-s2.0-85092733086"
"","","","International Conference on Computers and Information Processing Technologies, ICCIPT 2014","571-572","","","","","","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903445629&partnerID=40&md5=4d99cfb04c5d3dd6e4e752446f64f5d7","The proceedings contain 223 papers. The special focus in this conference is on Computers and Information Processing Technologies. The topics include: A large-scale and flexible BMS design; research on map reduce task dynamic balancing strategy based on file label; researches on data privacy in cloud computing based on game theory; the MPI and OpenMP implementation of parallel algorithm for generating Mandelbrot set; adaptive congestion control via dynamic output feedback; an advanced ECC dynamic password-based remote authentication scheme for cloud computing; an audio hiding algorithm based on spline interpolation and wavelet transform; evaluation method for anti-interference performance of measuring based on entropy loss; RE-based weighted distributed equipment layout; algorithms of mining maximum frequent itemsets based on compression matrix; a secret sharing scheme on access structure; a tag-based signature scheme with shorter signature length; an identity-based conditional proxy re-encryption in cloud computing environments; fine-grained access control with efficient revocation in cloud storage; integrity and fidelity evaluation of digital evidence in live forensics; MANET-based stable clustering algorithm and its performance analysis;; reinforcement learning for cloud computing digital library; research on design and construction method of bent functions; a novelty model for reliability assessment of complex system; a multi-attribute decision-making method based on SPAOWA operator; the forecasting research of Beijing tourism demand based on the BP neural network; setting of academic warning based on multivariate copula functions; the application of iteration learning control in silkworm incubation chamber system; fault diagnoses using inverse fuzzy model; a community detection method based on multi-objective optimization method; a high precision indoor positioning system based on VLC and smart handheld; a hybrid IGA-SA algorithm for optimization problems in fault diagnosis; efficient particle swarm optimization algorithm based on affinity propagation; fault diagnosis of transformer based on RBF neural network; features extraction for Lhasa Tibetan speech recognition; FECG extraction algorithm based on BSS using temporal structure and DWT; fuzzy clustering segmentation algorithm research for biomedical image based on artificial life; hourly solar radiation forecast based on k-NN nonparametric regression model; multi-thread memory particle swarm optimization for dynamic optimization problems; recognizing event in short text based on decision tree; reliability analysis based on Markov process for repairable systems; short-term prediction of ship motion based on EMD-SVM; design of a two-wheel self-balanced vehicle system; moving target detection and tracking control simulation platform; new research for traffic state identification; large naval ship evaluation method attended by multiple experts; fuzzy comprehensive evaluation method of experimental teaching quality based on AHP; the planning system based on the postponement manufacturing theory; Tibetan-Chinese named entity extraction based on comparable corpus; the research on the development of smart library; an Iot-based remote health monitoring and management system; analysis of user influence using user behavior and random walk; tax revenue loss under electronic commerce in China; tax administration problem in the e-business environment; research on the elements of e-government performance evaluation; application of information technology in the county government; a study on simulative system of mobile payment; casting process solutions optimization of LFC forklift box; FEM analysis of sheet incremental forming process; application research of PBL method in PLC control technology; a phase anti-ambiguity method for USBL system; smart community security system based on sensor web; research on static game theory based secure routing algorithm in WSN; human activity recognition using smart-phone sensors; design of circuit for alcohol measurements using three-electrode biosensor; study on passivity-based control of TNPC PV grid-connected inverter; theoretical studies of novel high power millimeter generator based on vacuum electron devices; the study on intelligent insecticidal lamp with LED; the intelligent desk lamp designed for special populations; the design of freeform surface Fresnel lens used for LED uniform illumination; stabilization of a class of chaotic systems via single-state adaptive feedback controller; research on 5V internal power supply circuit of switching power supply; optimization design of photovoltaic system MPPT controller; modeling hydraulic power system with surge tank; dispersion curves and fields for a chiral negative refraction parallel-plate waveguide under PMC boundary; a novel dead-time control method for double end converter; a low standby power consumption control circuit for switching power supply; a flyback 25W switching power supply for electric vehicle; a distributed DC power devise based on DSP; a 3 GHz semi-digital delay locked loop with high resolution; a dual-DSP sonobuoy signal processing system; transmission of image information in the network multimedia teaching; context-assisted fast face detection; the EMD analysis AE signals of rock failure under uniaxial compression; simulation of dynamic light scattering signal based on AR Model; disparity estimation of 3-D mesh for stereo video coding; taxi bidirectional search system based on smart phone; dynamic biomedical image segmentation based on wavelet transform; research on issues of across border area in network games; an RFID-assisted digital souvenir generation system; rock image pore identification based on fuzzy C-means clustering and neural networks; a video characteristics watermarking algorithm based on bees evolutional computation; study of slice cell counting system; upper-body pose recognition using cylinder pattern model; tomato disease image retrieval based on composite features the research of ortho-rectification to QuickBird image with more mountains based on ERDAS10.0; pedestrian detection optimization algorithm based on low-altitude UAV; improved face recognition using 2D-LDA with weighted covariance scatter; challenging the recognition of facial expression via deep learning and applied study of size measurement based on image.","","","","Trans Tech Publications Ltd","","2-s2.0-84903445629"
"Ding J.; Li X.; Gudivada V.N.","Ding, Junhua (7402608357); Li, Xinchuan (36194758400); Gudivada, Venkat N. (6602858683)","7402608357; 36194758400; 6602858683","Augmentation and evaluation of training data for deep learning","2018-January","","","2603","2611","8","10.1109/BigData.2017.8258220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047761559&doi=10.1109%2fBigData.2017.8258220&partnerID=40&md5=a55fd08262459b1a6b2d24cc9bc3a6c2","Deep learning is an important technique for extracting value from big data. However, the effectiveness of deep learning requires large volumes of high quality training data. In many cases, the size of training data is not large enough for effectively training a deep learning classifier. Data augmentation is a widely adopted approach for increasing the amount of training data. But the quality of the augmented data may be questionable. Therefore, a systematic evaluation of training data is critical. Furthermore, if the training data is noisy, it is necessary to separate out the noise data automatically. In this paper, we propose a deep learning classifier for automatically separating good training data from noisy data. To effectively train the deep learning classifier, the original training data need to be transformed to suit the input format of the classifier. Moreover, we investigate different data augmentation approaches to generate sufficient volume of training data from limited size original training data. We evaluated the quality of the training data through cross validation of the classification accuracy with different classification algorithms. We also check the pattern of each data item and compare the distributions of datasets. We demonstrate the effectiveness of the proposed approach through an experimental investigation of automated classification of massive biomedical images. Our approach is generic and is easily adaptable to other big data domains. © 2017 IEEE.","big data; convolutional neural network; deep learning; diffraction image; machine learning; neural network; support vector machine","Big data; Clustering algorithms; Deep learning; Deep neural networks; Learning systems; Neural networks; Quality control; Support vector machines; Automated classification; Classification accuracy; Classification algorithm; Convolutional neural network; Diffraction images; Experimental investigations; Learning classifiers; Systematic evaluation; Classification (of information)","National Science Foundation, NSF, (1730568); East Carolina University, ECU","Institute of Electrical and Electronics Engineers Inc.","","2-s2.0-85047761559"
"Kandaswamy C.; Silva L.M.; Alexandre L.A.; Santos J.M.","Kandaswamy, Chetak (56038853000); Silva, Luís M (57210568776); Alexandre, Luís A (8847713100); Santos, Jorge M (7402389359)","56038853000; 57210568776; 8847713100; 7402389359","Deep transfer learning ensemble for classification","9094","","","335","348","13","10.1007/978-3-319-19258-1_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937439174&doi=10.1007%2f978-3-319-19258-1_29&partnerID=40&md5=3d3beada33ef02236f0429504be93c4f","Transfer learning algorithms typically assume that the training data and the test data come from different distribution. It is better at adapting to learn new tasks and concepts more quickly and accurately by exploiting previously gained knowledge. Deep Transfer Learning (DTL) emerged as a new paradigm in transfer learning in which a deep model offer greater flexibility in extracting high-level features. DTL offers selective layer based transference, and it is problem specific. In this paper, we propose the Ensemble of Deep Transfer Learning (EDTL) methodology to reduce the impact of selective layer based transference and provide optimized framework to work for three major transfer learning cases. Empirical results on character, object and biomedical image recognition tasks achieves that the proposed method indicate statistically significant classification accuracy over the other established transfer learning method. © Springer International Publishing Switzerland 2015.","Deep learning; Ensemble; Transfer learning","Algorithms; Artificial intelligence; Image recognition; Neural networks; Classification accuracy; Deep learning; Different distributions; Ensemble; High-level features; Selective layers; Transfer learning; Transfer learning methods; Learning algorithms","","Springer Verlag","","2-s2.0-84937439174"
"Pang S.; Orgun M.A.; Du A.; Yu Z.","Pang, Shuchao (55639762100); Orgun, Mehmet A. (6603681610); Du, Anan (56167972000); Yu, Zhezhou (8938987700)","55639762100; 6603681610; 56167972000; 8938987700","Leveraging deep preference learning for indexing and retrieval of biomedical images","","","8008308","126","129","3","10.1109/NER.2017.8008308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028599309&doi=10.1109%2fNER.2017.8008308&partnerID=40&md5=e6b7c31eed1e4172f3af6ab7a0d4ea44","This paper presents an original framework based on deep learning and preference learning to retrieve and characterize biomedical images for assisting physicians in diagnosing complex diseases with potentially only small differences between them. In particular, we use deep learning to extract the high-level and compact features for biomedical images. In contrast to the traditional biomedical algorithms or general image retrieval systems that only consider the use of pixel and/or hand-crafted features to represent images, we utilize deep neural networks for feature discovery of biomedical images. Moreover, in order to be able to index the similarly referenced images, we introduce preference learning in a novel way to learn what kinds of images we need so that we can obtain the similarity ranking list of biomedical images. We evaluate the performance of our system in detailed experiments over the well-known available OASIS-MRI database for whole brain neuroimaging as a benchmark and compare it with those of the traditional biomedical and general image retrieval approaches. Our proposed system exhibits an outstanding retrieval ability and efficiency for biomedical image applications. © 2017 IEEE.","","Benchmarking; Bioinformatics; Deep learning; Deep neural networks; Diagnosis; Image retrieval; Magnetic resonance imaging; Neuroimaging; Bio-medical algorithms; Biomedical images; Compact Features; Feature discovery; Image retrieval systems; Indexing and retrieval; Preference learning; Similarity rankings; Search engines","Science and Technology Development Plan of Jilin Province, (20150204007GX); Specialized Research Fund for the Doctoral Program of Higher Education of China, SRFDP, (20120061110045)","IEEE Computer Society","","2-s2.0-85028599309"
"Albarqouni S.; Baur C.; Achilles F.; Belagiannis V.; Demirci S.; Navab N.","Albarqouni, Shadi (55129204800); Baur, Christoph (56982679100); Achilles, Felix (57118240900); Belagiannis, Vasileios (35483155200); Demirci, Stefanie (57213376774); Navab, Nassir (7003458998)","55129204800; 56982679100; 57118240900; 35483155200; 57213376774; 7003458998","AggNet: Deep Learning From Crowds for Mitosis Detection in Breast Cancer Histology Images","35","5","7405343","1313","1321","8","10.1109/TMI.2016.2528120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969939903&doi=10.1109%2fTMI.2016.2528120&partnerID=40&md5=ff385d9219cfc107aeb2fa15261a230e","The lack of publicly available ground-truth data has been identified as the major challenge for transferring recent developments in deep learning to the biomedical imaging domain. Though crowdsourcing has enabled annotation of large scale databases for real world images, its application for biomedical purposes requires a deeper understanding and hence, more precise definition of the actual annotation task. The fact that expert tasks are being outsourced to non-expert users may lead to noisy annotations introducing disagreement between users. Despite being a valuable resource for learning annotation models from crowdsourcing, conventional machine-learning methods may have difficulties dealing with noisy annotations during training. In this manuscript, we present a new concept for learning from crowds that handle data aggregation directly as part of the learning process of the convolutional neural network (CNN) via additional crowdsourcing layer (AggNet). Besides, we present an experimental study on learning from crowds designed to answer the following questions. 1) Can deep CNN be trained with data collected from crowdsourcing? 2) How to adapt the CNN to train on multiple types of annotation datasets (ground truth and crowd-based)? 3) How does the choice of annotation and aggregation affect the accuracy? Our experimental setup involved Annot8, a self-implemented web-platform based on Crowdflower API realizing image annotation tasks for a publicly available biomedical image database. Our results give valuable insights into the functionality of deep CNN learning from crowd annotations and prove the necessity of data aggregation integration. © 2016 IEEE.","Aggregation; crowdsourcing; deep learning; gamification; online learning","Breast Neoplasms; Crowdsourcing; Female; Histocytochemistry; Humans; Image Interpretation, Computer-Assisted; Internet; Machine Learning; Mitosis; Neural Networks (Computer); Video Games; Agglomeration; Artificial intelligence; Crowdsourcing; Image retrieval; Learning systems; Neural networks; Biomedical image database; Conventional machines; Convolutional neural network; Deep learning; Gamification; Large-scale database; Online learning; Precise definition; algorithm; Article; breast biopsy; breast cancer; cancer diagnosis; clinical article; convolutional neural network; crowdsourcing; data base; experimental study; histopathology; human; human tissue; machine learning; mitosis; artificial neural network; breast tumor; computer assisted diagnosis; crowdsourcing; cytochemistry; diagnostic imaging; female; Internet; machine learning; physiology; procedures; video game; Medical imaging","","Institute of Electrical and Electronics Engineers Inc.","26891484","2-s2.0-84969939903"
"Lee C.S.; Tyring A.J.; Deruyter N.P.; Wu Y.; Rokem A.; Lee A.Y.","Lee, Cecilia S. (56472056400); Tyring, Ariel J. (56221971100); Deruyter, Nicolaas P. (57193351908); Wu, Yue (57194851622); Rokem, Ariel (6507945628); Lee, Aaron Y. (26635526200)","56472056400; 56221971100; 57193351908; 57194851622; 6507945628; 26635526200","Deep-learning based, automated segmentation of macular edema in optical coherence tomography","8","7","295030","3440","3448","8","10.1364/BOE.8.003440","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023600747&doi=10.1364%2fBOE.8.003440&partnerID=40&md5=23e1aa7909ff747ee8d7b8a90f60665b","Evaluation of clinical images is essential for diagnosis in many specialties. Therefore the development of computer vision algorithms to help analyze biomedical images will be important. In ophthalmology, optical coherence tomography (OCT) is critical for managing retinal conditions. We developed a convolutional neural network (CNN) that detects intraretinal fluid (IRF) on OCT in a manner indistinguishable from clinicians. Using 1,289 OCT images, the CNN segmented images with a 0.911 cross-validated Dice coefficient, compared with segmentations by experts. Additionally, the agreement between experts and between experts and CNN were similar. Our results reveal that CNN can be trained to perform automated segmentations of clinically relevant image features. © 2017 Optical Society of America.","","Bioinformatics; Deep learning; Image segmentation; Neural networks; Ophthalmology; Tomography; Automated segmentation; Biomedical images; Clinical images; Computer vision algorithms; Convolutional neural network; Dice coefficient; Intra-retinal fluids; Segmented images; Article; artificial neural network; correlation coefficient; human; image analysis; image segmentation; learning algorithm; macular edema; optical coherence tomography; retina detachment; training; validation process; Optical tomography","National Eye Institute, NEI, (K23EY02492); Alfred P. Sloan Foundation; Gordon and Betty Moore Foundation, GBMF; Research to Prevent Blindness, RPB; Nvidia","OSA - The Optical Society","","2-s2.0-85023600747"
"Pang S.; Yu Z.; Orgun M.A.","Pang, Shuchao (55639762100); Yu, Zhezhou (8938987700); Orgun, Mehmet A. (6603681610)","55639762100; 8938987700; 6603681610","A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images","140","","","283","293","10","10.1016/j.cmpb.2016.12.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011883667&doi=10.1016%2fj.cmpb.2016.12.019&partnerID=40&md5=3461c46640f53b42561a301ee3e549bd","Background and objectives Highly accurate classification of biomedical images is an essential task in the clinical diagnosis of numerous medical diseases identified from those images. Traditional image classification methods combined with hand-crafted image feature descriptors and various classifiers are not able to effectively improve the accuracy rate and meet the high requirements of classification of biomedical images. The same also holds true for artificial neural network models directly trained with limited biomedical images used as training data or directly used as a black box to extract the deep features based on another distant dataset. In this study, we propose a highly reliable and accurate end-to-end classifier for all kinds of biomedical images via deep learning and transfer learning. Methods We first apply domain transferred deep convolutional neural network for building a deep model; and then develop an overall deep learning architecture based on the raw pixels of original biomedical images using supervised training. In our model, we do not need the manual design of the feature space, seek an effective feature vector classifier or segment specific detection object and image patches, which are the main technological difficulties in the adoption of traditional image classification methods. Moreover, we do not need to be concerned with whether there are large training sets of annotated biomedical images, affordable parallel computing resources featuring GPUs or long times to wait for training a perfect deep model, which are the main problems to train deep neural networks for biomedical image classification as observed in recent works. Results With the utilization of a simple data augmentation method and fast convergence speed, our algorithm can achieve the best accuracy rate and outstanding classification ability for biomedical images. We have evaluated our classifier on several well-known public biomedical datasets and compared it with several state-of-the-art approaches. Conclusions We propose a robust automated end-to-end classifier for biomedical images based on a domain transferred deep convolutional neural network model that shows a highly reliable and accurate performance which has been confirmed on several public biomedical image datasets. © 2017 Elsevier Ireland Ltd","Biomedical image classification; Convolutional neural network; Data augmentation; Deep learning; Transfer learning","Diagnostic Imaging; Machine Learning; Models, Theoretical; Neural Networks (Computer); Bioinformatics; Computer aided diagnosis; Convolution; Data mining; Deep learning; Deep neural networks; Diagnosis; Image classification; Image segmentation; Medical imaging; Neural networks; Program processors; Vector spaces; Artificial neural network models; Classification ability; Classification methods; Convolutional neural network; Data augmentation; Fast convergence speed; State-of-the-art approach; Transfer learning; Article; artificial neural network; automation; back propagation; biomedicine; classification algorithm; classifier; controlled study; convolutional neural network; deep learning; diagnostic imaging; high resolution computer tomography; histogram; human; image analysis; image processing; machine learning; medical technology; support vector machine; training; transfer learning; velocity; machine learning; theoretical model; Classification (of information)","","Elsevier Ireland Ltd","28254085","2-s2.0-85011883667"
